Soft limit: 1024
Hard limit: 1048576
Soft limit: 20000
Hard limit: 1048576
Rlow=78000.000000
Rhigh=202000.000000
Horizontal partitions = [13, 4, 3]
Vertical partitions = [4, 3, 1]
Created folder: separated_csvs_4_30_25
Folder already exists: pwl_files
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 0 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 0 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 0 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35734, 0.14722, 0.29456, 0.29897, 0.11406, 0.089126, 0.036775, 0.75706, 0.43884, 0.30931]
Predicted label: 7
Correct prediction
Energy consumption = 193.803936 pJ
sum error= 0
Actual label: 2
Output voltages: [0.39548, 0.31923, 0.6387, 0.42401, 0.12288, 0.040096, 0.36269, 0.15068, 0.35306, 0.1549]
Predicted label: 2
Correct prediction
Energy consumption = 192.330818 pJ
sum error= 0
Actual label: 1
Output voltages: [0.16563, 0.76495, 0.15469, 0.18339, 0.29643, 0.18761, 0.47134, 0.1426, 0.27183, 0.23052]
Predicted label: 1
Correct prediction
Energy consumption = 204.056966 pJ
sum error= 0
Actual label: 0
Output voltages: [0.73814, 0.21767, 0.23272, 0.17016, 0.20422, 0.18094, 0.42256, 0.24641, 0.26056, 0.26806]
Predicted label: 0
Correct prediction
Energy consumption = 195.748890 pJ
sum error= 0
Actual label: 4
Output voltages: [0.19246, 0.14407, 0.31339, 0.17719, 0.74351, 0.061513, 0.27771, 0.25279, 0.20559, 0.34571]
Predicted label: 4
Correct prediction
Energy consumption = 197.996171 pJ
sum error= 0
Actual label: 1
Output voltages: [0.19961, 0.75587, 0.18142, 0.21901, 0.33401, 0.11421, 0.4062, 0.12252, 0.31843, 0.24481]
Predicted label: 1
Correct prediction
Energy consumption = 206.776070 pJ
sum error= 0
Actual label: 4
Output voltages: [0.078368, 0.22488, 0.24278, 0.062553, 0.61566, 0.17805, 0.21042, 0.12495, 0.45315, 0.30495]
Predicted label: 4
Correct prediction
Energy consumption = 193.147380 pJ
sum error= 0
Actual label: 9
Output voltages: [0.35356, 0.13597, 0.37932, 0.24515, 0.3596, 0.092375, 0.14997, 0.16822, 0.30828, 0.7174]
Predicted label: 9
Correct prediction
Energy consumption = 204.790636 pJ
sum error= 0
Actual label: 5
Output voltages: [0.27339, 0.047738, 0.11418, 0.21525, 0.32176, 0.60834, 0.49721, 0.081452, 0.48085, 0.24699]
Predicted label: 5
Correct prediction
Energy consumption = 198.248030 pJ
sum error= 0
Actual label: 9
Output voltages: [0.4074, 0.10411, 0.20652, 0.19453, 0.31827, 0.17919, 0.08158, 0.21968, 0.45339, 0.64128]
Predicted label: 9
Correct prediction
Energy consumption = 180.928089 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 1 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 1 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 1 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73575, 0.24254, 0.30086, 0.14233, 0.1561, 0.18798, 0.42436, 0.16441, 0.26264, 0.3116]
Predicted label: 0
Correct prediction
Energy consumption = 199.888706 pJ
sum error= 0
Actual label: 6
Output voltages: [0.35191, 0.23431, 0.2781, 0.08465, 0.34652, 0.32662, 0.74312, 0.078247, 0.36585, 0.18035]
Predicted label: 6
Correct prediction
Energy consumption = 186.645255 pJ
sum error= 0
Actual label: 9
Output voltages: [0.29351, 0.14329, 0.20106, 0.26983, 0.33959, 0.12275, 0.11869, 0.23034, 0.37507, 0.6698]
Predicted label: 9
Correct prediction
Energy consumption = 194.707612 pJ
sum error= 0
Actual label: 0
Output voltages: [0.71237, 0.23303, 0.17876, 0.1862, 0.15997, 0.25797, 0.45676, 0.14107, 0.34922, 0.22234]
Predicted label: 0
Correct prediction
Energy consumption = 196.888157 pJ
sum error= 0
Actual label: 1
Output voltages: [0.24974, 0.76865, 0.29638, 0.26991, 0.17634, 0.064023, 0.35861, 0.093551, 0.30272, 0.22568]
Predicted label: 1
Correct prediction
Energy consumption = 209.763923 pJ
sum error= 0
Actual label: 5
Output voltages: [0.29459, 0.056766, 0.15852, 0.36377, 0.12667, 0.72209, 0.26482, 0.27776, 0.51339, 0.16358]
Predicted label: 5
Correct prediction
Energy consumption = 193.527585 pJ
sum error= 0
Actual label: 9
Output voltages: [0.37795, 0.10025, 0.22264, 0.22121, 0.34695, 0.16712, 0.18755, 0.26929, 0.35225, 0.64208]
Predicted label: 9
Correct prediction
Energy consumption = 196.392967 pJ
sum error= 0
Actual label: 7
Output voltages: [0.4004, 0.15276, 0.25906, 0.37842, 0.093905, 0.13583, 0.046282, 0.75538, 0.3554, 0.33911]
Predicted label: 7
Correct prediction
Energy consumption = 191.051914 pJ
sum error= 0
Actual label: 3
Output voltages: [0.19762, 0.17896, 0.44248, 0.56771, 0.10846, 0.10169, 0.28188, 0.20373, 0.50124, 0.19888]
Predicted label: 3
Correct prediction
Energy consumption = 197.897098 pJ
sum error= 0
Actual label: 4
Output voltages: [0.22191, 0.1638, 0.33631, 0.15779, 0.75865, 0.060942, 0.26493, 0.31904, 0.1996, 0.27555]
Predicted label: 4
Correct prediction
Energy consumption = 195.309556 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 2 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 2 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 2 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.38504, 0.13788, 0.20377, 0.26491, 0.35635, 0.092103, 0.057465, 0.19378, 0.34927, 0.65292]
Predicted label: 9
Correct prediction
Energy consumption = 198.851438 pJ
sum error= 0
Actual label: 6
Output voltages: [0.35645, 0.17378, 0.2493, 0.15351, 0.30159, 0.46811, 0.72143, 0.073314, 0.40213, 0.15022]
Predicted label: 6
Correct prediction
Energy consumption = 189.183390 pJ
sum error= 0
Actual label: 6
Output voltages: [0.40338, 0.25749, 0.19539, 0.16868, 0.36835, 0.3721, 0.70988, 0.076772, 0.32774, 0.30533]
Predicted label: 6
Correct prediction
Energy consumption = 192.460822 pJ
sum error= 0
Actual label: 5
Output voltages: [0.28871, 0.04337, 0.075061, 0.33706, 0.26821, 0.71158, 0.42674, 0.10983, 0.45378, 0.20481]
Predicted label: 5
Correct prediction
Energy consumption = 184.667135 pJ
sum error= 0
Actual label: 4
Output voltages: [0.19538, 0.1474, 0.35941, 0.18205, 0.75564, 0.056501, 0.28695, 0.35168, 0.15319, 0.33063]
Predicted label: 4
Correct prediction
Energy consumption = 196.492910 pJ
sum error= 0
Actual label: 0
Output voltages: [0.69999, 0.24639, 0.27153, 0.13407, 0.16539, 0.095604, 0.42998, 0.21457, 0.34707, 0.28706]
Predicted label: 0
Correct prediction
Energy consumption = 190.821517 pJ
sum error= 0
Actual label: 7
Output voltages: [0.39055, 0.27126, 0.20262, 0.36721, 0.15344, 0.16932, 0.048144, 0.75462, 0.18085, 0.37047]
Predicted label: 7
Correct prediction
Energy consumption = 191.928618 pJ
sum error= 0
Actual label: 4
Output voltages: [0.1399, 0.14928, 0.33829, 0.17603, 0.75634, 0.075431, 0.26478, 0.25559, 0.19124, 0.28977]
Predicted label: 4
Correct prediction
Energy consumption = 192.052985 pJ
sum error= 0
Actual label: 0
Output voltages: [0.71991, 0.21568, 0.35987, 0.29106, 0.14567, 0.10054, 0.34389, 0.19399, 0.33568, 0.2684]
Predicted label: 0
Correct prediction
Energy consumption = 203.494147 pJ
sum error= 0
Actual label: 1
Output voltages: [0.25473, 0.75695, 0.19769, 0.36651, 0.19357, 0.14797, 0.31286, 0.090258, 0.32077, 0.29074]
Predicted label: 1
Correct prediction
Energy consumption = 213.170109 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 3 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 3 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 3 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29364, 0.17373, 0.25036, 0.76075, 0.21738, 0.21513, 0.1393, 0.27764, 0.39624, 0.28116]
Predicted label: 3
Correct prediction
Energy consumption = 187.095319 pJ
sum error= 0
Actual label: 1
Output voltages: [0.18362, 0.75014, 0.19057, 0.30265, 0.27806, 0.092814, 0.22217, 0.13447, 0.21725, 0.3535]
Predicted label: 1
Correct prediction
Energy consumption = 213.845636 pJ
sum error= 0
Actual label: 3
Output voltages: [0.30854, 0.18912, 0.33801, 0.75719, 0.21707, 0.14535, 0.1919, 0.23851, 0.41439, 0.19207]
Predicted label: 3
Correct prediction
Energy consumption = 190.277658 pJ
sum error= 0
Actual label: 4
Output voltages: [0.37856, 0.22777, 0.38291, 0.053628, 0.62413, 0.14777, 0.51985, 0.18581, 0.21052, 0.069057]
Predicted label: 4
Correct prediction
Energy consumption = 198.312528 pJ
sum error= 0
Actual label: 7
Output voltages: [0.30062, 0.24239, 0.45381, 0.26519, 0.12236, 0.052476, 0.045827, 0.73913, 0.36458, 0.34762]
Predicted label: 7
Correct prediction
Energy consumption = 195.381120 pJ
sum error= 0
Actual label: 2
Output voltages: [0.2763, 0.25715, 0.74173, 0.31109, 0.13993, 0.042479, 0.24707, 0.22174, 0.41836, 0.15765]
Predicted label: 2
Correct prediction
Energy consumption = 182.028360 pJ
sum error= 0
Actual label: 7
Output voltages: [0.24698, 0.22604, 0.44997, 0.2931, 0.07462, 0.038148, 0.090231, 0.73552, 0.37282, 0.25063]
Predicted label: 7
Correct prediction
Energy consumption = 189.580296 pJ
sum error= 0
Actual label: 1
Output voltages: [0.22103, 0.75957, 0.27789, 0.30171, 0.21975, 0.10098, 0.28655, 0.14049, 0.29529, 0.27423]
Predicted label: 1
Correct prediction
Energy consumption = 212.173546 pJ
sum error= 0
Actual label: 2
Output voltages: [0.3793, 0.30929, 0.64734, 0.37423, 0.076107, 0.047273, 0.31246, 0.24086, 0.40387, 0.15932]
Predicted label: 2
Correct prediction
Energy consumption = 197.225928 pJ
sum error= 0
Actual label: 1
Output voltages: [0.18226, 0.76408, 0.1157, 0.34392, 0.15573, 0.15152, 0.39738, 0.099979, 0.37148, 0.20462]
Predicted label: 1
Correct prediction
Energy consumption = 205.796835 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 4 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 4 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 4 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.28013, 0.76838, 0.24043, 0.26848, 0.21716, 0.07874, 0.3095, 0.20388, 0.29111, 0.29201]
Predicted label: 1
Correct prediction
Energy consumption = 214.871833 pJ
sum error= 0
Actual label: 7
Output voltages: [0.28336, 0.35136, 0.43009, 0.28738, 0.16295, 0.026831, 0.049538, 0.70418, 0.24513, 0.29433]
Predicted label: 7
Correct prediction
Energy consumption = 194.906090 pJ
sum error= 0
Actual label: 4
Output voltages: [0.15611, 0.18717, 0.26764, 0.15323, 0.74176, 0.074642, 0.23049, 0.26195, 0.23202, 0.33199]
Predicted label: 4
Correct prediction
Energy consumption = 202.064100 pJ
sum error= 0
Actual label: 2
Output voltages: [0.21014, 0.31883, 0.63785, 0.30131, 0.38393, 0.050186, 0.29012, 0.29616, 0.2799, 0.1162]
Predicted label: 2
Correct prediction
Energy consumption = 189.089298 pJ
sum error= 0
Actual label: 3
Output voltages: [0.26714, 0.28598, 0.26145, 0.74986, 0.29221, 0.19047, 0.19004, 0.27084, 0.31197, 0.21201]
Predicted label: 3
Correct prediction
Energy consumption = 202.045345 pJ
sum error= 0
Actual label: 5
Output voltages: [0.31666, 0.055251, 0.10277, 0.38421, 0.12208, 0.70084, 0.27932, 0.18676, 0.53829, 0.23421]
Predicted label: 5
Correct prediction
Energy consumption = 193.937485 pJ
sum error= 0
Actual label: 1
Output voltages: [0.16839, 0.70031, 0.23256, 0.38792, 0.26417, 0.12562, 0.15993, 0.26097, 0.34754, 0.27854]
Predicted label: 1
Correct prediction
Energy consumption = 208.607851 pJ
sum error= 0
Actual label: 2
Output voltages: [0.3972, 0.30511, 0.75737, 0.26067, 0.22287, 0.034183, 0.30567, 0.32858, 0.33666, 0.25055]
Predicted label: 2
Correct prediction
Energy consumption = 183.685004 pJ
sum error= 0
Actual label: 4
Output voltages: [0.14158, 0.19887, 0.25135, 0.078492, 0.71022, 0.19239, 0.32372, 0.22853, 0.36927, 0.27111]
Predicted label: 4
Correct prediction
Energy consumption = 199.468659 pJ
sum error= 0
Actual label: 4
Output voltages: [0.18758, 0.10801, 0.296, 0.12868, 0.7644, 0.15654, 0.31222, 0.25479, 0.23506, 0.26835]
Predicted label: 4
Correct prediction
Energy consumption = 185.636586 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 5 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 5 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 5 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.34316, 0.18484, 0.23966, 0.1295, 0.31867, 0.34209, 0.72928, 0.10998, 0.45285, 0.097034]
Predicted label: 6
Correct prediction
Energy consumption = 191.025809 pJ
sum error= 0
Actual label: 3
Output voltages: [0.37815, 0.1369, 0.28831, 0.73317, 0.16553, 0.22811, 0.15896, 0.21937, 0.53571, 0.21693]
Predicted label: 3
Correct prediction
Energy consumption = 190.914765 pJ
sum error= 0
Actual label: 5
Output voltages: [0.23694, 0.048071, 0.067172, 0.34956, 0.30555, 0.73204, 0.39615, 0.13539, 0.50289, 0.21193]
Predicted label: 5
Correct prediction
Energy consumption = 179.338626 pJ
sum error= 0
Actual label: 5
Output voltages: [0.3166, 0.047967, 0.11019, 0.33778, 0.1677, 0.7221, 0.29092, 0.26403, 0.508, 0.20157]
Predicted label: 5
Correct prediction
Energy consumption = 179.988729 pJ
sum error= 0
Actual label: 6
Output voltages: [0.29357, 0.28809, 0.32472, 0.061839, 0.3153, 0.31408, 0.74876, 0.059337, 0.33927, 0.1737]
Predicted label: 6
Correct prediction
Energy consumption = 185.273245 pJ
sum error= 0
Actual label: 0
Output voltages: [0.6836, 0.25584, 0.253, 0.19077, 0.19085, 0.12917, 0.43046, 0.1828, 0.38925, 0.25699]
Predicted label: 0
Correct prediction
Energy consumption = 202.104713 pJ
sum error= 0
Actual label: 4
Output voltages: [0.14124, 0.14097, 0.33833, 0.12048, 0.75898, 0.07873, 0.2928, 0.29838, 0.22585, 0.26417]
Predicted label: 4
Correct prediction
Energy consumption = 190.455421 pJ
sum error= 0
Actual label: 1
Output voltages: [0.20749, 0.76023, 0.22958, 0.26163, 0.30344, 0.057476, 0.33736, 0.13409, 0.31525, 0.24459]
Predicted label: 1
Correct prediction
Energy consumption = 204.411344 pJ
sum error= 0
Actual label: 9
Output voltages: [0.35798, 0.084467, 0.21766, 0.24104, 0.3187, 0.20967, 0.10143, 0.29118, 0.35961, 0.68017]
Predicted label: 9
Correct prediction
Energy consumption = 191.583309 pJ
sum error= 0
Actual label: 5
Output voltages: [0.31778, 0.060169, 0.044318, 0.36666, 0.31339, 0.72091, 0.28351, 0.15977, 0.40561, 0.25329]
Predicted label: 5
Correct prediction
Energy consumption = 191.975991 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 6 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 6 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 6 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.36939, 0.22123, 0.070469, 0.44151, 0.068127, 0.18024, 0.039327, 0.68115, 0.32245, 0.42119]
Predicted label: 7
Correct prediction
Energy consumption = 204.481812 pJ
sum error= 0
Actual label: 8
Output voltages: [0.25246, 0.11299, 0.44881, 0.28083, 0.1418, 0.15896, 0.21592, 0.1325, 0.73451, 0.25255]
Predicted label: 8
Correct prediction
Energy consumption = 182.968339 pJ
sum error= 0
Actual label: 9
Output voltages: [0.28128, 0.1282, 0.16076, 0.25243, 0.25434, 0.41986, 0.20318, 0.21287, 0.37623, 0.60669]
Predicted label: 9
Correct prediction
Energy consumption = 199.849206 pJ
sum error= 0
Actual label: 3
Output voltages: [0.32415, 0.13161, 0.40335, 0.69858, 0.11125, 0.17331, 0.06043, 0.22132, 0.53312, 0.27558]
Predicted label: 3
Correct prediction
Energy consumption = 189.973616 pJ
sum error= 0
Actual label: 7
Output voltages: [0.2226, 0.12449, 0.35047, 0.46237, 0.16135, 0.079811, 0.042442, 0.67405, 0.47759, 0.28994]
Predicted label: 7
Correct prediction
Energy consumption = 180.553060 pJ
sum error= 0
Actual label: 4
Output voltages: [0.19592, 0.2499, 0.20078, 0.32551, 0.66302, 0.086742, 0.18121, 0.15207, 0.25518, 0.38526]
Predicted label: 4
Correct prediction
Energy consumption = 208.672173 pJ
sum error= 0
Actual label: 6
Output voltages: [0.49125, 0.33313, 0.32735, 0.18171, 0.15058, 0.13758, 0.65651, 0.068027, 0.38081, 0.27788]
Predicted label: 6
Correct prediction
Energy consumption = 204.031402 pJ
sum error= 0
Actual label: 4
Output voltages: [0.14302, 0.15882, 0.31928, 0.12308, 0.75928, 0.10799, 0.32345, 0.22942, 0.19615, 0.30035]
Predicted label: 4
Correct prediction
Energy consumption = 194.443917 pJ
sum error= 0
Actual label: 3
Output voltages: [0.26344, 0.13438, 0.31331, 0.73575, 0.1733, 0.15627, 0.10293, 0.23182, 0.46041, 0.32136]
Predicted label: 3
Correct prediction
Energy consumption = 188.633875 pJ
sum error= 0
Actual label: 0
Output voltages: [0.70083, 0.20112, 0.29784, 0.19068, 0.071819, 0.18905, 0.43407, 0.14488, 0.27749, 0.31235]
Predicted label: 0
Correct prediction
Energy consumption = 185.384595 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 7 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 7 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 7 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.39948, 0.14037, 0.27424, 0.35155, 0.091249, 0.095839, 0.044448, 0.73538, 0.44631, 0.35509]
Predicted label: 7
Correct prediction
Energy consumption = 197.898554 pJ
sum error= 0
Actual label: 0
Output voltages: [0.74288, 0.23225, 0.26216, 0.14837, 0.16214, 0.19191, 0.41808, 0.1657, 0.27894, 0.26419]
Predicted label: 0
Correct prediction
Energy consumption = 188.610606 pJ
sum error= 0
Actual label: 2
Output voltages: [0.48253, 0.20354, 0.70944, 0.34211, 0.11984, 0.036653, 0.25833, 0.29435, 0.35118, 0.1723]
Predicted label: 2
Correct prediction
Energy consumption = 183.662772 pJ
sum error= 0
Actual label: 9
Output voltages: [0.32522, 0.14368, 0.2634, 0.18186, 0.30517, 0.075702, 0.064247, 0.20106, 0.48922, 0.58886]
Predicted label: 9
Correct prediction
Energy consumption = 192.216679 pJ
sum error= 0
Actual label: 1
Output voltages: [0.25129, 0.7648, 0.20678, 0.33357, 0.25608, 0.082184, 0.36164, 0.12637, 0.27515, 0.28351]
Predicted label: 1
Correct prediction
Energy consumption = 211.263866 pJ
sum error= 0
Actual label: 7
Output voltages: [0.24729, 0.15216, 0.36126, 0.3732, 0.26023, 0.045147, 0.041654, 0.66546, 0.35547, 0.3452]
Predicted label: 7
Correct prediction
Energy consumption = 188.714060 pJ
sum error= 0
Actual label: 3
Output voltages: [0.30787, 0.20509, 0.30403, 0.7627, 0.2032, 0.21153, 0.17008, 0.17357, 0.41947, 0.24372]
Predicted label: 3
Correct prediction
Energy consumption = 182.016942 pJ
sum error= 0
Actual label: 2
Output voltages: [0.38984, 0.35724, 0.74301, 0.3181, 0.10054, 0.032967, 0.21743, 0.32908, 0.32646, 0.27501]
Predicted label: 2
Correct prediction
Energy consumption = 178.761328 pJ
sum error= 0
Actual label: 9
Output voltages: [0.27441, 0.18635, 0.26501, 0.17454, 0.38101, 0.05427, 0.078251, 0.11284, 0.45184, 0.5748]
Predicted label: 9
Correct prediction
Energy consumption = 193.024908 pJ
sum error= 0
Actual label: 7
Output voltages: [0.3145, 0.17513, 0.24314, 0.3719, 0.096376, 0.10306, 0.031693, 0.74411, 0.41423, 0.36695]
Predicted label: 7
Correct prediction
Energy consumption = 188.491689 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 8 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 8 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 8 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.47463, 0.18968, 0.20844, 0.21396, 0.28414, 0.18929, 0.066928, 0.70279, 0.25045, 0.47273]
Predicted label: 7
Correct prediction
Energy consumption = 206.446556 pJ
sum error= 0
Actual label: 6
Output voltages: [0.28707, 0.19854, 0.29522, 0.093323, 0.33269, 0.34817, 0.73805, 0.06925, 0.39597, 0.10946]
Predicted label: 6
Correct prediction
Energy consumption = 196.786861 pJ
sum error= 0
Actual label: 2
Output voltages: [0.37111, 0.24938, 0.75283, 0.31599, 0.17963, 0.037785, 0.2826, 0.31791, 0.39286, 0.2231]
Predicted label: 2
Correct prediction
Energy consumption = 186.162585 pJ
sum error= 0
Actual label: 7
Output voltages: [0.28891, 0.21071, 0.16601, 0.2491, 0.21135, 0.17825, 0.051942, 0.76382, 0.28118, 0.34469]
Predicted label: 7
Correct prediction
Energy consumption = 198.400050 pJ
sum error= 0
Actual label: 8
Output voltages: [0.23281, 0.21107, 0.28115, 0.26872, 0.18281, 0.19557, 0.34799, 0.086249, 0.73517, 0.27243]
Predicted label: 8
Correct prediction
Energy consumption = 190.134312 pJ
sum error= 0
Actual label: 4
Output voltages: [0.14592, 0.18956, 0.26319, 0.11412, 0.75723, 0.094052, 0.30401, 0.32857, 0.25805, 0.26905]
Predicted label: 4
Correct prediction
Energy consumption = 199.172167 pJ
sum error= 0
Actual label: 7
Output voltages: [0.29602, 0.26257, 0.33803, 0.27372, 0.097606, 0.064887, 0.036632, 0.74281, 0.47465, 0.29526]
Predicted label: 7
Correct prediction
Energy consumption = 199.025819 pJ
sum error= 0
Actual label: 3
Output voltages: [0.39813, 0.1713, 0.25553, 0.70397, 0.26503, 0.16319, 0.19361, 0.40919, 0.31654, 0.14475]
Predicted label: 3
Correct prediction
Energy consumption = 199.376936 pJ
sum error= 0
Actual label: 6
Output voltages: [0.30124, 0.21266, 0.32241, 0.13589, 0.32152, 0.37659, 0.74999, 0.078598, 0.32427, 0.15888]
Predicted label: 6
Correct prediction
Energy consumption = 194.110853 pJ
sum error= 0
Actual label: 1
Output voltages: [0.21189, 0.7352, 0.29573, 0.26184, 0.33947, 0.08081, 0.45983, 0.09356, 0.28515, 0.16111]
Predicted label: 1
Correct prediction
Energy consumption = 203.385706 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 9 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 9 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 9 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34292, 0.17723, 0.2946, 0.75362, 0.13459, 0.19662, 0.14005, 0.17323, 0.47987, 0.22053]
Predicted label: 3
Correct prediction
Energy consumption = 190.821112 pJ
sum error= 0
Actual label: 6
Output voltages: [0.34064, 0.18732, 0.22181, 0.17558, 0.33535, 0.39109, 0.72609, 0.059416, 0.40416, 0.16585]
Predicted label: 6
Correct prediction
Energy consumption = 187.663738 pJ
sum error= 0
Actual label: 9
Output voltages: [0.35103, 0.12459, 0.2102, 0.24894, 0.48961, 0.082331, 0.066064, 0.1217, 0.33404, 0.55501]
Predicted label: 9
Correct prediction
Energy consumption = 197.754176 pJ
sum error= 0
Actual label: 3
Output voltages: [0.30911, 0.11168, 0.24793, 0.72808, 0.29892, 0.25885, 0.12987, 0.15438, 0.42774, 0.27855]
Predicted label: 3
Correct prediction
Energy consumption = 194.941639 pJ
sum error= 0
Actual label: 1
Output voltages: [0.19847, 0.73662, 0.34652, 0.11972, 0.26642, 0.088559, 0.4528, 0.084567, 0.34021, 0.25422]
Predicted label: 1
Correct prediction
Energy consumption = 202.908767 pJ
sum error= 0
Actual label: 4
Output voltages: [0.16449, 0.14897, 0.27128, 0.086205, 0.63776, 0.14252, 0.35129, 0.13069, 0.36118, 0.24604]
Predicted label: 4
Correct prediction
Energy consumption = 189.968571 pJ
sum error= 0
Actual label: 1
Output voltages: [0.15565, 0.67275, 0.23745, 0.33547, 0.27023, 0.14627, 0.19153, 0.10236, 0.23062, 0.38053]
Predicted label: 1
Correct prediction
Energy consumption = 212.406924 pJ
sum error= 0
Actual label: 7
Output voltages: [0.21294, 0.17067, 0.36952, 0.39339, 0.14771, 0.048196, 0.048955, 0.61298, 0.6017, 0.20086]
Predicted label: 7
Correct prediction
Energy consumption = 193.282272 pJ
sum error= 0
Actual label: 6
Output voltages: [0.26633, 0.17352, 0.29605, 0.094373, 0.30421, 0.34324, 0.71649, 0.072539, 0.43824, 0.11108]
Predicted label: 6
Correct prediction
Energy consumption = 193.319458 pJ
sum error= 0
Actual label: 9
Output voltages: [0.38893, 0.10852, 0.20668, 0.27538, 0.32402, 0.26754, 0.14717, 0.26265, 0.32241, 0.71028]
Predicted label: 9
Correct prediction
Energy consumption = 192.022383 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 10 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 10 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 10 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.28807, 0.29664, 0.27817, 0.096124, 0.25999, 0.38005, 0.74859, 0.099063, 0.39073, 0.15703]
Predicted label: 6
Correct prediction
Energy consumption = 192.919717 pJ
sum error= 0
Actual label: 0
Output voltages: [0.73066, 0.25122, 0.21003, 0.19999, 0.15136, 0.22677, 0.41501, 0.13453, 0.27888, 0.27308]
Predicted label: 0
Correct prediction
Energy consumption = 190.265507 pJ
sum error= 0
Actual label: 5
Output voltages: [0.26931, 0.071244, 0.14933, 0.42891, 0.13036, 0.65436, 0.17968, 0.18993, 0.57663, 0.26917]
Predicted label: 5
Correct prediction
Energy consumption = 184.371206 pJ
sum error= 0
Actual label: 4
Output voltages: [0.14762, 0.16266, 0.36896, 0.16004, 0.76324, 0.089774, 0.25881, 0.3058, 0.18878, 0.26183]
Predicted label: 4
Correct prediction
Energy consumption = 190.050313 pJ
sum error= 0
Actual label: 9
Output voltages: [0.2673, 0.071068, 0.10506, 0.2651, 0.33783, 0.49066, 0.14296, 0.22708, 0.4137, 0.52583]
Predicted label: 9
Correct prediction
Energy consumption = 193.590601 pJ
sum error= 0
Actual label: 9
Output voltages: [0.31418, 0.12135, 0.20447, 0.25255, 0.28097, 0.26747, 0.13412, 0.28085, 0.34417, 0.67069]
Predicted label: 9
Correct prediction
Energy consumption = 186.539884 pJ
sum error= 0
Actual label: 2
Output voltages: [0.36334, 0.15461, 0.72779, 0.38584, 0.12621, 0.039997, 0.23641, 0.24992, 0.41759, 0.14057]
Predicted label: 2
Correct prediction
Energy consumption = 187.871038 pJ
sum error= 0
Actual label: 1
Output voltages: [0.32865, 0.74104, 0.26628, 0.25489, 0.26779, 0.19086, 0.50201, 0.052311, 0.29409, 0.25304]
Predicted label: 1
Correct prediction
Energy consumption = 204.204174 pJ
sum error= 0
Actual label: 9
Output voltages: [0.36081, 0.18913, 0.17806, 0.28353, 0.25923, 0.18473, 0.088214, 0.20804, 0.34233, 0.69643]
Predicted label: 9
Correct prediction
Energy consumption = 205.232179 pJ
sum error= 0
Actual label: 4
Output voltages: [0.22115, 0.16123, 0.26684, 0.11523, 0.75401, 0.10059, 0.36893, 0.21901, 0.224, 0.20159]
Predicted label: 4
Correct prediction
Energy consumption = 188.723778 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 11 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 11 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 11 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26929, 0.19637, 0.26386, 0.41237, 0.097618, 0.22955, 0.21721, 0.092971, 0.72982, 0.26542]
Predicted label: 8
Correct prediction
Energy consumption = 195.040843 pJ
sum error= 0
Actual label: 7
Output voltages: [0.34319, 0.395, 0.37821, 0.32757, 0.083915, 0.038788, 0.057939, 0.58047, 0.42275, 0.35484]
Predicted label: 7
Correct prediction
Energy consumption = 206.178023 pJ
sum error= 0
Actual label: 3
Output voltages: [0.33369, 0.19474, 0.27839, 0.75715, 0.16913, 0.22947, 0.17805, 0.17411, 0.40564, 0.23024]
Predicted label: 3
Correct prediction
Energy consumption = 190.808038 pJ
sum error= 0
Actual label: 9
Output voltages: [0.3349, 0.18479, 0.20933, 0.36458, 0.26237, 0.22364, 0.14564, 0.26381, 0.30398, 0.70615]
Predicted label: 9
Correct prediction
Energy consumption = 196.188804 pJ
sum error= 0
Actual label: 7
Output voltages: [0.36104, 0.11264, 0.35302, 0.35834, 0.16774, 0.052627, 0.05546, 0.71276, 0.32365, 0.39089]
Predicted label: 7
Correct prediction
Energy consumption = 187.712927 pJ
sum error= 0
Actual label: 4
Output voltages: [0.24853, 0.26157, 0.12818, 0.15753, 0.57007, 0.17883, 0.30763, 0.17738, 0.2461, 0.44749]
Predicted label: 4
Correct prediction
Energy consumption = 201.981178 pJ
sum error= 0
Actual label: 4
Output voltages: [0.17517, 0.24273, 0.26389, 0.22254, 0.69195, 0.098792, 0.17467, 0.22104, 0.22178, 0.43788]
Predicted label: 4
Correct prediction
Energy consumption = 198.413883 pJ
sum error= 0
Actual label: 4
Output voltages: [0.1304, 0.14567, 0.33972, 0.12759, 0.76316, 0.10804, 0.2725, 0.23355, 0.24338, 0.27658]
Predicted label: 4
Correct prediction
Energy consumption = 181.630179 pJ
sum error= 0
Actual label: 9
Output voltages: [0.35118, 0.12759, 0.19825, 0.26816, 0.40651, 0.13476, 0.077561, 0.28455, 0.29489, 0.64991]
Predicted label: 9
Correct prediction
Energy consumption = 188.357303 pJ
sum error= 0
Actual label: 2
Output voltages: [0.31621, 0.26226, 0.70293, 0.28717, 0.13842, 0.036379, 0.18627, 0.43557, 0.45609, 0.16272]
Predicted label: 2
Correct prediction
Energy consumption = 193.434340 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 12 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 12 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 12 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2638, 0.054149, 0.15426, 0.41009, 0.23722, 0.67272, 0.21082, 0.17852, 0.54632, 0.30341]
Predicted label: 5
Correct prediction
Energy consumption = 190.327227 pJ
sum error= 0
Actual label: 4
Output voltages: [0.17232, 0.15704, 0.15291, 0.089361, 0.64242, 0.20815, 0.35813, 0.20377, 0.31832, 0.30104]
Predicted label: 4
Correct prediction
Energy consumption = 197.740601 pJ
sum error= 0
Actual label: 7
Output voltages: [0.32408, 0.19847, 0.19533, 0.33691, 0.088382, 0.16367, 0.043341, 0.6949, 0.35924, 0.47346]
Predicted label: 7
Correct prediction
Energy consumption = 207.356972 pJ
sum error= 0
Actual label: 6
Output voltages: [0.34234, 0.2569, 0.34443, 0.096046, 0.29625, 0.27364, 0.741, 0.08334, 0.40261, 0.14756]
Predicted label: 6
Correct prediction
Energy consumption = 193.753766 pJ
sum error= 0
Actual label: 7
Output voltages: [0.23928, 0.196, 0.15338, 0.098796, 0.37874, 0.13236, 0.061475, 0.59911, 0.42396, 0.37369]
Predicted label: 7
Correct prediction
Energy consumption = 196.711870 pJ
sum error= 0
Actual label: 9
Output voltages: [0.33362, 0.23507, 0.28468, 0.1789, 0.56874, 0.10485, 0.22921, 0.24573, 0.22152, 0.62095]
Predicted label: 9
Correct prediction
Energy consumption = 204.456499 pJ
sum error= 0
Actual label: 0
Output voltages: [0.72262, 0.19923, 0.26425, 0.27584, 0.13386, 0.25659, 0.32732, 0.09218, 0.34498, 0.24345]
Predicted label: 0
Correct prediction
Energy consumption = 202.761234 pJ
sum error= 0
Actual label: 5
Output voltages: [0.21816, 0.077448, 0.08731, 0.3147, 0.23394, 0.71205, 0.29274, 0.10864, 0.53345, 0.22791]
Predicted label: 5
Correct prediction
Energy consumption = 183.347695 pJ
sum error= 0
Actual label: 8
Output voltages: [0.1715, 0.14308, 0.2577, 0.31489, 0.12121, 0.29691, 0.16639, 0.14101, 0.74892, 0.28651]
Predicted label: 8
Correct prediction
Energy consumption = 183.665539 pJ
sum error= 0
Actual label: 5
Output voltages: [0.24971, 0.049923, 0.11038, 0.36736, 0.20681, 0.69239, 0.24153, 0.15667, 0.5258, 0.28332]
Predicted label: 5
Correct prediction
Energy consumption = 179.620523 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 13 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 13 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 13 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31458, 0.14401, 0.19167, 0.17116, 0.30182, 0.45096, 0.70531, 0.063175, 0.40359, 0.16755]
Predicted label: 6
Correct prediction
Energy consumption = 193.983951 pJ
sum error= 0
Actual label: 6
Output voltages: [0.29667, 0.16798, 0.23726, 0.13628, 0.31708, 0.34419, 0.70287, 0.065324, 0.49538, 0.14326]
Predicted label: 6
Correct prediction
Energy consumption = 182.317512 pJ
sum error= 0
Actual label: 5
Output voltages: [0.25302, 0.049223, 0.13012, 0.3178, 0.23052, 0.68396, 0.34721, 0.15752, 0.57343, 0.23047]
Predicted label: 5
Correct prediction
Energy consumption = 182.641781 pJ
sum error= 0
Actual label: 7
Output voltages: [0.27544, 0.12251, 0.31254, 0.44781, 0.10464, 0.16064, 0.049815, 0.71279, 0.38969, 0.33638]
Predicted label: 7
Correct prediction
Energy consumption = 192.098591 pJ
sum error= 0
Actual label: 8
Output voltages: [0.216, 0.2226, 0.27382, 0.34595, 0.10532, 0.25344, 0.22843, 0.14973, 0.75349, 0.26536]
Predicted label: 8
Correct prediction
Energy consumption = 190.327048 pJ
sum error= 0
Actual label: 1
Output voltages: [0.15869, 0.76237, 0.28984, 0.29461, 0.21437, 0.064827, 0.38552, 0.1404, 0.31981, 0.20197]
Predicted label: 1
Correct prediction
Energy consumption = 209.926189 pJ
sum error= 0
Actual label: 0
Output voltages: [0.69894, 0.21978, 0.30235, 0.2412, 0.14768, 0.13925, 0.38275, 0.11742, 0.34202, 0.36969]
Predicted label: 0
Correct prediction
Energy consumption = 202.701832 pJ
sum error= 0
Actual label: 1
Output voltages: [0.2199, 0.74875, 0.28772, 0.26477, 0.32855, 0.05512, 0.346, 0.094801, 0.2764, 0.22616]
Predicted label: 1
Correct prediction
Energy consumption = 207.633225 pJ
sum error= 0
Actual label: 6
Output voltages: [0.3268, 0.26574, 0.3186, 0.085263, 0.36657, 0.30975, 0.74994, 0.081048, 0.32618, 0.14476]
Predicted label: 6
Correct prediction
Energy consumption = 190.840395 pJ
sum error= 0
Actual label: 4
Output voltages: [0.22638, 0.17654, 0.26357, 0.14716, 0.6404, 0.077587, 0.27481, 0.12245, 0.28096, 0.32652]
Predicted label: 4
Correct prediction
Energy consumption = 196.686882 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 14 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 14 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 14 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32976, 0.18433, 0.23348, 0.10736, 0.35524, 0.29308, 0.72302, 0.10406, 0.42548, 0.13076]
Predicted label: 6
Correct prediction
Energy consumption = 195.966846 pJ
sum error= 0
Actual label: 7
Output voltages: [0.40953, 0.27754, 0.26721, 0.28394, 0.072343, 0.08493, 0.054764, 0.74438, 0.39211, 0.34814]
Predicted label: 7
Correct prediction
Energy consumption = 206.955685 pJ
sum error= 0
Actual label: 3
Output voltages: [0.2673, 0.26216, 0.41324, 0.73223, 0.14498, 0.065297, 0.11917, 0.12229, 0.43143, 0.20037]
Predicted label: 3
Correct prediction
Energy consumption = 184.323245 pJ
sum error= 0
Actual label: 1
Output voltages: [0.18318, 0.76437, 0.28003, 0.18914, 0.24386, 0.087895, 0.33456, 0.14012, 0.31797, 0.25205]
Predicted label: 1
Correct prediction
Energy consumption = 208.347710 pJ
sum error= 0
Actual label: 7
Output voltages: [0.35599, 0.087181, 0.41152, 0.31308, 0.29537, 0.03448, 0.048646, 0.61752, 0.33304, 0.35485]
Predicted label: 7
Correct prediction
Energy consumption = 185.262066 pJ
sum error= 0
Actual label: 1
Output voltages: [0.15271, 0.75526, 0.1755, 0.39729, 0.27674, 0.17333, 0.17296, 0.19272, 0.20908, 0.38245]
Predicted label: 1
Correct prediction
Energy consumption = 210.090956 pJ
sum error= 0
Actual label: 8
Output voltages: [0.21421, 0.23029, 0.30007, 0.29814, 0.12366, 0.18645, 0.2241, 0.13613, 0.74782, 0.35014]
Predicted label: 8
Correct prediction
Energy consumption = 194.898348 pJ
sum error= 0
Actual label: 2
Output voltages: [0.33858, 0.18298, 0.74234, 0.31425, 0.18911, 0.042386, 0.26762, 0.23691, 0.43896, 0.14329]
Predicted label: 2
Correct prediction
Energy consumption = 185.402331 pJ
sum error= 0
Actual label: 0
Output voltages: [0.71216, 0.25773, 0.26319, 0.20084, 0.19333, 0.11978, 0.45927, 0.16105, 0.31051, 0.24851]
Predicted label: 0
Correct prediction
Energy consumption = 201.329446 pJ
sum error= 0
Actual label: 2
Output voltages: [0.28079, 0.094739, 0.63359, 0.34891, 0.34364, 0.052516, 0.18281, 0.14582, 0.41561, 0.32184]
Predicted label: 2
Correct prediction
Energy consumption = 196.640522 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 15 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 15 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 15 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29492, 0.11379, 0.24856, 0.30268, 0.32635, 0.23429, 0.19409, 0.25071, 0.35076, 0.64955]
Predicted label: 9
Correct prediction
Energy consumption = 201.720861 pJ
sum error= 0
Actual label: 9
Output voltages: [0.42978, 0.059384, 0.30165, 0.28991, 0.35038, 0.18549, 0.08277, 0.12293, 0.40769, 0.57819]
Predicted label: 9
Correct prediction
Energy consumption = 198.852215 pJ
sum error= 0
Actual label: 5
Output voltages: [0.27577, 0.11024, 0.097723, 0.33639, 0.25557, 0.73961, 0.34535, 0.10737, 0.40439, 0.25489]
Predicted label: 5
Correct prediction
Energy consumption = 190.570164 pJ
sum error= 0
Actual label: 5
Output voltages: [0.27642, 0.065531, 0.17273, 0.40918, 0.17863, 0.62216, 0.26508, 0.12267, 0.4998, 0.343]
Predicted label: 5
Correct prediction
Energy consumption = 183.869693 pJ
sum error= 0
Actual label: 1
Output voltages: [0.25652, 0.74743, 0.29472, 0.30591, 0.095431, 0.056837, 0.29574, 0.20556, 0.34297, 0.25395]
Predicted label: 1
Correct prediction
Energy consumption = 220.617034 pJ
sum error= 0
Actual label: 5
Output voltages: [0.22436, 0.046425, 0.053052, 0.36146, 0.32947, 0.69106, 0.34307, 0.13019, 0.49865, 0.23085]
Predicted label: 5
Correct prediction
Energy consumption = 189.813307 pJ
sum error= 0
Actual label: 6
Output voltages: [0.28699, 0.19113, 0.38723, 0.079253, 0.38949, 0.29475, 0.74926, 0.070878, 0.2667, 0.1455]
Predicted label: 6
Correct prediction
Energy consumption = 189.923572 pJ
sum error= 0
Actual label: 0
Output voltages: [0.72109, 0.23416, 0.28597, 0.19045, 0.18713, 0.14429, 0.44948, 0.16302, 0.31688, 0.33855]
Predicted label: 0
Correct prediction
Energy consumption = 196.794983 pJ
sum error= 0
Actual label: 3
Output voltages: [0.53996, 0.17921, 0.32467, 0.70728, 0.062239, 0.20816, 0.24632, 0.18608, 0.33041, 0.17234]
Predicted label: 3
Correct prediction
Energy consumption = 195.445216 pJ
sum error= 0
Actual label: 4
Output voltages: [0.17205, 0.26589, 0.20076, 0.32162, 0.71189, 0.093508, 0.22933, 0.27425, 0.09855, 0.34876]
Predicted label: 4
Correct prediction
Energy consumption = 196.408088 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 16 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 16 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 16 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.24026, 0.27494, 0.36083, 0.097085, 0.64436, 0.066849, 0.3393, 0.098119, 0.37238, 0.29742]
Predicted label: 4
Correct prediction
Energy consumption = 206.640184 pJ
sum error= 0
Actual label: 6
Output voltages: [0.29076, 0.14041, 0.27967, 0.095981, 0.34595, 0.35764, 0.72457, 0.042612, 0.39456, 0.17316]
Predicted label: 6
Correct prediction
Energy consumption = 178.583425 pJ
sum error= 0
Actual label: 5
Output voltages: [0.22612, 0.05489, 0.098158, 0.39265, 0.22794, 0.70903, 0.28225, 0.2095, 0.52006, 0.26401]
Predicted label: 5
Correct prediction
Energy consumption = 182.364385 pJ
sum error= 0
Actual label: 4
Output voltages: [0.19536, 0.14352, 0.29608, 0.14235, 0.75165, 0.11395, 0.22936, 0.29124, 0.2389, 0.33874]
Predicted label: 4
Correct prediction
Energy consumption = 194.048200 pJ
sum error= 0
Actual label: 6
Output voltages: [0.2692, 0.24625, 0.31857, 0.12062, 0.38421, 0.18859, 0.70289, 0.13208, 0.33525, 0.12623]
Predicted label: 6
Correct prediction
Energy consumption = 197.862078 pJ
sum error= 0
Actual label: 5
Output voltages: [0.22945, 0.055897, 0.15992, 0.36909, 0.16192, 0.67358, 0.28638, 0.22693, 0.5419, 0.2419]
Predicted label: 5
Correct prediction
Energy consumption = 187.882825 pJ
sum error= 0
Actual label: 4
Output voltages: [0.13016, 0.2355, 0.19673, 0.077232, 0.73762, 0.12187, 0.36884, 0.33037, 0.22096, 0.21601]
Predicted label: 4
Correct prediction
Energy consumption = 202.542254 pJ
sum error= 0
Actual label: 5
Output voltages: [0.34007, 0.070681, 0.050391, 0.43049, 0.35013, 0.72107, 0.27907, 0.18773, 0.28897, 0.14465]
Predicted label: 5
Correct prediction
Energy consumption = 187.941284 pJ
sum error= 0
Actual label: 1
Output voltages: [0.23402, 0.7552, 0.24326, 0.28905, 0.12696, 0.11909, 0.35687, 0.10091, 0.39842, 0.18588]
Predicted label: 1
Correct prediction
Energy consumption = 206.675885 pJ
sum error= 0
Actual label: 4
Output voltages: [0.16367, 0.18942, 0.22826, 0.19181, 0.73869, 0.077153, 0.21434, 0.29506, 0.28877, 0.27567]
Predicted label: 4
Correct prediction
Energy consumption = 199.084514 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 17 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 17 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 17 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.20723, 0.17711, 0.32475, 0.27982, 0.74717, 0.12998, 0.21507, 0.19215, 0.19373, 0.37208]
Predicted label: 4
Correct prediction
Energy consumption = 201.254107 pJ
sum error= 0
Actual label: 7
Output voltages: [0.39828, 0.18495, 0.45548, 0.2529, 0.1174, 0.057639, 0.057655, 0.54739, 0.51952, 0.37134]
Predicted label: 7
Correct prediction
Energy consumption = 199.219030 pJ
sum error= 0
Actual label: 2
Output voltages: [0.37435, 0.29069, 0.70441, 0.44741, 0.079854, 0.047443, 0.22448, 0.15531, 0.44432, 0.12758]
Predicted label: 2
Correct prediction
Energy consumption = 184.492556 pJ
sum error= 0
Actual label: 3
Output voltages: [0.40053, 0.18055, 0.23521, 0.75207, 0.11577, 0.29993, 0.16092, 0.22301, 0.35061, 0.14781]
Predicted label: 3
Correct prediction
Energy consumption = 184.651968 pJ
sum error= 0
Actual label: 2
Output voltages: [0.38321, 0.28168, 0.68301, 0.40207, 0.16739, 0.031956, 0.24044, 0.27294, 0.40091, 0.21454]
Predicted label: 2
Correct prediction
Energy consumption = 191.803578 pJ
sum error= 0
Actual label: 7
Output voltages: [0.37382, 0.42644, 0.32706, 0.39504, 0.077869, 0.036547, 0.069905, 0.54706, 0.41414, 0.33037]
Predicted label: 7
Correct prediction
Energy consumption = 208.355085 pJ
sum error= 0
Actual label: 1
Output voltages: [0.30229, 0.77128, 0.25727, 0.26721, 0.15098, 0.11686, 0.35482, 0.1451, 0.28041, 0.23734]
Predicted label: 1
Correct prediction
Energy consumption = 207.573915 pJ
sum error= 0
Actual label: 8
Output voltages: [0.31958, 0.17413, 0.2598, 0.33003, 0.22719, 0.089942, 0.26009, 0.059772, 0.67321, 0.28801]
Predicted label: 8
Correct prediction
Energy consumption = 207.440711 pJ
sum error= 0
Actual label: 1
Output voltages: [0.21076, 0.76193, 0.28635, 0.26613, 0.18317, 0.091193, 0.40235, 0.11916, 0.2826, 0.17183]
Predicted label: 1
Correct prediction
Energy consumption = 209.950906 pJ
sum error= 0
Actual label: 8
Output voltages: [0.22104, 0.25306, 0.36566, 0.29941, 0.19711, 0.15015, 0.27246, 0.1419, 0.72469, 0.33247]
Predicted label: 8
Correct prediction
Energy consumption = 194.940705 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 18 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 18 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 18 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.14751, 0.76298, 0.22409, 0.27702, 0.2389, 0.12991, 0.3007, 0.099974, 0.34761, 0.3464]
Predicted label: 1
Correct prediction
Energy consumption = 216.433641 pJ
sum error= 0
Actual label: 8
Output voltages: [0.26086, 0.18918, 0.41456, 0.2516, 0.12862, 0.13107, 0.27683, 0.15908, 0.7305, 0.26716]
Predicted label: 8
Correct prediction
Energy consumption = 194.732427 pJ
sum error= 0
Actual label: 5
Output voltages: [0.22151, 0.07904, 0.086603, 0.40257, 0.24302, 0.66646, 0.33141, 0.066311, 0.46643, 0.21073]
Predicted label: 5
Correct prediction
Energy consumption = 196.122712 pJ
sum error= 0
Actual label: 0
Output voltages: [0.72122, 0.26095, 0.23955, 0.15087, 0.11912, 0.16176, 0.44156, 0.16979, 0.25575, 0.27279]
Predicted label: 0
Correct prediction
Energy consumption = 193.414604 pJ
sum error= 0
Actual label: 8
Output voltages: [0.38041, 0.073124, 0.46822, 0.59524, 0.085199, 0.064376, 0.086546, 0.32361, 0.54867, 0.14404]
Predicted label: 3
Wrong prediction!
Energy consumption = 196.444050 pJ
sum error= 1
Actual label: 9
Output voltages: [0.24004, 0.16695, 0.13738, 0.26577, 0.47544, 0.16719, 0.33801, 0.16811, 0.24383, 0.54292]
Predicted label: 9
Correct prediction
Energy consumption = 193.434088 pJ
sum error= 1
Actual label: 2
Output voltages: [0.37284, 0.23446, 0.70883, 0.33441, 0.17072, 0.02764, 0.27728, 0.23192, 0.44715, 0.19477]
Predicted label: 2
Correct prediction
Energy consumption = 187.771188 pJ
sum error= 1
Actual label: 5
Output voltages: [0.2331, 0.050779, 0.13904, 0.37097, 0.24044, 0.69789, 0.28231, 0.19488, 0.56164, 0.27333]
Predicted label: 5
Correct prediction
Energy consumption = 183.103786 pJ
sum error= 1
Actual label: 0
Output voltages: [0.69609, 0.23515, 0.26469, 0.16973, 0.12741, 0.25433, 0.39056, 0.15369, 0.36794, 0.22758]
Predicted label: 0
Correct prediction
Energy consumption = 194.325787 pJ
sum error= 1
Actual label: 1
Output voltages: [0.089758, 0.71466, 0.2199, 0.39624, 0.32782, 0.13725, 0.21281, 0.15504, 0.23408, 0.31113]
Predicted label: 1
Correct prediction
Energy consumption = 211.286862 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 19 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 19 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 19 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23009, 0.66202, 0.19442, 0.30652, 0.22552, 0.048695, 0.31013, 0.067436, 0.468, 0.31977]
Predicted label: 1
Correct prediction
Energy consumption = 210.496018 pJ
sum error= 1
Actual label: 1
Output voltages: [0.095309, 0.70513, 0.3644, 0.43168, 0.29786, 0.098157, 0.14704, 0.26393, 0.17239, 0.30651]
Predicted label: 1
Correct prediction
Energy consumption = 212.454814 pJ
sum error= 1
Actual label: 0
Output voltages: [0.72482, 0.23129, 0.31655, 0.15661, 0.14808, 0.1273, 0.40016, 0.22927, 0.36568, 0.18793]
Predicted label: 0
Correct prediction
Energy consumption = 194.980830 pJ
sum error= 1
Actual label: 9
Output voltages: [0.25179, 0.080322, 0.20662, 0.31292, 0.31086, 0.21274, 0.057682, 0.31724, 0.36992, 0.62384]
Predicted label: 9
Correct prediction
Energy consumption = 205.107200 pJ
sum error= 1
Actual label: 0
Output voltages: [0.73875, 0.28897, 0.29551, 0.20667, 0.11411, 0.1586, 0.33068, 0.23879, 0.36754, 0.28108]
Predicted label: 0
Correct prediction
Energy consumption = 203.076548 pJ
sum error= 1
Actual label: 3
Output voltages: [0.21414, 0.24221, 0.34064, 0.75679, 0.18278, 0.10069, 0.17615, 0.21099, 0.33809, 0.32098]
Predicted label: 3
Correct prediction
Energy consumption = 199.841626 pJ
sum error= 1
Actual label: 1
Output voltages: [0.23722, 0.77188, 0.2572, 0.25682, 0.23375, 0.12014, 0.39309, 0.085745, 0.33278, 0.2501]
Predicted label: 1
Correct prediction
Energy consumption = 209.952092 pJ
sum error= 1
Actual label: 6
Output voltages: [0.27759, 0.18341, 0.30264, 0.087126, 0.31352, 0.32656, 0.73452, 0.079428, 0.4715, 0.14703]
Predicted label: 6
Correct prediction
Energy consumption = 187.599559 pJ
sum error= 1
Actual label: 4
Output voltages: [0.1472, 0.15221, 0.27638, 0.20369, 0.75152, 0.091397, 0.2574, 0.24956, 0.21012, 0.29053]
Predicted label: 4
Correct prediction
Energy consumption = 198.989049 pJ
sum error= 1
Actual label: 2
Output voltages: [0.29851, 0.21121, 0.70505, 0.37236, 0.11429, 0.033815, 0.25164, 0.3153, 0.49682, 0.15264]
Predicted label: 2
Correct prediction
Energy consumption = 184.600115 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 20 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 20 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 20 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.41451, 0.091572, 0.31593, 0.73354, 0.20209, 0.1142, 0.12989, 0.19757, 0.49644, 0.1299]
Predicted label: 3
Correct prediction
Energy consumption = 193.866784 pJ
sum error= 1
Actual label: 6
Output voltages: [0.32831, 0.26237, 0.30785, 0.13575, 0.2874, 0.33086, 0.74683, 0.074493, 0.33833, 0.21259]
Predicted label: 6
Correct prediction
Energy consumption = 186.983142 pJ
sum error= 1
Actual label: 1
Output voltages: [0.20476, 0.74363, 0.23078, 0.1992, 0.27003, 0.12817, 0.36549, 0.081032, 0.34334, 0.21312]
Predicted label: 1
Correct prediction
Energy consumption = 205.490683 pJ
sum error= 1
Actual label: 1
Output voltages: [0.22177, 0.75393, 0.13821, 0.22579, 0.33024, 0.23775, 0.36467, 0.092652, 0.23527, 0.37706]
Predicted label: 1
Correct prediction
Energy consumption = 216.241514 pJ
sum error= 1
Actual label: 1
Output voltages: [0.19526, 0.75806, 0.15443, 0.18201, 0.33339, 0.14219, 0.41672, 0.078418, 0.32473, 0.25862]
Predicted label: 1
Correct prediction
Energy consumption = 206.006246 pJ
sum error= 1
Actual label: 3
Output voltages: [0.30702, 0.20783, 0.28034, 0.76561, 0.18974, 0.14979, 0.18661, 0.29186, 0.37153, 0.27345]
Predicted label: 3
Correct prediction
Energy consumption = 186.084087 pJ
sum error= 1
Actual label: 9
Output voltages: [0.32001, 0.12153, 0.24681, 0.17827, 0.19945, 0.20312, 0.089286, 0.21853, 0.52019, 0.6142]
Predicted label: 9
Correct prediction
Energy consumption = 185.176388 pJ
sum error= 1
Actual label: 5
Output voltages: [0.30975, 0.044595, 0.099401, 0.46372, 0.13123, 0.62518, 0.21922, 0.31837, 0.45262, 0.22936]
Predicted label: 5
Correct prediction
Energy consumption = 190.712682 pJ
sum error= 1
Actual label: 2
Output voltages: [0.37974, 0.18734, 0.75225, 0.31631, 0.19478, 0.043525, 0.30135, 0.35075, 0.41247, 0.17494]
Predicted label: 2
Correct prediction
Energy consumption = 182.874209 pJ
sum error= 1
Actual label: 9
Output voltages: [0.34023, 0.074609, 0.13269, 0.289, 0.41362, 0.26427, 0.094554, 0.27529, 0.30097, 0.63654]
Predicted label: 9
Correct prediction
Energy consumption = 196.396708 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 21 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 21 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 21 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.17538, 0.13415, 0.32589, 0.13045, 0.74539, 0.061432, 0.24568, 0.24957, 0.26659, 0.29411]
Predicted label: 4
Correct prediction
Energy consumption = 200.408743 pJ
sum error= 1
Actual label: 5
Output voltages: [0.22684, 0.119, 0.071585, 0.372, 0.23991, 0.63698, 0.30177, 0.045196, 0.48751, 0.22879]
Predicted label: 5
Correct prediction
Energy consumption = 195.443229 pJ
sum error= 1
Actual label: 9
Output voltages: [0.30253, 0.10821, 0.16982, 0.38345, 0.28211, 0.24749, 0.062796, 0.26912, 0.28303, 0.68121]
Predicted label: 9
Correct prediction
Energy consumption = 197.589759 pJ
sum error= 1
Actual label: 3
Output voltages: [0.35235, 0.23613, 0.33279, 0.75746, 0.11684, 0.1017, 0.092939, 0.24032, 0.43118, 0.29479]
Predicted label: 3
Correct prediction
Energy consumption = 182.451683 pJ
sum error= 1
Actual label: 9
Output voltages: [0.29232, 0.12204, 0.23742, 0.25616, 0.23892, 0.10198, 0.075682, 0.22594, 0.50437, 0.60106]
Predicted label: 9
Correct prediction
Energy consumption = 193.537567 pJ
sum error= 1
Actual label: 0
Output voltages: [0.7215, 0.20479, 0.27013, 0.28341, 0.14612, 0.14463, 0.33542, 0.18903, 0.32555, 0.3186]
Predicted label: 0
Correct prediction
Energy consumption = 206.612089 pJ
sum error= 1
Actual label: 3
Output voltages: [0.35296, 0.22277, 0.30042, 0.76454, 0.14057, 0.14256, 0.13705, 0.20257, 0.40131, 0.25688]
Predicted label: 3
Correct prediction
Energy consumption = 184.454729 pJ
sum error= 1
Actual label: 6
Output voltages: [0.38627, 0.12789, 0.10739, 0.30027, 0.28018, 0.54682, 0.58203, 0.068065, 0.49296, 0.16371]
Predicted label: 6
Correct prediction
Energy consumption = 190.348965 pJ
sum error= 1
Actual label: 5
Output voltages: [0.21058, 0.07257, 0.046392, 0.27438, 0.20253, 0.73425, 0.30551, 0.20761, 0.47219, 0.22019]
Predicted label: 5
Correct prediction
Energy consumption = 193.981269 pJ
sum error= 1
Actual label: 5
Output voltages: [0.40586, 0.071089, 0.066824, 0.46611, 0.16014, 0.68645, 0.28973, 0.091582, 0.45557, 0.28436]
Predicted label: 5
Correct prediction
Energy consumption = 184.920901 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 22 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 22 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 22 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3635, 0.22324, 0.145, 0.23233, 0.17957, 0.16192, 0.049086, 0.75409, 0.33383, 0.3146]
Predicted label: 7
Correct prediction
Energy consumption = 204.261274 pJ
sum error= 1
Actual label: 2
Output voltages: [0.5065, 0.051587, 0.58346, 0.50735, 0.1254, 0.088581, 0.16514, 0.248, 0.41129, 0.19359]
Predicted label: 2
Correct prediction
Energy consumption = 195.201058 pJ
sum error= 1
Actual label: 2
Output voltages: [0.41334, 0.06505, 0.65462, 0.20234, 0.1768, 0.049565, 0.25401, 0.28879, 0.49401, 0.20641]
Predicted label: 2
Correct prediction
Energy consumption = 191.251405 pJ
sum error= 1
Actual label: 7
Output voltages: [0.37525, 0.24664, 0.3347, 0.29619, 0.13695, 0.053801, 0.05236, 0.74542, 0.31, 0.35835]
Predicted label: 7
Correct prediction
Energy consumption = 195.921537 pJ
sum error= 1
Actual label: 1
Output voltages: [0.20237, 0.7266, 0.24975, 0.19427, 0.28558, 0.11287, 0.39063, 0.12094, 0.34222, 0.24929]
Predicted label: 1
Correct prediction
Energy consumption = 207.842682 pJ
sum error= 1
Actual label: 2
Output voltages: [0.28902, 0.29451, 0.73492, 0.27222, 0.097118, 0.038202, 0.24445, 0.27249, 0.4817, 0.21049]
Predicted label: 2
Correct prediction
Energy consumption = 182.564901 pJ
sum error= 1
Actual label: 8
Output voltages: [0.16664, 0.26812, 0.268, 0.30598, 0.15624, 0.20892, 0.17013, 0.23068, 0.75132, 0.30095]
Predicted label: 8
Correct prediction
Energy consumption = 189.907121 pJ
sum error= 1
Actual label: 4
Output voltages: [0.22189, 0.2137, 0.27018, 0.25022, 0.75245, 0.066445, 0.28623, 0.25111, 0.239, 0.22183]
Predicted label: 4
Correct prediction
Energy consumption = 198.061461 pJ
sum error= 1
Actual label: 1
Output voltages: [0.16266, 0.75745, 0.22008, 0.20884, 0.34503, 0.10454, 0.38084, 0.13491, 0.31995, 0.2772]
Predicted label: 1
Correct prediction
Energy consumption = 210.858929 pJ
sum error= 1
Actual label: 7
Output voltages: [0.37676, 0.29238, 0.33158, 0.36734, 0.12693, 0.043859, 0.048389, 0.71965, 0.25403, 0.34909]
Predicted label: 7
Correct prediction
Energy consumption = 193.103397 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 23 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 23 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 23 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29194, 0.16834, 0.25445, 0.73354, 0.23631, 0.36081, 0.23775, 0.13768, 0.33947, 0.20862]
Predicted label: 3
Correct prediction
Energy consumption = 200.531547 pJ
sum error= 1
Actual label: 3
Output voltages: [0.30627, 0.2131, 0.30214, 0.75444, 0.16637, 0.25953, 0.15803, 0.12142, 0.36196, 0.20044]
Predicted label: 3
Correct prediction
Energy consumption = 186.422732 pJ
sum error= 1
Actual label: 8
Output voltages: [0.28002, 0.086063, 0.34397, 0.25413, 0.1118, 0.3823, 0.36855, 0.073131, 0.66485, 0.19641]
Predicted label: 8
Correct prediction
Energy consumption = 196.572452 pJ
sum error= 1
Actual label: 8
Output voltages: [0.20889, 0.15112, 0.2441, 0.25266, 0.12648, 0.17516, 0.093825, 0.25459, 0.71064, 0.41614]
Predicted label: 8
Correct prediction
Energy consumption = 193.042723 pJ
sum error= 1
Actual label: 7
Output voltages: [0.30046, 0.38382, 0.36145, 0.40053, 0.10365, 0.040837, 0.069608, 0.66576, 0.33532, 0.28974]
Predicted label: 7
Correct prediction
Energy consumption = 201.171155 pJ
sum error= 1
Actual label: 9
Output voltages: [0.43121, 0.081748, 0.22886, 0.16678, 0.27245, 0.23895, 0.17838, 0.30268, 0.38715, 0.62008]
Predicted label: 9
Correct prediction
Energy consumption = 193.076131 pJ
sum error= 1
Actual label: 2
Output voltages: [0.42742, 0.31779, 0.73956, 0.25173, 0.14638, 0.028086, 0.29756, 0.2888, 0.38969, 0.23322]
Predicted label: 2
Correct prediction
Energy consumption = 186.075578 pJ
sum error= 1
Actual label: 2
Output voltages: [0.33447, 0.39285, 0.72496, 0.27079, 0.28866, 0.030254, 0.28574, 0.23581, 0.258, 0.21822]
Predicted label: 2
Correct prediction
Energy consumption = 177.423658 pJ
sum error= 1
Actual label: 4
Output voltages: [0.15019, 0.20675, 0.23615, 0.1215, 0.73607, 0.10532, 0.32875, 0.32434, 0.24527, 0.27508]
Predicted label: 4
Correct prediction
Energy consumption = 189.637196 pJ
sum error= 1
Actual label: 1
Output voltages: [0.17382, 0.75552, 0.26648, 0.45182, 0.20311, 0.14122, 0.28539, 0.18509, 0.26625, 0.25818]
Predicted label: 1
Correct prediction
Energy consumption = 211.514313 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 24 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 24 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 24 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.20307, 0.053236, 0.12281, 0.35284, 0.29268, 0.65754, 0.34832, 0.10194, 0.53804, 0.27805]
Predicted label: 5
Correct prediction
Energy consumption = 189.609726 pJ
sum error= 1
Actual label: 9
Output voltages: [0.38548, 0.047347, 0.26369, 0.21933, 0.28883, 0.25835, 0.18335, 0.072014, 0.52917, 0.49102]
Predicted label: 8
Wrong prediction!
Energy consumption = 190.080396 pJ
sum error= 2
Actual label: 8
Output voltages: [0.35047, 0.24324, 0.32958, 0.18391, 0.19813, 0.11349, 0.35109, 0.08983, 0.65227, 0.33678]
Predicted label: 8
Correct prediction
Energy consumption = 189.130682 pJ
sum error= 2
Actual label: 7
Output voltages: [0.20137, 0.17482, 0.33233, 0.39335, 0.2567, 0.052613, 0.045555, 0.65191, 0.33658, 0.37929]
Predicted label: 7
Correct prediction
Energy consumption = 188.500253 pJ
sum error= 2
Actual label: 2
Output voltages: [0.37023, 0.30972, 0.69257, 0.31929, 0.13986, 0.042079, 0.20275, 0.42648, 0.40654, 0.18681]
Predicted label: 2
Correct prediction
Energy consumption = 189.919228 pJ
sum error= 2
Actual label: 3
Output voltages: [0.32297, 0.10302, 0.21127, 0.68894, 0.083845, 0.42617, 0.33365, 0.33516, 0.36036, 0.080218]
Predicted label: 3
Correct prediction
Energy consumption = 187.591217 pJ
sum error= 2
Actual label: 0
Output voltages: [0.66262, 0.13715, 0.30145, 0.11727, 0.14818, 0.29584, 0.38673, 0.058535, 0.30583, 0.3449]
Predicted label: 0
Correct prediction
Energy consumption = 192.321191 pJ
sum error= 2
Actual label: 4
Output voltages: [0.29836, 0.26033, 0.42167, 0.091457, 0.47676, 0.1771, 0.50979, 0.12583, 0.33584, 0.10028]
Predicted label: 6
Wrong prediction!
Energy consumption = 194.910775 pJ
sum error= 3
Actual label: 4
Output voltages: [0.15048, 0.15393, 0.2983, 0.13448, 0.75767, 0.058449, 0.3039, 0.28634, 0.20677, 0.27056]
Predicted label: 4
Correct prediction
Energy consumption = 189.234147 pJ
sum error= 3
Actual label: 2
Output voltages: [0.303, 0.41354, 0.67955, 0.36888, 0.15693, 0.028192, 0.28445, 0.1773, 0.38029, 0.21917]
Predicted label: 2
Correct prediction
Energy consumption = 186.881207 pJ
sum error= 3
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 25 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 25 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 25 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.28235, 0.13719, 0.29769, 0.17731, 0.65145, 0.075858, 0.21282, 0.23158, 0.28163, 0.49676]
Predicted label: 4
Correct prediction
Energy consumption = 202.551917 pJ
sum error= 3
Actual label: 1
Output voltages: [0.25818, 0.74389, 0.13622, 0.26769, 0.27431, 0.2108, 0.30499, 0.0812, 0.28651, 0.21008]
Predicted label: 1
Correct prediction
Energy consumption = 213.580447 pJ
sum error= 3
Actual label: 9
Output voltages: [0.37189, 0.13948, 0.23168, 0.28116, 0.27515, 0.18365, 0.12954, 0.26862, 0.37025, 0.70582]
Predicted label: 9
Correct prediction
Energy consumption = 198.498834 pJ
sum error= 3
Actual label: 5
Output voltages: [0.22942, 0.063261, 0.10122, 0.45954, 0.17562, 0.70415, 0.19883, 0.19454, 0.48169, 0.30236]
Predicted label: 5
Correct prediction
Energy consumption = 186.933490 pJ
sum error= 3
Actual label: 7
Output voltages: [0.30631, 0.27257, 0.34061, 0.36508, 0.10584, 0.04587, 0.058859, 0.75348, 0.26242, 0.36013]
Predicted label: 7
Correct prediction
Energy consumption = 201.087310 pJ
sum error= 3
Actual label: 7
Output voltages: [0.36258, 0.33467, 0.49572, 0.3714, 0.098071, 0.023483, 0.1005, 0.60249, 0.32102, 0.27878]
Predicted label: 7
Correct prediction
Energy consumption = 197.234726 pJ
sum error= 3
Actual label: 2
Output voltages: [0.34321, 0.34298, 0.66652, 0.4109, 0.10915, 0.032424, 0.27427, 0.21661, 0.42901, 0.17746]
Predicted label: 2
Correct prediction
Energy consumption = 182.170509 pJ
sum error= 3
Actual label: 8
Output voltages: [0.33785, 0.29633, 0.26785, 0.39891, 0.1477, 0.11229, 0.43067, 0.10284, 0.64396, 0.13749]
Predicted label: 8
Correct prediction
Energy consumption = 200.039321 pJ
sum error= 3
Actual label: 2
Output voltages: [0.49187, 0.22629, 0.71773, 0.3988, 0.13735, 0.043915, 0.26654, 0.26032, 0.3166, 0.20176]
Predicted label: 2
Correct prediction
Energy consumption = 187.841944 pJ
sum error= 3
Actual label: 6
Output voltages: [0.54126, 0.16902, 0.13216, 0.12135, 0.28216, 0.41549, 0.62442, 0.1267, 0.36495, 0.17956]
Predicted label: 6
Correct prediction
Energy consumption = 192.708247 pJ
sum error= 3
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 26 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 26 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 26 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2245, 0.21604, 0.36112, 0.21855, 0.15199, 0.19299, 0.23263, 0.10273, 0.74602, 0.30816]
Predicted label: 8
Correct prediction
Energy consumption = 182.976592 pJ
sum error= 3
Actual label: 5
Output voltages: [0.27663, 0.20496, 0.056479, 0.33186, 0.15368, 0.70044, 0.15531, 0.10755, 0.56499, 0.16917]
Predicted label: 5
Correct prediction
Energy consumption = 202.023699 pJ
sum error= 3
Actual label: 7
Output voltages: [0.30183, 0.24348, 0.1516, 0.31061, 0.10393, 0.1305, 0.039892, 0.72938, 0.43535, 0.41731]
Predicted label: 7
Correct prediction
Energy consumption = 198.473069 pJ
sum error= 3
Actual label: 7
Output voltages: [0.30562, 0.29197, 0.28158, 0.32126, 0.15293, 0.036485, 0.050594, 0.74111, 0.32005, 0.33813]
Predicted label: 7
Correct prediction
Energy consumption = 191.560502 pJ
sum error= 3
Actual label: 9
Output voltages: [0.21247, 0.27405, 0.29048, 0.24412, 0.47978, 0.2047, 0.14554, 0.11047, 0.28815, 0.60295]
Predicted label: 9
Correct prediction
Energy consumption = 207.725570 pJ
sum error= 3
Actual label: 1
Output voltages: [0.13965, 0.77107, 0.26637, 0.29158, 0.19359, 0.13534, 0.38152, 0.18541, 0.29743, 0.21365]
Predicted label: 1
Correct prediction
Energy consumption = 206.570318 pJ
sum error= 3
Actual label: 8
Output voltages: [0.46889, 0.13223, 0.26, 0.41855, 0.16695, 0.17415, 0.29825, 0.10311, 0.58606, 0.21966]
Predicted label: 8
Correct prediction
Energy consumption = 204.383308 pJ
sum error= 3
Actual label: 1
Output voltages: [0.23194, 0.75241, 0.32512, 0.29375, 0.2655, 0.064601, 0.37204, 0.083402, 0.29109, 0.22276]
Predicted label: 1
Correct prediction
Energy consumption = 204.922972 pJ
sum error= 3
Actual label: 8
Output voltages: [0.30455, 0.074243, 0.3229, 0.2094, 0.1732, 0.31171, 0.21328, 0.085783, 0.71008, 0.34903]
Predicted label: 8
Correct prediction
Energy consumption = 189.280075 pJ
sum error= 3
Actual label: 0
Output voltages: [0.72469, 0.17344, 0.29524, 0.22136, 0.066462, 0.25038, 0.40324, 0.20244, 0.2695, 0.23423]
Predicted label: 0
Correct prediction
Energy consumption = 186.260334 pJ
sum error= 3
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 27 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 27 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 27 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.324, 0.14668, 0.31895, 0.75106, 0.17478, 0.30159, 0.14748, 0.17331, 0.43281, 0.22648]
Predicted label: 3
Correct prediction
Energy consumption = 179.674857 pJ
sum error= 3
Actual label: 0
Output voltages: [0.74292, 0.21155, 0.27842, 0.22868, 0.20982, 0.16137, 0.41396, 0.20182, 0.26368, 0.32093]
Predicted label: 0
Correct prediction
Energy consumption = 202.534004 pJ
sum error= 3
Actual label: 1
Output voltages: [0.1624, 0.77202, 0.23549, 0.30216, 0.20624, 0.16465, 0.34171, 0.20519, 0.31552, 0.25008]
Predicted label: 1
Correct prediction
Energy consumption = 216.309855 pJ
sum error= 3
Actual label: 9
Output voltages: [0.31781, 0.12108, 0.19822, 0.24964, 0.27039, 0.21782, 0.096483, 0.23545, 0.41436, 0.66234]
Predicted label: 9
Correct prediction
Energy consumption = 193.826938 pJ
sum error= 3
Actual label: 9
Output voltages: [0.34822, 0.12204, 0.18331, 0.41294, 0.29023, 0.31054, 0.10074, 0.29263, 0.30166, 0.67085]
Predicted label: 9
Correct prediction
Energy consumption = 194.413512 pJ
sum error= 3
Actual label: 4
Output voltages: [0.18233, 0.17144, 0.30425, 0.16283, 0.75522, 0.1019, 0.29239, 0.29056, 0.19113, 0.33112]
Predicted label: 4
Correct prediction
Energy consumption = 196.780413 pJ
sum error= 3
Actual label: 1
Output voltages: [0.19361, 0.75832, 0.29822, 0.28202, 0.24184, 0.05705, 0.31248, 0.14665, 0.34594, 0.24269]
Predicted label: 1
Correct prediction
Energy consumption = 211.215316 pJ
sum error= 3
Actual label: 8
Output voltages: [0.20146, 0.22396, 0.26568, 0.21407, 0.16189, 0.16977, 0.23945, 0.22227, 0.74421, 0.29183]
Predicted label: 8
Correct prediction
Energy consumption = 189.462984 pJ
sum error= 3
Actual label: 2
Output voltages: [0.34833, 0.23844, 0.74405, 0.24512, 0.15973, 0.030346, 0.31262, 0.285, 0.42428, 0.2143]
Predicted label: 2
Correct prediction
Energy consumption = 193.204579 pJ
sum error= 3
Actual label: 1
Output voltages: [0.24047, 0.76657, 0.27537, 0.26987, 0.14668, 0.098011, 0.35866, 0.11184, 0.3098, 0.29112]
Predicted label: 1
Correct prediction
Energy consumption = 210.905940 pJ
sum error= 3
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 28 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 28 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 28 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.37632, 0.30736, 0.71096, 0.33475, 0.17017, 0.033924, 0.32595, 0.16004, 0.47643, 0.20617]
Predicted label: 2
Correct prediction
Energy consumption = 191.208974 pJ
sum error= 3
Actual label: 9
Output voltages: [0.33335, 0.14428, 0.17567, 0.23917, 0.3577, 0.18881, 0.14542, 0.16223, 0.36979, 0.63765]
Predicted label: 9
Correct prediction
Energy consumption = 193.594691 pJ
sum error= 3
Actual label: 7
Output voltages: [0.2295, 0.34152, 0.43786, 0.58245, 0.11481, 0.041485, 0.15808, 0.41901, 0.36668, 0.23882]
Predicted label: 3
Wrong prediction!
Energy consumption = 202.980226 pJ
sum error= 4
Actual label: 5
Output voltages: [0.23507, 0.13374, 0.060338, 0.3704, 0.17472, 0.72341, 0.31212, 0.1136, 0.45521, 0.21539]
Predicted label: 5
Correct prediction
Energy consumption = 188.167183 pJ
sum error= 4
Actual label: 9
Output voltages: [0.40911, 0.09105, 0.26652, 0.21813, 0.41654, 0.15465, 0.19939, 0.22178, 0.21597, 0.64458]
Predicted label: 9
Correct prediction
Energy consumption = 199.076574 pJ
sum error= 4
Actual label: 2
Output voltages: [0.43411, 0.27669, 0.71844, 0.32076, 0.17507, 0.027367, 0.31079, 0.27269, 0.37384, 0.17868]
Predicted label: 2
Correct prediction
Energy consumption = 189.456020 pJ
sum error= 4
Actual label: 6
Output voltages: [0.29157, 0.18888, 0.21624, 0.17324, 0.26398, 0.39981, 0.67146, 0.10923, 0.51158, 0.14091]
Predicted label: 6
Correct prediction
Energy consumption = 193.481965 pJ
sum error= 4
Actual label: 4
Output voltages: [0.11617, 0.18454, 0.24628, 0.21171, 0.72824, 0.17908, 0.20572, 0.27489, 0.25483, 0.41331]
Predicted label: 4
Correct prediction
Energy consumption = 195.011597 pJ
sum error= 4
Actual label: 1
Output voltages: [0.15738, 0.72609, 0.055491, 0.22696, 0.27467, 0.23163, 0.37717, 0.20759, 0.41711, 0.18159]
Predicted label: 1
Correct prediction
Energy consumption = 214.158881 pJ
sum error= 4
Actual label: 5
Output voltages: [0.20634, 0.082891, 0.21677, 0.3367, 0.16413, 0.58749, 0.35079, 0.11969, 0.5874, 0.21195]
Predicted label: 5
Correct prediction
Energy consumption = 193.364018 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 29 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 29 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 29 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.19331, 0.14686, 0.074547, 0.31944, 0.38575, 0.47634, 0.37465, 0.047781, 0.49337, 0.25627]
Predicted label: 8
Correct prediction
Energy consumption = 208.456451 pJ
sum error= 4
Actual label: 2
Output voltages: [0.3534, 0.31509, 0.70918, 0.38854, 0.1177, 0.037371, 0.30865, 0.11971, 0.41018, 0.1696]
Predicted label: 2
Correct prediction
Energy consumption = 191.817133 pJ
sum error= 4
Actual label: 9
Output voltages: [0.44492, 0.13605, 0.29986, 0.29086, 0.27918, 0.19086, 0.18188, 0.19546, 0.26997, 0.68462]
Predicted label: 9
Correct prediction
Energy consumption = 203.597600 pJ
sum error= 4
Actual label: 2
Output voltages: [0.39902, 0.26447, 0.75278, 0.28948, 0.18262, 0.0328, 0.24959, 0.31473, 0.35843, 0.26592]
Predicted label: 2
Correct prediction
Energy consumption = 185.690703 pJ
sum error= 4
Actual label: 0
Output voltages: [0.73481, 0.25408, 0.26524, 0.29642, 0.098666, 0.22757, 0.34993, 0.15573, 0.30934, 0.23252]
Predicted label: 0
Correct prediction
Energy consumption = 205.655601 pJ
sum error= 4
Actual label: 4
Output voltages: [0.16729, 0.13974, 0.29526, 0.21043, 0.75233, 0.1708, 0.23064, 0.22717, 0.22986, 0.41078]
Predicted label: 4
Correct prediction
Energy consumption = 206.392226 pJ
sum error= 4
Actual label: 0
Output voltages: [0.74086, 0.27566, 0.30566, 0.19163, 0.14732, 0.17013, 0.37881, 0.17687, 0.26376, 0.22607]
Predicted label: 0
Correct prediction
Energy consumption = 189.099669 pJ
sum error= 4
Actual label: 0
Output voltages: [0.66844, 0.17934, 0.23085, 0.16104, 0.091278, 0.26133, 0.44293, 0.11224, 0.28966, 0.34225]
Predicted label: 0
Correct prediction
Energy consumption = 186.953046 pJ
sum error= 4
Actual label: 2
Output voltages: [0.35884, 0.22708, 0.7005, 0.43072, 0.097666, 0.039771, 0.31221, 0.15563, 0.46646, 0.17868]
Predicted label: 2
Correct prediction
Energy consumption = 184.125384 pJ
sum error= 4
Actual label: 8
Output voltages: [0.23592, 0.26096, 0.28092, 0.34884, 0.096173, 0.28148, 0.1931, 0.22622, 0.75356, 0.23222]
Predicted label: 8
Correct prediction
Energy consumption = 193.053110 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 30 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 30 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 30 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.20338, 0.25056, 0.40148, 0.18779, 0.58954, 0.048888, 0.518, 0.15445, 0.21656, 0.11804]
Predicted label: 4
Correct prediction
Energy consumption = 196.573723 pJ
sum error= 4
Actual label: 7
Output voltages: [0.32681, 0.0977, 0.29634, 0.42525, 0.21346, 0.061931, 0.044447, 0.66093, 0.35085, 0.36443]
Predicted label: 7
Correct prediction
Energy consumption = 193.802143 pJ
sum error= 4
Actual label: 1
Output voltages: [0.2056, 0.76645, 0.26691, 0.28682, 0.22888, 0.12008, 0.39494, 0.096796, 0.28788, 0.24755]
Predicted label: 1
Correct prediction
Energy consumption = 207.179719 pJ
sum error= 4
Actual label: 2
Output voltages: [0.35745, 0.1785, 0.73775, 0.32669, 0.15039, 0.038908, 0.26927, 0.32831, 0.43175, 0.23657]
Predicted label: 2
Correct prediction
Energy consumption = 176.653903 pJ
sum error= 4
Actual label: 4
Output voltages: [0.068876, 0.20414, 0.15297, 0.056212, 0.73374, 0.13911, 0.28228, 0.25657, 0.39048, 0.21152]
Predicted label: 4
Correct prediction
Energy consumption = 202.475349 pJ
sum error= 4
Actual label: 0
Output voltages: [0.64297, 0.17601, 0.2938, 0.1341, 0.096042, 0.27226, 0.35963, 0.083879, 0.40108, 0.27664]
Predicted label: 0
Correct prediction
Energy consumption = 196.298679 pJ
sum error= 4
Actual label: 2
Output voltages: [0.33378, 0.39699, 0.70921, 0.32372, 0.18515, 0.02607, 0.34064, 0.19303, 0.37187, 0.24422]
Predicted label: 2
Correct prediction
Energy consumption = 185.468468 pJ
sum error= 4
Actual label: 7
Output voltages: [0.26635, 0.20567, 0.3408, 0.43742, 0.22378, 0.034129, 0.041624, 0.66111, 0.35498, 0.30638]
Predicted label: 7
Correct prediction
Energy consumption = 183.946536 pJ
sum error= 4
Actual label: 4
Output voltages: [0.11161, 0.21153, 0.263, 0.12329, 0.71664, 0.063715, 0.26118, 0.20682, 0.34191, 0.19903]
Predicted label: 4
Correct prediction
Energy consumption = 199.196726 pJ
sum error= 4
Actual label: 3
Output voltages: [0.34694, 0.22547, 0.32569, 0.75929, 0.21972, 0.24575, 0.23431, 0.16426, 0.40216, 0.177]
Predicted label: 3
Correct prediction
Energy consumption = 189.654042 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 31 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 31 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 31 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.31319, 0.20003, 0.30307, 0.75553, 0.21157, 0.18015, 0.14033, 0.20161, 0.43831, 0.23301]
Predicted label: 3
Correct prediction
Energy consumption = 194.503145 pJ
sum error= 4
Actual label: 0
Output voltages: [0.68353, 0.15639, 0.2919, 0.11512, 0.23694, 0.16007, 0.43701, 0.18272, 0.3342, 0.29923]
Predicted label: 0
Correct prediction
Energy consumption = 197.271712 pJ
sum error= 4
Actual label: 0
Output voltages: [0.72361, 0.22399, 0.2883, 0.19237, 0.19998, 0.11869, 0.43777, 0.15303, 0.3263, 0.29645]
Predicted label: 0
Correct prediction
Energy consumption = 198.313323 pJ
sum error= 4
Actual label: 3
Output voltages: [0.21191, 0.063911, 0.24995, 0.71675, 0.28781, 0.4122, 0.23204, 0.15537, 0.4141, 0.1017]
Predicted label: 3
Correct prediction
Energy consumption = 187.630938 pJ
sum error= 4
Actual label: 1
Output voltages: [0.19267, 0.76964, 0.20486, 0.35741, 0.25179, 0.14435, 0.37022, 0.20069, 0.23124, 0.27224]
Predicted label: 1
Correct prediction
Energy consumption = 214.268708 pJ
sum error= 4
Actual label: 9
Output voltages: [0.35095, 0.11918, 0.19805, 0.24986, 0.26722, 0.25449, 0.16997, 0.29121, 0.36549, 0.68304]
Predicted label: 9
Correct prediction
Energy consumption = 197.050835 pJ
sum error= 4
Actual label: 6
Output voltages: [0.33646, 0.21873, 0.16599, 0.2149, 0.24318, 0.46495, 0.70598, 0.11978, 0.43991, 0.12666]
Predicted label: 6
Correct prediction
Energy consumption = 191.081828 pJ
sum error= 4
Actual label: 5
Output voltages: [0.254, 0.053902, 0.069944, 0.2987, 0.23775, 0.69611, 0.2911, 0.23301, 0.59357, 0.11644]
Predicted label: 5
Correct prediction
Energy consumption = 183.188604 pJ
sum error= 4
Actual label: 2
Output voltages: [0.46341, 0.065311, 0.57422, 0.49357, 0.11098, 0.080061, 0.25402, 0.20704, 0.5541, 0.21628]
Predicted label: 2
Correct prediction
Energy consumption = 193.660897 pJ
sum error= 4
Actual label: 5
Output voltages: [0.22334, 0.0458, 0.21276, 0.27894, 0.25866, 0.63104, 0.30246, 0.099191, 0.59049, 0.25282]
Predicted label: 5
Correct prediction
Energy consumption = 186.468032 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 32 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 32 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 32 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.22111, 0.5053, 0.17318, 0.33174, 0.12394, 0.14402, 0.11444, 0.19704, 0.58692, 0.43491]
Predicted label: 8
Wrong prediction!
Energy consumption = 208.385183 pJ
sum error= 5
Actual label: 2
Output voltages: [0.3093, 0.38542, 0.47662, 0.44428, 0.043764, 0.043127, 0.18842, 0.39971, 0.45738, 0.23558]
Predicted label: 2
Correct prediction
Energy consumption = 200.763153 pJ
sum error= 5
Actual label: 9
Output voltages: [0.40267, 0.13097, 0.21366, 0.25079, 0.35893, 0.19874, 0.095164, 0.24372, 0.32885, 0.68536]
Predicted label: 9
Correct prediction
Energy consumption = 192.320409 pJ
sum error= 5
Actual label: 3
Output voltages: [0.33872, 0.24141, 0.27667, 0.7593, 0.12153, 0.21517, 0.13615, 0.18448, 0.48424, 0.23383]
Predicted label: 3
Correct prediction
Energy consumption = 188.067386 pJ
sum error= 5
Actual label: 0
Output voltages: [0.56408, 0.25349, 0.042584, 0.30419, 0.21001, 0.40621, 0.45775, 0.099111, 0.31723, 0.24452]
Predicted label: 0
Correct prediction
Energy consumption = 214.591087 pJ
sum error= 5
Actual label: 4
Output voltages: [0.18073, 0.19698, 0.17966, 0.13018, 0.6924, 0.094707, 0.31772, 0.22901, 0.31321, 0.20297]
Predicted label: 4
Correct prediction
Energy consumption = 198.027002 pJ
sum error= 5
Actual label: 2
Output voltages: [0.24382, 0.43658, 0.62023, 0.22331, 0.36912, 0.11692, 0.44497, 0.1586, 0.23498, 0.08601]
Predicted label: 2
Correct prediction
Energy consumption = 197.612847 pJ
sum error= 5
Actual label: 0
Output voltages: [0.70145, 0.26379, 0.2305, 0.18907, 0.15552, 0.12939, 0.45737, 0.18176, 0.32446, 0.26652]
Predicted label: 0
Correct prediction
Energy consumption = 196.649277 pJ
sum error= 5
Actual label: 7
Output voltages: [0.19594, 0.23154, 0.35084, 0.23378, 0.19819, 0.044629, 0.064232, 0.75377, 0.32685, 0.21782]
Predicted label: 7
Correct prediction
Energy consumption = 198.167564 pJ
sum error= 5
Actual label: 1
Output voltages: [0.16185, 0.76738, 0.22336, 0.29373, 0.19122, 0.11041, 0.39825, 0.14972, 0.34002, 0.21129]
Predicted label: 1
Correct prediction
Energy consumption = 210.364497 pJ
sum error= 5
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 33 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 33 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 33 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23165, 0.75783, 0.29154, 0.39229, 0.21154, 0.077151, 0.40731, 0.11047, 0.25074, 0.25434]
Predicted label: 1
Correct prediction
Energy consumption = 215.231465 pJ
sum error= 5
Actual label: 2
Output voltages: [0.32914, 0.38504, 0.71708, 0.31713, 0.15451, 0.023153, 0.31251, 0.20366, 0.36542, 0.26282]
Predicted label: 2
Correct prediction
Energy consumption = 186.928345 pJ
sum error= 5
Actual label: 1
Output voltages: [0.19682, 0.75378, 0.25183, 0.23302, 0.20929, 0.10747, 0.39521, 0.058796, 0.36613, 0.25409]
Predicted label: 1
Correct prediction
Energy consumption = 212.123815 pJ
sum error= 5
Actual label: 5
Output voltages: [0.21031, 0.10817, 0.16685, 0.2973, 0.16993, 0.67121, 0.2433, 0.074229, 0.54549, 0.22385]
Predicted label: 5
Correct prediction
Energy consumption = 189.192234 pJ
sum error= 5
Actual label: 3
Output voltages: [0.33116, 0.21375, 0.27889, 0.76186, 0.12645, 0.18877, 0.15077, 0.22982, 0.41539, 0.23223]
Predicted label: 3
Correct prediction
Energy consumption = 187.928801 pJ
sum error= 5
Actual label: 3
Output voltages: [0.30772, 0.27822, 0.35337, 0.74566, 0.14639, 0.0915, 0.17896, 0.11081, 0.4023, 0.24068]
Predicted label: 3
Correct prediction
Energy consumption = 185.222173 pJ
sum error= 5
Actual label: 9
Output voltages: [0.39253, 0.10413, 0.25496, 0.24085, 0.50093, 0.18952, 0.15687, 0.17409, 0.2467, 0.66202]
Predicted label: 9
Correct prediction
Energy consumption = 197.652343 pJ
sum error= 5
Actual label: 7
Output voltages: [0.37366, 0.18993, 0.28625, 0.4927, 0.044084, 0.11302, 0.0534, 0.69303, 0.30391, 0.33954]
Predicted label: 7
Correct prediction
Energy consumption = 196.941978 pJ
sum error= 5
Actual label: 8
Output voltages: [0.42059, 0.10126, 0.37391, 0.27384, 0.12144, 0.2403, 0.1633, 0.085934, 0.72149, 0.24975]
Predicted label: 8
Correct prediction
Energy consumption = 192.929594 pJ
sum error= 5
Actual label: 6
Output voltages: [0.26077, 0.20598, 0.28127, 0.14525, 0.26198, 0.39157, 0.7275, 0.058944, 0.40582, 0.15161]
Predicted label: 6
Correct prediction
Energy consumption = 180.542131 pJ
sum error= 5
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 34 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 34 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 34 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22013, 0.1776, 0.1389, 0.40435, 0.20621, 0.50797, 0.43157, 0.0491, 0.35058, 0.15886]
Predicted label: 5
Correct prediction
Energy consumption = 210.954304 pJ
sum error= 5
Actual label: 6
Output voltages: [0.27957, 0.095862, 0.27261, 0.13549, 0.27725, 0.30626, 0.64121, 0.12968, 0.44135, 0.19542]
Predicted label: 6
Correct prediction
Energy consumption = 200.355940 pJ
sum error= 5
Actual label: 1
Output voltages: [0.18005, 0.76818, 0.24715, 0.30561, 0.19925, 0.097814, 0.41879, 0.18805, 0.27696, 0.19126]
Predicted label: 1
Correct prediction
Energy consumption = 213.614266 pJ
sum error= 5
Actual label: 3
Output voltages: [0.36634, 0.1719, 0.23042, 0.7411, 0.24438, 0.4385, 0.21488, 0.12844, 0.33548, 0.18669]
Predicted label: 3
Correct prediction
Energy consumption = 193.858510 pJ
sum error= 5
Actual label: 8
Output voltages: [0.20621, 0.17422, 0.2649, 0.28914, 0.22227, 0.28333, 0.40538, 0.054535, 0.65888, 0.21951]
Predicted label: 8
Correct prediction
Energy consumption = 197.485093 pJ
sum error= 5
Actual label: 1
Output voltages: [0.24544, 0.74385, 0.29578, 0.31865, 0.30189, 0.05291, 0.30558, 0.14202, 0.31169, 0.24295]
Predicted label: 1
Correct prediction
Energy consumption = 215.703868 pJ
sum error= 5
Actual label: 0
Output voltages: [0.71074, 0.23946, 0.27694, 0.21284, 0.16977, 0.1391, 0.30355, 0.18406, 0.41136, 0.3356]
Predicted label: 0
Correct prediction
Energy consumption = 203.802500 pJ
sum error= 5
Actual label: 5
Output voltages: [0.19794, 0.050786, 0.081519, 0.32923, 0.29857, 0.64731, 0.2743, 0.086997, 0.53297, 0.25601]
Predicted label: 5
Correct prediction
Energy consumption = 183.721685 pJ
sum error= 5
Actual label: 1
Output voltages: [0.16617, 0.75289, 0.18615, 0.28216, 0.20897, 0.13201, 0.46448, 0.1597, 0.35039, 0.18492]
Predicted label: 1
Correct prediction
Energy consumption = 217.558208 pJ
sum error= 5
Actual label: 3
Output voltages: [0.20621, 0.23576, 0.33594, 0.73592, 0.11348, 0.088805, 0.091206, 0.28301, 0.43569, 0.26719]
Predicted label: 3
Correct prediction
Energy consumption = 191.504940 pJ
sum error= 5
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 35 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 35 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 35 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1819, 0.69289, 0.26619, 0.43512, 0.28682, 0.073422, 0.1809, 0.22357, 0.2962, 0.26323]
Predicted label: 1
Correct prediction
Energy consumption = 215.487598 pJ
sum error= 5
Actual label: 5
Output voltages: [0.27219, 0.05505, 0.14677, 0.36475, 0.1814, 0.69086, 0.30772, 0.18842, 0.55757, 0.24746]
Predicted label: 5
Correct prediction
Energy consumption = 188.844682 pJ
sum error= 5
Actual label: 5
Output voltages: [0.42009, 0.076927, 0.082012, 0.37902, 0.17554, 0.72948, 0.22055, 0.21736, 0.45625, 0.30075]
Predicted label: 5
Correct prediction
Energy consumption = 183.461641 pJ
sum error= 5
Actual label: 6
Output voltages: [0.37786, 0.23581, 0.2779, 0.1214, 0.31657, 0.25423, 0.71356, 0.068229, 0.38593, 0.16335]
Predicted label: 6
Correct prediction
Energy consumption = 194.711671 pJ
sum error= 5
Actual label: 1
Output voltages: [0.24733, 0.68688, 0.31625, 0.17715, 0.40686, 0.057697, 0.31698, 0.11835, 0.2797, 0.21287]
Predicted label: 1
Correct prediction
Energy consumption = 200.964269 pJ
sum error= 5
Actual label: 8
Output voltages: [0.22069, 0.13981, 0.12683, 0.33713, 0.19346, 0.41575, 0.37437, 0.06938, 0.71048, 0.24755]
Predicted label: 8
Correct prediction
Energy consumption = 194.806603 pJ
sum error= 5
Actual label: 5
Output voltages: [0.23613, 0.05896, 0.071871, 0.3462, 0.22519, 0.74342, 0.3197, 0.22999, 0.51896, 0.25481]
Predicted label: 5
Correct prediction
Energy consumption = 183.457181 pJ
sum error= 5
Actual label: 1
Output voltages: [0.22897, 0.75956, 0.19469, 0.28021, 0.21922, 0.13661, 0.33168, 0.069346, 0.35559, 0.25997]
Predicted label: 1
Correct prediction
Energy consumption = 221.595725 pJ
sum error= 5
Actual label: 7
Output voltages: [0.27683, 0.43113, 0.2857, 0.24371, 0.28984, 0.03806, 0.040222, 0.59412, 0.12514, 0.40849]
Predicted label: 7
Correct prediction
Energy consumption = 207.800981 pJ
sum error= 5
Actual label: 9
Output voltages: [0.2802, 0.16719, 0.27722, 0.17368, 0.40059, 0.055177, 0.072657, 0.14448, 0.40791, 0.59097]
Predicted label: 9
Correct prediction
Energy consumption = 189.839884 pJ
sum error= 5
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 36 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 36 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 36 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.17832, 0.082861, 0.28553, 0.13458, 0.69469, 0.26534, 0.28027, 0.27234, 0.2766, 0.43582]
Predicted label: 4
Correct prediction
Energy consumption = 196.205264 pJ
sum error= 5
Actual label: 6
Output voltages: [0.333, 0.24432, 0.25761, 0.13891, 0.30137, 0.445, 0.74922, 0.11955, 0.3654, 0.16245]
Predicted label: 6
Correct prediction
Energy consumption = 187.102205 pJ
sum error= 5
Actual label: 2
Output voltages: [0.41909, 0.31586, 0.65428, 0.26221, 0.10272, 0.026566, 0.23073, 0.46151, 0.3198, 0.20166]
Predicted label: 2
Correct prediction
Energy consumption = 197.744234 pJ
sum error= 5
Actual label: 2
Output voltages: [0.34961, 0.53836, 0.65898, 0.27467, 0.15238, 0.029204, 0.33581, 0.23759, 0.29844, 0.178]
Predicted label: 2
Correct prediction
Energy consumption = 180.492141 pJ
sum error= 5
Actual label: 5
Output voltages: [0.18652, 0.049244, 0.14631, 0.32074, 0.23201, 0.63978, 0.28911, 0.15523, 0.56534, 0.26574]
Predicted label: 5
Correct prediction
Energy consumption = 186.451946 pJ
sum error= 5
Actual label: 0
Output voltages: [0.68272, 0.18445, 0.23913, 0.25831, 0.23347, 0.13346, 0.34197, 0.17291, 0.44463, 0.30461]
Predicted label: 0
Correct prediction
Energy consumption = 207.121819 pJ
sum error= 5
Actual label: 6
Output voltages: [0.50415, 0.24834, 0.22629, 0.077987, 0.22846, 0.26612, 0.67793, 0.1882, 0.3315, 0.18047]
Predicted label: 6
Correct prediction
Energy consumption = 189.380693 pJ
sum error= 5
Actual label: 5
Output voltages: [0.19742, 0.047529, 0.26825, 0.4212, 0.20059, 0.53697, 0.14749, 0.14283, 0.62409, 0.24836]
Predicted label: 8
Wrong prediction!
Energy consumption = 189.879898 pJ
sum error= 6
Actual label: 6
Output voltages: [0.35311, 0.14969, 0.16411, 0.21523, 0.31339, 0.45729, 0.67386, 0.056658, 0.43536, 0.16793]
Predicted label: 6
Correct prediction
Energy consumption = 189.958463 pJ
sum error= 6
Actual label: 3
Output voltages: [0.36434, 0.12502, 0.29826, 0.7407, 0.12033, 0.23843, 0.069346, 0.27869, 0.47411, 0.30562]
Predicted label: 3
Correct prediction
Energy consumption = 187.317630 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 37 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 37 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 37 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.39891, 0.37091, 0.36476, 0.38825, 0.06186, 0.054555, 0.070198, 0.69518, 0.26383, 0.41549]
Predicted label: 7
Correct prediction
Energy consumption = 206.941267 pJ
sum error= 6
Actual label: 2
Output voltages: [0.41932, 0.26607, 0.73248, 0.31667, 0.17338, 0.03457, 0.32507, 0.23952, 0.43187, 0.14487]
Predicted label: 2
Correct prediction
Energy consumption = 186.772856 pJ
sum error= 6
Actual label: 0
Output voltages: [0.71071, 0.18074, 0.26565, 0.19476, 0.1221, 0.3277, 0.36704, 0.15183, 0.34138, 0.29183]
Predicted label: 0
Correct prediction
Energy consumption = 205.050496 pJ
sum error= 6
Actual label: 8
Output voltages: [0.27227, 0.20851, 0.36069, 0.25213, 0.21055, 0.082619, 0.30907, 0.10284, 0.72025, 0.3115]
Predicted label: 8
Correct prediction
Energy consumption = 194.283627 pJ
sum error= 6
Actual label: 8
Output voltages: [0.2519, 0.17298, 0.34427, 0.24441, 0.16787, 0.19294, 0.21932, 0.10748, 0.74349, 0.31237]
Predicted label: 8
Correct prediction
Energy consumption = 191.835931 pJ
sum error= 6
Actual label: 5
Output voltages: [0.22719, 0.05578, 0.09055, 0.3113, 0.23123, 0.6981, 0.362, 0.11308, 0.49569, 0.22659]
Predicted label: 5
Correct prediction
Energy consumption = 185.646077 pJ
sum error= 6
Actual label: 4
Output voltages: [0.24395, 0.19504, 0.19954, 0.30891, 0.67607, 0.15929, 0.1747, 0.22425, 0.18079, 0.47388]
Predicted label: 4
Correct prediction
Energy consumption = 202.066665 pJ
sum error= 6
Actual label: 1
Output voltages: [0.21074, 0.7683, 0.21555, 0.31546, 0.27438, 0.13063, 0.33, 0.17443, 0.24765, 0.27907]
Predicted label: 1
Correct prediction
Energy consumption = 216.448201 pJ
sum error= 6
Actual label: 1
Output voltages: [0.18255, 0.76975, 0.3026, 0.26925, 0.24841, 0.066172, 0.35608, 0.14528, 0.29336, 0.26155]
Predicted label: 1
Correct prediction
Energy consumption = 204.484623 pJ
sum error= 6
Actual label: 4
Output voltages: [0.17466, 0.16129, 0.30708, 0.14769, 0.75466, 0.064391, 0.28961, 0.28876, 0.23684, 0.29164]
Predicted label: 4
Correct prediction
Energy consumption = 194.943680 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 38 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 38 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 38 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.66425, 0.25106, 0.41755, 0.13421, 0.081585, 0.15229, 0.38837, 0.098195, 0.3308, 0.27777]
Predicted label: 0
Correct prediction
Energy consumption = 197.355481 pJ
sum error= 6
Actual label: 3
Output voltages: [0.32293, 0.16465, 0.4336, 0.66819, 0.046298, 0.065098, 0.12894, 0.39319, 0.4837, 0.22327]
Predicted label: 3
Correct prediction
Energy consumption = 193.732944 pJ
sum error= 6
Actual label: 3
Output voltages: [0.293, 0.128, 0.27403, 0.75334, 0.21623, 0.17579, 0.17075, 0.22056, 0.45308, 0.26776]
Predicted label: 3
Correct prediction
Energy consumption = 180.203960 pJ
sum error= 6
Actual label: 7
Output voltages: [0.31786, 0.27678, 0.26297, 0.39318, 0.12302, 0.062021, 0.048697, 0.7504, 0.31866, 0.35544]
Predicted label: 7
Correct prediction
Energy consumption = 192.482363 pJ
sum error= 6
Actual label: 6
Output voltages: [0.29102, 0.24378, 0.35751, 0.11122, 0.30607, 0.27883, 0.74599, 0.053402, 0.37195, 0.2072]
Predicted label: 6
Correct prediction
Energy consumption = 186.222484 pJ
sum error= 6
Actual label: 1
Output voltages: [0.19174, 0.77238, 0.18093, 0.26095, 0.26605, 0.12667, 0.39345, 0.11492, 0.29398, 0.23955]
Predicted label: 1
Correct prediction
Energy consumption = 210.984632 pJ
sum error= 6
Actual label: 6
Output voltages: [0.39731, 0.17048, 0.14228, 0.19886, 0.29653, 0.45549, 0.66893, 0.13615, 0.4324, 0.14566]
Predicted label: 6
Correct prediction
Energy consumption = 194.487355 pJ
sum error= 6
Actual label: 2
Output voltages: [0.33376, 0.33266, 0.73865, 0.37741, 0.17826, 0.031, 0.26131, 0.25691, 0.32602, 0.24468]
Predicted label: 2
Correct prediction
Energy consumption = 184.810754 pJ
sum error= 6
Actual label: 1
Output voltages: [0.34188, 0.68907, 0.31534, 0.080728, 0.38721, 0.052353, 0.28633, 0.16291, 0.28592, 0.31846]
Predicted label: 1
Correct prediction
Energy consumption = 204.655286 pJ
sum error= 6
Actual label: 9
Output voltages: [0.31176, 0.10677, 0.20712, 0.15755, 0.27206, 0.17798, 0.07918, 0.24421, 0.48667, 0.62602]
Predicted label: 9
Correct prediction
Energy consumption = 189.128260 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 39 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 39 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 39 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.41091, 0.11284, 0.73226, 0.31428, 0.13509, 0.055426, 0.29258, 0.23761, 0.38198, 0.14268]
Predicted label: 2
Correct prediction
Energy consumption = 198.221787 pJ
sum error= 6
Actual label: 8
Output voltages: [0.30373, 0.14577, 0.35193, 0.27041, 0.20768, 0.12352, 0.22568, 0.15024, 0.73412, 0.18762]
Predicted label: 8
Correct prediction
Energy consumption = 192.950106 pJ
sum error= 6
Actual label: 6
Output voltages: [0.31911, 0.19124, 0.21833, 0.18045, 0.30618, 0.4127, 0.72752, 0.077027, 0.34192, 0.16923]
Predicted label: 6
Correct prediction
Energy consumption = 188.416941 pJ
sum error= 6
Actual label: 1
Output voltages: [0.24363, 0.74516, 0.2403, 0.2676, 0.3601, 0.048012, 0.24928, 0.16722, 0.2625, 0.31628]
Predicted label: 1
Correct prediction
Energy consumption = 218.573335 pJ
sum error= 6
Actual label: 9
Output voltages: [0.36347, 0.15691, 0.15988, 0.28144, 0.36517, 0.17553, 0.14608, 0.2366, 0.31906, 0.63384]
Predicted label: 9
Correct prediction
Energy consumption = 192.276585 pJ
sum error= 6
Actual label: 5
Output voltages: [0.2328, 0.046436, 0.11442, 0.40849, 0.21316, 0.67563, 0.28389, 0.21705, 0.49949, 0.27189]
Predicted label: 5
Correct prediction
Energy consumption = 185.168076 pJ
sum error= 6
Actual label: 2
Output voltages: [0.36714, 0.21034, 0.69362, 0.29269, 0.26657, 0.037755, 0.27757, 0.33104, 0.39008, 0.1552]
Predicted label: 2
Correct prediction
Energy consumption = 188.973354 pJ
sum error= 6
Actual label: 5
Output voltages: [0.1545, 0.049236, 0.19903, 0.36603, 0.29586, 0.52008, 0.2681, 0.08728, 0.58771, 0.27821]
Predicted label: 8
Wrong prediction!
Energy consumption = 187.848258 pJ
sum error= 7
Actual label: 4
Output voltages: [0.16919, 0.18262, 0.3302, 0.14548, 0.75879, 0.062229, 0.28599, 0.32694, 0.19549, 0.29636]
Predicted label: 4
Correct prediction
Energy consumption = 191.858208 pJ
sum error= 7
Actual label: 4
Output voltages: [0.1422, 0.21961, 0.35084, 0.13223, 0.74677, 0.055283, 0.28387, 0.31622, 0.18305, 0.29503]
Predicted label: 4
Correct prediction
Energy consumption = 181.963938 pJ
sum error= 7
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 40 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 40 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 40 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.39256, 0.13468, 0.71963, 0.36257, 0.12586, 0.037771, 0.20295, 0.31199, 0.4363, 0.15533]
Predicted label: 2
Correct prediction
Energy consumption = 201.169360 pJ
sum error= 7
Actual label: 8
Output voltages: [0.26685, 0.14844, 0.37516, 0.4295, 0.10925, 0.086054, 0.22955, 0.18168, 0.68706, 0.25891]
Predicted label: 8
Correct prediction
Energy consumption = 196.661112 pJ
sum error= 7
Actual label: 3
Output voltages: [0.34691, 0.063597, 0.4326, 0.69033, 0.24954, 0.26008, 0.17828, 0.14202, 0.41428, 0.14489]
Predicted label: 3
Correct prediction
Energy consumption = 188.238872 pJ
sum error= 7
Actual label: 8
Output voltages: [0.17302, 0.175, 0.28748, 0.3055, 0.13044, 0.18221, 0.19827, 0.17022, 0.71067, 0.29387]
Predicted label: 8
Correct prediction
Energy consumption = 197.976792 pJ
sum error= 7
Actual label: 2
Output voltages: [0.26312, 0.29911, 0.66943, 0.37685, 0.081589, 0.032674, 0.20327, 0.33909, 0.46134, 0.18545]
Predicted label: 2
Correct prediction
Energy consumption = 195.898286 pJ
sum error= 7
Actual label: 4
Output voltages: [0.18579, 0.11469, 0.33589, 0.15956, 0.70518, 0.14849, 0.21576, 0.1352, 0.3168, 0.44904]
Predicted label: 4
Correct prediction
Energy consumption = 200.788045 pJ
sum error= 7
Actual label: 5
Output voltages: [0.3916, 0.050457, 0.094069, 0.31965, 0.19174, 0.54424, 0.29436, 0.12053, 0.53161, 0.32898]
Predicted label: 5
Correct prediction
Energy consumption = 199.112166 pJ
sum error= 7
Actual label: 0
Output voltages: [0.73475, 0.29668, 0.20501, 0.19865, 0.13731, 0.26717, 0.4183, 0.16057, 0.27927, 0.24425]
Predicted label: 0
Correct prediction
Energy consumption = 193.115459 pJ
sum error= 7
Actual label: 3
Output voltages: [0.38672, 0.19036, 0.28941, 0.74897, 0.15796, 0.17952, 0.28235, 0.1634, 0.38745, 0.16327]
Predicted label: 3
Correct prediction
Energy consumption = 198.129287 pJ
sum error= 7
Actual label: 1
Output voltages: [0.12046, 0.73684, 0.14041, 0.24988, 0.27859, 0.2433, 0.40313, 0.092949, 0.33766, 0.27339]
Predicted label: 1
Correct prediction
Energy consumption = 208.705599 pJ
sum error= 7
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 41 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 41 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 41 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32637, 0.23977, 0.17587, 0.33746, 0.13075, 0.14073, 0.040911, 0.7512, 0.32499, 0.41156]
Predicted label: 7
Correct prediction
Energy consumption = 200.965597 pJ
sum error= 7
Actual label: 7
Output voltages: [0.28944, 0.39154, 0.39034, 0.32569, 0.074176, 0.041556, 0.076237, 0.62766, 0.44083, 0.3278]
Predicted label: 7
Correct prediction
Energy consumption = 200.439018 pJ
sum error= 7
Actual label: 5
Output voltages: [0.2771, 0.06096, 0.070269, 0.48799, 0.19335, 0.64558, 0.14763, 0.20987, 0.49084, 0.28779]
Predicted label: 5
Correct prediction
Energy consumption = 193.468344 pJ
sum error= 7
Actual label: 7
Output voltages: [0.36246, 0.18896, 0.22902, 0.22399, 0.16513, 0.12942, 0.045088, 0.75479, 0.38143, 0.32827]
Predicted label: 7
Correct prediction
Energy consumption = 196.633512 pJ
sum error= 7
Actual label: 9
Output voltages: [0.32317, 0.21936, 0.17477, 0.31946, 0.48711, 0.17458, 0.21647, 0.22268, 0.17784, 0.64666]
Predicted label: 9
Correct prediction
Energy consumption = 203.277570 pJ
sum error= 7
Actual label: 7
Output voltages: [0.26929, 0.17984, 0.19555, 0.28472, 0.20397, 0.15835, 0.044028, 0.7536, 0.30328, 0.33839]
Predicted label: 7
Correct prediction
Energy consumption = 197.629656 pJ
sum error= 7
Actual label: 1
Output voltages: [0.16128, 0.76625, 0.20647, 0.25047, 0.1983, 0.13664, 0.46643, 0.097694, 0.32488, 0.22308]
Predicted label: 1
Correct prediction
Energy consumption = 205.410545 pJ
sum error= 7
Actual label: 9
Output voltages: [0.25402, 0.11838, 0.17083, 0.32419, 0.21646, 0.10955, 0.050929, 0.35471, 0.48004, 0.59351]
Predicted label: 9
Correct prediction
Energy consumption = 194.092904 pJ
sum error= 7
Actual label: 2
Output voltages: [0.39389, 0.15037, 0.72532, 0.33135, 0.17131, 0.036164, 0.24269, 0.28088, 0.46174, 0.16169]
Predicted label: 2
Correct prediction
Energy consumption = 181.475455 pJ
sum error= 7
Actual label: 1
Output voltages: [0.14956, 0.76646, 0.18858, 0.34617, 0.19889, 0.18444, 0.38124, 0.21975, 0.31666, 0.20811]
Predicted label: 1
Correct prediction
Energy consumption = 210.893555 pJ
sum error= 7
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 42 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 42 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 42 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.21971, 0.13044, 0.29819, 0.13684, 0.731, 0.056496, 0.18339, 0.33009, 0.22899, 0.27172]
Predicted label: 4
Correct prediction
Energy consumption = 192.389787 pJ
sum error= 7
Actual label: 2
Output voltages: [0.31979, 0.2014, 0.72756, 0.32114, 0.10506, 0.038915, 0.23946, 0.28733, 0.4627, 0.16864]
Predicted label: 2
Correct prediction
Energy consumption = 190.926723 pJ
sum error= 7
Actual label: 9
Output voltages: [0.33139, 0.1354, 0.21771, 0.2432, 0.26451, 0.16111, 0.066486, 0.25023, 0.39596, 0.67338]
Predicted label: 9
Correct prediction
Energy consumption = 195.823515 pJ
sum error= 7
Actual label: 2
Output voltages: [0.43835, 0.31631, 0.73492, 0.31639, 0.1156, 0.032707, 0.26991, 0.2636, 0.40727, 0.25335]
Predicted label: 2
Correct prediction
Energy consumption = 187.642436 pJ
sum error= 7
Actual label: 0
Output voltages: [0.71582, 0.25244, 0.28034, 0.13726, 0.21391, 0.18425, 0.46607, 0.15394, 0.26151, 0.36065]
Predicted label: 0
Correct prediction
Energy consumption = 197.357585 pJ
sum error= 7
Actual label: 4
Output voltages: [0.18216, 0.19165, 0.3503, 0.059549, 0.75053, 0.06767, 0.37877, 0.25685, 0.22745, 0.28623]
Predicted label: 4
Correct prediction
Energy consumption = 197.042045 pJ
sum error= 7
Actual label: 9
Output voltages: [0.37064, 0.12031, 0.20373, 0.27779, 0.3269, 0.10588, 0.05499, 0.22685, 0.36851, 0.64523]
Predicted label: 9
Correct prediction
Energy consumption = 188.611288 pJ
sum error= 7
Actual label: 1
Output voltages: [0.24333, 0.76344, 0.24716, 0.28354, 0.22319, 0.14107, 0.3614, 0.088128, 0.31238, 0.26713]
Predicted label: 1
Correct prediction
Energy consumption = 211.509161 pJ
sum error= 7
Actual label: 4
Output voltages: [0.15234, 0.24841, 0.30623, 0.13562, 0.74763, 0.10162, 0.40852, 0.21398, 0.23502, 0.15184]
Predicted label: 4
Correct prediction
Energy consumption = 196.313228 pJ
sum error= 7
Actual label: 8
Output voltages: [0.15893, 0.17384, 0.25755, 0.26341, 0.17188, 0.25295, 0.22598, 0.12305, 0.73849, 0.33927]
Predicted label: 8
Correct prediction
Energy consumption = 193.493254 pJ
sum error= 7
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 43 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 43 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 43 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17887, 0.75638, 0.22671, 0.12632, 0.27263, 0.15194, 0.4878, 0.064756, 0.34288, 0.19855]
Predicted label: 1
Correct prediction
Energy consumption = 209.670052 pJ
sum error= 7
Actual label: 8
Output voltages: [0.23986, 0.16221, 0.3813, 0.21818, 0.18427, 0.18275, 0.21088, 0.12042, 0.74293, 0.39174]
Predicted label: 8
Correct prediction
Energy consumption = 190.240795 pJ
sum error= 7
Actual label: 4
Output voltages: [0.11728, 0.19045, 0.30515, 0.25194, 0.74998, 0.16783, 0.33, 0.28259, 0.19754, 0.24975]
Predicted label: 4
Correct prediction
Energy consumption = 202.325636 pJ
sum error= 7
Actual label: 5
Output voltages: [0.24069, 0.077662, 0.058611, 0.45255, 0.26406, 0.6599, 0.2704, 0.083374, 0.50157, 0.15633]
Predicted label: 5
Correct prediction
Energy consumption = 182.760650 pJ
sum error= 7
Actual label: 9
Output voltages: [0.37804, 0.15851, 0.22487, 0.3127, 0.2667, 0.19837, 0.16987, 0.25062, 0.30996, 0.72292]
Predicted label: 9
Correct prediction
Energy consumption = 195.711472 pJ
sum error= 7
Actual label: 8
Output voltages: [0.23551, 0.3634, 0.33916, 0.30947, 0.12707, 0.048137, 0.067484, 0.38348, 0.61182, 0.23353]
Predicted label: 8
Correct prediction
Energy consumption = 197.877166 pJ
sum error= 7
Actual label: 8
Output voltages: [0.20303, 0.2569, 0.30841, 0.17495, 0.2292, 0.14566, 0.18585, 0.11026, 0.73021, 0.32314]
Predicted label: 8
Correct prediction
Energy consumption = 196.878690 pJ
sum error= 7
Actual label: 3
Output voltages: [0.2441, 0.12695, 0.2775, 0.73885, 0.23516, 0.2795, 0.094491, 0.22655, 0.50349, 0.18919]
Predicted label: 3
Correct prediction
Energy consumption = 183.485566 pJ
sum error= 7
Actual label: 7
Output voltages: [0.33554, 0.2166, 0.27149, 0.34313, 0.1619, 0.084084, 0.045885, 0.74522, 0.27159, 0.36862]
Predicted label: 7
Correct prediction
Energy consumption = 197.434455 pJ
sum error= 7
Actual label: 6
Output voltages: [0.35826, 0.16323, 0.21385, 0.18016, 0.27482, 0.47709, 0.71139, 0.091587, 0.41495, 0.18658]
Predicted label: 6
Correct prediction
Energy consumption = 192.375220 pJ
sum error= 7
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 44 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 44 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 44 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72438, 0.21156, 0.22175, 0.13256, 0.16002, 0.19104, 0.37524, 0.18551, 0.30802, 0.25624]
Predicted label: 0
Correct prediction
Energy consumption = 191.491951 pJ
sum error= 7
Actual label: 0
Output voltages: [0.65277, 0.23109, 0.2107, 0.15511, 0.23179, 0.16393, 0.50748, 0.161, 0.32187, 0.17434]
Predicted label: 0
Correct prediction
Energy consumption = 195.447825 pJ
sum error= 7
Actual label: 3
Output voltages: [0.29306, 0.13708, 0.2488, 0.75888, 0.23244, 0.27744, 0.24206, 0.19187, 0.40223, 0.24429]
Predicted label: 3
Correct prediction
Energy consumption = 190.311369 pJ
sum error= 7
Actual label: 0
Output voltages: [0.61307, 0.2258, 0.29257, 0.22261, 0.15409, 0.082433, 0.34031, 0.17743, 0.51502, 0.36922]
Predicted label: 0
Correct prediction
Energy consumption = 207.232839 pJ
sum error= 7
Actual label: 2
Output voltages: [0.25657, 0.12362, 0.57562, 0.48818, 0.061512, 0.080818, 0.1369, 0.30215, 0.58841, 0.15614]
Predicted label: 8
Wrong prediction!
Energy consumption = 187.543295 pJ
sum error= 8
Actual label: 6
Output voltages: [0.49977, 0.10486, 0.11231, 0.057346, 0.41523, 0.38222, 0.58419, 0.24027, 0.30342, 0.24295]
Predicted label: 6
Correct prediction
Energy consumption = 190.490144 pJ
sum error= 8
Actual label: 6
Output voltages: [0.34812, 0.18036, 0.21659, 0.17012, 0.2777, 0.40673, 0.70455, 0.051917, 0.42489, 0.21866]
Predicted label: 6
Correct prediction
Energy consumption = 185.771280 pJ
sum error= 8
Actual label: 4
Output voltages: [0.2381, 0.18262, 0.17328, 0.14482, 0.68228, 0.11554, 0.22844, 0.28908, 0.26967, 0.37593]
Predicted label: 4
Correct prediction
Energy consumption = 192.678241 pJ
sum error= 8
Actual label: 9
Output voltages: [0.2647, 0.14159, 0.26235, 0.39064, 0.17095, 0.18277, 0.14817, 0.063989, 0.63424, 0.35939]
Predicted label: 8
Wrong prediction!
Energy consumption = 202.777800 pJ
sum error= 9
Actual label: 3
Output voltages: [0.27328, 0.054119, 0.21146, 0.67186, 0.21032, 0.48335, 0.21473, 0.22018, 0.44832, 0.20364]
Predicted label: 3
Correct prediction
Energy consumption = 182.520654 pJ
sum error= 9
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 45 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 45 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 45 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.20189, 0.11898, 0.22439, 0.72214, 0.30498, 0.33727, 0.22817, 0.15933, 0.4143, 0.24284]
Predicted label: 3
Correct prediction
Energy consumption = 202.269146 pJ
sum error= 9
Actual label: 3
Output voltages: [0.29313, 0.12499, 0.3044, 0.71651, 0.179, 0.11755, 0.082102, 0.22564, 0.51814, 0.24802]
Predicted label: 3
Correct prediction
Energy consumption = 175.031273 pJ
sum error= 9
Actual label: 2
Output voltages: [0.30778, 0.42741, 0.69126, 0.35575, 0.19093, 0.027487, 0.28437, 0.1552, 0.31731, 0.22445]
Predicted label: 2
Correct prediction
Energy consumption = 186.794999 pJ
sum error= 9
Actual label: 3
Output voltages: [0.30047, 0.2179, 0.35991, 0.75972, 0.13163, 0.16555, 0.17789, 0.16165, 0.36329, 0.20505]
Predicted label: 3
Correct prediction
Energy consumption = 182.030145 pJ
sum error= 9
Actual label: 9
Output voltages: [0.41768, 0.081419, 0.21209, 0.19403, 0.3668, 0.25075, 0.15936, 0.21984, 0.34369, 0.71824]
Predicted label: 9
Correct prediction
Energy consumption = 187.285427 pJ
sum error= 9
Actual label: 1
Output voltages: [0.2184, 0.75927, 0.30691, 0.23777, 0.29795, 0.056241, 0.40213, 0.12598, 0.26813, 0.21632]
Predicted label: 1
Correct prediction
Energy consumption = 209.287965 pJ
sum error= 9
Actual label: 2
Output voltages: [0.32037, 0.48092, 0.71126, 0.22623, 0.14455, 0.02338, 0.23595, 0.30941, 0.28204, 0.18315]
Predicted label: 2
Correct prediction
Energy consumption = 184.998786 pJ
sum error= 9
Actual label: 6
Output voltages: [0.31148, 0.094653, 0.17665, 0.24254, 0.34945, 0.37926, 0.63738, 0.054727, 0.52237, 0.19989]
Predicted label: 6
Correct prediction
Energy consumption = 190.595367 pJ
sum error= 9
Actual label: 8
Output voltages: [0.18562, 0.26696, 0.28962, 0.26143, 0.14426, 0.18056, 0.15929, 0.16667, 0.7493, 0.31971]
Predicted label: 8
Correct prediction
Energy consumption = 187.888349 pJ
sum error= 9
Actual label: 0
Output voltages: [0.70448, 0.20792, 0.24668, 0.10638, 0.16126, 0.24812, 0.44097, 0.16163, 0.28385, 0.25911]
Predicted label: 0
Correct prediction
Energy consumption = 196.894543 pJ
sum error= 9
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 46 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 46 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 46 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.1797, 0.1035, 0.1004, 0.39067, 0.19775, 0.65414, 0.1827, 0.13445, 0.50647, 0.25992]
Predicted label: 5
Correct prediction
Energy consumption = 191.009507 pJ
sum error= 9
Actual label: 6
Output voltages: [0.29021, 0.23382, 0.35627, 0.075018, 0.36376, 0.30058, 0.74468, 0.066593, 0.34808, 0.14844]
Predicted label: 6
Correct prediction
Energy consumption = 188.529848 pJ
sum error= 9
Actual label: 6
Output voltages: [0.28738, 0.11663, 0.25198, 0.25891, 0.19159, 0.48808, 0.64777, 0.059132, 0.52991, 0.19503]
Predicted label: 6
Correct prediction
Energy consumption = 185.957262 pJ
sum error= 9
Actual label: 6
Output voltages: [0.30476, 0.17941, 0.35124, 0.092463, 0.32498, 0.25927, 0.73705, 0.054595, 0.39211, 0.19607]
Predicted label: 6
Correct prediction
Energy consumption = 178.932451 pJ
sum error= 9
Actual label: 3
Output voltages: [0.27916, 0.24889, 0.25888, 0.72394, 0.053428, 0.20891, 0.070482, 0.32172, 0.58588, 0.24075]
Predicted label: 3
Correct prediction
Energy consumption = 185.278129 pJ
sum error= 9
Actual label: 8
Output voltages: [0.20662, 0.23077, 0.22023, 0.33776, 0.084394, 0.2402, 0.08816, 0.3409, 0.74015, 0.29116]
Predicted label: 8
Correct prediction
Energy consumption = 195.902828 pJ
sum error= 9
Actual label: 8
Output voltages: [0.25162, 0.22448, 0.37884, 0.23593, 0.17358, 0.12194, 0.22972, 0.11671, 0.74107, 0.32594]
Predicted label: 8
Correct prediction
Energy consumption = 187.426144 pJ
sum error= 9
Actual label: 2
Output voltages: [0.39145, 0.35376, 0.72979, 0.26778, 0.09475, 0.023131, 0.25708, 0.35289, 0.32318, 0.23229]
Predicted label: 2
Correct prediction
Energy consumption = 181.519570 pJ
sum error= 9
Actual label: 7
Output voltages: [0.35701, 0.10454, 0.40396, 0.38205, 0.14923, 0.047539, 0.044354, 0.51769, 0.52905, 0.33146]
Predicted label: 8
Wrong prediction!
Energy consumption = 181.123407 pJ
sum error= 10
Actual label: 5
Output voltages: [0.20544, 0.082962, 0.20576, 0.3349, 0.16198, 0.50106, 0.19613, 0.079365, 0.60847, 0.31471]
Predicted label: 8
Wrong prediction!
Energy consumption = 185.303890 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 47 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 47 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 47 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2244, 0.16552, 0.31923, 0.45014, 0.072587, 0.27169, 0.19628, 0.14252, 0.74061, 0.24564]
Predicted label: 8
Correct prediction
Energy consumption = 193.256772 pJ
sum error= 11
Actual label: 9
Output voltages: [0.37119, 0.13821, 0.16888, 0.30695, 0.22185, 0.16038, 0.063746, 0.36052, 0.4261, 0.63258]
Predicted label: 9
Correct prediction
Energy consumption = 192.796007 pJ
sum error= 11
Actual label: 6
Output voltages: [0.31908, 0.21848, 0.36742, 0.063355, 0.3043, 0.2651, 0.74301, 0.11417, 0.3548, 0.14223]
Predicted label: 6
Correct prediction
Energy consumption = 196.195405 pJ
sum error= 11
Actual label: 1
Output voltages: [0.16417, 0.77219, 0.1785, 0.35847, 0.16329, 0.22437, 0.30735, 0.21696, 0.30029, 0.26516]
Predicted label: 1
Correct prediction
Energy consumption = 214.126007 pJ
sum error= 11
Actual label: 8
Output voltages: [0.21431, 0.23414, 0.31148, 0.34235, 0.11039, 0.1488, 0.16727, 0.094249, 0.72163, 0.33148]
Predicted label: 8
Correct prediction
Energy consumption = 188.148197 pJ
sum error= 11
Actual label: 4
Output voltages: [0.20046, 0.12565, 0.26164, 0.11221, 0.76061, 0.24989, 0.28008, 0.24609, 0.22535, 0.3579]
Predicted label: 4
Correct prediction
Energy consumption = 197.957578 pJ
sum error= 11
Actual label: 1
Output voltages: [0.26124, 0.76234, 0.26261, 0.29005, 0.22304, 0.060971, 0.32706, 0.11466, 0.33794, 0.29937]
Predicted label: 1
Correct prediction
Energy consumption = 206.688075 pJ
sum error= 11
Actual label: 2
Output voltages: [0.27678, 0.28402, 0.7337, 0.34458, 0.13882, 0.034274, 0.22941, 0.20192, 0.43114, 0.15991]
Predicted label: 2
Correct prediction
Energy consumption = 182.458020 pJ
sum error= 11
Actual label: 5
Output voltages: [0.30499, 0.067386, 0.11683, 0.48292, 0.28956, 0.55605, 0.42642, 0.073974, 0.45924, 0.18664]
Predicted label: 5
Correct prediction
Energy consumption = 197.582280 pJ
sum error= 11
Actual label: 9
Output voltages: [0.30823, 0.073833, 0.23654, 0.34115, 0.30282, 0.24521, 0.10758, 0.098033, 0.46761, 0.56488]
Predicted label: 9
Correct prediction
Energy consumption = 196.663319 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 48 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 48 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 48 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1574, 0.76205, 0.16994, 0.16426, 0.19834, 0.15612, 0.44922, 0.13832, 0.3814, 0.14732]
Predicted label: 1
Correct prediction
Energy consumption = 202.274307 pJ
sum error= 11
Actual label: 9
Output voltages: [0.39785, 0.1227, 0.21096, 0.23518, 0.32359, 0.17907, 0.10078, 0.28198, 0.36234, 0.68378]
Predicted label: 9
Correct prediction
Energy consumption = 200.525921 pJ
sum error= 11
Actual label: 7
Output voltages: [0.39708, 0.29981, 0.13986, 0.41665, 0.0738, 0.17925, 0.044296, 0.71865, 0.28017, 0.44955]
Predicted label: 7
Correct prediction
Energy consumption = 197.351344 pJ
sum error= 11
Actual label: 5
Output voltages: [0.28925, 0.11261, 0.037689, 0.26631, 0.25735, 0.73997, 0.32218, 0.16719, 0.44504, 0.18017]
Predicted label: 5
Correct prediction
Energy consumption = 188.554326 pJ
sum error= 11
Actual label: 4
Output voltages: [0.1684, 0.14445, 0.23275, 0.14174, 0.75165, 0.095101, 0.21931, 0.32296, 0.20824, 0.30395]
Predicted label: 4
Correct prediction
Energy consumption = 193.788444 pJ
sum error= 11
Actual label: 0
Output voltages: [0.73443, 0.26335, 0.25753, 0.24013, 0.15986, 0.19368, 0.42941, 0.10242, 0.28896, 0.37116]
Predicted label: 0
Correct prediction
Energy consumption = 201.792487 pJ
sum error= 11
Actual label: 8
Output voltages: [0.14326, 0.23158, 0.25488, 0.32108, 0.1647, 0.18117, 0.14737, 0.18129, 0.72557, 0.28998]
Predicted label: 8
Correct prediction
Energy consumption = 190.604832 pJ
sum error= 11
Actual label: 9
Output voltages: [0.38798, 0.11069, 0.23923, 0.27951, 0.37188, 0.1664, 0.11607, 0.30131, 0.2989, 0.66807]
Predicted label: 9
Correct prediction
Energy consumption = 191.065183 pJ
sum error= 11
Actual label: 9
Output voltages: [0.31757, 0.080088, 0.23139, 0.18694, 0.294, 0.12444, 0.063522, 0.25492, 0.47917, 0.62874]
Predicted label: 9
Correct prediction
Energy consumption = 184.548175 pJ
sum error= 11
Actual label: 1
Output voltages: [0.18897, 0.76899, 0.18695, 0.18706, 0.27976, 0.14312, 0.42075, 0.14177, 0.31414, 0.21503]
Predicted label: 1
Correct prediction
Energy consumption = 208.195170 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 49 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 49 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 49 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.57704, 0.21866, 0.36535, 0.12681, 0.37964, 0.063142, 0.52254, 0.19696, 0.19765, 0.27771]
Predicted label: 0
Correct prediction
Energy consumption = 195.888514 pJ
sum error= 11
Actual label: 5
Output voltages: [0.2301, 0.05426, 0.071659, 0.40246, 0.27244, 0.69536, 0.30082, 0.1621, 0.41235, 0.28888]
Predicted label: 5
Correct prediction
Energy consumption = 190.662861 pJ
sum error= 11
Actual label: 2
Output voltages: [0.25183, 0.19508, 0.61503, 0.40911, 0.064654, 0.085746, 0.26829, 0.21739, 0.58062, 0.12149]
Predicted label: 2
Correct prediction
Energy consumption = 188.170334 pJ
sum error= 11
Actual label: 3
Output voltages: [0.33748, 0.1642, 0.34097, 0.75464, 0.18529, 0.15056, 0.16653, 0.19318, 0.43654, 0.17488]
Predicted label: 3
Correct prediction
Energy consumption = 177.977936 pJ
sum error= 11
Actual label: 7
Output voltages: [0.33878, 0.20704, 0.28327, 0.27697, 0.10175, 0.085183, 0.044983, 0.75257, 0.44816, 0.3319]
Predicted label: 7
Correct prediction
Energy consumption = 195.594211 pJ
sum error= 11
Actual label: 8
Output voltages: [0.42455, 0.18666, 0.34402, 0.24928, 0.19772, 0.1268, 0.45227, 0.058157, 0.58741, 0.20154]
Predicted label: 8
Correct prediction
Energy consumption = 197.241695 pJ
sum error= 11
Actual label: 9
Output voltages: [0.36715, 0.12317, 0.14136, 0.32488, 0.27894, 0.2773, 0.12847, 0.35491, 0.28485, 0.63376]
Predicted label: 9
Correct prediction
Energy consumption = 200.291926 pJ
sum error= 11
Actual label: 4
Output voltages: [0.22097, 0.35361, 0.25725, 0.12289, 0.62503, 0.042716, 0.15026, 0.11335, 0.36796, 0.37394]
Predicted label: 4
Correct prediction
Energy consumption = 204.604203 pJ
sum error= 11
Actual label: 0
Output voltages: [0.6897, 0.18134, 0.2273, 0.24055, 0.18744, 0.10093, 0.30533, 0.2178, 0.3775, 0.29436]
Predicted label: 0
Correct prediction
Energy consumption = 211.124622 pJ
sum error= 11
Actual label: 6
Output voltages: [0.29562, 0.16813, 0.21063, 0.14328, 0.27574, 0.38795, 0.68843, 0.10235, 0.51931, 0.11903]
Predicted label: 6
Correct prediction
Energy consumption = 186.882513 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 50 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 50 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 50 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33038, 0.2009, 0.27611, 0.76203, 0.16752, 0.11288, 0.1542, 0.20335, 0.41742, 0.25381]
Predicted label: 3
Correct prediction
Energy consumption = 188.211678 pJ
sum error= 11
Actual label: 9
Output voltages: [0.45414, 0.099402, 0.25778, 0.2497, 0.30331, 0.15623, 0.15311, 0.20973, 0.26272, 0.69055]
Predicted label: 9
Correct prediction
Energy consumption = 192.617474 pJ
sum error= 11
Actual label: 5
Output voltages: [0.28495, 0.0675, 0.20857, 0.37833, 0.20405, 0.64676, 0.21867, 0.11226, 0.53722, 0.21778]
Predicted label: 5
Correct prediction
Energy consumption = 196.576885 pJ
sum error= 11
Actual label: 2
Output voltages: [0.40677, 0.2112, 0.71511, 0.36023, 0.18911, 0.030606, 0.27888, 0.23419, 0.40814, 0.18694]
Predicted label: 2
Correct prediction
Energy consumption = 180.569320 pJ
sum error= 11
Actual label: 1
Output voltages: [0.1981, 0.76115, 0.25343, 0.33663, 0.21059, 0.068117, 0.24759, 0.21629, 0.36619, 0.24761]
Predicted label: 1
Correct prediction
Energy consumption = 211.187672 pJ
sum error= 11
Actual label: 3
Output voltages: [0.29358, 0.18672, 0.34906, 0.7386, 0.14998, 0.096158, 0.12396, 0.092262, 0.53096, 0.24461]
Predicted label: 3
Correct prediction
Energy consumption = 180.164529 pJ
sum error= 11
Actual label: 1
Output voltages: [0.19553, 0.75208, 0.086969, 0.18005, 0.34299, 0.22011, 0.39755, 0.14237, 0.30124, 0.19759]
Predicted label: 1
Correct prediction
Energy consumption = 205.021353 pJ
sum error= 11
Actual label: 3
Output voltages: [0.26603, 0.14581, 0.31436, 0.70061, 0.29426, 0.27172, 0.14863, 0.11963, 0.44978, 0.17345]
Predicted label: 3
Correct prediction
Energy consumption = 195.809674 pJ
sum error= 11
Actual label: 6
Output voltages: [0.29468, 0.12952, 0.20862, 0.16828, 0.29599, 0.40512, 0.65971, 0.084642, 0.50687, 0.16223]
Predicted label: 6
Correct prediction
Energy consumption = 185.743411 pJ
sum error= 11
Actual label: 5
Output voltages: [0.2192, 0.058521, 0.12835, 0.45547, 0.16506, 0.66026, 0.19094, 0.22382, 0.49766, 0.31377]
Predicted label: 5
Correct prediction
Energy consumption = 184.638943 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 51 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 51 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 51 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37372, 0.096175, 0.36936, 0.38255, 0.14021, 0.058199, 0.040808, 0.62626, 0.40878, 0.34776]
Predicted label: 7
Correct prediction
Energy consumption = 190.731850 pJ
sum error= 11
Actual label: 4
Output voltages: [0.071625, 0.37998, 0.1442, 0.076093, 0.63925, 0.13945, 0.16774, 0.21758, 0.39417, 0.32957]
Predicted label: 4
Correct prediction
Energy consumption = 208.190177 pJ
sum error= 11
Actual label: 2
Output voltages: [0.36748, 0.37288, 0.72593, 0.29995, 0.15477, 0.024725, 0.29059, 0.21302, 0.3616, 0.24997]
Predicted label: 2
Correct prediction
Energy consumption = 187.544579 pJ
sum error= 11
Actual label: 2
Output voltages: [0.41743, 0.25238, 0.72549, 0.41555, 0.17188, 0.039948, 0.29799, 0.24381, 0.32752, 0.18327]
Predicted label: 2
Correct prediction
Energy consumption = 190.044796 pJ
sum error= 11
Actual label: 6
Output voltages: [0.39519, 0.30174, 0.28627, 0.10204, 0.2429, 0.25811, 0.69326, 0.11668, 0.3772, 0.1782]
Predicted label: 6
Correct prediction
Energy consumption = 202.469926 pJ
sum error= 11
Actual label: 3
Output voltages: [0.22762, 0.27057, 0.32201, 0.74537, 0.16189, 0.13723, 0.072986, 0.28628, 0.42172, 0.29311]
Predicted label: 3
Correct prediction
Energy consumption = 194.096562 pJ
sum error= 11
Actual label: 2
Output voltages: [0.32657, 0.16935, 0.73821, 0.3237, 0.3024, 0.050762, 0.22246, 0.27476, 0.37635, 0.16397]
Predicted label: 2
Correct prediction
Energy consumption = 183.957470 pJ
sum error= 11
Actual label: 6
Output voltages: [0.30651, 0.23292, 0.29525, 0.11508, 0.35108, 0.28552, 0.74012, 0.098457, 0.36033, 0.14035]
Predicted label: 6
Correct prediction
Energy consumption = 195.044161 pJ
sum error= 11
Actual label: 5
Output voltages: [0.22564, 0.061104, 0.11648, 0.30131, 0.21652, 0.65493, 0.30898, 0.11345, 0.56339, 0.24042]
Predicted label: 5
Correct prediction
Energy consumption = 184.136712 pJ
sum error= 11
Actual label: 4
Output voltages: [0.1988, 0.22468, 0.27441, 0.24241, 0.69918, 0.07078, 0.16959, 0.19759, 0.27822, 0.3739]
Predicted label: 4
Correct prediction
Energy consumption = 206.841448 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 52 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 52 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 52 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.15645, 0.30231, 0.25056, 0.29062, 0.16814, 0.29214, 0.21364, 0.13183, 0.73563, 0.27893]
Predicted label: 8
Correct prediction
Energy consumption = 207.939678 pJ
sum error= 11
Actual label: 9
Output voltages: [0.32283, 0.22318, 0.2057, 0.23378, 0.40955, 0.14318, 0.12944, 0.16424, 0.29492, 0.71186]
Predicted label: 9
Correct prediction
Energy consumption = 200.927644 pJ
sum error= 11
Actual label: 7
Output voltages: [0.32171, 0.13748, 0.19248, 0.45781, 0.18359, 0.1319, 0.040225, 0.69081, 0.34478, 0.42523]
Predicted label: 7
Correct prediction
Energy consumption = 194.128372 pJ
sum error= 11
Actual label: 1
Output voltages: [0.091201, 0.72881, 0.21691, 0.19052, 0.29928, 0.13474, 0.27312, 0.17285, 0.42924, 0.23532]
Predicted label: 1
Correct prediction
Energy consumption = 193.153889 pJ
sum error= 11
Actual label: 3
Output voltages: [0.32311, 0.20156, 0.31051, 0.75134, 0.20568, 0.24503, 0.24532, 0.21787, 0.41496, 0.14179]
Predicted label: 3
Correct prediction
Energy consumption = 188.722005 pJ
sum error= 11
Actual label: 0
Output voltages: [0.7241, 0.20601, 0.26512, 0.13231, 0.13618, 0.20045, 0.41137, 0.18304, 0.30442, 0.265]
Predicted label: 0
Correct prediction
Energy consumption = 193.446916 pJ
sum error= 11
Actual label: 3
Output voltages: [0.25856, 0.16484, 0.17778, 0.72291, 0.20207, 0.39223, 0.19507, 0.15948, 0.43065, 0.27346]
Predicted label: 3
Correct prediction
Energy consumption = 196.823714 pJ
sum error= 11
Actual label: 8
Output voltages: [0.4137, 0.12467, 0.34134, 0.4019, 0.1604, 0.26505, 0.23329, 0.087983, 0.71586, 0.31797]
Predicted label: 8
Correct prediction
Energy consumption = 190.395669 pJ
sum error= 11
Actual label: 3
Output voltages: [0.31207, 0.17058, 0.3499, 0.72742, 0.064039, 0.11113, 0.17965, 0.29368, 0.48235, 0.15826]
Predicted label: 3
Correct prediction
Energy consumption = 182.924059 pJ
sum error= 11
Actual label: 1
Output voltages: [0.12103, 0.76586, 0.24509, 0.33739, 0.19474, 0.16721, 0.45727, 0.17238, 0.26647, 0.18818]
Predicted label: 1
Correct prediction
Energy consumption = 201.106997 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 53 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 53 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 53 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30123, 0.24212, 0.23574, 0.23768, 0.53608, 0.097691, 0.16976, 0.096556, 0.2483, 0.61285]
Predicted label: 9
Correct prediction
Energy consumption = 205.792021 pJ
sum error= 11
Actual label: 3
Output voltages: [0.34473, 0.15833, 0.30418, 0.74596, 0.11889, 0.15932, 0.31365, 0.20252, 0.38375, 0.10997]
Predicted label: 3
Correct prediction
Energy consumption = 197.786951 pJ
sum error= 11
Actual label: 4
Output voltages: [0.29768, 0.26079, 0.21668, 0.16641, 0.69351, 0.08529, 0.35634, 0.25059, 0.14005, 0.31981]
Predicted label: 4
Correct prediction
Energy consumption = 210.322174 pJ
sum error= 11
Actual label: 4
Output voltages: [0.1634, 0.18814, 0.32882, 0.06019, 0.75301, 0.077032, 0.33749, 0.22561, 0.2387, 0.30723]
Predicted label: 4
Correct prediction
Energy consumption = 196.302186 pJ
sum error= 11
Actual label: 6
Output voltages: [0.28645, 0.23156, 0.30191, 0.15972, 0.28006, 0.35562, 0.72858, 0.089674, 0.44895, 0.097049]
Predicted label: 6
Correct prediction
Energy consumption = 192.783284 pJ
sum error= 11
Actual label: 4
Output voltages: [0.1818, 0.15426, 0.33232, 0.1336, 0.74997, 0.06296, 0.32388, 0.2955, 0.23956, 0.23504]
Predicted label: 4
Correct prediction
Energy consumption = 193.392676 pJ
sum error= 11
Actual label: 2
Output voltages: [0.34895, 0.3642, 0.71252, 0.22767, 0.19161, 0.025871, 0.29279, 0.31488, 0.37679, 0.21908]
Predicted label: 2
Correct prediction
Energy consumption = 194.182387 pJ
sum error= 11
Actual label: 1
Output voltages: [0.17325, 0.75603, 0.33705, 0.20719, 0.22818, 0.06509, 0.44388, 0.097667, 0.31928, 0.20801]
Predicted label: 1
Correct prediction
Energy consumption = 202.009850 pJ
sum error= 11
Actual label: 8
Output voltages: [0.2852, 0.25516, 0.31966, 0.3255, 0.17472, 0.22138, 0.25989, 0.060022, 0.73764, 0.27686]
Predicted label: 8
Correct prediction
Energy consumption = 195.589809 pJ
sum error= 11
Actual label: 2
Output voltages: [0.42439, 0.13215, 0.70676, 0.34488, 0.2309, 0.03817, 0.17077, 0.24506, 0.46842, 0.16135]
Predicted label: 2
Correct prediction
Energy consumption = 183.133327 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 54 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 54 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 54 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.29369, 0.064316, 0.12479, 0.42616, 0.17586, 0.6978, 0.21556, 0.16218, 0.53698, 0.29144]
Predicted label: 5
Correct prediction
Energy consumption = 188.753841 pJ
sum error= 11
Actual label: 4
Output voltages: [0.14354, 0.13922, 0.31997, 0.18413, 0.76207, 0.086635, 0.31342, 0.27793, 0.19145, 0.27219]
Predicted label: 4
Correct prediction
Energy consumption = 194.052807 pJ
sum error= 11
Actual label: 8
Output voltages: [0.14832, 0.14027, 0.27093, 0.31459, 0.20961, 0.19568, 0.17631, 0.12034, 0.69913, 0.36802]
Predicted label: 8
Correct prediction
Energy consumption = 197.002409 pJ
sum error= 11
Actual label: 8
Output voltages: [0.1883, 0.1583, 0.25348, 0.34584, 0.21939, 0.15269, 0.07969, 0.26474, 0.64677, 0.37183]
Predicted label: 8
Correct prediction
Energy consumption = 203.547851 pJ
sum error= 11
Actual label: 4
Output voltages: [0.13042, 0.20573, 0.27812, 0.1632, 0.76244, 0.12426, 0.29196, 0.35653, 0.22691, 0.25179]
Predicted label: 4
Correct prediction
Energy consumption = 198.472501 pJ
sum error= 11
Actual label: 0
Output voltages: [0.70313, 0.22658, 0.27713, 0.20046, 0.14505, 0.11472, 0.34198, 0.1979, 0.34525, 0.31337]
Predicted label: 0
Correct prediction
Energy consumption = 197.882879 pJ
sum error= 11
Actual label: 0
Output voltages: [0.71066, 0.20465, 0.23734, 0.13655, 0.20777, 0.206, 0.45581, 0.15937, 0.27544, 0.26417]
Predicted label: 0
Correct prediction
Energy consumption = 189.063025 pJ
sum error= 11
Actual label: 2
Output voltages: [0.26946, 0.30078, 0.64172, 0.42156, 0.057084, 0.054238, 0.26069, 0.15545, 0.54593, 0.18828]
Predicted label: 2
Correct prediction
Energy consumption = 187.329971 pJ
sum error= 11
Actual label: 3
Output voltages: [0.31341, 0.1593, 0.35388, 0.75515, 0.25227, 0.24049, 0.21688, 0.1992, 0.39187, 0.19016]
Predicted label: 3
Correct prediction
Energy consumption = 192.355212 pJ
sum error= 11
Actual label: 2
Output voltages: [0.46805, 0.22202, 0.74275, 0.33697, 0.11421, 0.046299, 0.33131, 0.2418, 0.34592, 0.18399]
Predicted label: 2
Correct prediction
Energy consumption = 184.913781 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 55 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 55 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 55 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.27994, 0.14887, 0.26013, 0.50333, 0.24619, 0.056551, 0.039599, 0.55951, 0.35795, 0.36233]
Predicted label: 7
Correct prediction
Energy consumption = 189.821940 pJ
sum error= 11
Actual label: 7
Output voltages: [0.23511, 0.27014, 0.33856, 0.43635, 0.16792, 0.053592, 0.039337, 0.54617, 0.42053, 0.31577]
Predicted label: 7
Correct prediction
Energy consumption = 194.461037 pJ
sum error= 11
Actual label: 0
Output voltages: [0.6131, 0.17066, 0.12084, 0.16732, 0.21151, 0.28817, 0.50143, 0.19996, 0.32736, 0.25353]
Predicted label: 0
Correct prediction
Energy consumption = 206.872996 pJ
sum error= 11
Actual label: 8
Output voltages: [0.17199, 0.1541, 0.24655, 0.25224, 0.20539, 0.34047, 0.36489, 0.17938, 0.71673, 0.15145]
Predicted label: 8
Correct prediction
Energy consumption = 189.227414 pJ
sum error= 11
Actual label: 7
Output voltages: [0.13761, 0.2388, 0.4141, 0.15198, 0.26984, 0.050978, 0.047233, 0.75295, 0.45501, 0.14103]
Predicted label: 7
Correct prediction
Energy consumption = 198.567873 pJ
sum error= 11
Actual label: 4
Output voltages: [0.17692, 0.20068, 0.23827, 0.17891, 0.70726, 0.10794, 0.2635, 0.18866, 0.23838, 0.26876]
Predicted label: 4
Correct prediction
Energy consumption = 204.954765 pJ
sum error= 11
Actual label: 4
Output voltages: [0.12497, 0.18103, 0.30321, 0.0892, 0.76382, 0.12122, 0.31202, 0.25402, 0.24545, 0.28624]
Predicted label: 4
Correct prediction
Energy consumption = 184.646061 pJ
sum error= 11
Actual label: 7
Output voltages: [0.29849, 0.38576, 0.37398, 0.29601, 0.089377, 0.036444, 0.04606, 0.71164, 0.29778, 0.32383]
Predicted label: 7
Correct prediction
Energy consumption = 204.911765 pJ
sum error= 11
Actual label: 9
Output voltages: [0.30412, 0.17077, 0.1631, 0.26505, 0.30753, 0.11459, 0.087961, 0.22509, 0.36737, 0.68515]
Predicted label: 9
Correct prediction
Energy consumption = 199.039415 pJ
sum error= 11
Actual label: 6
Output voltages: [0.32545, 0.14409, 0.31717, 0.052085, 0.41803, 0.19374, 0.70284, 0.090029, 0.32369, 0.18672]
Predicted label: 6
Correct prediction
Energy consumption = 180.779003 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 56 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 56 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 56 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37006, 0.1341, 0.1961, 0.29369, 0.38188, 0.18572, 0.10867, 0.15907, 0.32864, 0.69268]
Predicted label: 9
Correct prediction
Energy consumption = 189.848868 pJ
sum error= 11
Actual label: 0
Output voltages: [0.60993, 0.17015, 0.27353, 0.22931, 0.050854, 0.28416, 0.48879, 0.14608, 0.28225, 0.28943]
Predicted label: 0
Correct prediction
Energy consumption = 194.957408 pJ
sum error= 11
Actual label: 9
Output voltages: [0.3343, 0.14973, 0.18015, 0.31387, 0.32106, 0.2737, 0.2376, 0.26072, 0.28362, 0.68087]
Predicted label: 9
Correct prediction
Energy consumption = 198.870784 pJ
sum error= 11
Actual label: 8
Output voltages: [0.19484, 0.18936, 0.31323, 0.23923, 0.19423, 0.18502, 0.21409, 0.1234, 0.72642, 0.30477]
Predicted label: 8
Correct prediction
Energy consumption = 195.525610 pJ
sum error= 11
Actual label: 0
Output voltages: [0.72886, 0.25611, 0.22602, 0.17289, 0.14416, 0.19763, 0.41068, 0.20155, 0.28588, 0.3423]
Predicted label: 0
Correct prediction
Energy consumption = 199.500685 pJ
sum error= 11
Actual label: 4
Output voltages: [0.092407, 0.17559, 0.17075, 0.12157, 0.64343, 0.17544, 0.2423, 0.18274, 0.3569, 0.34596]
Predicted label: 4
Correct prediction
Energy consumption = 191.813850 pJ
sum error= 11
Actual label: 6
Output voltages: [0.32245, 0.29686, 0.20349, 0.20438, 0.29035, 0.32371, 0.69952, 0.13003, 0.4252, 0.070471]
Predicted label: 6
Correct prediction
Energy consumption = 196.027359 pJ
sum error= 11
Actual label: 0
Output voltages: [0.73733, 0.20215, 0.27142, 0.24073, 0.15118, 0.16972, 0.35821, 0.17038, 0.35899, 0.29794]
Predicted label: 0
Correct prediction
Energy consumption = 196.691596 pJ
sum error= 11
Actual label: 6
Output voltages: [0.33284, 0.25372, 0.22541, 0.17502, 0.27244, 0.41709, 0.70096, 0.082331, 0.46053, 0.14605]
Predicted label: 6
Correct prediction
Energy consumption = 190.227400 pJ
sum error= 11
Actual label: 3
Output voltages: [0.14268, 0.099858, 0.28393, 0.73195, 0.31759, 0.36191, 0.20635, 0.25392, 0.41148, 0.14216]
Predicted label: 3
Correct prediction
Energy consumption = 190.551031 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 57 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 57 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 57 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2733, 0.086202, 0.14083, 0.4224, 0.15507, 0.67252, 0.23541, 0.14651, 0.51341, 0.33702]
Predicted label: 5
Correct prediction
Energy consumption = 192.132552 pJ
sum error= 11
Actual label: 4
Output voltages: [0.27991, 0.1505, 0.27768, 0.17621, 0.7254, 0.053464, 0.17282, 0.25911, 0.18563, 0.46535]
Predicted label: 4
Correct prediction
Energy consumption = 195.795216 pJ
sum error= 11
Actual label: 8
Output voltages: [0.25295, 0.098517, 0.31622, 0.28918, 0.2002, 0.15591, 0.13288, 0.11656, 0.6959, 0.34258]
Predicted label: 8
Correct prediction
Energy consumption = 201.310431 pJ
sum error= 11
Actual label: 3
Output voltages: [0.41606, 0.15018, 0.2495, 0.75841, 0.14772, 0.23306, 0.20825, 0.20048, 0.39787, 0.21254]
Predicted label: 3
Correct prediction
Energy consumption = 185.693392 pJ
sum error= 11
Actual label: 3
Output voltages: [0.41911, 0.19009, 0.27343, 0.75174, 0.061823, 0.27496, 0.097984, 0.31271, 0.42275, 0.18907]
Predicted label: 3
Correct prediction
Energy consumption = 185.703150 pJ
sum error= 11
Actual label: 9
Output voltages: [0.31439, 0.12821, 0.1958, 0.29057, 0.29007, 0.11803, 0.061634, 0.24739, 0.39331, 0.64665]
Predicted label: 9
Correct prediction
Energy consumption = 188.988792 pJ
sum error= 11
Actual label: 3
Output voltages: [0.37825, 0.18777, 0.28098, 0.76059, 0.1294, 0.22825, 0.14657, 0.21819, 0.46453, 0.17656]
Predicted label: 3
Correct prediction
Energy consumption = 181.626925 pJ
sum error= 11
Actual label: 3
Output voltages: [0.22041, 0.27625, 0.25457, 0.75638, 0.11122, 0.089232, 0.096112, 0.3009, 0.42183, 0.23797]
Predicted label: 3
Correct prediction
Energy consumption = 171.596952 pJ
sum error= 11
Actual label: 3
Output voltages: [0.26991, 0.18576, 0.36099, 0.61345, 0.057871, 0.12273, 0.07421, 0.33071, 0.6053, 0.18971]
Predicted label: 3
Correct prediction
Energy consumption = 180.291636 pJ
sum error= 11
Actual label: 7
Output voltages: [0.44165, 0.17916, 0.19742, 0.28697, 0.28926, 0.16782, 0.053541, 0.71858, 0.27035, 0.37946]
Predicted label: 7
Correct prediction
Energy consumption = 197.671151 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 58 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 58 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 58 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18879, 0.27878, 0.30345, 0.34097, 0.12029, 0.16357, 0.17388, 0.19274, 0.74852, 0.31657]
Predicted label: 8
Correct prediction
Energy consumption = 193.599341 pJ
sum error= 11
Actual label: 0
Output voltages: [0.68347, 0.16615, 0.26899, 0.10252, 0.15866, 0.22982, 0.46067, 0.13105, 0.30592, 0.27814]
Predicted label: 0
Correct prediction
Energy consumption = 193.866134 pJ
sum error= 11
Actual label: 8
Output voltages: [0.2603, 0.23614, 0.50301, 0.53908, 0.26102, 0.041053, 0.23567, 0.085346, 0.47518, 0.19845]
Predicted label: 3
Wrong prediction!
Energy consumption = 198.007096 pJ
sum error= 12
Actual label: 2
Output voltages: [0.31162, 0.14008, 0.52281, 0.46218, 0.11069, 0.040175, 0.067462, 0.44607, 0.54909, 0.14817]
Predicted label: 8
Wrong prediction!
Energy consumption = 187.388059 pJ
sum error= 13
Actual label: 1
Output voltages: [0.20208, 0.74428, 0.15913, 0.40034, 0.22238, 0.12305, 0.24581, 0.21471, 0.25171, 0.28438]
Predicted label: 1
Correct prediction
Energy consumption = 214.939237 pJ
sum error= 13
Actual label: 7
Output voltages: [0.31515, 0.26519, 0.20529, 0.42878, 0.093042, 0.081139, 0.045262, 0.74134, 0.32941, 0.3915]
Predicted label: 7
Correct prediction
Energy consumption = 204.787629 pJ
sum error= 13
Actual label: 0
Output voltages: [0.74184, 0.2556, 0.24395, 0.17435, 0.18627, 0.21289, 0.41953, 0.14901, 0.27208, 0.27133]
Predicted label: 0
Correct prediction
Energy consumption = 192.791976 pJ
sum error= 13
Actual label: 6
Output voltages: [0.34801, 0.21738, 0.20751, 0.17227, 0.30811, 0.34581, 0.732, 0.058907, 0.37654, 0.13652]
Predicted label: 6
Correct prediction
Energy consumption = 189.549577 pJ
sum error= 13
Actual label: 5
Output voltages: [0.28794, 0.06703, 0.087054, 0.40785, 0.19315, 0.74064, 0.27448, 0.26402, 0.50347, 0.2588]
Predicted label: 5
Correct prediction
Energy consumption = 185.560617 pJ
sum error= 13
Actual label: 4
Output voltages: [0.099502, 0.20046, 0.31145, 0.14106, 0.72657, 0.096076, 0.17891, 0.16906, 0.35594, 0.33949]
Predicted label: 4
Correct prediction
Energy consumption = 200.242034 pJ
sum error= 13
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 59 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 59 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 59 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.39116, 0.20154, 0.3553, 0.75464, 0.20731, 0.13436, 0.12456, 0.17863, 0.38167, 0.19998]
Predicted label: 3
Correct prediction
Energy consumption = 186.138242 pJ
sum error= 13
Actual label: 8
Output voltages: [0.43061, 0.35299, 0.37924, 0.54115, 0.044777, 0.080249, 0.34473, 0.17307, 0.50511, 0.14059]
Predicted label: 3
Wrong prediction!
Energy consumption = 198.288088 pJ
sum error= 14
Actual label: 0
Output voltages: [0.74209, 0.25201, 0.25334, 0.22445, 0.14339, 0.16787, 0.3959, 0.1641, 0.27859, 0.31104]
Predicted label: 0
Correct prediction
Energy consumption = 189.616855 pJ
sum error= 14
Actual label: 9
Output voltages: [0.31666, 0.10734, 0.14929, 0.2334, 0.25927, 0.13595, 0.051055, 0.28313, 0.48289, 0.62043]
Predicted label: 9
Correct prediction
Energy consumption = 193.475814 pJ
sum error= 14
Actual label: 6
Output voltages: [0.31868, 0.24458, 0.21321, 0.20669, 0.26384, 0.38724, 0.72872, 0.09157, 0.42495, 0.15876]
Predicted label: 6
Correct prediction
Energy consumption = 196.938089 pJ
sum error= 14
Actual label: 3
Output voltages: [0.26811, 0.14994, 0.34798, 0.73852, 0.29342, 0.17927, 0.20033, 0.1815, 0.45365, 0.14413]
Predicted label: 3
Correct prediction
Energy consumption = 185.272256 pJ
sum error= 14
Actual label: 8
Output voltages: [0.25918, 0.082676, 0.28285, 0.27891, 0.1609, 0.26144, 0.17178, 0.11206, 0.68637, 0.33873]
Predicted label: 8
Correct prediction
Energy consumption = 187.728530 pJ
sum error= 14
Actual label: 0
Output voltages: [0.6216, 0.081227, 0.31492, 0.12754, 0.34607, 0.22496, 0.47547, 0.26547, 0.1215, 0.26501]
Predicted label: 0
Correct prediction
Energy consumption = 190.503399 pJ
sum error= 14
Actual label: 9
Output voltages: [0.3116, 0.14766, 0.2306, 0.17592, 0.26609, 0.11514, 0.069727, 0.18898, 0.43818, 0.6685]
Predicted label: 9
Correct prediction
Energy consumption = 193.453948 pJ
sum error= 14
Actual label: 9
Output voltages: [0.3963, 0.12673, 0.21454, 0.28872, 0.41468, 0.19735, 0.074594, 0.31651, 0.25627, 0.65295]
Predicted label: 9
Correct prediction
Energy consumption = 190.019303 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 60 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 60 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 60 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.28796, 0.1779, 0.29274, 0.11728, 0.34945, 0.40557, 0.73683, 0.051344, 0.34868, 0.18729]
Predicted label: 6
Correct prediction
Energy consumption = 186.718951 pJ
sum error= 14
Actual label: 8
Output voltages: [0.30556, 0.26771, 0.33894, 0.21589, 0.16656, 0.060164, 0.17557, 0.20378, 0.68137, 0.35046]
Predicted label: 8
Correct prediction
Energy consumption = 200.028911 pJ
sum error= 14
Actual label: 6
Output voltages: [0.32454, 0.17465, 0.33532, 0.071877, 0.35894, 0.27847, 0.71928, 0.069903, 0.38391, 0.1992]
Predicted label: 6
Correct prediction
Energy consumption = 188.897944 pJ
sum error= 14
Actual label: 8
Output voltages: [0.15487, 0.10688, 0.22155, 0.29341, 0.21441, 0.38276, 0.26311, 0.12979, 0.68133, 0.29406]
Predicted label: 8
Correct prediction
Energy consumption = 197.042295 pJ
sum error= 14
Actual label: 5
Output voltages: [0.2093, 0.07885, 0.10968, 0.35808, 0.22759, 0.7215, 0.30485, 0.17578, 0.46036, 0.2874]
Predicted label: 5
Correct prediction
Energy consumption = 186.622472 pJ
sum error= 14
Actual label: 7
Output voltages: [0.2823, 0.18542, 0.37571, 0.42604, 0.18814, 0.042552, 0.037441, 0.64569, 0.37554, 0.32481]
Predicted label: 7
Correct prediction
Energy consumption = 192.011748 pJ
sum error= 14
Actual label: 8
Output voltages: [0.26184, 0.19936, 0.29889, 0.446, 0.10278, 0.18566, 0.26256, 0.067808, 0.68317, 0.31721]
Predicted label: 8
Correct prediction
Energy consumption = 191.432737 pJ
sum error= 14
Actual label: 6
Output voltages: [0.28488, 0.24369, 0.26582, 0.16824, 0.26905, 0.32509, 0.73834, 0.10025, 0.40254, 0.18824]
Predicted label: 6
Correct prediction
Energy consumption = 194.798710 pJ
sum error= 14
Actual label: 0
Output voltages: [0.74374, 0.27501, 0.21689, 0.20996, 0.13045, 0.20964, 0.33066, 0.16079, 0.2737, 0.35842]
Predicted label: 0
Correct prediction
Energy consumption = 199.739229 pJ
sum error= 14
Actual label: 2
Output voltages: [0.33276, 0.32259, 0.73804, 0.28861, 0.13662, 0.024278, 0.32655, 0.21293, 0.40676, 0.29853]
Predicted label: 2
Correct prediction
Energy consumption = 183.890106 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 61 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 61 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 61 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.23814, 0.18442, 0.29795, 0.11155, 0.68921, 0.06527, 0.37815, 0.18338, 0.38711, 0.11115]
Predicted label: 4
Correct prediction
Energy consumption = 195.571091 pJ
sum error= 14
Actual label: 0
Output voltages: [0.69176, 0.21428, 0.33833, 0.14383, 0.17923, 0.11173, 0.46757, 0.19968, 0.34673, 0.30414]
Predicted label: 0
Correct prediction
Energy consumption = 208.264644 pJ
sum error= 14
Actual label: 2
Output voltages: [0.38423, 0.22096, 0.74, 0.33823, 0.24666, 0.037831, 0.29554, 0.30668, 0.3382, 0.23419]
Predicted label: 2
Correct prediction
Energy consumption = 190.003688 pJ
sum error= 14
Actual label: 2
Output voltages: [0.32173, 0.31673, 0.57295, 0.46962, 0.046311, 0.051089, 0.22253, 0.20081, 0.49278, 0.30486]
Predicted label: 2
Correct prediction
Energy consumption = 193.386835 pJ
sum error= 14
Actual label: 3
Output voltages: [0.34515, 0.28073, 0.34133, 0.75497, 0.13895, 0.061981, 0.10399, 0.21896, 0.40176, 0.31267]
Predicted label: 3
Correct prediction
Energy consumption = 193.361372 pJ
sum error= 14
Actual label: 1
Output voltages: [0.21267, 0.68174, 0.27899, 0.16385, 0.34715, 0.12623, 0.38023, 0.084915, 0.37146, 0.17694]
Predicted label: 1
Correct prediction
Energy consumption = 200.507867 pJ
sum error= 14
Actual label: 9
Output voltages: [0.36485, 0.091341, 0.16977, 0.31219, 0.33789, 0.26172, 0.073695, 0.28529, 0.27557, 0.64069]
Predicted label: 9
Correct prediction
Energy consumption = 200.705180 pJ
sum error= 14
Actual label: 7
Output voltages: [0.30177, 0.13699, 0.38927, 0.43954, 0.17035, 0.042512, 0.050631, 0.63985, 0.41604, 0.25252]
Predicted label: 7
Correct prediction
Energy consumption = 188.164040 pJ
sum error= 14
Actual label: 5
Output voltages: [0.25069, 0.059845, 0.10202, 0.41775, 0.17556, 0.73145, 0.26355, 0.24564, 0.50559, 0.22987]
Predicted label: 5
Correct prediction
Energy consumption = 190.841533 pJ
sum error= 14
Actual label: 1
Output voltages: [0.15929, 0.44862, 0.26956, 0.16804, 0.10099, 0.14869, 0.26115, 0.31482, 0.61323, 0.19788]
Predicted label: 8
Wrong prediction!
Energy consumption = 207.209552 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 62 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 62 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 62 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74949, 0.26908, 0.31781, 0.21734, 0.14674, 0.14091, 0.38298, 0.19985, 0.33753, 0.25507]
Predicted label: 0
Correct prediction
Energy consumption = 203.970794 pJ
sum error= 15
Actual label: 8
Output voltages: [0.21974, 0.25828, 0.30389, 0.34551, 0.14188, 0.16153, 0.23869, 0.072273, 0.73407, 0.33979]
Predicted label: 8
Correct prediction
Energy consumption = 204.477196 pJ
sum error= 15
Actual label: 4
Output voltages: [0.21231, 0.18917, 0.27154, 0.11198, 0.75092, 0.068015, 0.32975, 0.25235, 0.21639, 0.26972]
Predicted label: 4
Correct prediction
Energy consumption = 200.926730 pJ
sum error= 15
Actual label: 6
Output voltages: [0.29062, 0.21501, 0.29786, 0.10694, 0.35904, 0.34837, 0.74189, 0.089554, 0.35272, 0.099701]
Predicted label: 6
Correct prediction
Energy consumption = 189.461191 pJ
sum error= 15
Actual label: 2
Output voltages: [0.25266, 0.45496, 0.64397, 0.27831, 0.093723, 0.037266, 0.32891, 0.074912, 0.46003, 0.31729]
Predicted label: 2
Correct prediction
Energy consumption = 196.351931 pJ
sum error= 15
Actual label: 6
Output voltages: [0.22765, 0.21756, 0.3938, 0.049433, 0.55895, 0.18316, 0.62124, 0.0934, 0.30094, 0.15366]
Predicted label: 6
Correct prediction
Energy consumption = 185.446294 pJ
sum error= 15
Actual label: 7
Output voltages: [0.32628, 0.31932, 0.37944, 0.2955, 0.15348, 0.051727, 0.046631, 0.75313, 0.31387, 0.3297]
Predicted label: 7
Correct prediction
Energy consumption = 197.460833 pJ
sum error= 15
Actual label: 9
Output voltages: [0.32057, 0.14961, 0.22138, 0.2716, 0.31772, 0.16495, 0.24184, 0.20507, 0.34005, 0.69887]
Predicted label: 9
Correct prediction
Energy consumption = 201.860270 pJ
sum error= 15
Actual label: 3
Output voltages: [0.17321, 0.2232, 0.3092, 0.73048, 0.14909, 0.079487, 0.090031, 0.26413, 0.35533, 0.43208]
Predicted label: 3
Correct prediction
Energy consumption = 188.605936 pJ
sum error= 15
Actual label: 2
Output voltages: [0.46323, 0.079004, 0.66231, 0.38725, 0.17522, 0.043702, 0.20212, 0.28593, 0.4331, 0.1524]
Predicted label: 2
Correct prediction
Energy consumption = 186.802244 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 63 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 63 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 63 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39222, 0.11294, 0.22004, 0.26319, 0.29582, 0.2943, 0.1827, 0.24222, 0.33521, 0.68013]
Predicted label: 9
Correct prediction
Energy consumption = 197.598059 pJ
sum error= 15
Actual label: 8
Output voltages: [0.25489, 0.18248, 0.35911, 0.19467, 0.18597, 0.15706, 0.1979, 0.20521, 0.73623, 0.31708]
Predicted label: 8
Correct prediction
Energy consumption = 198.906608 pJ
sum error= 15
Actual label: 2
Output voltages: [0.45548, 0.18075, 0.72633, 0.33371, 0.14018, 0.044194, 0.29585, 0.23181, 0.45489, 0.21654]
Predicted label: 2
Correct prediction
Energy consumption = 185.007261 pJ
sum error= 15
Actual label: 2
Output voltages: [0.36936, 0.27714, 0.74754, 0.27452, 0.20061, 0.031216, 0.3143, 0.24832, 0.3836, 0.20078]
Predicted label: 2
Correct prediction
Energy consumption = 173.675972 pJ
sum error= 15
Actual label: 9
Output voltages: [0.3805, 0.079238, 0.18353, 0.22051, 0.31073, 0.2414, 0.081821, 0.34738, 0.329, 0.67431]
Predicted label: 9
Correct prediction
Energy consumption = 189.465362 pJ
sum error= 15
Actual label: 2
Output voltages: [0.31496, 0.30091, 0.6938, 0.31396, 0.15751, 0.033473, 0.30438, 0.20072, 0.43773, 0.22158]
Predicted label: 2
Correct prediction
Energy consumption = 194.507644 pJ
sum error= 15
Actual label: 7
Output voltages: [0.36284, 0.19487, 0.1827, 0.26962, 0.086521, 0.13963, 0.044396, 0.74549, 0.46063, 0.38294]
Predicted label: 7
Correct prediction
Energy consumption = 197.792219 pJ
sum error= 15
Actual label: 3
Output voltages: [0.36913, 0.18812, 0.33649, 0.74291, 0.1152, 0.076663, 0.23562, 0.21552, 0.45485, 0.13962]
Predicted label: 3
Correct prediction
Energy consumption = 185.796893 pJ
sum error= 15
Actual label: 5
Output voltages: [0.29693, 0.091037, 0.042259, 0.34704, 0.21188, 0.74178, 0.28383, 0.26034, 0.42844, 0.19517]
Predicted label: 5
Correct prediction
Energy consumption = 198.265949 pJ
sum error= 15
Actual label: 9
Output voltages: [0.32902, 0.14614, 0.20025, 0.29599, 0.34564, 0.12563, 0.10299, 0.20583, 0.38491, 0.66815]
Predicted label: 9
Correct prediction
Energy consumption = 188.416286 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 64 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 64 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 64 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17986, 0.75486, 0.18759, 0.44936, 0.1853, 0.14822, 0.2065, 0.18871, 0.26487, 0.31205]
Predicted label: 1
Correct prediction
Energy consumption = 212.311062 pJ
sum error= 15
Actual label: 8
Output voltages: [0.28896, 0.076349, 0.27167, 0.44901, 0.11819, 0.27028, 0.2928, 0.065465, 0.6839, 0.26625]
Predicted label: 8
Correct prediction
Energy consumption = 198.419512 pJ
sum error= 15
Actual label: 0
Output voltages: [0.682, 0.093451, 0.18134, 0.16618, 0.15965, 0.30968, 0.33885, 0.31958, 0.22418, 0.30146]
Predicted label: 0
Correct prediction
Energy consumption = 191.746539 pJ
sum error= 15
Actual label: 2
Output voltages: [0.34204, 0.34254, 0.7253, 0.34589, 0.1581, 0.026215, 0.25595, 0.25302, 0.38623, 0.2242]
Predicted label: 2
Correct prediction
Energy consumption = 186.448771 pJ
sum error= 15
Actual label: 0
Output voltages: [0.73062, 0.1788, 0.24101, 0.16743, 0.21116, 0.17841, 0.37569, 0.14788, 0.28796, 0.35361]
Predicted label: 0
Correct prediction
Energy consumption = 195.598940 pJ
sum error= 15
Actual label: 5
Output voltages: [0.19734, 0.044673, 0.18321, 0.37616, 0.30205, 0.58164, 0.39988, 0.10147, 0.50163, 0.24032]
Predicted label: 5
Correct prediction
Energy consumption = 198.198224 pJ
sum error= 15
Actual label: 2
Output voltages: [0.26933, 0.3895, 0.45885, 0.23164, 0.39732, 0.15091, 0.5968, 0.13541, 0.3531, 0.048583]
Predicted label: 6
Wrong prediction!
Energy consumption = 203.117414 pJ
sum error= 16
Actual label: 1
Output voltages: [0.19901, 0.75876, 0.2606, 0.33539, 0.25117, 0.058854, 0.22991, 0.22611, 0.28268, 0.27787]
Predicted label: 1
Correct prediction
Energy consumption = 214.480913 pJ
sum error= 16
Actual label: 3
Output voltages: [0.27778, 0.18281, 0.29945, 0.7516, 0.16346, 0.15356, 0.10764, 0.19759, 0.47997, 0.23113]
Predicted label: 3
Correct prediction
Energy consumption = 180.830879 pJ
sum error= 16
Actual label: 7
Output voltages: [0.35417, 0.30007, 0.34214, 0.45194, 0.069403, 0.045735, 0.055696, 0.68002, 0.24903, 0.43045]
Predicted label: 7
Correct prediction
Energy consumption = 195.883699 pJ
sum error= 16
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 65 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 65 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 65 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.33376, 0.2302, 0.2203, 0.124, 0.30087, 0.41757, 0.74529, 0.11645, 0.37384, 0.15699]
Predicted label: 6
Correct prediction
Energy consumption = 192.624955 pJ
sum error= 16
Actual label: 7
Output voltages: [0.28651, 0.24414, 0.22384, 0.32661, 0.10199, 0.081178, 0.035412, 0.74756, 0.38017, 0.38276]
Predicted label: 7
Correct prediction
Energy consumption = 206.569465 pJ
sum error= 16
Actual label: 1
Output voltages: [0.16253, 0.76531, 0.25936, 0.25514, 0.22515, 0.096707, 0.35855, 0.08662, 0.37225, 0.24294]
Predicted label: 1
Correct prediction
Energy consumption = 206.736198 pJ
sum error= 16
Actual label: 2
Output voltages: [0.40586, 0.36205, 0.73424, 0.21339, 0.13368, 0.024558, 0.28584, 0.33814, 0.35731, 0.23121]
Predicted label: 2
Correct prediction
Energy consumption = 185.585953 pJ
sum error= 16
Actual label: 5
Output voltages: [0.28249, 0.15339, 0.137, 0.48501, 0.10101, 0.67676, 0.24348, 0.1607, 0.44715, 0.2582]
Predicted label: 5
Correct prediction
Energy consumption = 197.292403 pJ
sum error= 16
Actual label: 8
Output voltages: [0.31101, 0.15005, 0.36766, 0.38342, 0.10912, 0.19878, 0.17854, 0.1377, 0.73636, 0.22984]
Predicted label: 8
Correct prediction
Energy consumption = 187.898890 pJ
sum error= 16
Actual label: 0
Output voltages: [0.74484, 0.24464, 0.22005, 0.17572, 0.12853, 0.26726, 0.35868, 0.17387, 0.29643, 0.26727]
Predicted label: 0
Correct prediction
Energy consumption = 190.592564 pJ
sum error= 16
Actual label: 3
Output voltages: [0.39928, 0.18065, 0.31109, 0.75135, 0.19551, 0.20758, 0.1175, 0.19249, 0.43055, 0.22179]
Predicted label: 3
Correct prediction
Energy consumption = 189.742841 pJ
sum error= 16
Actual label: 7
Output voltages: [0.37271, 0.17325, 0.13982, 0.16531, 0.42758, 0.14899, 0.050939, 0.72665, 0.28305, 0.27794]
Predicted label: 7
Correct prediction
Energy consumption = 194.465005 pJ
sum error= 16
Actual label: 2
Output voltages: [0.27916, 0.43872, 0.56293, 0.17367, 0.19784, 0.023405, 0.14043, 0.43576, 0.34206, 0.19853]
Predicted label: 2
Correct prediction
Energy consumption = 195.036361 pJ
sum error= 16
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 66 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 66 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 66 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16295, 0.21399, 0.33603, 0.17589, 0.75124, 0.048136, 0.37024, 0.30143, 0.12695, 0.232]
Predicted label: 4
Correct prediction
Energy consumption = 196.440116 pJ
sum error= 16
Actual label: 0
Output voltages: [0.65755, 0.29483, 0.22963, 0.23279, 0.19569, 0.13026, 0.48329, 0.19701, 0.39736, 0.25048]
Predicted label: 0
Correct prediction
Energy consumption = 210.022333 pJ
sum error= 16
Actual label: 9
Output voltages: [0.38315, 0.097274, 0.23169, 0.33753, 0.34122, 0.18052, 0.0912, 0.3083, 0.32325, 0.69835]
Predicted label: 9
Correct prediction
Energy consumption = 197.555917 pJ
sum error= 16
Actual label: 1
Output voltages: [0.20927, 0.75288, 0.3537, 0.33629, 0.3048, 0.070745, 0.32978, 0.15249, 0.2299, 0.23062]
Predicted label: 1
Correct prediction
Energy consumption = 213.177261 pJ
sum error= 16
Actual label: 8
Output voltages: [0.15327, 0.22049, 0.29786, 0.27131, 0.16167, 0.28071, 0.22421, 0.16272, 0.7513, 0.24567]
Predicted label: 8
Correct prediction
Energy consumption = 191.935901 pJ
sum error= 16
Actual label: 6
Output voltages: [0.28952, 0.24987, 0.35142, 0.060707, 0.35701, 0.26343, 0.7514, 0.070011, 0.33328, 0.16622]
Predicted label: 6
Correct prediction
Energy consumption = 188.405978 pJ
sum error= 16
Actual label: 7
Output voltages: [0.29932, 0.30769, 0.27825, 0.22702, 0.20465, 0.055442, 0.041004, 0.68411, 0.27296, 0.43366]
Predicted label: 7
Correct prediction
Energy consumption = 202.285383 pJ
sum error= 16
Actual label: 7
Output voltages: [0.35454, 0.47123, 0.26846, 0.5714, 0.047191, 0.065968, 0.064213, 0.50574, 0.41317, 0.24477]
Predicted label: 3
Wrong prediction!
Energy consumption = 208.682757 pJ
sum error= 17
Actual label: 4
Output voltages: [0.068522, 0.27328, 0.26747, 0.20529, 0.72768, 0.10615, 0.37641, 0.28102, 0.24109, 0.23776]
Predicted label: 4
Correct prediction
Energy consumption = 206.564301 pJ
sum error= 17
Actual label: 3
Output voltages: [0.28395, 0.22937, 0.33453, 0.75641, 0.15463, 0.10789, 0.16219, 0.20811, 0.39498, 0.27399]
Predicted label: 3
Correct prediction
Energy consumption = 191.855247 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 67 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 67 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 67 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.11299, 0.17959, 0.19528, 0.12279, 0.71879, 0.11983, 0.13716, 0.25688, 0.41111, 0.23557]
Predicted label: 4
Correct prediction
Energy consumption = 197.986899 pJ
sum error= 17
Actual label: 9
Output voltages: [0.32039, 0.080302, 0.15482, 0.36637, 0.28448, 0.30121, 0.16041, 0.23657, 0.34494, 0.65744]
Predicted label: 9
Correct prediction
Energy consumption = 198.374195 pJ
sum error= 17
Actual label: 1
Output voltages: [0.2324, 0.76517, 0.25092, 0.28706, 0.25262, 0.081308, 0.39883, 0.10885, 0.27039, 0.19522]
Predicted label: 1
Correct prediction
Energy consumption = 212.951073 pJ
sum error= 17
Actual label: 9
Output voltages: [0.38551, 0.098915, 0.21464, 0.16934, 0.29296, 0.16784, 0.14896, 0.11837, 0.47838, 0.56379]
Predicted label: 9
Correct prediction
Energy consumption = 191.525283 pJ
sum error= 17
Actual label: 5
Output voltages: [0.22761, 0.065553, 0.12172, 0.63086, 0.23631, 0.58544, 0.32552, 0.18331, 0.36899, 0.14039]
Predicted label: 3
Wrong prediction!
Energy consumption = 197.879515 pJ
sum error= 18
Actual label: 1
Output voltages: [0.27401, 0.76557, 0.21736, 0.25747, 0.29679, 0.10942, 0.37402, 0.13799, 0.24241, 0.23129]
Predicted label: 1
Correct prediction
Energy consumption = 213.242622 pJ
sum error= 18
Actual label: 7
Output voltages: [0.33022, 0.2525, 0.35056, 0.21535, 0.070147, 0.057304, 0.052636, 0.70507, 0.42929, 0.36397]
Predicted label: 7
Correct prediction
Energy consumption = 194.421226 pJ
sum error= 18
Actual label: 3
Output voltages: [0.3874, 0.18828, 0.32113, 0.75245, 0.0978, 0.15191, 0.2195, 0.15904, 0.42006, 0.15878]
Predicted label: 3
Correct prediction
Energy consumption = 187.488425 pJ
sum error= 18
Actual label: 9
Output voltages: [0.32661, 0.13538, 0.17405, 0.30163, 0.38424, 0.26026, 0.21616, 0.38702, 0.25404, 0.65573]
Predicted label: 9
Correct prediction
Energy consumption = 202.565641 pJ
sum error= 18
Actual label: 7
Output voltages: [0.3713, 0.30787, 0.36704, 0.34381, 0.11448, 0.039682, 0.058993, 0.72104, 0.27459, 0.37652]
Predicted label: 7
Correct prediction
Energy consumption = 204.312736 pJ
sum error= 18
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 68 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 68 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 68 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29617, 0.17015, 0.43618, 0.052902, 0.42139, 0.28751, 0.73084, 0.077177, 0.30018, 0.14185]
Predicted label: 6
Correct prediction
Energy consumption = 187.539958 pJ
sum error= 18
Actual label: 9
Output voltages: [0.34375, 0.074576, 0.17882, 0.34158, 0.30327, 0.23823, 0.079253, 0.35107, 0.36015, 0.65925]
Predicted label: 9
Correct prediction
Energy consumption = 194.597821 pJ
sum error= 18
Actual label: 1
Output voltages: [0.27341, 0.76956, 0.25509, 0.25955, 0.21807, 0.077604, 0.36645, 0.16296, 0.26732, 0.26472]
Predicted label: 1
Correct prediction
Energy consumption = 217.469813 pJ
sum error= 18
Actual label: 3
Output voltages: [0.30711, 0.18702, 0.20091, 0.74874, 0.17699, 0.39622, 0.25796, 0.17128, 0.34736, 0.20479]
Predicted label: 3
Correct prediction
Energy consumption = 193.791446 pJ
sum error= 18
Actual label: 7
Output voltages: [0.099593, 0.30202, 0.4077, 0.55403, 0.19472, 0.15382, 0.12763, 0.52645, 0.25618, 0.28462]
Predicted label: 3
Wrong prediction!
Energy consumption = 201.973836 pJ
sum error= 19
Actual label: 8
Output voltages: [0.26517, 0.18634, 0.48374, 0.29283, 0.11471, 0.095761, 0.18276, 0.21618, 0.70513, 0.35549]
Predicted label: 8
Correct prediction
Energy consumption = 195.228362 pJ
sum error= 19
Actual label: 3
Output voltages: [0.37758, 0.20075, 0.36029, 0.74826, 0.16555, 0.1246, 0.13971, 0.153, 0.44392, 0.2658]
Predicted label: 3
Correct prediction
Energy consumption = 183.940232 pJ
sum error= 19
Actual label: 3
Output voltages: [0.21837, 0.22092, 0.33687, 0.74507, 0.12548, 0.13195, 0.14014, 0.11494, 0.46645, 0.26861]
Predicted label: 3
Correct prediction
Energy consumption = 175.185911 pJ
sum error= 19
Actual label: 6
Output voltages: [0.28477, 0.10405, 0.16683, 0.18621, 0.2936, 0.42039, 0.65878, 0.085029, 0.48795, 0.18041]
Predicted label: 6
Correct prediction
Energy consumption = 189.760515 pJ
sum error= 19
Actual label: 7
Output voltages: [0.39943, 0.23992, 0.088927, 0.24425, 0.3688, 0.1146, 0.12009, 0.51831, 0.28905, 0.46669]
Predicted label: 7
Correct prediction
Energy consumption = 211.421742 pJ
sum error= 19
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 69 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 69 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 69 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.27984, 0.24151, 0.72517, 0.37381, 0.1541, 0.03045, 0.23067, 0.23518, 0.44811, 0.19842]
Predicted label: 2
Correct prediction
Energy consumption = 190.294944 pJ
sum error= 19
Actual label: 8
Output voltages: [0.06305, 0.21122, 0.28433, 0.099686, 0.39706, 0.15732, 0.28668, 0.31639, 0.61194, 0.21908]
Predicted label: 8
Correct prediction
Energy consumption = 195.992798 pJ
sum error= 19
Actual label: 5
Output voltages: [0.23503, 0.15196, 0.047438, 0.44219, 0.12071, 0.72786, 0.22737, 0.20311, 0.45557, 0.18396]
Predicted label: 5
Correct prediction
Energy consumption = 198.954058 pJ
sum error= 19
Actual label: 8
Output voltages: [0.1999, 0.22247, 0.24651, 0.31305, 0.19798, 0.19702, 0.19076, 0.12204, 0.72455, 0.2727]
Predicted label: 8
Correct prediction
Energy consumption = 196.729271 pJ
sum error= 19
Actual label: 5
Output voltages: [0.18343, 0.1781, 0.045116, 0.3583, 0.27348, 0.7368, 0.26548, 0.14821, 0.5295, 0.13326]
Predicted label: 5
Correct prediction
Energy consumption = 203.739899 pJ
sum error= 19
Actual label: 1
Output voltages: [0.18344, 0.76761, 0.18445, 0.27559, 0.27289, 0.095005, 0.35885, 0.17466, 0.29785, 0.223]
Predicted label: 1
Correct prediction
Energy consumption = 208.447526 pJ
sum error= 19
Actual label: 1
Output voltages: [0.17348, 0.76379, 0.17211, 0.39607, 0.20008, 0.15538, 0.28394, 0.13886, 0.33725, 0.30257]
Predicted label: 1
Correct prediction
Energy consumption = 203.302062 pJ
sum error= 19
Actual label: 4
Output voltages: [0.18797, 0.15381, 0.30722, 0.18457, 0.75809, 0.077592, 0.25179, 0.26064, 0.24442, 0.26878]
Predicted label: 4
Correct prediction
Energy consumption = 197.069112 pJ
sum error= 19
Actual label: 4
Output voltages: [0.094301, 0.16239, 0.28524, 0.099327, 0.61642, 0.15403, 0.2502, 0.20556, 0.40199, 0.31887]
Predicted label: 4
Correct prediction
Energy consumption = 193.916019 pJ
sum error= 19
Actual label: 3
Output voltages: [0.2529, 0.20585, 0.29078, 0.75387, 0.16801, 0.21266, 0.09926, 0.29504, 0.38022, 0.26417]
Predicted label: 3
Correct prediction
Energy consumption = 185.289854 pJ
sum error= 19
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 70 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 70 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 70 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.22228, 0.69246, 0.3298, 0.39163, 0.24809, 0.059492, 0.21181, 0.14215, 0.33228, 0.27507]
Predicted label: 1
Correct prediction
Energy consumption = 215.795199 pJ
sum error= 19
Actual label: 0
Output voltages: [0.73602, 0.2602, 0.27371, 0.22283, 0.14974, 0.12407, 0.35774, 0.18572, 0.34246, 0.25931]
Predicted label: 0
Correct prediction
Energy consumption = 193.176194 pJ
sum error= 19
Actual label: 7
Output voltages: [0.35098, 0.27932, 0.38899, 0.20342, 0.12716, 0.039643, 0.043269, 0.62087, 0.42457, 0.35716]
Predicted label: 7
Correct prediction
Energy consumption = 204.246428 pJ
sum error= 19
Actual label: 7
Output voltages: [0.30216, 0.23865, 0.34112, 0.48052, 0.12399, 0.053685, 0.056564, 0.68288, 0.22586, 0.39244]
Predicted label: 7
Correct prediction
Energy consumption = 187.832229 pJ
sum error= 19
Actual label: 0
Output voltages: [0.73163, 0.23774, 0.3254, 0.21295, 0.14728, 0.13195, 0.37594, 0.20949, 0.3016, 0.22502]
Predicted label: 0
Correct prediction
Energy consumption = 197.086461 pJ
sum error= 19
Actual label: 7
Output voltages: [0.27684, 0.25411, 0.2544, 0.31338, 0.11658, 0.056404, 0.047321, 0.75137, 0.29627, 0.38042]
Predicted label: 7
Correct prediction
Energy consumption = 200.634342 pJ
sum error= 19
Actual label: 9
Output voltages: [0.40181, 0.11259, 0.16055, 0.25324, 0.24064, 0.25352, 0.064392, 0.40507, 0.34806, 0.64882]
Predicted label: 9
Correct prediction
Energy consumption = 189.471566 pJ
sum error= 19
Actual label: 4
Output voltages: [0.1264, 0.21299, 0.20805, 0.12, 0.52517, 0.12317, 0.17435, 0.26754, 0.51253, 0.26313]
Predicted label: 4
Correct prediction
Energy consumption = 197.960070 pJ
sum error= 19
Actual label: 4
Output voltages: [0.11638, 0.18852, 0.27711, 0.086711, 0.75116, 0.10507, 0.26475, 0.24348, 0.28823, 0.26512]
Predicted label: 4
Correct prediction
Energy consumption = 202.604049 pJ
sum error= 19
Actual label: 8
Output voltages: [0.2562, 0.23179, 0.30884, 0.43982, 0.08016, 0.20802, 0.21322, 0.12535, 0.73665, 0.2837]
Predicted label: 8
Correct prediction
Energy consumption = 194.579467 pJ
sum error= 19
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 71 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 71 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 71 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.28516, 0.049569, 0.06593, 0.43691, 0.16888, 0.67395, 0.25181, 0.2118, 0.56897, 0.16967]
Predicted label: 5
Correct prediction
Energy consumption = 189.501474 pJ
sum error= 19
Actual label: 5
Output voltages: [0.30376, 0.064146, 0.099791, 0.41948, 0.19916, 0.67046, 0.22379, 0.15421, 0.56706, 0.25673]
Predicted label: 5
Correct prediction
Energy consumption = 177.983052 pJ
sum error= 19
Actual label: 4
Output voltages: [0.23625, 0.19171, 0.23052, 0.20345, 0.7471, 0.12711, 0.26067, 0.21446, 0.18754, 0.40812]
Predicted label: 4
Correct prediction
Energy consumption = 202.352451 pJ
sum error= 19
Actual label: 0
Output voltages: [0.73286, 0.24956, 0.22064, 0.22655, 0.1046, 0.29056, 0.34335, 0.14699, 0.34277, 0.27345]
Predicted label: 0
Correct prediction
Energy consumption = 198.991048 pJ
sum error= 19
Actual label: 8
Output voltages: [0.28955, 0.15224, 0.3583, 0.29035, 0.16909, 0.22085, 0.17739, 0.14117, 0.74882, 0.30529]
Predicted label: 8
Correct prediction
Energy consumption = 195.493883 pJ
sum error= 19
Actual label: 2
Output voltages: [0.36648, 0.19666, 0.71346, 0.36095, 0.089676, 0.042856, 0.2321, 0.2679, 0.50708, 0.19669]
Predicted label: 2
Correct prediction
Energy consumption = 183.092766 pJ
sum error= 19
Actual label: 1
Output voltages: [0.25555, 0.60468, 0.37324, 0.40274, 0.049427, 0.044297, 0.26327, 0.303, 0.41783, 0.24683]
Predicted label: 1
Correct prediction
Energy consumption = 199.917798 pJ
sum error= 19
Actual label: 0
Output voltages: [0.44969, 0.076763, 0.23249, 0.25366, 0.29001, 0.25602, 0.55188, 0.154, 0.28021, 0.17254]
Predicted label: 6
Wrong prediction!
Energy consumption = 196.566085 pJ
sum error= 20
Actual label: 8
Output voltages: [0.26302, 0.21971, 0.39271, 0.27021, 0.14844, 0.11332, 0.21723, 0.15382, 0.72883, 0.34403]
Predicted label: 8
Correct prediction
Energy consumption = 201.892891 pJ
sum error= 20
Actual label: 4
Output voltages: [0.17033, 0.1538, 0.26045, 0.12118, 0.75057, 0.16688, 0.26151, 0.25097, 0.27225, 0.34168]
Predicted label: 4
Correct prediction
Energy consumption = 192.260028 pJ
sum error= 20
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 72 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 72 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 72 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24098, 0.072562, 0.25452, 0.32643, 0.15465, 0.58963, 0.42137, 0.14665, 0.57304, 0.14074]
Predicted label: 5
Correct prediction
Energy consumption = 197.829512 pJ
sum error= 20
Actual label: 0
Output voltages: [0.73219, 0.22039, 0.28746, 0.22622, 0.1025, 0.29265, 0.39047, 0.10826, 0.24693, 0.35389]
Predicted label: 0
Correct prediction
Energy consumption = 192.127118 pJ
sum error= 20
Actual label: 4
Output voltages: [0.19231, 0.14967, 0.287, 0.12236, 0.76103, 0.1264, 0.27509, 0.30869, 0.25456, 0.28673]
Predicted label: 4
Correct prediction
Energy consumption = 190.644500 pJ
sum error= 20
Actual label: 0
Output voltages: [0.61801, 0.19639, 0.24508, 0.13609, 0.34194, 0.10472, 0.54307, 0.13087, 0.2507, 0.25201]
Predicted label: 0
Correct prediction
Energy consumption = 202.474322 pJ
sum error= 20
Actual label: 6
Output voltages: [0.29342, 0.24218, 0.34771, 0.10605, 0.29767, 0.36022, 0.74839, 0.11065, 0.38222, 0.11917]
Predicted label: 6
Correct prediction
Energy consumption = 187.271179 pJ
sum error= 20
Actual label: 1
Output voltages: [0.1441, 0.76296, 0.16583, 0.22768, 0.27693, 0.1473, 0.37808, 0.14373, 0.35419, 0.2137]
Predicted label: 1
Correct prediction
Energy consumption = 212.969956 pJ
sum error= 20
Actual label: 7
Output voltages: [0.24153, 0.16313, 0.1496, 0.26647, 0.27041, 0.27471, 0.098851, 0.4818, 0.24311, 0.40522]
Predicted label: 7
Correct prediction
Energy consumption = 207.592470 pJ
sum error= 20
Actual label: 3
Output voltages: [0.28164, 0.27863, 0.3257, 0.74484, 0.080571, 0.16281, 0.1698, 0.16812, 0.37463, 0.24843]
Predicted label: 3
Correct prediction
Energy consumption = 182.781997 pJ
sum error= 20
Actual label: 2
Output voltages: [0.33225, 0.24463, 0.70724, 0.32622, 0.086882, 0.034383, 0.24522, 0.31475, 0.49269, 0.24781]
Predicted label: 2
Correct prediction
Energy consumption = 180.649447 pJ
sum error= 20
Actual label: 6
Output voltages: [0.29613, 0.089941, 0.19293, 0.19142, 0.30194, 0.45412, 0.65287, 0.054272, 0.49386, 0.1844]
Predicted label: 6
Correct prediction
Energy consumption = 186.302151 pJ
sum error= 20
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 73 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 73 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 73 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.5142, 0.19151, 0.2003, 0.17098, 0.24565, 0.18414, 0.1356, 0.72554, 0.262, 0.31759]
Predicted label: 7
Correct prediction
Energy consumption = 196.883826 pJ
sum error= 20
Actual label: 2
Output voltages: [0.40973, 0.14385, 0.72363, 0.42172, 0.14528, 0.045637, 0.25334, 0.21496, 0.43293, 0.202]
Predicted label: 2
Correct prediction
Energy consumption = 187.241170 pJ
sum error= 20
Actual label: 6
Output voltages: [0.27674, 0.21492, 0.30411, 0.098676, 0.31025, 0.35357, 0.74473, 0.091321, 0.37413, 0.18617]
Predicted label: 6
Correct prediction
Energy consumption = 192.794297 pJ
sum error= 20
Actual label: 9
Output voltages: [0.29123, 0.12647, 0.24236, 0.29241, 0.26852, 0.18804, 0.080239, 0.19226, 0.42974, 0.69182]
Predicted label: 9
Correct prediction
Energy consumption = 190.801923 pJ
sum error= 20
Actual label: 3
Output voltages: [0.35197, 0.14547, 0.29609, 0.75456, 0.24433, 0.2974, 0.19561, 0.17052, 0.4117, 0.18068]
Predicted label: 3
Correct prediction
Energy consumption = 189.457269 pJ
sum error= 20
Actual label: 1
Output voltages: [0.21811, 0.77243, 0.26166, 0.2718, 0.18009, 0.1515, 0.3778, 0.11682, 0.33887, 0.24909]
Predicted label: 1
Correct prediction
Energy consumption = 208.044352 pJ
sum error= 20
Actual label: 4
Output voltages: [0.18516, 0.16877, 0.34616, 0.11015, 0.76042, 0.06531, 0.37884, 0.22196, 0.2084, 0.30287]
Predicted label: 4
Correct prediction
Energy consumption = 193.157394 pJ
sum error= 20
Actual label: 6
Output voltages: [0.35417, 0.13642, 0.31899, 0.041864, 0.35095, 0.26393, 0.71014, 0.088031, 0.34664, 0.17163]
Predicted label: 6
Correct prediction
Energy consumption = 183.290499 pJ
sum error= 20
Actual label: 2
Output voltages: [0.31932, 0.26071, 0.68944, 0.42543, 0.097893, 0.032806, 0.24124, 0.16518, 0.46693, 0.18415]
Predicted label: 2
Correct prediction
Energy consumption = 189.911234 pJ
sum error= 20
Actual label: 5
Output voltages: [0.31378, 0.070773, 0.13031, 0.35717, 0.18302, 0.72827, 0.43312, 0.18908, 0.40771, 0.23347]
Predicted label: 5
Correct prediction
Energy consumption = 186.465332 pJ
sum error= 20
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 74 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 74 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 74 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.29312, 0.26558, 0.23738, 0.23615, 0.39253, 0.11297, 0.06942, 0.17986, 0.25102, 0.7051]
Predicted label: 9
Wrong prediction!
Energy consumption = 203.581811 pJ
sum error= 21
Actual label: 2
Output voltages: [0.38335, 0.28413, 0.71327, 0.29257, 0.094272, 0.033094, 0.27935, 0.28718, 0.47549, 0.26588]
Predicted label: 2
Correct prediction
Energy consumption = 190.738779 pJ
sum error= 21
Actual label: 0
Output voltages: [0.73925, 0.26795, 0.28209, 0.17658, 0.1198, 0.18755, 0.38676, 0.16752, 0.28225, 0.24128]
Predicted label: 0
Correct prediction
Energy consumption = 187.135463 pJ
sum error= 21
Actual label: 6
Output voltages: [0.33297, 0.19241, 0.24043, 0.16259, 0.32287, 0.39174, 0.72381, 0.10951, 0.45125, 0.11614]
Predicted label: 6
Correct prediction
Energy consumption = 187.172057 pJ
sum error= 21
Actual label: 2
Output voltages: [0.39331, 0.25, 0.71772, 0.40051, 0.16011, 0.04328, 0.23789, 0.22277, 0.32092, 0.15238]
Predicted label: 2
Correct prediction
Energy consumption = 199.833275 pJ
sum error= 21
Actual label: 1
Output voltages: [0.22028, 0.74597, 0.14727, 0.14928, 0.38182, 0.16711, 0.37396, 0.08388, 0.32425, 0.26565]
Predicted label: 1
Correct prediction
Energy consumption = 208.059215 pJ
sum error= 21
Actual label: 7
Output voltages: [0.3034, 0.34034, 0.34254, 0.23824, 0.11066, 0.042686, 0.053541, 0.70394, 0.23787, 0.40133]
Predicted label: 7
Correct prediction
Energy consumption = 203.048810 pJ
sum error= 21
Actual label: 3
Output voltages: [0.23477, 0.25678, 0.27615, 0.74946, 0.11708, 0.074313, 0.16378, 0.23944, 0.43597, 0.28038]
Predicted label: 3
Correct prediction
Energy consumption = 184.299711 pJ
sum error= 21
Actual label: 4
Output voltages: [0.24322, 0.17019, 0.28791, 0.17677, 0.7538, 0.11907, 0.23067, 0.21454, 0.21362, 0.366]
Predicted label: 4
Correct prediction
Energy consumption = 196.341698 pJ
sum error= 21
Actual label: 1
Output voltages: [0.18651, 0.76849, 0.25757, 0.24693, 0.22409, 0.073586, 0.38283, 0.14705, 0.32997, 0.23141]
Predicted label: 1
Correct prediction
Energy consumption = 209.665400 pJ
sum error= 21
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 75 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 75 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 75 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69856, 0.25478, 0.23014, 0.17429, 0.17264, 0.17859, 0.51288, 0.16862, 0.33714, 0.21657]
Predicted label: 0
Correct prediction
Energy consumption = 200.392932 pJ
sum error= 21
Actual label: 5
Output voltages: [0.19717, 0.054416, 0.13651, 0.33141, 0.23739, 0.69402, 0.24619, 0.21498, 0.59736, 0.28312]
Predicted label: 5
Correct prediction
Energy consumption = 185.174194 pJ
sum error= 21
Actual label: 4
Output voltages: [0.18395, 0.1866, 0.28405, 0.14709, 0.74768, 0.050869, 0.2785, 0.31816, 0.1681, 0.25944]
Predicted label: 4
Correct prediction
Energy consumption = 197.999715 pJ
sum error= 21
Actual label: 3
Output voltages: [0.3645, 0.10123, 0.44128, 0.68727, 0.20561, 0.06051, 0.1103, 0.19627, 0.49273, 0.23535]
Predicted label: 3
Correct prediction
Energy consumption = 183.568011 pJ
sum error= 21
Actual label: 1
Output voltages: [0.1151, 0.7636, 0.21974, 0.25446, 0.19499, 0.13519, 0.3444, 0.13482, 0.4198, 0.24305]
Predicted label: 1
Correct prediction
Energy consumption = 209.688310 pJ
sum error= 21
Actual label: 1
Output voltages: [0.19073, 0.76174, 0.22054, 0.32368, 0.25182, 0.15013, 0.28013, 0.10615, 0.25929, 0.35015]
Predicted label: 1
Correct prediction
Energy consumption = 209.920567 pJ
sum error= 21
Actual label: 7
Output voltages: [0.36364, 0.27235, 0.4301, 0.32506, 0.12654, 0.031569, 0.056147, 0.72302, 0.3239, 0.26355]
Predicted label: 7
Correct prediction
Energy consumption = 192.516072 pJ
sum error= 21
Actual label: 4
Output voltages: [0.13888, 0.14662, 0.26127, 0.18305, 0.7412, 0.093438, 0.26865, 0.23259, 0.26736, 0.25473]
Predicted label: 4
Correct prediction
Energy consumption = 199.236325 pJ
sum error= 21
Actual label: 9
Output voltages: [0.36763, 0.13907, 0.2093, 0.31399, 0.33472, 0.18399, 0.10998, 0.25588, 0.33763, 0.66991]
Predicted label: 9
Correct prediction
Energy consumption = 183.835610 pJ
sum error= 21
Actual label: 9
Output voltages: [0.30728, 0.090616, 0.20847, 0.27979, 0.25432, 0.15926, 0.058122, 0.23846, 0.46677, 0.61496]
Predicted label: 9
Correct prediction
Energy consumption = 183.291726 pJ
sum error= 21
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 76 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 76 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 76 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25917, 0.22068, 0.23364, 0.32513, 0.62925, 0.050899, 0.089715, 0.13456, 0.25132, 0.47002]
Predicted label: 4
Correct prediction
Energy consumption = 199.246509 pJ
sum error= 21
Actual label: 8
Output voltages: [0.22702, 0.23066, 0.32834, 0.26689, 0.1709, 0.16105, 0.33191, 0.067813, 0.70043, 0.37192]
Predicted label: 8
Correct prediction
Energy consumption = 196.906687 pJ
sum error= 21
Actual label: 4
Output voltages: [0.21417, 0.098914, 0.40215, 0.15179, 0.75121, 0.083878, 0.35657, 0.23418, 0.20619, 0.26778]
Predicted label: 4
Correct prediction
Energy consumption = 199.008932 pJ
sum error= 21
Actual label: 0
Output voltages: [0.66071, 0.20784, 0.42338, 0.27866, 0.042923, 0.21222, 0.34399, 0.13069, 0.39745, 0.22988]
Predicted label: 0
Correct prediction
Energy consumption = 195.662460 pJ
sum error= 21
Actual label: 2
Output voltages: [0.37837, 0.11329, 0.73378, 0.29286, 0.13516, 0.042206, 0.25734, 0.34937, 0.4852, 0.18146]
Predicted label: 2
Correct prediction
Energy consumption = 180.295230 pJ
sum error= 21
Actual label: 4
Output voltages: [0.14873, 0.19182, 0.26569, 0.16047, 0.73616, 0.071261, 0.25263, 0.19438, 0.25301, 0.29046]
Predicted label: 4
Correct prediction
Energy consumption = 204.812374 pJ
sum error= 21
Actual label: 5
Output voltages: [0.26485, 0.049089, 0.20065, 0.30173, 0.13445, 0.62264, 0.23705, 0.14219, 0.6427, 0.23341]
Predicted label: 8
Wrong prediction!
Energy consumption = 190.151312 pJ
sum error= 22
Actual label: 1
Output voltages: [0.31755, 0.73798, 0.24393, 0.22614, 0.39435, 0.042269, 0.27173, 0.17892, 0.20075, 0.31415]
Predicted label: 1
Correct prediction
Energy consumption = 209.327434 pJ
sum error= 22
Actual label: 1
Output voltages: [0.20806, 0.76711, 0.26538, 0.25705, 0.14876, 0.10218, 0.50027, 0.10535, 0.277, 0.18524]
Predicted label: 1
Correct prediction
Energy consumption = 201.664295 pJ
sum error= 22
Actual label: 6
Output voltages: [0.34638, 0.15164, 0.16511, 0.26659, 0.23528, 0.54595, 0.66756, 0.072094, 0.46886, 0.21551]
Predicted label: 6
Correct prediction
Energy consumption = 189.345718 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 77 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 77 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 77 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19649, 0.17037, 0.28151, 0.089432, 0.72814, 0.050412, 0.34296, 0.27064, 0.27888, 0.21053]
Predicted label: 4
Correct prediction
Energy consumption = 199.237532 pJ
sum error= 22
Actual label: 7
Output voltages: [0.38321, 0.25738, 0.16731, 0.18959, 0.18741, 0.14308, 0.065866, 0.71867, 0.33948, 0.48032]
Predicted label: 7
Correct prediction
Energy consumption = 202.673926 pJ
sum error= 22
Actual label: 1
Output voltages: [0.18646, 0.73867, 0.14035, 0.32391, 0.1012, 0.0765, 0.22026, 0.23572, 0.41682, 0.3058]
Predicted label: 1
Correct prediction
Energy consumption = 214.531182 pJ
sum error= 22
Actual label: 9
Output voltages: [0.36718, 0.18039, 0.20838, 0.27028, 0.32706, 0.13703, 0.086341, 0.35857, 0.29631, 0.70271]
Predicted label: 9
Correct prediction
Energy consumption = 197.502037 pJ
sum error= 22
Actual label: 4
Output voltages: [0.22863, 0.17512, 0.31526, 0.1798, 0.67474, 0.041239, 0.12017, 0.22326, 0.24874, 0.4281]
Predicted label: 4
Correct prediction
Energy consumption = 200.387228 pJ
sum error= 22
Actual label: 2
Output voltages: [0.41973, 0.23475, 0.70914, 0.33534, 0.16209, 0.027511, 0.34636, 0.27544, 0.46788, 0.19574]
Predicted label: 2
Correct prediction
Energy consumption = 189.120408 pJ
sum error= 22
Actual label: 4
Output voltages: [0.16298, 0.073327, 0.35282, 0.12105, 0.74987, 0.22298, 0.27283, 0.26894, 0.21072, 0.36733]
Predicted label: 4
Correct prediction
Energy consumption = 195.886889 pJ
sum error= 22
Actual label: 1
Output voltages: [0.29745, 0.76313, 0.23724, 0.31488, 0.18978, 0.092557, 0.36286, 0.11548, 0.28327, 0.25323]
Predicted label: 1
Correct prediction
Energy consumption = 211.736846 pJ
sum error= 22
Actual label: 5
Output voltages: [0.22734, 0.043313, 0.10916, 0.31003, 0.29636, 0.67958, 0.33749, 0.16247, 0.56469, 0.24713]
Predicted label: 5
Correct prediction
Energy consumption = 187.060297 pJ
sum error= 22
Actual label: 5
Output voltages: [0.3238, 0.17858, 0.046853, 0.38556, 0.23201, 0.73692, 0.32656, 0.065629, 0.38234, 0.22256]
Predicted label: 5
Correct prediction
Energy consumption = 185.872350 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 78 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 78 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 78 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.43292, 0.17144, 0.094445, 0.71208, 0.18693, 0.48868, 0.16725, 0.35981, 0.3781, 0.10835]
Predicted label: 3
Correct prediction
Energy consumption = 195.361830 pJ
sum error= 22
Actual label: 8
Output voltages: [0.33415, 0.30178, 0.23805, 0.30998, 0.094847, 0.26196, 0.42937, 0.10624, 0.61444, 0.18461]
Predicted label: 8
Correct prediction
Energy consumption = 203.712556 pJ
sum error= 22
Actual label: 3
Output voltages: [0.30761, 0.21393, 0.32204, 0.74766, 0.2061, 0.16751, 0.2186, 0.17749, 0.41611, 0.18755]
Predicted label: 3
Correct prediction
Energy consumption = 185.750970 pJ
sum error= 22
Actual label: 1
Output voltages: [0.25092, 0.76662, 0.22334, 0.24376, 0.22206, 0.18678, 0.35044, 0.10065, 0.33454, 0.2435]
Predicted label: 1
Correct prediction
Energy consumption = 209.533555 pJ
sum error= 22
Actual label: 4
Output voltages: [0.24503, 0.14359, 0.30785, 0.15736, 0.74042, 0.22163, 0.25543, 0.18006, 0.22174, 0.39925]
Predicted label: 4
Correct prediction
Energy consumption = 206.771304 pJ
sum error= 22
Actual label: 5
Output voltages: [0.25233, 0.050083, 0.13625, 0.44801, 0.16327, 0.65243, 0.19939, 0.25913, 0.52616, 0.28377]
Predicted label: 5
Correct prediction
Energy consumption = 190.458940 pJ
sum error= 22
Actual label: 6
Output voltages: [0.38212, 0.24396, 0.23515, 0.13533, 0.23638, 0.4364, 0.71055, 0.12799, 0.37513, 0.1145]
Predicted label: 6
Correct prediction
Energy consumption = 192.963772 pJ
sum error= 22
Actual label: 8
Output voltages: [0.27599, 0.16443, 0.30958, 0.27932, 0.17144, 0.21416, 0.16691, 0.11014, 0.74329, 0.40627]
Predicted label: 8
Correct prediction
Energy consumption = 182.260102 pJ
sum error= 22
Actual label: 9
Output voltages: [0.3359, 0.1116, 0.22094, 0.33898, 0.27025, 0.17934, 0.10679, 0.31209, 0.35575, 0.66841]
Predicted label: 9
Correct prediction
Energy consumption = 195.652467 pJ
sum error= 22
Actual label: 4
Output voltages: [0.20711, 0.22586, 0.33518, 0.18862, 0.74247, 0.041754, 0.31658, 0.3137, 0.14944, 0.32577]
Predicted label: 4
Correct prediction
Energy consumption = 196.429733 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 79 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 79 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 79 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1763, 0.75747, 0.17939, 0.36944, 0.19008, 0.17442, 0.41215, 0.13535, 0.33811, 0.16454]
Predicted label: 1
Correct prediction
Energy consumption = 210.663305 pJ
sum error= 22
Actual label: 5
Output voltages: [0.19892, 0.052721, 0.13698, 0.25884, 0.29439, 0.61402, 0.2137, 0.27739, 0.45453, 0.43745]
Predicted label: 5
Correct prediction
Energy consumption = 191.535050 pJ
sum error= 22
Actual label: 3
Output voltages: [0.26223, 0.21351, 0.25471, 0.75327, 0.1513, 0.20176, 0.088095, 0.27387, 0.52872, 0.24033]
Predicted label: 3
Correct prediction
Energy consumption = 179.227566 pJ
sum error= 22
Actual label: 8
Output voltages: [0.22, 0.16633, 0.32086, 0.27645, 0.11183, 0.16529, 0.19201, 0.14472, 0.73701, 0.34475]
Predicted label: 8
Correct prediction
Energy consumption = 189.334023 pJ
sum error= 22
Actual label: 0
Output voltages: [0.71675, 0.28871, 0.2301, 0.14109, 0.13209, 0.15958, 0.43349, 0.1877, 0.27688, 0.26698]
Predicted label: 0
Correct prediction
Energy consumption = 192.347172 pJ
sum error= 22
Actual label: 3
Output voltages: [0.42767, 0.23039, 0.2673, 0.73379, 0.11383, 0.25572, 0.27498, 0.16173, 0.3974, 0.17321]
Predicted label: 3
Correct prediction
Energy consumption = 206.520392 pJ
sum error= 22
Actual label: 2
Output voltages: [0.42058, 0.13425, 0.71596, 0.38575, 0.14558, 0.045978, 0.2421, 0.24338, 0.43182, 0.15679]
Predicted label: 2
Correct prediction
Energy consumption = 192.728002 pJ
sum error= 22
Actual label: 5
Output voltages: [0.316, 0.39924, 0.078272, 0.26384, 0.056128, 0.6151, 0.26533, 0.065758, 0.55421, 0.20323]
Predicted label: 5
Correct prediction
Energy consumption = 201.469373 pJ
sum error= 22
Actual label: 1
Output voltages: [0.24566, 0.75938, 0.30104, 0.30985, 0.25123, 0.069877, 0.32685, 0.12277, 0.24877, 0.25836]
Predicted label: 1
Correct prediction
Energy consumption = 206.634223 pJ
sum error= 22
Actual label: 2
Output voltages: [0.34074, 0.34189, 0.74179, 0.35233, 0.2084, 0.031049, 0.25597, 0.32815, 0.34167, 0.23029]
Predicted label: 2
Correct prediction
Energy consumption = 181.701568 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 80 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 80 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 80 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.4331, 0.15759, 0.32451, 0.4361, 0.19794, 0.11026, 0.28702, 0.052687, 0.62577, 0.31988]
Predicted label: 8
Correct prediction
Energy consumption = 204.541630 pJ
sum error= 22
Actual label: 3
Output voltages: [0.33874, 0.14233, 0.28054, 0.75251, 0.2375, 0.21642, 0.2586, 0.22319, 0.4159, 0.18459]
Predicted label: 3
Correct prediction
Energy consumption = 186.945139 pJ
sum error= 22
Actual label: 4
Output voltages: [0.13562, 0.18006, 0.27334, 0.098574, 0.75789, 0.10563, 0.3045, 0.34755, 0.22846, 0.24792]
Predicted label: 4
Correct prediction
Energy consumption = 194.151718 pJ
sum error= 22
Actual label: 4
Output voltages: [0.16678, 0.19673, 0.32856, 0.068265, 0.75637, 0.053709, 0.33809, 0.24944, 0.21213, 0.28401]
Predicted label: 4
Correct prediction
Energy consumption = 193.433080 pJ
sum error= 22
Actual label: 0
Output voltages: [0.63316, 0.073506, 0.3468, 0.28877, 0.10003, 0.20988, 0.34977, 0.10324, 0.4337, 0.32599]
Predicted label: 0
Correct prediction
Energy consumption = 196.274943 pJ
sum error= 22
Actual label: 8
Output voltages: [0.23079, 0.20417, 0.33374, 0.29284, 0.14662, 0.19968, 0.18013, 0.18197, 0.75608, 0.24598]
Predicted label: 8
Correct prediction
Energy consumption = 187.724684 pJ
sum error= 22
Actual label: 8
Output voltages: [0.25055, 0.17466, 0.30186, 0.26195, 0.18092, 0.24965, 0.29088, 0.1168, 0.74057, 0.29629]
Predicted label: 8
Correct prediction
Energy consumption = 191.463555 pJ
sum error= 22
Actual label: 3
Output voltages: [0.31907, 0.17481, 0.30646, 0.7545, 0.20078, 0.25722, 0.17635, 0.14028, 0.44795, 0.18897]
Predicted label: 3
Correct prediction
Energy consumption = 183.768652 pJ
sum error= 22
Actual label: 3
Output voltages: [0.37408, 0.14346, 0.24918, 0.75792, 0.21242, 0.2761, 0.24212, 0.17265, 0.35382, 0.19409]
Predicted label: 3
Correct prediction
Energy consumption = 182.006030 pJ
sum error= 22
Actual label: 1
Output voltages: [0.21132, 0.76403, 0.13281, 0.33004, 0.29509, 0.12876, 0.23017, 0.20281, 0.29703, 0.26546]
Predicted label: 1
Correct prediction
Energy consumption = 215.465297 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 81 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 81 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 81 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32722, 0.12964, 0.52417, 0.30641, 0.083739, 0.056855, 0.15225, 0.64359, 0.40317, 0.2969]
Predicted label: 7
Correct prediction
Energy consumption = 201.493229 pJ
sum error= 22
Actual label: 3
Output voltages: [0.29929, 0.26219, 0.28469, 0.75875, 0.15412, 0.12636, 0.1011, 0.28143, 0.41845, 0.22009]
Predicted label: 3
Correct prediction
Energy consumption = 180.416257 pJ
sum error= 22
Actual label: 5
Output voltages: [0.27058, 0.049272, 0.11134, 0.347, 0.22566, 0.70123, 0.34322, 0.16679, 0.55719, 0.28565]
Predicted label: 5
Correct prediction
Energy consumption = 185.368547 pJ
sum error= 22
Actual label: 9
Output voltages: [0.39773, 0.11771, 0.25176, 0.14391, 0.303, 0.1296, 0.11798, 0.20168, 0.47814, 0.62837]
Predicted label: 9
Correct prediction
Energy consumption = 185.184986 pJ
sum error= 22
Actual label: 6
Output voltages: [0.33186, 0.21726, 0.23199, 0.16254, 0.32453, 0.41535, 0.73021, 0.10181, 0.37784, 0.10039]
Predicted label: 6
Correct prediction
Energy consumption = 197.368804 pJ
sum error= 22
Actual label: 3
Output voltages: [0.40717, 0.15677, 0.33465, 0.74753, 0.11657, 0.14179, 0.14167, 0.20022, 0.41562, 0.25761]
Predicted label: 3
Correct prediction
Energy consumption = 194.182035 pJ
sum error= 22
Actual label: 2
Output voltages: [0.34338, 0.24294, 0.69095, 0.36494, 0.13906, 0.030853, 0.28636, 0.21875, 0.51429, 0.24576]
Predicted label: 2
Correct prediction
Energy consumption = 181.547338 pJ
sum error= 22
Actual label: 6
Output voltages: [0.39481, 0.1667, 0.30658, 0.067165, 0.33475, 0.24216, 0.72405, 0.064502, 0.38016, 0.15661]
Predicted label: 6
Correct prediction
Energy consumption = 182.969097 pJ
sum error= 22
Actual label: 1
Output voltages: [0.23633, 0.74803, 0.23034, 0.26627, 0.16232, 0.10533, 0.45826, 0.098986, 0.38056, 0.16436]
Predicted label: 1
Correct prediction
Energy consumption = 202.888340 pJ
sum error= 22
Actual label: 3
Output voltages: [0.47698, 0.12518, 0.32625, 0.74798, 0.19435, 0.21879, 0.13615, 0.20446, 0.34917, 0.12547]
Predicted label: 3
Correct prediction
Energy consumption = 182.650401 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 82 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 82 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 82 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32761, 0.20353, 0.30801, 0.11509, 0.3239, 0.30197, 0.73308, 0.050987, 0.41676, 0.18151]
Predicted label: 6
Correct prediction
Energy consumption = 182.750074 pJ
sum error= 22
Actual label: 0
Output voltages: [0.71787, 0.25879, 0.22553, 0.15237, 0.15412, 0.19577, 0.41856, 0.14296, 0.28557, 0.3403]
Predicted label: 0
Correct prediction
Energy consumption = 193.145984 pJ
sum error= 22
Actual label: 7
Output voltages: [0.40173, 0.17287, 0.14114, 0.39713, 0.085114, 0.22045, 0.042126, 0.74118, 0.38534, 0.38171]
Predicted label: 7
Correct prediction
Energy consumption = 196.533464 pJ
sum error= 22
Actual label: 2
Output voltages: [0.26776, 0.14135, 0.66988, 0.26714, 0.21373, 0.061295, 0.29684, 0.18276, 0.53641, 0.20804]
Predicted label: 2
Correct prediction
Energy consumption = 190.606578 pJ
sum error= 22
Actual label: 1
Output voltages: [0.16397, 0.76919, 0.23799, 0.2103, 0.2312, 0.12273, 0.40996, 0.14056, 0.32843, 0.19136]
Predicted label: 1
Correct prediction
Energy consumption = 208.930547 pJ
sum error= 22
Actual label: 7
Output voltages: [0.29797, 0.22596, 0.18959, 0.29541, 0.1667, 0.12489, 0.040699, 0.75405, 0.43533, 0.39801]
Predicted label: 7
Correct prediction
Energy consumption = 202.568923 pJ
sum error= 22
Actual label: 1
Output voltages: [0.1271, 0.76858, 0.21563, 0.29158, 0.22122, 0.15573, 0.45869, 0.20327, 0.29833, 0.18653]
Predicted label: 1
Correct prediction
Energy consumption = 208.097706 pJ
sum error= 22
Actual label: 4
Output voltages: [0.10331, 0.1015, 0.21043, 0.16893, 0.69256, 0.20553, 0.17213, 0.25827, 0.37649, 0.34722]
Predicted label: 4
Correct prediction
Energy consumption = 192.014350 pJ
sum error= 22
Actual label: 2
Output voltages: [0.35944, 0.26403, 0.73251, 0.36617, 0.14125, 0.034625, 0.29371, 0.19776, 0.47675, 0.19672]
Predicted label: 2
Correct prediction
Energy consumption = 188.392176 pJ
sum error= 22
Actual label: 4
Output voltages: [0.32897, 0.13208, 0.36871, 0.20895, 0.57952, 0.042045, 0.21909, 0.19171, 0.5082, 0.21595]
Predicted label: 4
Correct prediction
Energy consumption = 189.523068 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 83 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 83 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 83 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36152, 0.26175, 0.73838, 0.27906, 0.21086, 0.026931, 0.24509, 0.29688, 0.34448, 0.19692]
Predicted label: 2
Correct prediction
Energy consumption = 193.388205 pJ
sum error= 22
Actual label: 1
Output voltages: [0.22755, 0.76272, 0.3, 0.29851, 0.21588, 0.052071, 0.34159, 0.078963, 0.31471, 0.2954]
Predicted label: 1
Correct prediction
Energy consumption = 212.161585 pJ
sum error= 22
Actual label: 7
Output voltages: [0.23639, 0.16375, 0.2826, 0.42634, 0.23081, 0.053962, 0.043502, 0.72235, 0.35209, 0.30592]
Predicted label: 7
Correct prediction
Energy consumption = 186.141520 pJ
sum error= 22
Actual label: 9
Output voltages: [0.41753, 0.13258, 0.10073, 0.29908, 0.39493, 0.20289, 0.092788, 0.23231, 0.30054, 0.60915]
Predicted label: 9
Correct prediction
Energy consumption = 190.341629 pJ
sum error= 22
Actual label: 6
Output voltages: [0.29213, 0.36632, 0.27851, 0.25179, 0.25675, 0.21835, 0.71248, 0.059526, 0.44289, 0.082197]
Predicted label: 6
Correct prediction
Energy consumption = 198.410093 pJ
sum error= 22
Actual label: 1
Output voltages: [0.2033, 0.76756, 0.24041, 0.23479, 0.26869, 0.10486, 0.37351, 0.14735, 0.29807, 0.22729]
Predicted label: 1
Correct prediction
Energy consumption = 208.678364 pJ
sum error= 22
Actual label: 1
Output voltages: [0.21489, 0.7496, 0.31795, 0.29195, 0.32213, 0.048001, 0.32815, 0.15193, 0.23335, 0.22511]
Predicted label: 1
Correct prediction
Energy consumption = 201.249005 pJ
sum error= 22
Actual label: 2
Output voltages: [0.30104, 0.45638, 0.71188, 0.28996, 0.11594, 0.026911, 0.27478, 0.22627, 0.30743, 0.20551]
Predicted label: 2
Correct prediction
Energy consumption = 186.836740 pJ
sum error= 22
Actual label: 4
Output voltages: [0.13861, 0.17464, 0.30005, 0.17782, 0.74745, 0.074433, 0.21636, 0.31264, 0.223, 0.37532]
Predicted label: 4
Correct prediction
Energy consumption = 194.403837 pJ
sum error= 22
Actual label: 8
Output voltages: [0.35914, 0.097567, 0.18265, 0.37552, 0.27496, 0.22878, 0.40062, 0.043777, 0.62663, 0.24689]
Predicted label: 8
Correct prediction
Energy consumption = 192.595781 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 84 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 84 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 84 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.15604, 0.74677, 0.23946, 0.26914, 0.23948, 0.057342, 0.35725, 0.13359, 0.38954, 0.27331]
Predicted label: 1
Correct prediction
Energy consumption = 211.657690 pJ
sum error= 22
Actual label: 7
Output voltages: [0.31383, 0.12962, 0.30074, 0.24287, 0.27508, 0.054343, 0.067821, 0.73299, 0.3179, 0.3843]
Predicted label: 7
Correct prediction
Energy consumption = 193.099764 pJ
sum error= 22
Actual label: 7
Output voltages: [0.35244, 0.29951, 0.52217, 0.28339, 0.12828, 0.018273, 0.1067, 0.55991, 0.24524, 0.33605]
Predicted label: 7
Correct prediction
Energy consumption = 189.090983 pJ
sum error= 22
Actual label: 4
Output voltages: [0.12286, 0.13588, 0.36, 0.1276, 0.7613, 0.1422, 0.30876, 0.25466, 0.22965, 0.29475]
Predicted label: 4
Correct prediction
Energy consumption = 195.240235 pJ
sum error= 22
Actual label: 8
Output voltages: [0.18095, 0.26155, 0.20852, 0.33797, 0.063381, 0.24028, 0.14542, 0.38121, 0.71237, 0.24694]
Predicted label: 8
Correct prediction
Energy consumption = 198.770334 pJ
sum error= 22
Actual label: 0
Output voltages: [0.73921, 0.24214, 0.2293, 0.25988, 0.12807, 0.18019, 0.30719, 0.18114, 0.34617, 0.28701]
Predicted label: 0
Correct prediction
Energy consumption = 193.011580 pJ
sum error= 22
Actual label: 7
Output voltages: [0.59736, 0.1501, 0.29317, 0.2102, 0.26617, 0.12783, 0.15007, 0.34525, 0.21165, 0.50311]
Predicted label: 0
Wrong prediction!
Energy consumption = 195.512266 pJ
sum error= 23
Actual label: 3
Output voltages: [0.30877, 0.18782, 0.37447, 0.68566, 0.19186, 0.092616, 0.1267, 0.098071, 0.50915, 0.29812]
Predicted label: 3
Correct prediction
Energy consumption = 183.810866 pJ
sum error= 23
Actual label: 1
Output voltages: [0.2074, 0.76183, 0.19583, 0.22101, 0.33459, 0.18019, 0.46177, 0.1044, 0.25378, 0.23559]
Predicted label: 1
Correct prediction
Energy consumption = 212.109266 pJ
sum error= 23
Actual label: 3
Output voltages: [0.3079, 0.24576, 0.40001, 0.74104, 0.16941, 0.08807, 0.17838, 0.15087, 0.37989, 0.16045]
Predicted label: 3
Correct prediction
Energy consumption = 185.392919 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 85 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 85 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 85 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.31159, 0.75138, 0.31791, 0.23865, 0.28886, 0.053433, 0.2938, 0.1075, 0.3535, 0.25376]
Predicted label: 1
Correct prediction
Energy consumption = 209.907923 pJ
sum error= 23
Actual label: 0
Output voltages: [0.70795, 0.22266, 0.27265, 0.21519, 0.18474, 0.11839, 0.39992, 0.12731, 0.39131, 0.21712]
Predicted label: 0
Correct prediction
Energy consumption = 198.788548 pJ
sum error= 23
Actual label: 7
Output voltages: [0.31642, 0.26695, 0.29084, 0.28662, 0.14896, 0.050096, 0.072369, 0.75745, 0.25178, 0.30268]
Predicted label: 7
Correct prediction
Energy consumption = 198.403935 pJ
sum error= 23
Actual label: 7
Output voltages: [0.27892, 0.33341, 0.39019, 0.34163, 0.073696, 0.060612, 0.045394, 0.71446, 0.4223, 0.29195]
Predicted label: 7
Correct prediction
Energy consumption = 188.100276 pJ
sum error= 23
Actual label: 0
Output voltages: [0.72033, 0.30658, 0.23733, 0.20089, 0.10793, 0.15595, 0.45548, 0.1711, 0.2951, 0.30479]
Predicted label: 0
Correct prediction
Energy consumption = 192.962124 pJ
sum error= 23
Actual label: 3
Output voltages: [0.28569, 0.14605, 0.34713, 0.7352, 0.17611, 0.096013, 0.091025, 0.21825, 0.46338, 0.2602]
Predicted label: 3
Correct prediction
Energy consumption = 187.267450 pJ
sum error= 23
Actual label: 5
Output voltages: [0.26345, 0.059987, 0.1747, 0.29016, 0.19501, 0.64873, 0.21487, 0.12237, 0.55816, 0.25257]
Predicted label: 5
Correct prediction
Energy consumption = 178.168674 pJ
sum error= 23
Actual label: 5
Output voltages: [0.26706, 0.13082, 0.058218, 0.48537, 0.13944, 0.73827, 0.23283, 0.15944, 0.43743, 0.22894]
Predicted label: 5
Correct prediction
Energy consumption = 195.609920 pJ
sum error= 23
Actual label: 2
Output voltages: [0.34942, 0.18359, 0.73849, 0.32137, 0.13861, 0.043159, 0.26626, 0.32765, 0.4597, 0.17821]
Predicted label: 2
Correct prediction
Energy consumption = 194.942838 pJ
sum error= 23
Actual label: 7
Output voltages: [0.2521, 0.27335, 0.20896, 0.28392, 0.16537, 0.070844, 0.041888, 0.73859, 0.27562, 0.44181]
Predicted label: 7
Correct prediction
Energy consumption = 200.630079 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 86 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 86 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 86 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.2457, 0.1945, 0.36459, 0.078432, 0.30876, 0.35026, 0.74147, 0.05298, 0.42048, 0.15905]
Predicted label: 6
Correct prediction
Energy consumption = 186.518183 pJ
sum error= 23
Actual label: 6
Output voltages: [0.28531, 0.17591, 0.29963, 0.15829, 0.29798, 0.40753, 0.73465, 0.067443, 0.39637, 0.13811]
Predicted label: 6
Correct prediction
Energy consumption = 184.962262 pJ
sum error= 23
Actual label: 9
Output voltages: [0.36891, 0.086536, 0.18638, 0.2582, 0.30649, 0.14706, 0.086642, 0.31238, 0.40661, 0.61698]
Predicted label: 9
Correct prediction
Energy consumption = 200.664972 pJ
sum error= 23
Actual label: 2
Output voltages: [0.40034, 0.15123, 0.72924, 0.31028, 0.13063, 0.043849, 0.21098, 0.33742, 0.49018, 0.17157]
Predicted label: 2
Correct prediction
Energy consumption = 190.557736 pJ
sum error= 23
Actual label: 8
Output voltages: [0.27005, 0.16271, 0.27575, 0.26565, 0.16644, 0.30074, 0.18345, 0.11375, 0.74422, 0.27933]
Predicted label: 8
Correct prediction
Energy consumption = 186.500919 pJ
sum error= 23
Actual label: 3
Output voltages: [0.41534, 0.17445, 0.2536, 0.7571, 0.13544, 0.2497, 0.18915, 0.20751, 0.34826, 0.21911]
Predicted label: 3
Correct prediction
Energy consumption = 193.148113 pJ
sum error= 23
Actual label: 5
Output voltages: [0.23541, 0.065816, 0.13326, 0.31699, 0.21939, 0.64509, 0.37818, 0.17668, 0.45732, 0.34307]
Predicted label: 5
Correct prediction
Energy consumption = 193.250612 pJ
sum error= 23
Actual label: 2
Output voltages: [0.3848, 0.40621, 0.70855, 0.29232, 0.14093, 0.020602, 0.27203, 0.28903, 0.29936, 0.24005]
Predicted label: 2
Correct prediction
Energy consumption = 192.824137 pJ
sum error= 23
Actual label: 2
Output voltages: [0.44612, 0.19921, 0.71272, 0.34734, 0.14754, 0.040307, 0.32109, 0.26336, 0.38147, 0.19245]
Predicted label: 2
Correct prediction
Energy consumption = 191.428916 pJ
sum error= 23
Actual label: 5
Output voltages: [0.21558, 0.090937, 0.088623, 0.36398, 0.18876, 0.71214, 0.24531, 0.15128, 0.51567, 0.27188]
Predicted label: 5
Correct prediction
Energy consumption = 188.441480 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 87 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 87 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 87 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32171, 0.18566, 0.21364, 0.2063, 0.23294, 0.38029, 0.65448, 0.11016, 0.51316, 0.16013]
Predicted label: 6
Correct prediction
Energy consumption = 193.342578 pJ
sum error= 23
Actual label: 0
Output voltages: [0.72851, 0.25648, 0.32127, 0.18859, 0.15937, 0.095272, 0.41808, 0.19572, 0.35293, 0.26149]
Predicted label: 0
Correct prediction
Energy consumption = 187.827730 pJ
sum error= 23
Actual label: 8
Output voltages: [0.21234, 0.15861, 0.23419, 0.31614, 0.12981, 0.18498, 0.14067, 0.12196, 0.72552, 0.37881]
Predicted label: 8
Correct prediction
Energy consumption = 200.136770 pJ
sum error= 23
Actual label: 2
Output voltages: [0.31708, 0.25715, 0.73228, 0.32783, 0.13236, 0.030797, 0.17199, 0.40052, 0.34685, 0.23711]
Predicted label: 2
Correct prediction
Energy consumption = 184.940712 pJ
sum error= 23
Actual label: 9
Output voltages: [0.34711, 0.19387, 0.1789, 0.2801, 0.36583, 0.05799, 0.12015, 0.10856, 0.39869, 0.59713]
Predicted label: 9
Correct prediction
Energy consumption = 203.775527 pJ
sum error= 23
Actual label: 2
Output voltages: [0.38649, 0.099815, 0.67239, 0.39663, 0.064951, 0.050463, 0.17654, 0.34938, 0.52021, 0.13586]
Predicted label: 2
Correct prediction
Energy consumption = 190.909686 pJ
sum error= 23
Actual label: 8
Output voltages: [0.30602, 0.11247, 0.28869, 0.37611, 0.12311, 0.32717, 0.19089, 0.09427, 0.74763, 0.28558]
Predicted label: 8
Correct prediction
Energy consumption = 186.801705 pJ
sum error= 23
Actual label: 8
Output voltages: [0.2994, 0.15834, 0.41759, 0.24187, 0.21176, 0.089503, 0.4314, 0.069923, 0.68341, 0.33154]
Predicted label: 8
Correct prediction
Energy consumption = 194.941157 pJ
sum error= 23
Actual label: 8
Output voltages: [0.32344, 0.16823, 0.34492, 0.29598, 0.15161, 0.21909, 0.26161, 0.098383, 0.72811, 0.38702]
Predicted label: 8
Correct prediction
Energy consumption = 194.099219 pJ
sum error= 23
Actual label: 8
Output voltages: [0.22093, 0.23178, 0.32247, 0.29929, 0.13408, 0.2241, 0.34244, 0.06832, 0.71254, 0.19887]
Predicted label: 8
Correct prediction
Energy consumption = 192.785530 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 88 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 88 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 88 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.41763, 0.24107, 0.27451, 0.19438, 0.15282, 0.1515, 0.043979, 0.67218, 0.38204, 0.46267]
Predicted label: 7
Correct prediction
Energy consumption = 195.006510 pJ
sum error= 23
Actual label: 4
Output voltages: [0.19739, 0.16094, 0.23162, 0.28583, 0.60765, 0.19333, 0.17053, 0.1468, 0.30358, 0.47873]
Predicted label: 4
Correct prediction
Energy consumption = 207.791190 pJ
sum error= 23
Actual label: 9
Output voltages: [0.30477, 0.14219, 0.17448, 0.25239, 0.39226, 0.13751, 0.11335, 0.25881, 0.35999, 0.63291]
Predicted label: 9
Correct prediction
Energy consumption = 191.539545 pJ
sum error= 23
Actual label: 3
Output voltages: [0.33987, 0.1567, 0.26487, 0.64763, 0.1067, 0.41306, 0.17447, 0.24302, 0.33274, 0.223]
Predicted label: 3
Correct prediction
Energy consumption = 203.832557 pJ
sum error= 23
Actual label: 0
Output voltages: [0.69269, 0.18327, 0.22984, 0.11911, 0.19803, 0.16884, 0.38663, 0.19687, 0.3703, 0.31126]
Predicted label: 0
Correct prediction
Energy consumption = 205.821760 pJ
sum error= 23
Actual label: 6
Output voltages: [0.26455, 0.17995, 0.268, 0.12773, 0.43241, 0.4031, 0.7063, 0.11445, 0.33013, 0.081751]
Predicted label: 6
Correct prediction
Energy consumption = 195.746866 pJ
sum error= 23
Actual label: 6
Output voltages: [0.33323, 0.25817, 0.34145, 0.16763, 0.24007, 0.33635, 0.74573, 0.075264, 0.36076, 0.20609]
Predicted label: 6
Correct prediction
Energy consumption = 188.076038 pJ
sum error= 23
Actual label: 3
Output voltages: [0.30881, 0.18496, 0.30129, 0.75746, 0.21496, 0.16327, 0.15258, 0.15584, 0.42127, 0.25865]
Predicted label: 3
Correct prediction
Energy consumption = 186.930708 pJ
sum error= 23
Actual label: 2
Output voltages: [0.328, 0.18127, 0.74141, 0.35327, 0.16898, 0.03392, 0.21905, 0.35485, 0.3843, 0.20006]
Predicted label: 2
Correct prediction
Energy consumption = 180.474589 pJ
sum error= 23
Actual label: 1
Output voltages: [0.1881, 0.76432, 0.28316, 0.22676, 0.19556, 0.15645, 0.48138, 0.11926, 0.30794, 0.22564]
Predicted label: 1
Correct prediction
Energy consumption = 207.536257 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 89 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 89 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 89 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23707, 0.10112, 0.24617, 0.7291, 0.25435, 0.33035, 0.24843, 0.11723, 0.44429, 0.23071]
Predicted label: 3
Correct prediction
Energy consumption = 194.536521 pJ
sum error= 23
Actual label: 2
Output voltages: [0.34967, 0.43622, 0.72072, 0.30454, 0.10555, 0.033894, 0.34785, 0.12459, 0.40414, 0.27898]
Predicted label: 2
Correct prediction
Energy consumption = 189.417893 pJ
sum error= 23
Actual label: 2
Output voltages: [0.35169, 0.22461, 0.73821, 0.30883, 0.15929, 0.029159, 0.27575, 0.281, 0.38616, 0.22575]
Predicted label: 2
Correct prediction
Energy consumption = 187.218853 pJ
sum error= 23
Actual label: 9
Output voltages: [0.42018, 0.087282, 0.18319, 0.2349, 0.30611, 0.27305, 0.17759, 0.26964, 0.3282, 0.67093]
Predicted label: 9
Correct prediction
Energy consumption = 192.128306 pJ
sum error= 23
Actual label: 3
Output voltages: [0.40052, 0.14119, 0.3685, 0.61531, 0.10507, 0.15197, 0.31901, 0.11962, 0.51292, 0.13308]
Predicted label: 3
Correct prediction
Energy consumption = 196.531637 pJ
sum error= 23
Actual label: 0
Output voltages: [0.62327, 0.21461, 0.25772, 0.20558, 0.19745, 0.3196, 0.4247, 0.1723, 0.33207, 0.18109]
Predicted label: 0
Correct prediction
Energy consumption = 207.077153 pJ
sum error= 23
Actual label: 0
Output voltages: [0.64925, 0.243, 0.34345, 0.1911, 0.23005, 0.089844, 0.47465, 0.21451, 0.26213, 0.24071]
Predicted label: 0
Correct prediction
Energy consumption = 193.974298 pJ
sum error= 23
Actual label: 5
Output voltages: [0.23076, 0.055643, 0.15119, 0.31525, 0.25042, 0.64215, 0.34717, 0.078602, 0.55004, 0.23083]
Predicted label: 5
Correct prediction
Energy consumption = 181.102779 pJ
sum error= 23
Actual label: 7
Output voltages: [0.27015, 0.17554, 0.36789, 0.47436, 0.18137, 0.034968, 0.06582, 0.61112, 0.37075, 0.25182]
Predicted label: 7
Correct prediction
Energy consumption = 191.285826 pJ
sum error= 23
Actual label: 8
Output voltages: [0.27132, 0.18031, 0.3068, 0.29299, 0.13701, 0.29922, 0.21937, 0.11866, 0.74476, 0.26742]
Predicted label: 8
Correct prediction
Energy consumption = 189.269242 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 90 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 90 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 90 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.18566, 0.6006, 0.17409, 0.56216, 0.26946, 0.37046, 0.31444, 0.14235, 0.20719, 0.23149]
Predicted label: 1
Correct prediction
Energy consumption = 212.981425 pJ
sum error= 23
Actual label: 4
Output voltages: [0.14231, 0.22673, 0.22363, 0.17287, 0.74324, 0.20556, 0.20136, 0.2147, 0.21041, 0.43012]
Predicted label: 4
Correct prediction
Energy consumption = 200.209213 pJ
sum error= 23
Actual label: 4
Output voltages: [0.13527, 0.20018, 0.1599, 0.066695, 0.64554, 0.18773, 0.16557, 0.2939, 0.36833, 0.3617]
Predicted label: 4
Correct prediction
Energy consumption = 202.421507 pJ
sum error= 23
Actual label: 6
Output voltages: [0.32164, 0.18782, 0.25803, 0.17791, 0.3065, 0.35272, 0.70418, 0.05069, 0.43574, 0.19138]
Predicted label: 6
Correct prediction
Energy consumption = 193.902694 pJ
sum error= 23
Actual label: 0
Output voltages: [0.67502, 0.24045, 0.21228, 0.14566, 0.11841, 0.22676, 0.41701, 0.17263, 0.32968, 0.31837]
Predicted label: 0
Correct prediction
Energy consumption = 197.764400 pJ
sum error= 23
Actual label: 2
Output voltages: [0.39047, 0.24048, 0.74544, 0.30151, 0.17488, 0.035981, 0.25301, 0.2851, 0.36779, 0.18699]
Predicted label: 2
Correct prediction
Energy consumption = 188.956564 pJ
sum error= 23
Actual label: 9
Output voltages: [0.31869, 0.063107, 0.23628, 0.25394, 0.46276, 0.17886, 0.10457, 0.44939, 0.25185, 0.58482]
Predicted label: 9
Correct prediction
Energy consumption = 192.345583 pJ
sum error= 23
Actual label: 1
Output voltages: [0.18406, 0.74723, 0.25524, 0.1863, 0.32519, 0.074066, 0.39067, 0.22344, 0.24405, 0.26899]
Predicted label: 1
Correct prediction
Energy consumption = 207.317465 pJ
sum error= 23
Actual label: 4
Output voltages: [0.093738, 0.20286, 0.29615, 0.23946, 0.74876, 0.059968, 0.17531, 0.30818, 0.22975, 0.23472]
Predicted label: 4
Correct prediction
Energy consumption = 192.713595 pJ
sum error= 23
Actual label: 7
Output voltages: [0.33245, 0.2506, 0.20359, 0.3554, 0.11387, 0.14438, 0.032028, 0.71682, 0.32271, 0.42612]
Predicted label: 7
Correct prediction
Energy consumption = 195.041329 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 91 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 91 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 91 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.11476, 0.17452, 0.26603, 0.11504, 0.75974, 0.089184, 0.28258, 0.36085, 0.25172, 0.2203]
Predicted label: 4
Correct prediction
Energy consumption = 197.244952 pJ
sum error= 23
Actual label: 7
Output voltages: [0.32875, 0.35755, 0.45819, 0.33644, 0.058109, 0.035327, 0.06284, 0.68372, 0.38719, 0.23127]
Predicted label: 7
Correct prediction
Energy consumption = 201.923855 pJ
sum error= 23
Actual label: 3
Output voltages: [0.27421, 0.16056, 0.29293, 0.75854, 0.19688, 0.16757, 0.13498, 0.19591, 0.44873, 0.28199]
Predicted label: 3
Correct prediction
Energy consumption = 179.752238 pJ
sum error= 23
Actual label: 9
Output voltages: [0.3813, 0.10087, 0.26259, 0.24094, 0.41016, 0.19884, 0.2028, 0.16824, 0.25938, 0.70133]
Predicted label: 9
Correct prediction
Energy consumption = 193.309683 pJ
sum error= 23
Actual label: 8
Output voltages: [0.18734, 0.19443, 0.27577, 0.31807, 0.11995, 0.31212, 0.24434, 0.15197, 0.74532, 0.2342]
Predicted label: 8
Correct prediction
Energy consumption = 202.612305 pJ
sum error= 23
Actual label: 8
Output voltages: [0.24301, 0.22061, 0.23041, 0.36725, 0.07352, 0.28883, 0.30929, 0.15964, 0.67731, 0.20748]
Predicted label: 8
Correct prediction
Energy consumption = 200.811974 pJ
sum error= 23
Actual label: 4
Output voltages: [0.33299, 0.067735, 0.35779, 0.0702, 0.63535, 0.10837, 0.34981, 0.15862, 0.40026, 0.26754]
Predicted label: 4
Correct prediction
Energy consumption = 200.188413 pJ
sum error= 23
Actual label: 7
Output voltages: [0.28981, 0.25151, 0.25286, 0.27585, 0.11311, 0.07559, 0.048371, 0.75872, 0.29861, 0.35671]
Predicted label: 7
Correct prediction
Energy consumption = 201.145821 pJ
sum error= 23
Actual label: 1
Output voltages: [0.27199, 0.75574, 0.2481, 0.24567, 0.29794, 0.17618, 0.40926, 0.05045, 0.25351, 0.27883]
Predicted label: 1
Correct prediction
Energy consumption = 212.852456 pJ
sum error= 23
Actual label: 2
Output voltages: [0.39965, 0.19298, 0.69511, 0.41384, 0.090009, 0.035998, 0.28115, 0.31589, 0.39918, 0.1964]
Predicted label: 2
Correct prediction
Energy consumption = 189.526685 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 92 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 92 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 92 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23515, 0.76688, 0.18835, 0.31804, 0.28271, 0.071019, 0.2449, 0.16925, 0.27097, 0.30914]
Predicted label: 1
Correct prediction
Energy consumption = 214.773383 pJ
sum error= 23
Actual label: 2
Output voltages: [0.42985, 0.14289, 0.7392, 0.33218, 0.21522, 0.041319, 0.28986, 0.32147, 0.4442, 0.18455]
Predicted label: 2
Correct prediction
Energy consumption = 188.402871 pJ
sum error= 23
Actual label: 2
Output voltages: [0.29273, 0.30949, 0.72607, 0.32103, 0.077697, 0.033425, 0.23107, 0.30377, 0.45722, 0.23607]
Predicted label: 2
Correct prediction
Energy consumption = 188.065991 pJ
sum error= 23
Actual label: 3
Output voltages: [0.30787, 0.20419, 0.27712, 0.75879, 0.1305, 0.12142, 0.14778, 0.19589, 0.45533, 0.23583]
Predicted label: 3
Correct prediction
Energy consumption = 172.584739 pJ
sum error= 23
Actual label: 2
Output voltages: [0.33578, 0.26592, 0.66114, 0.29376, 0.066952, 0.028608, 0.1675, 0.53161, 0.42944, 0.14699]
Predicted label: 2
Correct prediction
Energy consumption = 182.587584 pJ
sum error= 23
Actual label: 3
Output voltages: [0.30516, 0.12855, 0.34674, 0.74675, 0.26146, 0.16372, 0.11283, 0.2332, 0.4534, 0.22382]
Predicted label: 3
Correct prediction
Energy consumption = 176.044693 pJ
sum error= 23
Actual label: 2
Output voltages: [0.47189, 0.29087, 0.46617, 0.11954, 0.26921, 0.061914, 0.38076, 0.13183, 0.37625, 0.2051]
Predicted label: 0
Wrong prediction!
Energy consumption = 203.495945 pJ
sum error= 24
Actual label: 3
Output voltages: [0.41557, 0.16113, 0.34266, 0.75506, 0.12644, 0.1611, 0.17673, 0.20229, 0.37148, 0.22804]
Predicted label: 3
Correct prediction
Energy consumption = 192.214098 pJ
sum error= 24
Actual label: 9
Output voltages: [0.34303, 0.079491, 0.23847, 0.2099, 0.28795, 0.216, 0.1196, 0.26413, 0.44138, 0.62209]
Predicted label: 9
Correct prediction
Energy consumption = 192.988468 pJ
sum error= 24
Actual label: 1
Output voltages: [0.13681, 0.76944, 0.18048, 0.27282, 0.19213, 0.14671, 0.30066, 0.15911, 0.35043, 0.25885]
Predicted label: 1
Correct prediction
Energy consumption = 212.986833 pJ
sum error= 24
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 93 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 93 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 93 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.29358, 0.20084, 0.28016, 0.48863, 0.25472, 0.034135, 0.091548, 0.5359, 0.33382, 0.32428]
Predicted label: 7
Correct prediction
Energy consumption = 196.511755 pJ
sum error= 24
Actual label: 4
Output voltages: [0.31855, 0.15444, 0.30153, 0.24073, 0.60237, 0.11981, 0.21558, 0.28417, 0.2094, 0.54723]
Predicted label: 4
Correct prediction
Energy consumption = 200.858238 pJ
sum error= 24
Actual label: 0
Output voltages: [0.71922, 0.25763, 0.25517, 0.23946, 0.086562, 0.29137, 0.36604, 0.10218, 0.27395, 0.31589]
Predicted label: 0
Correct prediction
Energy consumption = 199.271176 pJ
sum error= 24
Actual label: 3
Output voltages: [0.32693, 0.16299, 0.2783, 0.75365, 0.2761, 0.30158, 0.20235, 0.17337, 0.39397, 0.20273]
Predicted label: 3
Correct prediction
Energy consumption = 189.807946 pJ
sum error= 24
Actual label: 5
Output voltages: [0.21449, 0.060963, 0.1797, 0.25199, 0.23223, 0.58661, 0.30794, 0.18945, 0.48011, 0.37813]
Predicted label: 5
Correct prediction
Energy consumption = 196.701221 pJ
sum error= 24
Actual label: 5
Output voltages: [0.24959, 0.066879, 0.062119, 0.37116, 0.19768, 0.71365, 0.22859, 0.1866, 0.56877, 0.18369]
Predicted label: 5
Correct prediction
Energy consumption = 181.090978 pJ
sum error= 24
Actual label: 8
Output voltages: [0.29394, 0.12139, 0.25282, 0.31297, 0.16329, 0.41836, 0.27433, 0.084251, 0.72662, 0.21405]
Predicted label: 8
Correct prediction
Energy consumption = 191.704913 pJ
sum error= 24
Actual label: 6
Output voltages: [0.26772, 0.19345, 0.40579, 0.05133, 0.34019, 0.26582, 0.74314, 0.069021, 0.36763, 0.13322]
Predicted label: 6
Correct prediction
Energy consumption = 186.801194 pJ
sum error= 24
Actual label: 3
Output voltages: [0.21166, 0.076455, 0.16674, 0.47441, 0.20351, 0.4474, 0.24294, 0.06229, 0.60755, 0.30415]
Predicted label: 8
Wrong prediction!
Energy consumption = 189.219951 pJ
sum error= 25
Actual label: 2
Output voltages: [0.42301, 0.17907, 0.57642, 0.2849, 0.11423, 0.042477, 0.26412, 0.36588, 0.48507, 0.15175]
Predicted label: 2
Correct prediction
Energy consumption = 194.279828 pJ
sum error= 25
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 94 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 94 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 94 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30249, 0.083883, 0.20705, 0.27051, 0.26222, 0.42282, 0.61966, 0.049703, 0.4803, 0.23135]
Predicted label: 6
Correct prediction
Energy consumption = 189.586454 pJ
sum error= 25
Actual label: 7
Output voltages: [0.32567, 0.22138, 0.2272, 0.38166, 0.12352, 0.086337, 0.04056, 0.75557, 0.37704, 0.34933]
Predicted label: 7
Correct prediction
Energy consumption = 202.049506 pJ
sum error= 25
Actual label: 6
Output voltages: [0.3028, 0.18174, 0.27313, 0.13233, 0.2996, 0.45756, 0.73667, 0.087179, 0.39417, 0.12478]
Predicted label: 6
Correct prediction
Energy consumption = 186.629406 pJ
sum error= 25
Actual label: 6
Output voltages: [0.34219, 0.16459, 0.22086, 0.1703, 0.30251, 0.43709, 0.69652, 0.091644, 0.4209, 0.12115]
Predicted label: 6
Correct prediction
Energy consumption = 182.470567 pJ
sum error= 25
Actual label: 3
Output voltages: [0.28623, 0.31175, 0.22163, 0.75343, 0.1012, 0.18141, 0.14169, 0.18376, 0.45682, 0.27085]
Predicted label: 3
Correct prediction
Energy consumption = 205.453510 pJ
sum error= 25
Actual label: 2
Output voltages: [0.38654, 0.26992, 0.73885, 0.37145, 0.19237, 0.0369, 0.31121, 0.17561, 0.44244, 0.23194]
Predicted label: 2
Correct prediction
Energy consumption = 183.438568 pJ
sum error= 25
Actual label: 7
Output voltages: [0.30244, 0.39915, 0.42934, 0.39774, 0.092268, 0.029046, 0.078748, 0.65128, 0.24642, 0.32214]
Predicted label: 7
Correct prediction
Energy consumption = 200.335293 pJ
sum error= 25
Actual label: 8
Output voltages: [0.36248, 0.1985, 0.25894, 0.27637, 0.23492, 0.092626, 0.1863, 0.12468, 0.5388, 0.55771]
Predicted label: 9
Wrong prediction!
Energy consumption = 204.365748 pJ
sum error= 26
Actual label: 1
Output voltages: [0.11932, 0.74988, 0.261, 0.34834, 0.26761, 0.15661, 0.328, 0.21686, 0.26882, 0.24828]
Predicted label: 1
Correct prediction
Energy consumption = 212.409312 pJ
sum error= 26
Actual label: 1
Output voltages: [0.21964, 0.7589, 0.26776, 0.30047, 0.23344, 0.12098, 0.365, 0.097469, 0.2844, 0.23847]
Predicted label: 1
Correct prediction
Energy consumption = 196.943191 pJ
sum error= 26
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 95 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 95 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 95 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30189, 0.11123, 0.54385, 0.38419, 0.19511, 0.032446, 0.059286, 0.5386, 0.40911, 0.29246]
Predicted label: 2
Wrong prediction!
Energy consumption = 193.611623 pJ
sum error= 27
Actual label: 5
Output voltages: [0.25253, 0.044581, 0.062708, 0.17793, 0.33644, 0.64911, 0.20105, 0.34576, 0.43545, 0.37174]
Predicted label: 5
Correct prediction
Energy consumption = 199.682515 pJ
sum error= 27
Actual label: 6
Output voltages: [0.277, 0.17182, 0.30612, 0.0951, 0.35101, 0.28632, 0.73783, 0.13174, 0.32161, 0.19245]
Predicted label: 6
Correct prediction
Energy consumption = 194.190267 pJ
sum error= 27
Actual label: 4
Output voltages: [0.13763, 0.20905, 0.27549, 0.22471, 0.73632, 0.051456, 0.15313, 0.26362, 0.224, 0.26906]
Predicted label: 4
Correct prediction
Energy consumption = 191.003366 pJ
sum error= 27
Actual label: 9
Output voltages: [0.35694, 0.13072, 0.19749, 0.24959, 0.32914, 0.21284, 0.10647, 0.22889, 0.31631, 0.70384]
Predicted label: 9
Correct prediction
Energy consumption = 194.996592 pJ
sum error= 27
Actual label: 5
Output voltages: [0.2253, 0.046142, 0.17951, 0.37169, 0.24361, 0.57872, 0.37259, 0.10967, 0.53241, 0.2083]
Predicted label: 5
Correct prediction
Energy consumption = 194.762961 pJ
sum error= 27
Actual label: 1
Output voltages: [0.29464, 0.51152, 0.40429, 0.39854, 0.078816, 0.2266, 0.45809, 0.10423, 0.38771, 0.094748]
Predicted label: 1
Correct prediction
Energy consumption = 200.664828 pJ
sum error= 27
Actual label: 3
Output voltages: [0.28396, 0.080814, 0.21171, 0.7405, 0.22197, 0.28494, 0.25137, 0.1445, 0.42453, 0.19508]
Predicted label: 3
Correct prediction
Energy consumption = 188.731426 pJ
sum error= 27
Actual label: 3
Output voltages: [0.45618, 0.2015, 0.25503, 0.73799, 0.14585, 0.25017, 0.1097, 0.28979, 0.35566, 0.16849]
Predicted label: 3
Correct prediction
Energy consumption = 193.153968 pJ
sum error= 27
Actual label: 4
Output voltages: [0.14856, 0.30982, 0.23754, 0.26277, 0.69887, 0.1709, 0.28525, 0.14407, 0.22097, 0.39485]
Predicted label: 4
Correct prediction
Energy consumption = 203.011846 pJ
sum error= 27
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 96 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 96 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 96 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24194, 0.081192, 0.18473, 0.3322, 0.13536, 0.22866, 0.063762, 0.40973, 0.59274, 0.45311]
Predicted label: 8
Wrong prediction!
Energy consumption = 190.829999 pJ
sum error= 28
Actual label: 8
Output voltages: [0.1691, 0.27132, 0.29642, 0.3741, 0.10614, 0.17605, 0.16768, 0.13259, 0.74391, 0.2748]
Predicted label: 8
Correct prediction
Energy consumption = 190.433428 pJ
sum error= 28
Actual label: 9
Output voltages: [0.29176, 0.089306, 0.18344, 0.16507, 0.33606, 0.18555, 0.079265, 0.37878, 0.38703, 0.65623]
Predicted label: 9
Correct prediction
Energy consumption = 193.490312 pJ
sum error= 28
Actual label: 1
Output voltages: [0.13561, 0.74986, 0.12679, 0.23566, 0.35465, 0.12854, 0.31304, 0.095044, 0.34861, 0.35109]
Predicted label: 1
Correct prediction
Energy consumption = 213.305030 pJ
sum error= 28
Actual label: 1
Output voltages: [0.21872, 0.74123, 0.27672, 0.17605, 0.36459, 0.062822, 0.37219, 0.16268, 0.24777, 0.23873]
Predicted label: 1
Correct prediction
Energy consumption = 203.600151 pJ
sum error= 28
Actual label: 6
Output voltages: [0.54534, 0.32483, 0.18725, 0.17327, 0.1974, 0.30773, 0.57831, 0.17464, 0.40951, 0.067277]
Predicted label: 6
Correct prediction
Energy consumption = 195.343681 pJ
sum error= 28
Actual label: 9
Output voltages: [0.29259, 0.11033, 0.16954, 0.26069, 0.23257, 0.18192, 0.054221, 0.29273, 0.51421, 0.62804]
Predicted label: 9
Correct prediction
Energy consumption = 192.119589 pJ
sum error= 28
Actual label: 1
Output voltages: [0.22847, 0.76927, 0.27407, 0.19821, 0.2003, 0.085362, 0.36522, 0.15199, 0.31659, 0.22274]
Predicted label: 1
Correct prediction
Energy consumption = 209.423371 pJ
sum error= 28
Actual label: 4
Output voltages: [0.21807, 0.16398, 0.41097, 0.12505, 0.74666, 0.047801, 0.27897, 0.25691, 0.19831, 0.3179]
Predicted label: 4
Correct prediction
Energy consumption = 202.712034 pJ
sum error= 28
Actual label: 4
Output voltages: [0.11137, 0.082763, 0.16583, 0.2764, 0.58076, 0.18542, 0.16531, 0.26566, 0.40643, 0.28836]
Predicted label: 4
Correct prediction
Energy consumption = 195.315328 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 97 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 97 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 97 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.19539, 0.044629, 0.16985, 0.30042, 0.25605, 0.62322, 0.29877, 0.14321, 0.48876, 0.29994]
Predicted label: 5
Correct prediction
Energy consumption = 188.592527 pJ
sum error= 28
Actual label: 4
Output voltages: [0.13364, 0.13121, 0.34003, 0.20484, 0.74597, 0.17183, 0.25899, 0.16197, 0.27613, 0.31468]
Predicted label: 4
Correct prediction
Energy consumption = 200.179624 pJ
sum error= 28
Actual label: 0
Output voltages: [0.73332, 0.27763, 0.23215, 0.17409, 0.13272, 0.21648, 0.41539, 0.16766, 0.24696, 0.27282]
Predicted label: 0
Correct prediction
Energy consumption = 194.026764 pJ
sum error= 28
Actual label: 6
Output voltages: [0.33086, 0.28129, 0.32567, 0.069213, 0.29041, 0.29455, 0.74463, 0.096019, 0.37553, 0.16522]
Predicted label: 6
Correct prediction
Energy consumption = 187.275751 pJ
sum error= 28
Actual label: 2
Output voltages: [0.34355, 0.30288, 0.73079, 0.32453, 0.13513, 0.024601, 0.27607, 0.25302, 0.38742, 0.21315]
Predicted label: 2
Correct prediction
Energy consumption = 189.621059 pJ
sum error= 28
Actual label: 2
Output voltages: [0.40972, 0.11154, 0.5761, 0.56247, 0.12661, 0.043261, 0.19299, 0.24039, 0.48949, 0.16158]
Predicted label: 2
Correct prediction
Energy consumption = 187.902106 pJ
sum error= 28
Actual label: 3
Output voltages: [0.25482, 0.27561, 0.35419, 0.71953, 0.16369, 0.05454, 0.11892, 0.090483, 0.47626, 0.30372]
Predicted label: 3
Correct prediction
Energy consumption = 190.134731 pJ
sum error= 28
Actual label: 1
Output voltages: [0.19355, 0.67627, 0.26205, 0.23209, 0.33473, 0.14774, 0.52443, 0.07074, 0.27365, 0.21534]
Predicted label: 1
Correct prediction
Energy consumption = 213.669667 pJ
sum error= 28
Actual label: 5
Output voltages: [0.28406, 0.092346, 0.17707, 0.37531, 0.16499, 0.71767, 0.22613, 0.13658, 0.56751, 0.27451]
Predicted label: 5
Correct prediction
Energy consumption = 189.166743 pJ
sum error= 28
Actual label: 1
Output voltages: [0.20817, 0.75759, 0.27372, 0.3506, 0.11589, 0.071346, 0.32783, 0.17029, 0.36835, 0.22793]
Predicted label: 1
Correct prediction
Energy consumption = 202.655889 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 98 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 98 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 98 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40816, 0.2596, 0.74344, 0.30071, 0.2238, 0.035104, 0.26517, 0.29658, 0.36588, 0.20525]
Predicted label: 2
Correct prediction
Energy consumption = 190.527280 pJ
sum error= 28
Actual label: 0
Output voltages: [0.69285, 0.22819, 0.29306, 0.19907, 0.176, 0.11634, 0.50171, 0.15347, 0.33246, 0.24842]
Predicted label: 0
Correct prediction
Energy consumption = 193.247909 pJ
sum error= 28
Actual label: 3
Output voltages: [0.28882, 0.25973, 0.39431, 0.72519, 0.11392, 0.058935, 0.14006, 0.093389, 0.44899, 0.23926]
Predicted label: 3
Correct prediction
Energy consumption = 193.851600 pJ
sum error= 28
Actual label: 8
Output voltages: [0.2677, 0.20568, 0.32191, 0.25965, 0.21012, 0.23226, 0.26598, 0.075833, 0.75063, 0.26583]
Predicted label: 8
Correct prediction
Energy consumption = 191.309886 pJ
sum error= 28
Actual label: 1
Output voltages: [0.26886, 0.76239, 0.27485, 0.19301, 0.29664, 0.15508, 0.41116, 0.076574, 0.24373, 0.25084]
Predicted label: 1
Correct prediction
Energy consumption = 215.864662 pJ
sum error= 28
Actual label: 2
Output voltages: [0.28113, 0.23281, 0.71968, 0.35027, 0.12494, 0.030763, 0.28611, 0.2204, 0.47534, 0.18761]
Predicted label: 2
Correct prediction
Energy consumption = 189.285942 pJ
sum error= 28
Actual label: 6
Output voltages: [0.28637, 0.15049, 0.24708, 0.15267, 0.29119, 0.37744, 0.6989, 0.055542, 0.42403, 0.21738]
Predicted label: 6
Correct prediction
Energy consumption = 189.718854 pJ
sum error= 28
Actual label: 7
Output voltages: [0.18006, 0.20298, 0.20881, 0.31372, 0.24782, 0.15529, 0.042567, 0.7628, 0.352, 0.24796]
Predicted label: 7
Correct prediction
Energy consumption = 194.015009 pJ
sum error= 28
Actual label: 1
Output voltages: [0.19999, 0.75627, 0.17912, 0.30181, 0.30047, 0.14103, 0.21523, 0.17771, 0.26354, 0.34382]
Predicted label: 1
Correct prediction
Energy consumption = 210.570781 pJ
sum error= 28
Actual label: 6
Output voltages: [0.36737, 0.22994, 0.33625, 0.12948, 0.27006, 0.2578, 0.72632, 0.089562, 0.40309, 0.12141]
Predicted label: 6
Correct prediction
Energy consumption = 198.292443 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 99 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 99 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 99 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.38361, 0.1856, 0.66423, 0.37157, 0.23805, 0.035573, 0.20857, 0.27496, 0.5027, 0.16468]
Predicted label: 2
Correct prediction
Energy consumption = 192.007781 pJ
sum error= 28
Actual label: 3
Output voltages: [0.2782, 0.1847, 0.2577, 0.74691, 0.10047, 0.26035, 0.10127, 0.24728, 0.4972, 0.18783]
Predicted label: 3
Correct prediction
Energy consumption = 183.256959 pJ
sum error= 28
Actual label: 9
Output voltages: [0.29561, 0.057907, 0.25114, 0.24461, 0.42339, 0.1023, 0.068202, 0.28355, 0.37152, 0.51391]
Predicted label: 9
Correct prediction
Energy consumption = 199.955625 pJ
sum error= 28
Actual label: 0
Output voltages: [0.71555, 0.19037, 0.24249, 0.25998, 0.1735, 0.14515, 0.2982, 0.2019, 0.34804, 0.28589]
Predicted label: 0
Correct prediction
Energy consumption = 201.539800 pJ
sum error= 28
Actual label: 1
Output voltages: [0.097459, 0.72214, 0.35539, 0.41918, 0.13135, 0.11693, 0.18599, 0.25692, 0.41263, 0.2326]
Predicted label: 1
Correct prediction
Energy consumption = 214.086831 pJ
sum error= 28
Actual label: 2
Output voltages: [0.51037, 0.20859, 0.72627, 0.36838, 0.07958, 0.065593, 0.2819, 0.28878, 0.31082, 0.19085]
Predicted label: 2
Correct prediction
Energy consumption = 195.642216 pJ
sum error= 28
Actual label: 2
Output voltages: [0.37997, 0.2411, 0.73462, 0.32436, 0.16544, 0.037736, 0.31385, 0.20114, 0.48863, 0.22693]
Predicted label: 2
Correct prediction
Energy consumption = 174.063768 pJ
sum error= 28
Actual label: 0
Output voltages: [0.73771, 0.22159, 0.28793, 0.19041, 0.17257, 0.1189, 0.38472, 0.18209, 0.33516, 0.23835]
Predicted label: 0
Correct prediction
Energy consumption = 185.489231 pJ
sum error= 28
Actual label: 8
Output voltages: [0.25693, 0.1936, 0.29425, 0.20384, 0.16202, 0.21095, 0.21552, 0.23732, 0.74334, 0.25922]
Predicted label: 8
Correct prediction
Energy consumption = 187.371893 pJ
sum error= 28
Actual label: 9
Output voltages: [0.41759, 0.071735, 0.25713, 0.24542, 0.3753, 0.1743, 0.13165, 0.36815, 0.27588, 0.62098]
Predicted label: 9
Correct prediction
Energy consumption = 200.017061 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 100 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 100 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 100 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37049, 0.17952, 0.14342, 0.33337, 0.43886, 0.14568, 0.12299, 0.13287, 0.27657, 0.61136]
Predicted label: 9
Correct prediction
Energy consumption = 198.481176 pJ
sum error= 28
Actual label: 0
Output voltages: [0.69701, 0.23153, 0.21213, 0.16266, 0.24023, 0.15765, 0.52261, 0.18904, 0.277, 0.23412]
Predicted label: 0
Correct prediction
Energy consumption = 200.670870 pJ
sum error= 28
Actual label: 2
Output voltages: [0.34304, 0.31111, 0.6707, 0.3607, 0.094624, 0.036344, 0.29054, 0.21501, 0.53649, 0.21649]
Predicted label: 2
Correct prediction
Energy consumption = 189.829102 pJ
sum error= 28
Actual label: 5
Output voltages: [0.22103, 0.058238, 0.16957, 0.54873, 0.18933, 0.52131, 0.21327, 0.16596, 0.53142, 0.22898]
Predicted label: 3
Wrong prediction!
Energy consumption = 186.987207 pJ
sum error= 29
Actual label: 1
Output voltages: [0.26771, 0.75028, 0.1786, 0.30532, 0.30959, 0.095131, 0.29255, 0.083018, 0.30181, 0.32182]
Predicted label: 1
Correct prediction
Energy consumption = 208.100836 pJ
sum error= 29
Actual label: 9
Output voltages: [0.33098, 0.15308, 0.20484, 0.30397, 0.31542, 0.097676, 0.11516, 0.25767, 0.33581, 0.69437]
Predicted label: 9
Correct prediction
Energy consumption = 198.208308 pJ
sum error= 29
Actual label: 7
Output voltages: [0.34136, 0.21537, 0.14219, 0.28328, 0.17772, 0.15595, 0.043908, 0.68427, 0.3435, 0.47195]
Predicted label: 7
Correct prediction
Energy consumption = 202.720030 pJ
sum error= 29
Actual label: 8
Output voltages: [0.20861, 0.25, 0.21428, 0.36495, 0.12619, 0.20162, 0.19003, 0.074751, 0.73016, 0.35614]
Predicted label: 8
Correct prediction
Energy consumption = 199.551808 pJ
sum error= 29
Actual label: 1
Output voltages: [0.19297, 0.77003, 0.20516, 0.25774, 0.23954, 0.18686, 0.38602, 0.12507, 0.29265, 0.24933]
Predicted label: 1
Correct prediction
Energy consumption = 206.733554 pJ
sum error= 29
Actual label: 0
Output voltages: [0.65584, 0.19527, 0.21109, 0.13881, 0.13057, 0.36721, 0.41237, 0.093201, 0.34414, 0.28653]
Predicted label: 0
Correct prediction
Energy consumption = 197.105100 pJ
sum error= 29
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 101 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 101 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 101 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13858, 0.11394, 0.2973, 0.11951, 0.625, 0.049666, 0.18605, 0.33408, 0.42575, 0.2299]
Predicted label: 4
Correct prediction
Energy consumption = 202.742404 pJ
sum error= 29
Actual label: 1
Output voltages: [0.27214, 0.76172, 0.2163, 0.28393, 0.17886, 0.12614, 0.40647, 0.069605, 0.33628, 0.21859]
Predicted label: 1
Correct prediction
Energy consumption = 207.062421 pJ
sum error= 29
Actual label: 7
Output voltages: [0.30725, 0.19096, 0.28558, 0.4848, 0.29053, 0.06096, 0.048607, 0.64885, 0.26791, 0.38541]
Predicted label: 7
Correct prediction
Energy consumption = 189.078847 pJ
sum error= 29
Actual label: 9
Output voltages: [0.37315, 0.14946, 0.20886, 0.26002, 0.43753, 0.20973, 0.14918, 0.21455, 0.31542, 0.65919]
Predicted label: 9
Correct prediction
Energy consumption = 194.731409 pJ
sum error= 29
Actual label: 6
Output voltages: [0.49253, 0.053383, 0.14787, 0.33109, 0.17213, 0.58844, 0.38612, 0.089556, 0.4109, 0.16773]
Predicted label: 5
Wrong prediction!
Energy consumption = 195.045435 pJ
sum error= 30
Actual label: 4
Output voltages: [0.14735, 0.16775, 0.22881, 0.17499, 0.68581, 0.065195, 0.14135, 0.24549, 0.40406, 0.26109]
Predicted label: 4
Correct prediction
Energy consumption = 202.339593 pJ
sum error= 30
Actual label: 2
Output voltages: [0.31342, 0.23201, 0.6995, 0.45517, 0.11802, 0.044946, 0.26268, 0.20401, 0.40584, 0.11648]
Predicted label: 2
Correct prediction
Energy consumption = 191.048632 pJ
sum error= 30
Actual label: 6
Output voltages: [0.25719, 0.19154, 0.56077, 0.043869, 0.28832, 0.21986, 0.65341, 0.078743, 0.30995, 0.18099]
Predicted label: 6
Correct prediction
Energy consumption = 190.049704 pJ
sum error= 30
Actual label: 8
Output voltages: [0.24742, 0.10392, 0.26085, 0.29687, 0.13381, 0.27959, 0.19394, 0.096193, 0.719, 0.32381]
Predicted label: 8
Correct prediction
Energy consumption = 197.917196 pJ
sum error= 30
Actual label: 1
Output voltages: [0.24139, 0.74203, 0.18769, 0.20461, 0.36375, 0.10043, 0.32579, 0.2038, 0.25834, 0.26365]
Predicted label: 1
Correct prediction
Energy consumption = 200.906365 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 102 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 102 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 102 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29584, 0.19489, 0.35861, 0.75498, 0.15358, 0.091581, 0.14688, 0.16509, 0.44425, 0.21677]
Predicted label: 3
Correct prediction
Energy consumption = 181.890717 pJ
sum error= 30
Actual label: 7
Output voltages: [0.45857, 0.20167, 0.35918, 0.11243, 0.068009, 0.090567, 0.072193, 0.67746, 0.49986, 0.31307]
Predicted label: 7
Correct prediction
Energy consumption = 186.286013 pJ
sum error= 30
Actual label: 5
Output voltages: [0.20423, 0.061369, 0.11067, 0.41646, 0.2663, 0.62154, 0.17781, 0.18683, 0.49351, 0.34424]
Predicted label: 5
Correct prediction
Energy consumption = 190.270545 pJ
sum error= 30
Actual label: 4
Output voltages: [0.20225, 0.16212, 0.27151, 0.09718, 0.7393, 0.10234, 0.41402, 0.20609, 0.22679, 0.26151]
Predicted label: 4
Correct prediction
Energy consumption = 199.274141 pJ
sum error= 30
Actual label: 4
Output voltages: [0.13242, 0.19733, 0.22284, 0.16235, 0.75168, 0.076259, 0.25603, 0.27413, 0.29483, 0.18089]
Predicted label: 4
Correct prediction
Energy consumption = 194.276781 pJ
sum error= 30
Actual label: 1
Output voltages: [0.16863, 0.76107, 0.2614, 0.24186, 0.29008, 0.12817, 0.44298, 0.14949, 0.28598, 0.18359]
Predicted label: 1
Correct prediction
Energy consumption = 199.812159 pJ
sum error= 30
Actual label: 8
Output voltages: [0.26299, 0.080981, 0.13792, 0.26653, 0.16624, 0.49772, 0.24835, 0.19249, 0.65489, 0.30576]
Predicted label: 8
Correct prediction
Energy consumption = 204.775071 pJ
sum error= 30
Actual label: 1
Output voltages: [0.23945, 0.74693, 0.31225, 0.21517, 0.27399, 0.0558, 0.34122, 0.1365, 0.31409, 0.23179]
Predicted label: 1
Correct prediction
Energy consumption = 210.486874 pJ
sum error= 30
Actual label: 3
Output voltages: [0.30103, 0.11699, 0.32988, 0.68229, 0.2196, 0.22144, 0.19273, 0.18241, 0.4792, 0.17773]
Predicted label: 3
Correct prediction
Energy consumption = 194.600306 pJ
sum error= 30
Actual label: 8
Output voltages: [0.22877, 0.32131, 0.22837, 0.3275, 0.10005, 0.15815, 0.17819, 0.23905, 0.74373, 0.24867]
Predicted label: 8
Correct prediction
Energy consumption = 199.231510 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 103 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 103 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 103 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16793, 0.7652, 0.20483, 0.23671, 0.21323, 0.12349, 0.31104, 0.10512, 0.39532, 0.22286]
Predicted label: 1
Correct prediction
Energy consumption = 213.509053 pJ
sum error= 30
Actual label: 2
Output voltages: [0.28606, 0.17586, 0.74113, 0.30713, 0.25445, 0.037016, 0.21997, 0.30207, 0.38481, 0.21424]
Predicted label: 2
Correct prediction
Energy consumption = 183.531574 pJ
sum error= 30
Actual label: 5
Output voltages: [0.2949, 0.056802, 0.16218, 0.28129, 0.19223, 0.67837, 0.45878, 0.1167, 0.52685, 0.18493]
Predicted label: 5
Correct prediction
Energy consumption = 199.203306 pJ
sum error= 30
Actual label: 8
Output voltages: [0.32931, 0.43018, 0.33025, 0.30686, 0.23635, 0.05851, 0.27971, 0.046131, 0.57651, 0.26325]
Predicted label: 8
Correct prediction
Energy consumption = 203.685651 pJ
sum error= 30
Actual label: 0
Output voltages: [0.71907, 0.26417, 0.2922, 0.19615, 0.14453, 0.088479, 0.33252, 0.17661, 0.34166, 0.31457]
Predicted label: 0
Correct prediction
Energy consumption = 195.770161 pJ
sum error= 30
Actual label: 6
Output voltages: [0.28442, 0.16412, 0.33546, 0.069959, 0.37324, 0.2216, 0.7271, 0.09513, 0.29807, 0.24305]
Predicted label: 6
Correct prediction
Energy consumption = 185.429726 pJ
sum error= 30
Actual label: 2
Output voltages: [0.33633, 0.32767, 0.73274, 0.24221, 0.15719, 0.023036, 0.31415, 0.26448, 0.41526, 0.2413]
Predicted label: 2
Correct prediction
Energy consumption = 189.846706 pJ
sum error= 30
Actual label: 1
Output voltages: [0.24067, 0.76924, 0.30664, 0.25041, 0.19117, 0.11227, 0.36533, 0.13931, 0.31526, 0.24133]
Predicted label: 1
Correct prediction
Energy consumption = 212.739554 pJ
sum error= 30
Actual label: 1
Output voltages: [0.26284, 0.76501, 0.19203, 0.26633, 0.13438, 0.22859, 0.42013, 0.10222, 0.34056, 0.21887]
Predicted label: 1
Correct prediction
Energy consumption = 205.972966 pJ
sum error= 30
Actual label: 7
Output voltages: [0.098662, 0.59129, 0.40986, 0.46705, 0.35883, 0.052549, 0.28071, 0.29277, 0.086805, 0.31878]
Predicted label: 1
Wrong prediction!
Energy consumption = 200.026979 pJ
sum error= 31
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 104 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 104 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 104 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.22754, 0.76812, 0.21488, 0.30125, 0.18267, 0.20653, 0.41164, 0.17748, 0.21538, 0.19577]
Predicted label: 1
Correct prediction
Energy consumption = 216.945114 pJ
sum error= 31
Actual label: 5
Output voltages: [0.22227, 0.046443, 0.072086, 0.31619, 0.26562, 0.70092, 0.32153, 0.091432, 0.54013, 0.22571]
Predicted label: 5
Correct prediction
Energy consumption = 187.011272 pJ
sum error= 31
Actual label: 3
Output voltages: [0.24225, 0.14077, 0.22534, 0.74382, 0.28213, 0.25404, 0.16454, 0.1928, 0.38202, 0.26464]
Predicted label: 3
Correct prediction
Energy consumption = 194.292600 pJ
sum error= 31
Actual label: 4
Output voltages: [0.15341, 0.12826, 0.24818, 0.1826, 0.7103, 0.1722, 0.17871, 0.29085, 0.31877, 0.30935]
Predicted label: 4
Correct prediction
Energy consumption = 202.343675 pJ
sum error= 31
Actual label: 6
Output voltages: [0.37343, 0.33491, 0.41546, 0.13988, 0.20803, 0.055519, 0.52961, 0.091949, 0.48031, 0.24963]
Predicted label: 6
Correct prediction
Energy consumption = 198.185179 pJ
sum error= 31
Actual label: 9
Output voltages: [0.27121, 0.31701, 0.20664, 0.25641, 0.41996, 0.10395, 0.10645, 0.10945, 0.3062, 0.60612]
Predicted label: 9
Correct prediction
Energy consumption = 206.196631 pJ
sum error= 31
Actual label: 5
Output voltages: [0.19044, 0.069006, 0.067796, 0.43441, 0.24392, 0.71769, 0.26264, 0.16053, 0.44443, 0.28816]
Predicted label: 5
Correct prediction
Energy consumption = 189.904077 pJ
sum error= 31
Actual label: 0
Output voltages: [0.69208, 0.2442, 0.28983, 0.17837, 0.15174, 0.15462, 0.47557, 0.16731, 0.2694, 0.29492]
Predicted label: 0
Correct prediction
Energy consumption = 184.529707 pJ
sum error= 31
Actual label: 9
Output voltages: [0.32157, 0.10987, 0.19914, 0.30674, 0.29738, 0.35852, 0.23168, 0.25066, 0.24874, 0.6539]
Predicted label: 9
Correct prediction
Energy consumption = 189.767716 pJ
sum error= 31
Actual label: 2
Output voltages: [0.44729, 0.1684, 0.74813, 0.31877, 0.18215, 0.048066, 0.29874, 0.31762, 0.39432, 0.15984]
Predicted label: 2
Correct prediction
Energy consumption = 185.077596 pJ
sum error= 31
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 105 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 105 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 105 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.47108, 0.063727, 0.67915, 0.39062, 0.13822, 0.077341, 0.15555, 0.28825, 0.45923, 0.19403]
Predicted label: 2
Correct prediction
Energy consumption = 193.460953 pJ
sum error= 31
Actual label: 4
Output voltages: [0.1526, 0.17031, 0.2032, 0.16675, 0.72651, 0.13113, 0.29888, 0.2827, 0.31748, 0.30125]
Predicted label: 4
Correct prediction
Energy consumption = 196.082189 pJ
sum error= 31
Actual label: 8
Output voltages: [0.26523, 0.15272, 0.20695, 0.35838, 0.12905, 0.28357, 0.17748, 0.10681, 0.71165, 0.35177]
Predicted label: 8
Correct prediction
Energy consumption = 196.936835 pJ
sum error= 31
Actual label: 2
Output voltages: [0.47191, 0.18917, 0.73614, 0.37221, 0.14529, 0.048962, 0.26277, 0.25834, 0.37862, 0.18631]
Predicted label: 2
Correct prediction
Energy consumption = 188.076253 pJ
sum error= 31
Actual label: 1
Output voltages: [0.18958, 0.76493, 0.20357, 0.27569, 0.25234, 0.10288, 0.37112, 0.19434, 0.31057, 0.23323]
Predicted label: 1
Correct prediction
Energy consumption = 213.088231 pJ
sum error= 31
Actual label: 7
Output voltages: [0.34901, 0.21787, 0.22147, 0.26713, 0.18481, 0.06859, 0.055755, 0.73304, 0.30312, 0.39871]
Predicted label: 7
Correct prediction
Energy consumption = 206.261148 pJ
sum error= 31
Actual label: 2
Output voltages: [0.38338, 0.23245, 0.68712, 0.38655, 0.1613, 0.029683, 0.26563, 0.19588, 0.50827, 0.20915]
Predicted label: 2
Correct prediction
Energy consumption = 186.229904 pJ
sum error= 31
Actual label: 4
Output voltages: [0.13567, 0.20079, 0.28365, 0.13058, 0.74406, 0.058576, 0.28486, 0.27084, 0.19773, 0.26292]
Predicted label: 4
Correct prediction
Energy consumption = 195.814587 pJ
sum error= 31
Actual label: 9
Output voltages: [0.36613, 0.1453, 0.22873, 0.25043, 0.27468, 0.14551, 0.058397, 0.26115, 0.37763, 0.65917]
Predicted label: 9
Correct prediction
Energy consumption = 187.924773 pJ
sum error= 31
Actual label: 4
Output voltages: [0.20837, 0.18645, 0.28296, 0.15378, 0.73324, 0.095157, 0.38701, 0.228, 0.17604, 0.2735]
Predicted label: 4
Correct prediction
Energy consumption = 200.566574 pJ
sum error= 31
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 106 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 106 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 106 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25015, 0.13246, 0.27408, 0.20603, 0.73131, 0.087264, 0.28023, 0.2105, 0.26703, 0.31004]
Predicted label: 4
Correct prediction
Energy consumption = 197.218646 pJ
sum error= 31
Actual label: 0
Output voltages: [0.73789, 0.23927, 0.2173, 0.1721, 0.17578, 0.23021, 0.39131, 0.17175, 0.31465, 0.22174]
Predicted label: 0
Correct prediction
Energy consumption = 195.784254 pJ
sum error= 31
Actual label: 3
Output voltages: [0.20665, 0.18109, 0.28433, 0.6251, 0.13049, 0.12904, 0.052129, 0.3975, 0.4326, 0.44994]
Predicted label: 3
Correct prediction
Energy consumption = 194.954732 pJ
sum error= 31
Actual label: 9
Output voltages: [0.35836, 0.12015, 0.20394, 0.2997, 0.38981, 0.12434, 0.065421, 0.20256, 0.35736, 0.63116]
Predicted label: 9
Correct prediction
Energy consumption = 191.362727 pJ
sum error= 31
Actual label: 2
Output voltages: [0.34482, 0.23149, 0.70553, 0.47193, 0.16088, 0.032373, 0.22704, 0.30066, 0.40054, 0.19312]
Predicted label: 2
Correct prediction
Energy consumption = 187.347227 pJ
sum error= 31
Actual label: 2
Output voltages: [0.38186, 0.21028, 0.71864, 0.37333, 0.18106, 0.028945, 0.27159, 0.23754, 0.4633, 0.21718]
Predicted label: 2
Correct prediction
Energy consumption = 176.545426 pJ
sum error= 31
Actual label: 3
Output voltages: [0.25086, 0.28307, 0.29586, 0.75674, 0.12261, 0.078476, 0.12838, 0.29521, 0.35459, 0.26414]
Predicted label: 3
Correct prediction
Energy consumption = 184.019355 pJ
sum error= 31
Actual label: 3
Output voltages: [0.25025, 0.22535, 0.25953, 0.7535, 0.12558, 0.21684, 0.13124, 0.16123, 0.46507, 0.25392]
Predicted label: 3
Correct prediction
Energy consumption = 174.861973 pJ
sum error= 31
Actual label: 8
Output voltages: [0.070856, 0.43272, 0.17702, 0.21983, 0.34673, 0.28143, 0.25977, 0.10691, 0.64915, 0.17148]
Predicted label: 8
Correct prediction
Energy consumption = 203.632813 pJ
sum error= 31
Actual label: 3
Output voltages: [0.23042, 0.10791, 0.22881, 0.65061, 0.20596, 0.27484, 0.16496, 0.12099, 0.53675, 0.29739]
Predicted label: 3
Correct prediction
Energy consumption = 194.625370 pJ
sum error= 31
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 107 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 107 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 107 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2742, 0.043181, 0.15632, 0.37663, 0.20184, 0.64343, 0.2818, 0.14789, 0.55963, 0.25206]
Predicted label: 5
Correct prediction
Energy consumption = 181.358877 pJ
sum error= 31
Actual label: 7
Output voltages: [0.32711, 0.24398, 0.27112, 0.23253, 0.20446, 0.059308, 0.038172, 0.73749, 0.30444, 0.34149]
Predicted label: 7
Correct prediction
Energy consumption = 201.566867 pJ
sum error= 31
Actual label: 3
Output voltages: [0.35753, 0.17023, 0.1512, 0.6439, 0.12734, 0.46778, 0.12755, 0.14042, 0.48868, 0.31523]
Predicted label: 3
Correct prediction
Energy consumption = 192.136645 pJ
sum error= 31
Actual label: 5
Output voltages: [0.22899, 0.053358, 0.08921, 0.39442, 0.2198, 0.60594, 0.21958, 0.13, 0.57008, 0.26934]
Predicted label: 5
Correct prediction
Energy consumption = 179.005087 pJ
sum error= 31
Actual label: 8
Output voltages: [0.20784, 0.14043, 0.31024, 0.35511, 0.17444, 0.21315, 0.12911, 0.21169, 0.73496, 0.2898]
Predicted label: 8
Correct prediction
Energy consumption = 188.249987 pJ
sum error= 31
Actual label: 1
Output voltages: [0.21378, 0.77095, 0.2246, 0.21689, 0.24073, 0.13031, 0.46322, 0.091915, 0.24886, 0.23263]
Predicted label: 1
Correct prediction
Energy consumption = 209.967440 pJ
sum error= 31
Actual label: 2
Output voltages: [0.33869, 0.26719, 0.71969, 0.35934, 0.088999, 0.036114, 0.22261, 0.27291, 0.44699, 0.20891]
Predicted label: 2
Correct prediction
Energy consumption = 184.921731 pJ
sum error= 31
Actual label: 4
Output voltages: [0.17409, 0.13047, 0.27026, 0.12971, 0.73289, 0.09288, 0.23083, 0.27552, 0.33607, 0.25741]
Predicted label: 4
Correct prediction
Energy consumption = 200.948069 pJ
sum error= 31
Actual label: 4
Output voltages: [0.26093, 0.17916, 0.32678, 0.13988, 0.72914, 0.05653, 0.4594, 0.26114, 0.16204, 0.1624]
Predicted label: 4
Correct prediction
Energy consumption = 200.267757 pJ
sum error= 31
Actual label: 6
Output voltages: [0.40234, 0.22602, 0.29504, 0.1243, 0.25847, 0.2291, 0.69925, 0.073923, 0.36651, 0.18695]
Predicted label: 6
Correct prediction
Energy consumption = 187.787525 pJ
sum error= 31
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 108 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 108 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 108 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.18619, 0.16632, 0.29358, 0.19845, 0.72223, 0.035154, 0.15258, 0.2683, 0.22069, 0.39371]
Predicted label: 4
Correct prediction
Energy consumption = 202.246142 pJ
sum error= 31
Actual label: 9
Output voltages: [0.26618, 0.069478, 0.28598, 0.374, 0.29397, 0.14774, 0.06612, 0.41892, 0.32795, 0.62293]
Predicted label: 9
Correct prediction
Energy consumption = 198.663593 pJ
sum error= 31
Actual label: 5
Output voltages: [0.2703, 0.15634, 0.081864, 0.39492, 0.12908, 0.70277, 0.37459, 0.11634, 0.46592, 0.17408]
Predicted label: 5
Correct prediction
Energy consumption = 202.583336 pJ
sum error= 31
Actual label: 1
Output voltages: [0.16143, 0.76144, 0.28072, 0.38889, 0.23898, 0.1316, 0.32584, 0.14383, 0.2573, 0.28094]
Predicted label: 1
Correct prediction
Energy consumption = 209.572363 pJ
sum error= 31
Actual label: 0
Output voltages: [0.747, 0.28097, 0.28951, 0.15244, 0.13712, 0.2018, 0.34861, 0.20872, 0.29755, 0.24601]
Predicted label: 0
Correct prediction
Energy consumption = 190.099676 pJ
sum error= 31
Actual label: 6
Output voltages: [0.2875, 0.25504, 0.27769, 0.13175, 0.27345, 0.4565, 0.73781, 0.12305, 0.42152, 0.066951]
Predicted label: 6
Correct prediction
Energy consumption = 192.300414 pJ
sum error= 31
Actual label: 9
Output voltages: [0.41605, 0.065875, 0.2582, 0.16823, 0.36391, 0.17375, 0.11345, 0.21895, 0.40961, 0.61266]
Predicted label: 9
Correct prediction
Energy consumption = 195.676988 pJ
sum error= 31
Actual label: 5
Output voltages: [0.23704, 0.089467, 0.12678, 0.30162, 0.1717, 0.68374, 0.28836, 0.092558, 0.58912, 0.21515]
Predicted label: 5
Correct prediction
Energy consumption = 192.195041 pJ
sum error= 31
Actual label: 9
Output voltages: [0.35098, 0.1101, 0.18429, 0.23875, 0.29286, 0.24498, 0.085541, 0.30024, 0.44818, 0.65675]
Predicted label: 9
Correct prediction
Energy consumption = 185.036886 pJ
sum error= 31
Actual label: 5
Output voltages: [0.29971, 0.048146, 0.044602, 0.43697, 0.25711, 0.67677, 0.34716, 0.20178, 0.41202, 0.30311]
Predicted label: 5
Correct prediction
Energy consumption = 191.394481 pJ
sum error= 31
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 109 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 109 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 109 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43362, 0.10834, 0.23785, 0.28532, 0.2201, 0.20102, 0.15805, 0.26542, 0.40147, 0.64369]
Predicted label: 9
Correct prediction
Energy consumption = 203.352167 pJ
sum error= 31
Actual label: 7
Output voltages: [0.24598, 0.19097, 0.34717, 0.45261, 0.1649, 0.066095, 0.050226, 0.69324, 0.32718, 0.31062]
Predicted label: 7
Correct prediction
Energy consumption = 186.879376 pJ
sum error= 31
Actual label: 3
Output voltages: [0.26045, 0.15073, 0.3148, 0.75423, 0.35999, 0.34338, 0.16401, 0.17605, 0.32446, 0.2401]
Predicted label: 3
Correct prediction
Energy consumption = 186.877671 pJ
sum error= 31
Actual label: 8
Output voltages: [0.28942, 0.20378, 0.39191, 0.36371, 0.12191, 0.13969, 0.22704, 0.13277, 0.74028, 0.31079]
Predicted label: 8
Correct prediction
Energy consumption = 192.713709 pJ
sum error= 31
Actual label: 0
Output voltages: [0.73326, 0.2306, 0.25599, 0.19717, 0.2101, 0.14741, 0.44476, 0.18444, 0.31092, 0.27035]
Predicted label: 0
Correct prediction
Energy consumption = 203.171962 pJ
sum error= 31
Actual label: 3
Output voltages: [0.35713, 0.17149, 0.23709, 0.75374, 0.20845, 0.26545, 0.19522, 0.1553, 0.36969, 0.2221]
Predicted label: 3
Correct prediction
Energy consumption = 196.573168 pJ
sum error= 31
Actual label: 7
Output voltages: [0.51505, 0.15555, 0.16168, 0.13348, 0.18928, 0.24042, 0.13982, 0.50091, 0.32135, 0.49706]
Predicted label: 0
Wrong prediction!
Energy consumption = 194.098758 pJ
sum error= 32
Actual label: 1
Output voltages: [0.15308, 0.76421, 0.20454, 0.32213, 0.22789, 0.15718, 0.42561, 0.19603, 0.2843, 0.16646]
Predicted label: 1
Correct prediction
Energy consumption = 213.433914 pJ
sum error= 32
Actual label: 3
Output voltages: [0.3137, 0.16807, 0.25597, 0.75946, 0.20447, 0.34371, 0.18203, 0.16069, 0.37236, 0.2035]
Predicted label: 3
Correct prediction
Energy consumption = 192.686504 pJ
sum error= 32
Actual label: 6
Output voltages: [0.30172, 0.26807, 0.29971, 0.22436, 0.31034, 0.30283, 0.68457, 0.10134, 0.36818, 0.059606]
Predicted label: 6
Correct prediction
Energy consumption = 184.773864 pJ
sum error= 32
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 110 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 110 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 110 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30254, 0.27902, 0.23469, 0.14414, 0.16231, 0.084011, 0.045508, 0.74193, 0.47911, 0.24618]
Predicted label: 7
Correct prediction
Energy consumption = 201.135919 pJ
sum error= 32
Actual label: 8
Output voltages: [0.26671, 0.13528, 0.28287, 0.37128, 0.25946, 0.20209, 0.26586, 0.10769, 0.66556, 0.28388]
Predicted label: 8
Correct prediction
Energy consumption = 203.231357 pJ
sum error= 32
Actual label: 5
Output voltages: [0.21662, 0.051965, 0.10144, 0.32708, 0.25852, 0.71804, 0.31169, 0.22311, 0.52285, 0.29517]
Predicted label: 5
Correct prediction
Energy consumption = 185.194474 pJ
sum error= 32
Actual label: 9
Output voltages: [0.3137, 0.10236, 0.19463, 0.32379, 0.36689, 0.31112, 0.12876, 0.32416, 0.28397, 0.64861]
Predicted label: 9
Correct prediction
Energy consumption = 190.414202 pJ
sum error= 32
Actual label: 7
Output voltages: [0.28784, 0.24945, 0.3621, 0.32007, 0.11047, 0.053534, 0.039112, 0.74608, 0.35761, 0.32881]
Predicted label: 7
Correct prediction
Energy consumption = 196.528122 pJ
sum error= 32
Actual label: 9
Output voltages: [0.32321, 0.09289, 0.2098, 0.2437, 0.36119, 0.17107, 0.11846, 0.30109, 0.39762, 0.64653]
Predicted label: 9
Correct prediction
Energy consumption = 184.787604 pJ
sum error= 32
Actual label: 6
Output voltages: [0.34628, 0.25321, 0.29143, 0.16284, 0.27115, 0.30098, 0.74652, 0.10016, 0.30918, 0.24358]
Predicted label: 6
Correct prediction
Energy consumption = 187.262316 pJ
sum error= 32
Actual label: 9
Output voltages: [0.43695, 0.085995, 0.2079, 0.40019, 0.32724, 0.23639, 0.18817, 0.057948, 0.45208, 0.50304]
Predicted label: 9
Correct prediction
Energy consumption = 201.215532 pJ
sum error= 32
Actual label: 6
Output voltages: [0.35687, 0.17496, 0.20164, 0.22297, 0.27489, 0.49008, 0.70923, 0.058802, 0.39504, 0.20449]
Predicted label: 6
Correct prediction
Energy consumption = 187.105095 pJ
sum error= 32
Actual label: 3
Output voltages: [0.34322, 0.17438, 0.38357, 0.73929, 0.23729, 0.13837, 0.20499, 0.14503, 0.40633, 0.16303]
Predicted label: 3
Correct prediction
Energy consumption = 186.068194 pJ
sum error= 32
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 111 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 111 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 111 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3533, 0.18866, 0.20347, 0.33256, 0.17516, 0.15066, 0.047325, 0.76345, 0.29011, 0.38696]
Predicted label: 7
Correct prediction
Energy consumption = 196.253625 pJ
sum error= 32
Actual label: 4
Output voltages: [0.1257, 0.1678, 0.26584, 0.18054, 0.7507, 0.060481, 0.23898, 0.32344, 0.21246, 0.24567]
Predicted label: 4
Correct prediction
Energy consumption = 192.657321 pJ
sum error= 32
Actual label: 4
Output voltages: [0.41041, 0.29545, 0.30207, 0.16447, 0.57354, 0.080415, 0.5666, 0.12999, 0.25434, 0.12353]
Predicted label: 4
Correct prediction
Energy consumption = 195.081275 pJ
sum error= 32
Actual label: 5
Output voltages: [0.20773, 0.04641, 0.10612, 0.3154, 0.25522, 0.7218, 0.33019, 0.1534, 0.56888, 0.21004]
Predicted label: 5
Correct prediction
Energy consumption = 187.611915 pJ
sum error= 32
Actual label: 3
Output voltages: [0.29129, 0.15991, 0.32797, 0.58008, 0.085376, 0.085742, 0.15972, 0.12319, 0.64041, 0.27854]
Predicted label: 8
Wrong prediction!
Energy consumption = 188.716950 pJ
sum error= 33
Actual label: 5
Output voltages: [0.22974, 0.064934, 0.14188, 0.38398, 0.20916, 0.67215, 0.18868, 0.23867, 0.46832, 0.35735]
Predicted label: 5
Correct prediction
Energy consumption = 184.703252 pJ
sum error= 33
Actual label: 4
Output voltages: [0.096108, 0.20256, 0.21935, 0.1999, 0.72881, 0.093344, 0.1773, 0.20998, 0.28098, 0.28377]
Predicted label: 4
Correct prediction
Energy consumption = 184.880277 pJ
sum error= 33
Actual label: 7
Output voltages: [0.30661, 0.3278, 0.43064, 0.4006, 0.089872, 0.053375, 0.03894, 0.6895, 0.37756, 0.37107]
Predicted label: 7
Correct prediction
Energy consumption = 193.157434 pJ
sum error= 33
Actual label: 8
Output voltages: [0.24225, 0.2429, 0.41206, 0.31413, 0.13097, 0.07123, 0.22701, 0.17563, 0.70433, 0.26735]
Predicted label: 8
Correct prediction
Energy consumption = 191.422032 pJ
sum error= 33
Actual label: 7
Output voltages: [0.2928, 0.085419, 0.59569, 0.2947, 0.15076, 0.040317, 0.085524, 0.5448, 0.60107, 0.18164]
Predicted label: 8
Wrong prediction!
Energy consumption = 183.104038 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 112 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 112 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 112 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.23883, 0.26571, 0.28125, 0.35061, 0.1412, 0.22868, 0.28722, 0.064929, 0.7221, 0.2899]
Predicted label: 8
Correct prediction
Energy consumption = 203.790222 pJ
sum error= 34
Actual label: 0
Output voltages: [0.70024, 0.23907, 0.26728, 0.19061, 0.20196, 0.11108, 0.47164, 0.16917, 0.3476, 0.23158]
Predicted label: 0
Correct prediction
Energy consumption = 206.845424 pJ
sum error= 34
Actual label: 7
Output voltages: [0.36006, 0.23278, 0.24648, 0.40856, 0.14225, 0.059266, 0.03525, 0.67313, 0.30421, 0.38003]
Predicted label: 7
Correct prediction
Energy consumption = 206.126559 pJ
sum error= 34
Actual label: 6
Output voltages: [0.32918, 0.21523, 0.26664, 0.14711, 0.28977, 0.43489, 0.74009, 0.078496, 0.39698, 0.15486]
Predicted label: 6
Correct prediction
Energy consumption = 188.930702 pJ
sum error= 34
Actual label: 8
Output voltages: [0.2804, 0.21045, 0.2274, 0.366, 0.054353, 0.24611, 0.18575, 0.19844, 0.69835, 0.33425]
Predicted label: 8
Correct prediction
Energy consumption = 197.975794 pJ
sum error= 34
Actual label: 8
Output voltages: [0.13319, 0.14186, 0.24143, 0.22926, 0.22214, 0.14605, 0.13045, 0.20406, 0.7044, 0.37509]
Predicted label: 8
Correct prediction
Energy consumption = 188.049600 pJ
sum error= 34
Actual label: 7
Output voltages: [0.41512, 0.29364, 0.24025, 0.26005, 0.13763, 0.12836, 0.067225, 0.74517, 0.27622, 0.29983]
Predicted label: 7
Correct prediction
Energy consumption = 196.859629 pJ
sum error= 34
Actual label: 3
Output voltages: [0.2658, 0.19565, 0.26929, 0.74957, 0.10666, 0.17886, 0.091447, 0.18756, 0.51748, 0.22444]
Predicted label: 3
Correct prediction
Energy consumption = 179.889643 pJ
sum error= 34
Actual label: 3
Output voltages: [0.43882, 0.055439, 0.3916, 0.63907, 0.0533, 0.21326, 0.13071, 0.31266, 0.51202, 0.19655]
Predicted label: 3
Correct prediction
Energy consumption = 190.476267 pJ
sum error= 34
Actual label: 1
Output voltages: [0.24153, 0.70991, 0.27603, 0.25188, 0.18356, 0.064315, 0.45534, 0.052601, 0.38001, 0.21985]
Predicted label: 1
Correct prediction
Energy consumption = 209.051958 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 113 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 113 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 113 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3443, 0.082123, 0.29349, 0.27095, 0.39622, 0.17281, 0.20987, 0.23025, 0.22201, 0.66644]
Predicted label: 9
Correct prediction
Energy consumption = 201.114541 pJ
sum error= 34
Actual label: 5
Output voltages: [0.23839, 0.053909, 0.063989, 0.21251, 0.3998, 0.73171, 0.40531, 0.20987, 0.45786, 0.25251]
Predicted label: 5
Correct prediction
Energy consumption = 195.625665 pJ
sum error= 34
Actual label: 2
Output voltages: [0.38912, 0.16179, 0.73864, 0.32452, 0.12287, 0.038987, 0.22962, 0.32634, 0.44026, 0.13816]
Predicted label: 2
Correct prediction
Energy consumption = 192.110138 pJ
sum error= 34
Actual label: 7
Output voltages: [0.33432, 0.35854, 0.38406, 0.21682, 0.14797, 0.029825, 0.046091, 0.73239, 0.24097, 0.28179]
Predicted label: 7
Correct prediction
Energy consumption = 196.895705 pJ
sum error= 34
Actual label: 3
Output voltages: [0.3136, 0.12828, 0.32694, 0.74972, 0.19311, 0.21279, 0.11236, 0.24869, 0.47258, 0.22079]
Predicted label: 3
Correct prediction
Energy consumption = 183.020734 pJ
sum error= 34
Actual label: 5
Output voltages: [0.37072, 0.23596, 0.05603, 0.39657, 0.15326, 0.72761, 0.24597, 0.055321, 0.45572, 0.19866]
Predicted label: 5
Correct prediction
Energy consumption = 194.166031 pJ
sum error= 34
Actual label: 1
Output voltages: [0.27032, 0.75045, 0.14492, 0.27269, 0.15656, 0.10451, 0.40687, 0.056742, 0.37857, 0.23244]
Predicted label: 1
Correct prediction
Energy consumption = 206.861253 pJ
sum error= 34
Actual label: 1
Output voltages: [0.22676, 0.77177, 0.20832, 0.23607, 0.19417, 0.17373, 0.4559, 0.10971, 0.28159, 0.20651]
Predicted label: 1
Correct prediction
Energy consumption = 205.676453 pJ
sum error= 34
Actual label: 2
Output voltages: [0.36974, 0.39688, 0.7208, 0.31861, 0.23103, 0.027227, 0.2594, 0.29441, 0.31009, 0.20957]
Predicted label: 2
Correct prediction
Energy consumption = 186.867292 pJ
sum error= 34
Actual label: 1
Output voltages: [0.17681, 0.73566, 0.29025, 0.24815, 0.21233, 0.05303, 0.39443, 0.093563, 0.39202, 0.21063]
Predicted label: 1
Correct prediction
Energy consumption = 207.162566 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 114 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 114 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 114 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15633, 0.11882, 0.33134, 0.13662, 0.75432, 0.11829, 0.24377, 0.29665, 0.22384, 0.34428]
Predicted label: 4
Correct prediction
Energy consumption = 197.762940 pJ
sum error= 34
Actual label: 7
Output voltages: [0.30892, 0.31137, 0.40762, 0.3141, 0.076156, 0.034987, 0.064653, 0.70718, 0.34073, 0.35625]
Predicted label: 7
Correct prediction
Energy consumption = 209.949414 pJ
sum error= 34
Actual label: 4
Output voltages: [0.20001, 0.25398, 0.26644, 0.10182, 0.74649, 0.05486, 0.31192, 0.29731, 0.15582, 0.30912]
Predicted label: 4
Correct prediction
Energy consumption = 204.084700 pJ
sum error= 34
Actual label: 7
Output voltages: [0.22428, 0.16809, 0.36186, 0.45455, 0.14635, 0.044155, 0.051052, 0.60337, 0.53234, 0.22991]
Predicted label: 7
Correct prediction
Energy consumption = 188.251529 pJ
sum error= 34
Actual label: 5
Output voltages: [0.23717, 0.050655, 0.098219, 0.38567, 0.21721, 0.72067, 0.27539, 0.22631, 0.53628, 0.26868]
Predicted label: 5
Correct prediction
Energy consumption = 187.093190 pJ
sum error= 34
Actual label: 4
Output voltages: [0.19668, 0.19568, 0.23037, 0.21355, 0.7024, 0.16474, 0.2422, 0.23434, 0.25306, 0.37026]
Predicted label: 4
Correct prediction
Energy consumption = 202.749711 pJ
sum error= 34
Actual label: 5
Output voltages: [0.19046, 0.075096, 0.12154, 0.47174, 0.19463, 0.6858, 0.23261, 0.16348, 0.4522, 0.31003]
Predicted label: 5
Correct prediction
Energy consumption = 187.689916 pJ
sum error= 34
Actual label: 4
Output voltages: [0.16867, 0.22989, 0.18357, 0.14048, 0.73446, 0.19001, 0.16537, 0.3426, 0.18997, 0.4008]
Predicted label: 4
Correct prediction
Energy consumption = 200.888875 pJ
sum error= 34
Actual label: 0
Output voltages: [0.71296, 0.22685, 0.28223, 0.20955, 0.17428, 0.11116, 0.48106, 0.17012, 0.33202, 0.23936]
Predicted label: 0
Correct prediction
Energy consumption = 199.755395 pJ
sum error= 34
Actual label: 8
Output voltages: [0.19191, 0.23744, 0.30787, 0.18849, 0.17599, 0.16086, 0.20654, 0.16068, 0.74323, 0.34213]
Predicted label: 8
Correct prediction
Energy consumption = 190.891922 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 115 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 115 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 115 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35348, 0.15017, 0.22052, 0.74321, 0.18634, 0.3118, 0.23755, 0.1829, 0.36478, 0.19474]
Predicted label: 3
Correct prediction
Energy consumption = 198.261399 pJ
sum error= 34
Actual label: 6
Output voltages: [0.32656, 0.28297, 0.17313, 0.19497, 0.24621, 0.40708, 0.71977, 0.11833, 0.45335, 0.15343]
Predicted label: 6
Correct prediction
Energy consumption = 197.520965 pJ
sum error= 34
Actual label: 9
Output voltages: [0.38253, 0.086138, 0.15838, 0.2259, 0.25284, 0.25535, 0.056447, 0.38095, 0.44822, 0.58609]
Predicted label: 9
Correct prediction
Energy consumption = 194.101889 pJ
sum error= 34
Actual label: 6
Output voltages: [0.28991, 0.11151, 0.18682, 0.26039, 0.22123, 0.45084, 0.55915, 0.06032, 0.57145, 0.1773]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.114749 pJ
sum error= 35
Actual label: 0
Output voltages: [0.6792, 0.19668, 0.27061, 0.15332, 0.24212, 0.15297, 0.41656, 0.17091, 0.35587, 0.30505]
Predicted label: 0
Correct prediction
Energy consumption = 200.495857 pJ
sum error= 35
Actual label: 2
Output voltages: [0.37175, 0.32573, 0.70962, 0.36878, 0.1448, 0.030615, 0.2539, 0.24714, 0.36194, 0.21143]
Predicted label: 2
Correct prediction
Energy consumption = 199.225127 pJ
sum error= 35
Actual label: 7
Output voltages: [0.26578, 0.33173, 0.26877, 0.39408, 0.062601, 0.20102, 0.10975, 0.60113, 0.43722, 0.25899]
Predicted label: 7
Correct prediction
Energy consumption = 195.634381 pJ
sum error= 35
Actual label: 4
Output voltages: [0.21683, 0.21859, 0.21232, 0.26487, 0.73327, 0.08978, 0.33118, 0.23875, 0.17732, 0.33441]
Predicted label: 4
Correct prediction
Energy consumption = 202.643053 pJ
sum error= 35
Actual label: 4
Output voltages: [0.14898, 0.14203, 0.30897, 0.11014, 0.75019, 0.060013, 0.30707, 0.30706, 0.18459, 0.23306]
Predicted label: 4
Correct prediction
Energy consumption = 188.016618 pJ
sum error= 35
Actual label: 4
Output voltages: [0.2152, 0.22123, 0.26296, 0.16756, 0.73254, 0.040154, 0.31464, 0.22415, 0.27853, 0.2192]
Predicted label: 4
Correct prediction
Energy consumption = 190.246728 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 116 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 116 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 116 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19925, 0.14636, 0.31098, 0.19759, 0.75851, 0.16669, 0.39728, 0.24664, 0.15753, 0.25357]
Predicted label: 4
Correct prediction
Energy consumption = 198.732497 pJ
sum error= 35
Actual label: 6
Output voltages: [0.34454, 0.14569, 0.16735, 0.26284, 0.33594, 0.46297, 0.7017, 0.037918, 0.36665, 0.27187]
Predicted label: 6
Correct prediction
Energy consumption = 193.766693 pJ
sum error= 35
Actual label: 6
Output voltages: [0.30514, 0.14307, 0.30908, 0.079283, 0.34145, 0.25013, 0.70974, 0.055379, 0.41493, 0.19772]
Predicted label: 6
Correct prediction
Energy consumption = 182.812782 pJ
sum error= 35
Actual label: 4
Output voltages: [0.10003, 0.14394, 0.20025, 0.10091, 0.7527, 0.1337, 0.3261, 0.38929, 0.33402, 0.14353]
Predicted label: 4
Correct prediction
Energy consumption = 193.467657 pJ
sum error= 35
Actual label: 7
Output voltages: [0.41516, 0.10735, 0.17311, 0.1453, 0.19012, 0.22124, 0.11883, 0.58454, 0.43924, 0.50015]
Predicted label: 7
Correct prediction
Energy consumption = 200.710817 pJ
sum error= 35
Actual label: 9
Output voltages: [0.3932, 0.1135, 0.19446, 0.21127, 0.31697, 0.13813, 0.086204, 0.29964, 0.34278, 0.65673]
Predicted label: 9
Correct prediction
Energy consumption = 194.889441 pJ
sum error= 35
Actual label: 3
Output voltages: [0.26899, 0.19666, 0.28602, 0.6286, 0.16019, 0.28667, 0.28992, 0.14299, 0.30977, 0.1105]
Predicted label: 3
Correct prediction
Energy consumption = 204.004899 pJ
sum error= 35
Actual label: 4
Output voltages: [0.10371, 0.17785, 0.25892, 0.14914, 0.75342, 0.09078, 0.2297, 0.3731, 0.29626, 0.19341]
Predicted label: 4
Correct prediction
Energy consumption = 192.228388 pJ
sum error= 35
Actual label: 5
Output voltages: [0.26743, 0.07468, 0.061008, 0.36047, 0.17079, 0.73282, 0.27922, 0.12377, 0.55141, 0.14639]
Predicted label: 5
Correct prediction
Energy consumption = 191.058532 pJ
sum error= 35
Actual label: 5
Output voltages: [0.28178, 0.10309, 0.070219, 0.31078, 0.19484, 0.61528, 0.29566, 0.071614, 0.48269, 0.28818]
Predicted label: 5
Correct prediction
Energy consumption = 187.061124 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 117 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 117 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 117 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18104, 0.12445, 0.1899, 0.4019, 0.13057, 0.29099, 0.20673, 0.1971, 0.74441, 0.2359]
Predicted label: 8
Correct prediction
Energy consumption = 196.309881 pJ
sum error= 35
Actual label: 7
Output voltages: [0.26416, 0.31162, 0.16205, 0.27061, 0.10817, 0.1178, 0.04176, 0.72412, 0.41196, 0.4301]
Predicted label: 7
Correct prediction
Energy consumption = 200.363968 pJ
sum error= 35
Actual label: 3
Output voltages: [0.31416, 0.15963, 0.31816, 0.75773, 0.23401, 0.21535, 0.156, 0.19401, 0.38756, 0.21652]
Predicted label: 3
Correct prediction
Energy consumption = 185.073499 pJ
sum error= 35
Actual label: 7
Output voltages: [0.3977, 0.26857, 0.18557, 0.17441, 0.31531, 0.041087, 0.090551, 0.5282, 0.37034, 0.32038]
Predicted label: 7
Correct prediction
Energy consumption = 209.348178 pJ
sum error= 35
Actual label: 2
Output voltages: [0.38, 0.33284, 0.69503, 0.40083, 0.12002, 0.039994, 0.32756, 0.12685, 0.40129, 0.16377]
Predicted label: 2
Correct prediction
Energy consumption = 187.620729 pJ
sum error= 35
Actual label: 7
Output voltages: [0.23263, 0.29797, 0.28041, 0.27258, 0.14732, 0.065001, 0.0469, 0.75554, 0.27234, 0.37574]
Predicted label: 7
Correct prediction
Energy consumption = 198.326144 pJ
sum error= 35
Actual label: 0
Output voltages: [0.70355, 0.25799, 0.22646, 0.32844, 0.19725, 0.089699, 0.34533, 0.1689, 0.39256, 0.27934]
Predicted label: 0
Correct prediction
Energy consumption = 202.794557 pJ
sum error= 35
Actual label: 2
Output voltages: [0.35281, 0.37072, 0.71333, 0.30957, 0.15851, 0.023156, 0.28498, 0.25179, 0.35076, 0.22419]
Predicted label: 2
Correct prediction
Energy consumption = 184.609790 pJ
sum error= 35
Actual label: 4
Output voltages: [0.46014, 0.12659, 0.23325, 0.20505, 0.49825, 0.051181, 0.42163, 0.08946, 0.42096, 0.13417]
Predicted label: 4
Correct prediction
Energy consumption = 191.582417 pJ
sum error= 35
Actual label: 1
Output voltages: [0.2958, 0.76335, 0.19785, 0.26674, 0.18031, 0.19562, 0.4104, 0.052255, 0.31842, 0.25863]
Predicted label: 1
Correct prediction
Energy consumption = 210.728680 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 118 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 118 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 118 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.22549, 0.7654, 0.19324, 0.30803, 0.21633, 0.17952, 0.34032, 0.089535, 0.27654, 0.29694]
Predicted label: 1
Correct prediction
Energy consumption = 207.384243 pJ
sum error= 35
Actual label: 6
Output voltages: [0.32516, 0.45111, 0.25644, 0.31566, 0.14323, 0.29088, 0.61887, 0.060923, 0.48222, 0.12241]
Predicted label: 6
Correct prediction
Energy consumption = 196.184086 pJ
sum error= 35
Actual label: 6
Output voltages: [0.29836, 0.10632, 0.20359, 0.33092, 0.19181, 0.57168, 0.57737, 0.080017, 0.44673, 0.16991]
Predicted label: 6
Correct prediction
Energy consumption = 202.971185 pJ
sum error= 35
Actual label: 9
Output voltages: [0.32467, 0.1818, 0.19146, 0.30972, 0.31343, 0.17835, 0.10408, 0.18184, 0.34173, 0.67212]
Predicted label: 9
Correct prediction
Energy consumption = 191.474502 pJ
sum error= 35
Actual label: 2
Output voltages: [0.23548, 0.33052, 0.71214, 0.29645, 0.16053, 0.03294, 0.34489, 0.26577, 0.40397, 0.21387]
Predicted label: 2
Correct prediction
Energy consumption = 195.824911 pJ
sum error= 35
Actual label: 8
Output voltages: [0.26107, 0.17019, 0.3046, 0.24838, 0.1994, 0.17085, 0.27895, 0.11241, 0.72583, 0.29319]
Predicted label: 8
Correct prediction
Energy consumption = 186.925180 pJ
sum error= 35
Actual label: 7
Output voltages: [0.30088, 0.17076, 0.15221, 0.17931, 0.27652, 0.22369, 0.04492, 0.76582, 0.32075, 0.28795]
Predicted label: 7
Correct prediction
Energy consumption = 195.584691 pJ
sum error= 35
Actual label: 2
Output voltages: [0.19432, 0.30525, 0.68004, 0.3938, 0.15268, 0.028867, 0.28715, 0.15184, 0.40545, 0.16111]
Predicted label: 2
Correct prediction
Energy consumption = 190.556773 pJ
sum error= 35
Actual label: 0
Output voltages: [0.72498, 0.25191, 0.24547, 0.18495, 0.19423, 0.10369, 0.33734, 0.18394, 0.34291, 0.29902]
Predicted label: 0
Correct prediction
Energy consumption = 197.515158 pJ
sum error= 35
Actual label: 1
Output voltages: [0.26918, 0.76866, 0.18265, 0.29364, 0.12665, 0.14905, 0.3393, 0.098294, 0.39265, 0.26333]
Predicted label: 1
Correct prediction
Energy consumption = 208.247677 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 119 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 119 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 119 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.23034, 0.097992, 0.14042, 0.46831, 0.17557, 0.72705, 0.26395, 0.21164, 0.47958, 0.27011]
Predicted label: 5
Correct prediction
Energy consumption = 190.700282 pJ
sum error= 35
Actual label: 0
Output voltages: [0.6837, 0.093728, 0.32772, 0.18426, 0.25004, 0.268, 0.42639, 0.29482, 0.15341, 0.24485]
Predicted label: 0
Correct prediction
Energy consumption = 187.244375 pJ
sum error= 35
Actual label: 9
Output voltages: [0.15978, 0.12835, 0.26501, 0.19997, 0.19914, 0.26942, 0.13128, 0.21377, 0.59175, 0.46019]
Predicted label: 8
Wrong prediction!
Energy consumption = 203.912049 pJ
sum error= 36
Actual label: 1
Output voltages: [0.28538, 0.76422, 0.19769, 0.29559, 0.26134, 0.13838, 0.36509, 0.13512, 0.28024, 0.21738]
Predicted label: 1
Correct prediction
Energy consumption = 213.869665 pJ
sum error= 36
Actual label: 7
Output voltages: [0.37318, 0.063097, 0.32784, 0.24611, 0.32872, 0.047368, 0.041926, 0.47284, 0.42198, 0.40717]
Predicted label: 7
Correct prediction
Energy consumption = 193.061590 pJ
sum error= 36
Actual label: 0
Output voltages: [0.72679, 0.25799, 0.21733, 0.19449, 0.14341, 0.15206, 0.3715, 0.17157, 0.35073, 0.30879]
Predicted label: 0
Correct prediction
Energy consumption = 196.980847 pJ
sum error= 36
Actual label: 6
Output voltages: [0.2923, 0.26087, 0.25377, 0.17351, 0.26076, 0.30533, 0.7322, 0.10649, 0.48407, 0.098279]
Predicted label: 6
Correct prediction
Energy consumption = 186.743664 pJ
sum error= 36
Actual label: 0
Output voltages: [0.7079, 0.26707, 0.23814, 0.18574, 0.21808, 0.12322, 0.49806, 0.19654, 0.30808, 0.25282]
Predicted label: 0
Correct prediction
Energy consumption = 204.856647 pJ
sum error= 36
Actual label: 8
Output voltages: [0.16662, 0.21064, 0.25372, 0.23742, 0.21714, 0.29266, 0.23373, 0.17021, 0.74451, 0.27687]
Predicted label: 8
Correct prediction
Energy consumption = 196.107889 pJ
sum error= 36
Actual label: 6
Output voltages: [0.37417, 0.17886, 0.20156, 0.19331, 0.27868, 0.50225, 0.72681, 0.089374, 0.33404, 0.17355]
Predicted label: 6
Correct prediction
Energy consumption = 187.411426 pJ
sum error= 36
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 120 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 120 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 120 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.32688, 0.23464, 0.16149, 0.40689, 0.17709, 0.25743, 0.424, 0.042845, 0.55819, 0.31684]
Predicted label: 8
Correct prediction
Energy consumption = 211.650260 pJ
sum error= 36
Actual label: 1
Output voltages: [0.25803, 0.75121, 0.27997, 0.29272, 0.3042, 0.051007, 0.30134, 0.093955, 0.31356, 0.2753]
Predicted label: 1
Correct prediction
Energy consumption = 207.354424 pJ
sum error= 36
Actual label: 8
Output voltages: [0.28458, 0.064533, 0.25778, 0.28653, 0.15022, 0.42566, 0.32985, 0.059284, 0.70808, 0.21091]
Predicted label: 8
Correct prediction
Energy consumption = 191.715889 pJ
sum error= 36
Actual label: 0
Output voltages: [0.74327, 0.25033, 0.26649, 0.17156, 0.18632, 0.18218, 0.4078, 0.18252, 0.30067, 0.1882]
Predicted label: 0
Correct prediction
Energy consumption = 192.092191 pJ
sum error= 36
Actual label: 3
Output voltages: [0.12598, 0.23807, 0.41803, 0.5672, 0.13729, 0.064248, 0.0707, 0.43575, 0.44068, 0.25655]
Predicted label: 3
Correct prediction
Energy consumption = 195.286478 pJ
sum error= 36
Actual label: 3
Output voltages: [0.34565, 0.21342, 0.32798, 0.76512, 0.16214, 0.21927, 0.11308, 0.23772, 0.40282, 0.25585]
Predicted label: 3
Correct prediction
Energy consumption = 179.333454 pJ
sum error= 36
Actual label: 7
Output voltages: [0.36523, 0.19602, 0.58955, 0.28465, 0.094575, 0.03731, 0.1356, 0.41234, 0.53927, 0.36172]
Predicted label: 2
Wrong prediction!
Energy consumption = 188.773709 pJ
sum error= 37
Actual label: 2
Output voltages: [0.3598, 0.241, 0.75295, 0.31654, 0.19993, 0.036822, 0.25309, 0.28688, 0.34602, 0.18295]
Predicted label: 2
Correct prediction
Energy consumption = 188.888560 pJ
sum error= 37
Actual label: 3
Output voltages: [0.23242, 0.23542, 0.26442, 0.75275, 0.13786, 0.11049, 0.13071, 0.27643, 0.41941, 0.27583]
Predicted label: 3
Correct prediction
Energy consumption = 194.740818 pJ
sum error= 37
Actual label: 6
Output voltages: [0.26768, 0.29904, 0.14912, 0.28009, 0.23585, 0.49188, 0.65002, 0.081317, 0.42081, 0.075527]
Predicted label: 6
Correct prediction
Energy consumption = 196.794524 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 121 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 121 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 121 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.41358, 0.25955, 0.74415, 0.34501, 0.19226, 0.036581, 0.24851, 0.30759, 0.39424, 0.18483]
Predicted label: 2
Correct prediction
Energy consumption = 189.060009 pJ
sum error= 37
Actual label: 1
Output voltages: [0.22583, 0.7202, 0.22983, 0.23453, 0.41997, 0.04626, 0.24076, 0.21631, 0.23307, 0.31706]
Predicted label: 1
Correct prediction
Energy consumption = 201.962396 pJ
sum error= 37
Actual label: 6
Output voltages: [0.37251, 0.20106, 0.18291, 0.28839, 0.27507, 0.31488, 0.59219, 0.1188, 0.55203, 0.10219]
Predicted label: 6
Correct prediction
Energy consumption = 197.400743 pJ
sum error= 37
Actual label: 1
Output voltages: [0.13708, 0.76363, 0.21116, 0.24701, 0.25286, 0.1092, 0.40211, 0.15785, 0.28114, 0.23095]
Predicted label: 1
Correct prediction
Energy consumption = 213.094420 pJ
sum error= 37
Actual label: 1
Output voltages: [0.19189, 0.74952, 0.21438, 0.19637, 0.17021, 0.07844, 0.40099, 0.10264, 0.43891, 0.25176]
Predicted label: 1
Correct prediction
Energy consumption = 206.174571 pJ
sum error= 37
Actual label: 3
Output voltages: [0.31586, 0.18503, 0.35942, 0.74803, 0.16261, 0.13595, 0.15484, 0.14469, 0.47706, 0.15975]
Predicted label: 3
Correct prediction
Energy consumption = 189.288192 pJ
sum error= 37
Actual label: 7
Output voltages: [0.32322, 0.2571, 0.16834, 0.28548, 0.23762, 0.10458, 0.048682, 0.71549, 0.25833, 0.46662]
Predicted label: 7
Correct prediction
Energy consumption = 203.301403 pJ
sum error= 37
Actual label: 9
Output voltages: [0.27872, 0.24572, 0.14357, 0.32841, 0.18867, 0.084735, 0.056831, 0.25253, 0.48462, 0.57008]
Predicted label: 9
Correct prediction
Energy consumption = 201.472735 pJ
sum error= 37
Actual label: 0
Output voltages: [0.74261, 0.29096, 0.20969, 0.24268, 0.12168, 0.21235, 0.39645, 0.16814, 0.28874, 0.24856]
Predicted label: 0
Correct prediction
Energy consumption = 198.591467 pJ
sum error= 37
Actual label: 8
Output voltages: [0.29159, 0.20657, 0.24965, 0.4351, 0.06353, 0.25569, 0.26408, 0.20797, 0.69169, 0.21845]
Predicted label: 8
Correct prediction
Energy consumption = 199.614614 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 122 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 122 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 122 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.71698, 0.25591, 0.24384, 0.20343, 0.098376, 0.25794, 0.40328, 0.11671, 0.29898, 0.32259]
Predicted label: 0
Correct prediction
Energy consumption = 204.707657 pJ
sum error= 37
Actual label: 5
Output voltages: [0.16174, 0.11114, 0.13194, 0.36046, 0.20926, 0.62572, 0.20809, 0.13647, 0.47786, 0.30908]
Predicted label: 5
Correct prediction
Energy consumption = 185.764063 pJ
sum error= 37
Actual label: 4
Output voltages: [0.13375, 0.10117, 0.31997, 0.21907, 0.74641, 0.060427, 0.24685, 0.23994, 0.24684, 0.24378]
Predicted label: 4
Correct prediction
Energy consumption = 192.109351 pJ
sum error= 37
Actual label: 0
Output voltages: [0.63758, 0.17513, 0.27089, 0.15463, 0.13573, 0.279, 0.45174, 0.14846, 0.28694, 0.28672]
Predicted label: 0
Correct prediction
Energy consumption = 192.446648 pJ
sum error= 37
Actual label: 2
Output voltages: [0.45588, 0.24794, 0.56374, 0.31234, 0.41699, 0.045323, 0.40322, 0.35755, 0.15936, 0.073448]
Predicted label: 2
Correct prediction
Energy consumption = 190.124013 pJ
sum error= 37
Actual label: 8
Output voltages: [0.20206, 0.22222, 0.27868, 0.2093, 0.22901, 0.23099, 0.21566, 0.16852, 0.7556, 0.29455]
Predicted label: 8
Correct prediction
Energy consumption = 193.460734 pJ
sum error= 37
Actual label: 7
Output voltages: [0.36476, 0.38625, 0.57423, 0.5274, 0.092815, 0.033198, 0.21561, 0.3558, 0.28224, 0.22833]
Predicted label: 2
Wrong prediction!
Energy consumption = 193.897338 pJ
sum error= 38
Actual label: 2
Output voltages: [0.30456, 0.36255, 0.7344, 0.38132, 0.16974, 0.029205, 0.18336, 0.30772, 0.30339, 0.20801]
Predicted label: 2
Correct prediction
Energy consumption = 176.212841 pJ
sum error= 38
Actual label: 9
Output voltages: [0.27209, 0.059514, 0.19341, 0.4342, 0.25343, 0.28598, 0.059755, 0.17753, 0.48207, 0.49865]
Predicted label: 9
Correct prediction
Energy consumption = 189.424923 pJ
sum error= 38
Actual label: 8
Output voltages: [0.26031, 0.19656, 0.32334, 0.35159, 0.13154, 0.17071, 0.17079, 0.17717, 0.7385, 0.32446]
Predicted label: 8
Correct prediction
Energy consumption = 192.114975 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 123 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 123 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 123 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.21706, 0.13122, 0.36335, 0.18571, 0.73372, 0.052717, 0.20342, 0.30068, 0.2131, 0.35107]
Predicted label: 4
Correct prediction
Energy consumption = 199.325564 pJ
sum error= 38
Actual label: 0
Output voltages: [0.71645, 0.2509, 0.27702, 0.18542, 0.17715, 0.11081, 0.40911, 0.17505, 0.26842, 0.3114]
Predicted label: 0
Correct prediction
Energy consumption = 199.509306 pJ
sum error= 38
Actual label: 9
Output voltages: [0.32048, 0.29144, 0.23675, 0.1468, 0.5007, 0.046355, 0.35886, 0.15421, 0.3139, 0.35871]
Predicted label: 4
Wrong prediction!
Energy consumption = 216.764823 pJ
sum error= 39
Actual label: 5
Output voltages: [0.24644, 0.098453, 0.098945, 0.37455, 0.25027, 0.69639, 0.46139, 0.1051, 0.42425, 0.23333]
Predicted label: 5
Correct prediction
Energy consumption = 192.133579 pJ
sum error= 39
Actual label: 8
Output voltages: [0.27088, 0.078381, 0.28716, 0.30436, 0.21062, 0.26785, 0.3697, 0.059878, 0.67216, 0.1882]
Predicted label: 8
Correct prediction
Energy consumption = 191.200545 pJ
sum error= 39
Actual label: 5
Output voltages: [0.20943, 0.058195, 0.1523, 0.30708, 0.24691, 0.68915, 0.29923, 0.16937, 0.56976, 0.26839]
Predicted label: 5
Correct prediction
Energy consumption = 182.684868 pJ
sum error= 39
Actual label: 1
Output voltages: [0.18995, 0.75656, 0.20459, 0.37475, 0.22695, 0.19129, 0.28833, 0.095464, 0.24455, 0.39828]
Predicted label: 1
Correct prediction
Energy consumption = 216.192354 pJ
sum error= 39
Actual label: 2
Output voltages: [0.32273, 0.39838, 0.71589, 0.30154, 0.14435, 0.028282, 0.32989, 0.15349, 0.35305, 0.22784]
Predicted label: 2
Correct prediction
Energy consumption = 191.464842 pJ
sum error= 39
Actual label: 1
Output voltages: [0.21023, 0.75853, 0.28347, 0.21621, 0.21246, 0.1078, 0.39907, 0.1393, 0.30632, 0.21735]
Predicted label: 1
Correct prediction
Energy consumption = 209.133747 pJ
sum error= 39
Actual label: 3
Output voltages: [0.30074, 0.19513, 0.20843, 0.75568, 0.20022, 0.27554, 0.19073, 0.16906, 0.40278, 0.2698]
Predicted label: 3
Correct prediction
Energy consumption = 190.700997 pJ
sum error= 39
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 124 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 124 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 124 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.24417, 0.7352, 0.12874, 0.31963, 0.20796, 0.19946, 0.46335, 0.095666, 0.31845, 0.20057]
Predicted label: 1
Correct prediction
Energy consumption = 215.554272 pJ
sum error= 39
Actual label: 7
Output voltages: [0.26646, 0.32181, 0.48387, 0.17335, 0.17728, 0.047499, 0.042879, 0.74254, 0.36956, 0.23268]
Predicted label: 7
Correct prediction
Energy consumption = 194.827604 pJ
sum error= 39
Actual label: 4
Output voltages: [0.38927, 0.18628, 0.20815, 0.20434, 0.66986, 0.11408, 0.25032, 0.17776, 0.22389, 0.48465]
Predicted label: 4
Correct prediction
Energy consumption = 206.033125 pJ
sum error= 39
Actual label: 5
Output voltages: [0.21934, 0.051876, 0.06016, 0.34419, 0.40511, 0.61314, 0.38327, 0.068717, 0.42076, 0.29104]
Predicted label: 5
Correct prediction
Energy consumption = 193.244586 pJ
sum error= 39
Actual label: 7
Output voltages: [0.29477, 0.37998, 0.28626, 0.37714, 0.099481, 0.03456, 0.05275, 0.62665, 0.29137, 0.3684]
Predicted label: 7
Correct prediction
Energy consumption = 215.345465 pJ
sum error= 39
Actual label: 2
Output voltages: [0.40177, 0.13289, 0.72722, 0.36088, 0.13227, 0.037986, 0.2507, 0.28994, 0.4671, 0.15916]
Predicted label: 2
Correct prediction
Energy consumption = 182.602562 pJ
sum error= 39
Actual label: 0
Output voltages: [0.73601, 0.21819, 0.14543, 0.26353, 0.15633, 0.35049, 0.42353, 0.17846, 0.27951, 0.26184]
Predicted label: 0
Correct prediction
Energy consumption = 198.542582 pJ
sum error= 39
Actual label: 9
Output voltages: [0.56084, 0.08323, 0.30087, 0.45681, 0.10554, 0.3488, 0.14224, 0.25776, 0.3352, 0.27641]
Predicted label: 0
Wrong prediction!
Energy consumption = 198.525950 pJ
sum error= 40
Actual label: 8
Output voltages: [0.31401, 0.080271, 0.24414, 0.39535, 0.08355, 0.50547, 0.39822, 0.12115, 0.56696, 0.13942]
Predicted label: 8
Correct prediction
Energy consumption = 203.469149 pJ
sum error= 40
Actual label: 8
Output voltages: [0.27094, 0.25178, 0.30009, 0.24643, 0.1594, 0.2489, 0.2267, 0.18501, 0.75155, 0.25523]
Predicted label: 8
Correct prediction
Energy consumption = 181.040360 pJ
sum error= 40
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 125 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 125 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 125 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.37135, 0.37138, 0.26371, 0.21619, 0.23268, 0.30717, 0.72414, 0.11068, 0.41976, 0.13094]
Predicted label: 6
Correct prediction
Energy consumption = 203.610809 pJ
sum error= 40
Actual label: 2
Output voltages: [0.45352, 0.24421, 0.61316, 0.48747, 0.20178, 0.047725, 0.34474, 0.17543, 0.27878, 0.15634]
Predicted label: 2
Correct prediction
Energy consumption = 191.984345 pJ
sum error= 40
Actual label: 5
Output voltages: [0.24861, 0.058036, 0.18519, 0.33114, 0.13726, 0.69639, 0.33426, 0.17229, 0.53878, 0.18671]
Predicted label: 5
Correct prediction
Energy consumption = 190.491029 pJ
sum error= 40
Actual label: 4
Output voltages: [0.30303, 0.13241, 0.36503, 0.096509, 0.66398, 0.046798, 0.46939, 0.15106, 0.252, 0.33126]
Predicted label: 4
Correct prediction
Energy consumption = 198.135009 pJ
sum error= 40
Actual label: 1
Output voltages: [0.19598, 0.76069, 0.22859, 0.29723, 0.21732, 0.133, 0.29554, 0.12562, 0.404, 0.24632]
Predicted label: 1
Correct prediction
Energy consumption = 217.320501 pJ
sum error= 40
Actual label: 9
Output voltages: [0.3215, 0.14416, 0.20793, 0.2977, 0.31377, 0.15661, 0.090925, 0.25686, 0.3174, 0.7068]
Predicted label: 9
Correct prediction
Energy consumption = 199.526115 pJ
sum error= 40
Actual label: 2
Output voltages: [0.4166, 0.31789, 0.70849, 0.384, 0.070645, 0.051258, 0.19809, 0.30251, 0.31965, 0.22786]
Predicted label: 2
Correct prediction
Energy consumption = 191.078543 pJ
sum error= 40
Actual label: 1
Output voltages: [0.15946, 0.74395, 0.13428, 0.15906, 0.34734, 0.205, 0.42149, 0.19129, 0.30021, 0.18212]
Predicted label: 1
Correct prediction
Energy consumption = 200.266246 pJ
sum error= 40
Actual label: 5
Output voltages: [0.20577, 0.07948, 0.14509, 0.32907, 0.17547, 0.69551, 0.21129, 0.12105, 0.58785, 0.27403]
Predicted label: 5
Correct prediction
Energy consumption = 198.035176 pJ
sum error= 40
Actual label: 8
Output voltages: [0.24825, 0.1373, 0.29881, 0.13588, 0.22246, 0.33154, 0.2327, 0.077075, 0.72074, 0.30605]
Predicted label: 8
Correct prediction
Energy consumption = 183.020595 pJ
sum error= 40
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 126 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 126 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 126 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35648, 0.63064, 0.23335, 0.31138, 0.076972, 0.059574, 0.086897, 0.42396, 0.36254, 0.33451]
Predicted label: 1
Wrong prediction!
Energy consumption = 215.005894 pJ
sum error= 41
Actual label: 0
Output voltages: [0.72582, 0.23401, 0.22402, 0.1643, 0.15792, 0.19697, 0.43548, 0.1724, 0.28859, 0.22948]
Predicted label: 0
Correct prediction
Energy consumption = 197.006655 pJ
sum error= 41
Actual label: 2
Output voltages: [0.38641, 0.34453, 0.74686, 0.26518, 0.16424, 0.026905, 0.31725, 0.25623, 0.37325, 0.23501]
Predicted label: 2
Correct prediction
Energy consumption = 191.968683 pJ
sum error= 41
Actual label: 4
Output voltages: [0.13197, 0.16982, 0.25287, 0.16984, 0.74146, 0.18898, 0.29383, 0.22952, 0.19477, 0.43982]
Predicted label: 4
Correct prediction
Energy consumption = 200.992967 pJ
sum error= 41
Actual label: 4
Output voltages: [0.21309, 0.12547, 0.17664, 0.18572, 0.72558, 0.20713, 0.2771, 0.30577, 0.25832, 0.31393]
Predicted label: 4
Correct prediction
Energy consumption = 195.998463 pJ
sum error= 41
Actual label: 3
Output voltages: [0.28731, 0.20033, 0.44556, 0.74336, 0.16138, 0.078421, 0.1566, 0.13858, 0.43169, 0.2029]
Predicted label: 3
Correct prediction
Energy consumption = 183.373127 pJ
sum error= 41
Actual label: 6
Output voltages: [0.3011, 0.19274, 0.36621, 0.099749, 0.31105, 0.17651, 0.6558, 0.096787, 0.39704, 0.23457]
Predicted label: 6
Correct prediction
Energy consumption = 195.911286 pJ
sum error= 41
Actual label: 8
Output voltages: [0.2334, 0.16163, 0.27156, 0.21735, 0.1759, 0.18484, 0.17146, 0.12514, 0.73969, 0.35621]
Predicted label: 8
Correct prediction
Energy consumption = 199.352581 pJ
sum error= 41
Actual label: 8
Output voltages: [0.19505, 0.22853, 0.35996, 0.24089, 0.14075, 0.12957, 0.19071, 0.24261, 0.73443, 0.28987]
Predicted label: 8
Correct prediction
Energy consumption = 187.356304 pJ
sum error= 41
Actual label: 2
Output voltages: [0.401, 0.19902, 0.73377, 0.26173, 0.25946, 0.043852, 0.26258, 0.22863, 0.3406, 0.24828]
Predicted label: 2
Correct prediction
Energy consumption = 195.129888 pJ
sum error= 41
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 127 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 127 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 127 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15823, 0.11405, 0.23711, 0.16263, 0.70954, 0.075404, 0.15528, 0.25502, 0.32156, 0.30329]
Predicted label: 4
Correct prediction
Energy consumption = 195.916678 pJ
sum error= 41
Actual label: 0
Output voltages: [0.65812, 0.15141, 0.29024, 0.092002, 0.15834, 0.25787, 0.40348, 0.10601, 0.3065, 0.29963]
Predicted label: 0
Correct prediction
Energy consumption = 201.959781 pJ
sum error= 41
Actual label: 5
Output voltages: [0.25342, 0.044129, 0.093206, 0.26517, 0.30969, 0.6613, 0.20291, 0.26064, 0.56399, 0.308]
Predicted label: 5
Correct prediction
Energy consumption = 190.529534 pJ
sum error= 41
Actual label: 0
Output voltages: [0.62998, 0.12405, 0.17969, 0.19697, 0.29192, 0.137, 0.48744, 0.16484, 0.34408, 0.29647]
Predicted label: 0
Correct prediction
Energy consumption = 196.407328 pJ
sum error= 41
Actual label: 4
Output voltages: [0.28132, 0.2391, 0.24755, 0.16406, 0.71027, 0.040784, 0.32237, 0.16607, 0.19439, 0.2747]
Predicted label: 4
Correct prediction
Energy consumption = 208.006099 pJ
sum error= 41
Actual label: 4
Output voltages: [0.19314, 0.14567, 0.32239, 0.25543, 0.72923, 0.045727, 0.16151, 0.2769, 0.27042, 0.30629]
Predicted label: 4
Correct prediction
Energy consumption = 196.999277 pJ
sum error= 41
Actual label: 7
Output voltages: [0.31242, 0.095944, 0.29218, 0.42372, 0.24672, 0.051628, 0.042988, 0.65669, 0.34228, 0.33818]
Predicted label: 7
Correct prediction
Energy consumption = 186.771561 pJ
sum error= 41
Actual label: 9
Output voltages: [0.31277, 0.091012, 0.17833, 0.25275, 0.34611, 0.27468, 0.17429, 0.2277, 0.36796, 0.65442]
Predicted label: 9
Correct prediction
Energy consumption = 183.440985 pJ
sum error= 41
Actual label: 3
Output voltages: [0.32404, 0.18125, 0.27795, 0.76376, 0.20628, 0.16731, 0.18732, 0.19455, 0.43252, 0.23096]
Predicted label: 3
Correct prediction
Energy consumption = 178.513852 pJ
sum error= 41
Actual label: 4
Output voltages: [0.18966, 0.18226, 0.23052, 0.13833, 0.65515, 0.099836, 0.28853, 0.3103, 0.22072, 0.2742]
Predicted label: 4
Correct prediction
Energy consumption = 190.703455 pJ
sum error= 41
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 128 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 128 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 128 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.15789, 0.75736, 0.22528, 0.25966, 0.24406, 0.16468, 0.36397, 0.16647, 0.34184, 0.20205]
Predicted label: 1
Correct prediction
Energy consumption = 217.960544 pJ
sum error= 41
Actual label: 5
Output voltages: [0.38241, 0.057454, 0.062452, 0.26991, 0.14913, 0.68176, 0.30178, 0.20613, 0.50179, 0.22543]
Predicted label: 5
Correct prediction
Energy consumption = 196.973963 pJ
sum error= 41
Actual label: 9
Output voltages: [0.39099, 0.103, 0.32556, 0.2289, 0.40552, 0.10179, 0.19025, 0.14739, 0.3874, 0.60344]
Predicted label: 9
Correct prediction
Energy consumption = 198.925722 pJ
sum error= 41
Actual label: 7
Output voltages: [0.31562, 0.054787, 0.50136, 0.56395, 0.23442, 0.086285, 0.085453, 0.29482, 0.45576, 0.25275]
Predicted label: 3
Wrong prediction!
Energy consumption = 190.835270 pJ
sum error= 42
Actual label: 3
Output voltages: [0.25459, 0.13505, 0.28063, 0.75383, 0.24293, 0.20543, 0.17315, 0.203, 0.45813, 0.24793]
Predicted label: 3
Correct prediction
Energy consumption = 176.579515 pJ
sum error= 42
Actual label: 5
Output voltages: [0.22098, 0.16144, 0.064722, 0.4821, 0.24915, 0.74202, 0.32518, 0.12581, 0.41574, 0.16048]
Predicted label: 5
Correct prediction
Energy consumption = 183.039732 pJ
sum error= 42
Actual label: 8
Output voltages: [0.19909, 0.26671, 0.32076, 0.31914, 0.13751, 0.15408, 0.26546, 0.12864, 0.72916, 0.29901]
Predicted label: 8
Correct prediction
Energy consumption = 197.602860 pJ
sum error= 42
Actual label: 8
Output voltages: [0.23391, 0.20719, 0.27761, 0.34663, 0.20606, 0.11918, 0.16557, 0.14351, 0.71859, 0.27303]
Predicted label: 8
Correct prediction
Energy consumption = 196.041271 pJ
sum error= 42
Actual label: 0
Output voltages: [0.62487, 0.17888, 0.25231, 0.21415, 0.19764, 0.068286, 0.37891, 0.23754, 0.37239, 0.29739]
Predicted label: 0
Correct prediction
Energy consumption = 207.936813 pJ
sum error= 42
Actual label: 5
Output voltages: [0.31654, 0.10223, 0.05008, 0.49211, 0.18164, 0.62645, 0.25299, 0.211, 0.43058, 0.34581]
Predicted label: 5
Correct prediction
Energy consumption = 192.082136 pJ
sum error= 42
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 129 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 129 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 129 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.21025, 0.084633, 0.14091, 0.59314, 0.28481, 0.47992, 0.26301, 0.11571, 0.37704, 0.18291]
Predicted label: 3
Correct prediction
Energy consumption = 206.056875 pJ
sum error= 42
Actual label: 3
Output voltages: [0.26031, 0.18256, 0.25707, 0.72063, 0.20107, 0.28291, 0.24554, 0.27166, 0.45137, 0.098048]
Predicted label: 3
Correct prediction
Energy consumption = 189.556049 pJ
sum error= 42
Actual label: 6
Output voltages: [0.28392, 0.11265, 0.24746, 0.21324, 0.23494, 0.39125, 0.67617, 0.067026, 0.43103, 0.19809]
Predicted label: 6
Correct prediction
Energy consumption = 195.181717 pJ
sum error= 42
Actual label: 6
Output voltages: [0.21791, 0.19779, 0.36473, 0.055725, 0.35112, 0.41359, 0.73646, 0.053918, 0.39657, 0.16542]
Predicted label: 6
Correct prediction
Energy consumption = 179.674890 pJ
sum error= 42
Actual label: 0
Output voltages: [0.73174, 0.23239, 0.22632, 0.17362, 0.18242, 0.16194, 0.42524, 0.14736, 0.2823, 0.29344]
Predicted label: 0
Correct prediction
Energy consumption = 197.383123 pJ
sum error= 42
Actual label: 1
Output voltages: [0.19198, 0.76445, 0.25107, 0.22956, 0.28013, 0.10314, 0.43539, 0.14144, 0.29252, 0.21898]
Predicted label: 1
Correct prediction
Energy consumption = 207.176895 pJ
sum error= 42
Actual label: 6
Output voltages: [0.20617, 0.11459, 0.1604, 0.29465, 0.30607, 0.41965, 0.55105, 0.14224, 0.49564, 0.11207]
Predicted label: 6
Correct prediction
Energy consumption = 201.179162 pJ
sum error= 42
Actual label: 0
Output voltages: [0.72787, 0.27847, 0.22463, 0.15842, 0.15075, 0.18101, 0.42063, 0.17984, 0.27379, 0.3139]
Predicted label: 0
Correct prediction
Energy consumption = 189.231947 pJ
sum error= 42
Actual label: 3
Output voltages: [0.31346, 0.16559, 0.3175, 0.75643, 0.19452, 0.13966, 0.15959, 0.27748, 0.47932, 0.21514]
Predicted label: 3
Correct prediction
Energy consumption = 185.216905 pJ
sum error= 42
Actual label: 5
Output voltages: [0.32114, 0.20178, 0.12706, 0.63747, 0.090815, 0.40175, 0.051445, 0.49694, 0.31477, 0.31818]
Predicted label: 3
Wrong prediction!
Energy consumption = 194.239828 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 130 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 130 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 130 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.29691, 0.14469, 0.27145, 0.15086, 0.71669, 0.049754, 0.24953, 0.25579, 0.20641, 0.37058]
Predicted label: 4
Correct prediction
Energy consumption = 200.747970 pJ
sum error= 43
Actual label: 4
Output voltages: [0.20267, 0.16248, 0.23548, 0.11737, 0.73687, 0.13835, 0.30125, 0.2557, 0.19961, 0.37209]
Predicted label: 4
Correct prediction
Energy consumption = 198.701681 pJ
sum error= 43
Actual label: 1
Output voltages: [0.17104, 0.75228, 0.19667, 0.23636, 0.28842, 0.10009, 0.25784, 0.26768, 0.30057, 0.29564]
Predicted label: 1
Correct prediction
Energy consumption = 218.539899 pJ
sum error= 43
Actual label: 2
Output voltages: [0.46062, 0.24765, 0.73577, 0.26631, 0.17416, 0.033089, 0.30192, 0.24593, 0.39651, 0.17886]
Predicted label: 2
Correct prediction
Energy consumption = 191.272582 pJ
sum error= 43
Actual label: 9
Output voltages: [0.36794, 0.13046, 0.24961, 0.32137, 0.30575, 0.15951, 0.10133, 0.26147, 0.32802, 0.69653]
Predicted label: 9
Correct prediction
Energy consumption = 193.714369 pJ
sum error= 43
Actual label: 1
Output voltages: [0.15223, 0.75662, 0.19783, 0.21309, 0.34735, 0.18673, 0.48336, 0.10734, 0.25538, 0.17518]
Predicted label: 1
Correct prediction
Energy consumption = 208.463376 pJ
sum error= 43
Actual label: 4
Output voltages: [0.14004, 0.21833, 0.34791, 0.097062, 0.75133, 0.060282, 0.27367, 0.19912, 0.21881, 0.38869]
Predicted label: 4
Correct prediction
Energy consumption = 199.205982 pJ
sum error= 43
Actual label: 6
Output voltages: [0.27686, 0.19398, 0.26052, 0.121, 0.35064, 0.38561, 0.73358, 0.075288, 0.36456, 0.1262]
Predicted label: 6
Correct prediction
Energy consumption = 192.103180 pJ
sum error= 43
Actual label: 9
Output voltages: [0.42713, 0.052683, 0.23936, 0.28258, 0.31899, 0.20771, 0.060911, 0.32449, 0.2509, 0.64218]
Predicted label: 9
Correct prediction
Energy consumption = 201.473206 pJ
sum error= 43
Actual label: 9
Output voltages: [0.36874, 0.12384, 0.22887, 0.28174, 0.335, 0.21938, 0.17515, 0.22848, 0.3242, 0.69169]
Predicted label: 9
Correct prediction
Energy consumption = 189.095422 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 131 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 131 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 131 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.28158, 0.19043, 0.18102, 0.74643, 0.1224, 0.29194, 0.13479, 0.31624, 0.32701, 0.25961]
Predicted label: 3
Correct prediction
Energy consumption = 197.777707 pJ
sum error= 43
Actual label: 9
Output voltages: [0.34219, 0.097085, 0.18765, 0.28768, 0.27791, 0.17389, 0.077938, 0.25754, 0.4045, 0.65156]
Predicted label: 9
Correct prediction
Energy consumption = 193.868746 pJ
sum error= 43
Actual label: 8
Output voltages: [0.3571, 0.10334, 0.25496, 0.26256, 0.29169, 0.080848, 0.20414, 0.091491, 0.5989, 0.38728]
Predicted label: 8
Correct prediction
Energy consumption = 191.104044 pJ
sum error= 43
Actual label: 4
Output voltages: [0.11519, 0.12101, 0.25597, 0.16749, 0.75622, 0.064525, 0.26435, 0.37226, 0.32857, 0.2106]
Predicted label: 4
Correct prediction
Energy consumption = 196.607271 pJ
sum error= 43
Actual label: 4
Output voltages: [0.20412, 0.099836, 0.39578, 0.057057, 0.75367, 0.13335, 0.35085, 0.22384, 0.19643, 0.23141]
Predicted label: 4
Correct prediction
Energy consumption = 196.450020 pJ
sum error= 43
Actual label: 3
Output voltages: [0.23371, 0.089572, 0.27646, 0.73496, 0.3497, 0.45302, 0.25815, 0.15199, 0.35675, 0.18999]
Predicted label: 3
Correct prediction
Energy consumption = 190.081492 pJ
sum error= 43
Actual label: 1
Output voltages: [0.21123, 0.75932, 0.32638, 0.21097, 0.21079, 0.072743, 0.3587, 0.11269, 0.3363, 0.22579]
Predicted label: 1
Correct prediction
Energy consumption = 210.157565 pJ
sum error= 43
Actual label: 3
Output voltages: [0.22277, 0.25189, 0.316, 0.7524, 0.12191, 0.090264, 0.11928, 0.18228, 0.45775, 0.2593]
Predicted label: 3
Correct prediction
Energy consumption = 179.658936 pJ
sum error= 43
Actual label: 1
Output voltages: [0.23872, 0.74719, 0.21588, 0.20949, 0.28236, 0.054516, 0.34144, 0.1201, 0.33018, 0.26303]
Predicted label: 1
Correct prediction
Energy consumption = 207.679046 pJ
sum error= 43
Actual label: 8
Output voltages: [0.58999, 0.14938, 0.20036, 0.45447, 0.060331, 0.20667, 0.44306, 0.22613, 0.38276, 0.09829]
Predicted label: 0
Wrong prediction!
Energy consumption = 199.829388 pJ
sum error= 44
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 132 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 132 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 132 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.25435, 0.28266, 0.30041, 0.38858, 0.099858, 0.1197, 0.26826, 0.095961, 0.72809, 0.26409]
Predicted label: 8
Correct prediction
Energy consumption = 198.817999 pJ
sum error= 44
Actual label: 7
Output voltages: [0.28992, 0.27926, 0.22156, 0.27323, 0.093216, 0.11078, 0.045039, 0.73622, 0.37303, 0.42008]
Predicted label: 7
Correct prediction
Energy consumption = 210.272936 pJ
sum error= 44
Actual label: 9
Output voltages: [0.3462, 0.11341, 0.20714, 0.28143, 0.33042, 0.21693, 0.12282, 0.30285, 0.38249, 0.6885]
Predicted label: 9
Correct prediction
Energy consumption = 181.163403 pJ
sum error= 44
Actual label: 4
Output voltages: [0.14147, 0.15326, 0.32447, 0.14616, 0.75911, 0.065236, 0.25195, 0.29288, 0.20805, 0.27385]
Predicted label: 4
Correct prediction
Energy consumption = 191.200260 pJ
sum error= 44
Actual label: 8
Output voltages: [0.31664, 0.25425, 0.2763, 0.16503, 0.28478, 0.11853, 0.19285, 0.13134, 0.6875, 0.31515]
Predicted label: 8
Correct prediction
Energy consumption = 199.395970 pJ
sum error= 44
Actual label: 8
Output voltages: [0.25333, 0.19798, 0.39991, 0.15768, 0.33994, 0.15618, 0.3295, 0.049988, 0.63808, 0.30608]
Predicted label: 8
Correct prediction
Energy consumption = 189.295838 pJ
sum error= 44
Actual label: 7
Output voltages: [0.31918, 0.30909, 0.56446, 0.1918, 0.12124, 0.034727, 0.13107, 0.42354, 0.5001, 0.4166]
Predicted label: 2
Wrong prediction!
Energy consumption = 196.639185 pJ
sum error= 45
Actual label: 9
Output voltages: [0.3999, 0.14788, 0.18154, 0.33108, 0.30695, 0.26627, 0.097932, 0.38243, 0.28023, 0.66037]
Predicted label: 9
Correct prediction
Energy consumption = 194.051535 pJ
sum error= 45
Actual label: 7
Output voltages: [0.34236, 0.17479, 0.17737, 0.24233, 0.17331, 0.13568, 0.089783, 0.62624, 0.42733, 0.44528]
Predicted label: 7
Correct prediction
Energy consumption = 201.834932 pJ
sum error= 45
Actual label: 1
Output voltages: [0.29762, 0.76184, 0.24571, 0.26053, 0.064504, 0.1146, 0.43274, 0.065264, 0.36814, 0.23229]
Predicted label: 1
Correct prediction
Energy consumption = 206.146262 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 133 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 133 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 133 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16913, 0.1438, 0.22143, 0.13812, 0.70987, 0.13098, 0.20079, 0.25925, 0.37092, 0.30206]
Predicted label: 4
Correct prediction
Energy consumption = 201.583283 pJ
sum error= 45
Actual label: 5
Output voltages: [0.12872, 0.071736, 0.19837, 0.37334, 0.23726, 0.51964, 0.24303, 0.1351, 0.59256, 0.28513]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.108394 pJ
sum error= 46
Actual label: 6
Output voltages: [0.29614, 0.26552, 0.29416, 0.10122, 0.31258, 0.36422, 0.74729, 0.10125, 0.33829, 0.15592]
Predicted label: 6
Correct prediction
Energy consumption = 191.010371 pJ
sum error= 46
Actual label: 0
Output voltages: [0.73606, 0.22824, 0.21832, 0.16085, 0.16889, 0.22444, 0.43023, 0.16559, 0.27542, 0.25445]
Predicted label: 0
Correct prediction
Energy consumption = 190.354724 pJ
sum error= 46
Actual label: 5
Output voltages: [0.18818, 0.057801, 0.19169, 0.35261, 0.25867, 0.56112, 0.29007, 0.18456, 0.48044, 0.36701]
Predicted label: 5
Correct prediction
Energy consumption = 198.020379 pJ
sum error= 46
Actual label: 2
Output voltages: [0.34375, 0.38528, 0.7372, 0.34819, 0.19709, 0.029102, 0.30302, 0.23291, 0.31481, 0.20597]
Predicted label: 2
Correct prediction
Energy consumption = 191.866977 pJ
sum error= 46
Actual label: 2
Output voltages: [0.32776, 0.40983, 0.71947, 0.30082, 0.14683, 0.025371, 0.28624, 0.23345, 0.3493, 0.2082]
Predicted label: 2
Correct prediction
Energy consumption = 180.505027 pJ
sum error= 46
Actual label: 2
Output voltages: [0.45331, 0.27079, 0.40899, 0.32083, 0.28052, 0.18455, 0.59565, 0.28545, 0.27635, 0.037994]
Predicted label: 6
Wrong prediction!
Energy consumption = 189.248193 pJ
sum error= 47
Actual label: 1
Output voltages: [0.1331, 0.76201, 0.24315, 0.35937, 0.26851, 0.13594, 0.26887, 0.23784, 0.29157, 0.25361]
Predicted label: 1
Correct prediction
Energy consumption = 205.897096 pJ
sum error= 47
Actual label: 5
Output voltages: [0.22368, 0.066665, 0.15503, 0.41331, 0.21058, 0.69988, 0.2778, 0.21717, 0.47239, 0.22977]
Predicted label: 5
Correct prediction
Energy consumption = 191.847355 pJ
sum error= 47
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 134 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 134 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 134 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22342, 0.056214, 0.17054, 0.27745, 0.17978, 0.64304, 0.35457, 0.11579, 0.59994, 0.19038]
Predicted label: 5
Correct prediction
Energy consumption = 192.865492 pJ
sum error= 47
Actual label: 2
Output voltages: [0.36985, 0.29866, 0.74736, 0.30286, 0.19465, 0.030621, 0.23974, 0.30436, 0.32814, 0.21273]
Predicted label: 2
Correct prediction
Energy consumption = 186.454133 pJ
sum error= 47
Actual label: 4
Output voltages: [0.18061, 0.12693, 0.29915, 0.12996, 0.75778, 0.16575, 0.20306, 0.2507, 0.21173, 0.37934]
Predicted label: 4
Correct prediction
Energy consumption = 202.064822 pJ
sum error= 47
Actual label: 9
Output voltages: [0.36883, 0.13501, 0.23457, 0.19228, 0.31693, 0.17556, 0.089286, 0.22365, 0.37044, 0.69506]
Predicted label: 9
Correct prediction
Energy consumption = 187.846507 pJ
sum error= 47
Actual label: 6
Output voltages: [0.37638, 0.29117, 0.24639, 0.15966, 0.22699, 0.38855, 0.73661, 0.1634, 0.40083, 0.12238]
Predicted label: 6
Correct prediction
Energy consumption = 198.688707 pJ
sum error= 47
Actual label: 2
Output voltages: [0.24601, 0.16555, 0.71388, 0.36855, 0.13855, 0.044454, 0.21017, 0.44889, 0.41523, 0.14717]
Predicted label: 2
Correct prediction
Energy consumption = 186.988663 pJ
sum error= 47
Actual label: 7
Output voltages: [0.27028, 0.2706, 0.23387, 0.2378, 0.15037, 0.092741, 0.036206, 0.75587, 0.40574, 0.31725]
Predicted label: 7
Correct prediction
Energy consumption = 194.136387 pJ
sum error= 47
Actual label: 7
Output voltages: [0.37021, 0.23775, 0.13786, 0.18037, 0.30166, 0.16973, 0.060981, 0.70186, 0.28955, 0.47127]
Predicted label: 7
Correct prediction
Energy consumption = 194.052750 pJ
sum error= 47
Actual label: 2
Output voltages: [0.45661, 0.26197, 0.74302, 0.3398, 0.13493, 0.06465, 0.34703, 0.2071, 0.28528, 0.20421]
Predicted label: 2
Correct prediction
Energy consumption = 196.773954 pJ
sum error= 47
Actual label: 2
Output voltages: [0.26607, 0.27719, 0.6653, 0.37898, 0.084952, 0.039652, 0.18847, 0.32577, 0.50252, 0.13985]
Predicted label: 2
Correct prediction
Energy consumption = 180.309010 pJ
sum error= 47
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 135 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 135 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 135 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.15138, 0.76865, 0.26971, 0.25604, 0.19108, 0.10257, 0.37213, 0.15997, 0.34883, 0.2046]
Predicted label: 1
Correct prediction
Energy consumption = 212.002999 pJ
sum error= 47
Actual label: 1
Output voltages: [0.16877, 0.73602, 0.21557, 0.20752, 0.28241, 0.08743, 0.41317, 0.05637, 0.3979, 0.20736]
Predicted label: 1
Correct prediction
Energy consumption = 206.772822 pJ
sum error= 47
Actual label: 2
Output voltages: [0.51049, 0.19928, 0.68282, 0.27152, 0.080511, 0.072052, 0.3211, 0.2337, 0.43396, 0.18312]
Predicted label: 2
Correct prediction
Energy consumption = 196.017523 pJ
sum error= 47
Actual label: 8
Output voltages: [0.16381, 0.30139, 0.27282, 0.30318, 0.11011, 0.16069, 0.20586, 0.14708, 0.72553, 0.36057]
Predicted label: 8
Correct prediction
Energy consumption = 201.528449 pJ
sum error= 47
Actual label: 3
Output voltages: [0.33019, 0.23488, 0.37707, 0.73886, 0.13376, 0.098398, 0.17468, 0.15443, 0.44519, 0.25428]
Predicted label: 3
Correct prediction
Energy consumption = 189.552095 pJ
sum error= 47
Actual label: 7
Output voltages: [0.26053, 0.23397, 0.18625, 0.1173, 0.45122, 0.064135, 0.045677, 0.58881, 0.33742, 0.3547]
Predicted label: 7
Correct prediction
Energy consumption = 212.327157 pJ
sum error= 47
Actual label: 2
Output voltages: [0.42834, 0.38384, 0.6663, 0.23687, 0.12789, 0.026424, 0.30586, 0.22467, 0.36633, 0.19834]
Predicted label: 2
Correct prediction
Energy consumption = 203.105288 pJ
sum error= 47
Actual label: 4
Output voltages: [0.34998, 0.16264, 0.25842, 0.080789, 0.69162, 0.076487, 0.35884, 0.24348, 0.14879, 0.39675]
Predicted label: 4
Correct prediction
Energy consumption = 208.507515 pJ
sum error= 47
Actual label: 1
Output voltages: [0.2136, 0.7595, 0.29535, 0.39676, 0.15553, 0.071982, 0.36024, 0.15242, 0.2744, 0.20395]
Predicted label: 1
Correct prediction
Energy consumption = 210.879542 pJ
sum error= 47
Actual label: 7
Output voltages: [0.35672, 0.2128, 0.37783, 0.31542, 0.1215, 0.036183, 0.042152, 0.72213, 0.34491, 0.30978]
Predicted label: 7
Correct prediction
Energy consumption = 192.309973 pJ
sum error= 47
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 136 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 136 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 136 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23793, 0.76274, 0.20812, 0.37954, 0.11697, 0.1553, 0.3039, 0.19184, 0.31883, 0.26031]
Predicted label: 1
Correct prediction
Energy consumption = 218.121484 pJ
sum error= 47
Actual label: 7
Output voltages: [0.29809, 0.33129, 0.28103, 0.41931, 0.099954, 0.090829, 0.033504, 0.73649, 0.36817, 0.36043]
Predicted label: 7
Correct prediction
Energy consumption = 195.427855 pJ
sum error= 47
Actual label: 6
Output voltages: [0.29452, 0.23315, 0.34791, 0.061485, 0.38581, 0.32699, 0.73492, 0.081624, 0.27046, 0.11221]
Predicted label: 6
Correct prediction
Energy consumption = 194.377839 pJ
sum error= 47
Actual label: 7
Output voltages: [0.28563, 0.30238, 0.55766, 0.32857, 0.21068, 0.023064, 0.15728, 0.63553, 0.14435, 0.37078]
Predicted label: 7
Correct prediction
Energy consumption = 195.124805 pJ
sum error= 47
Actual label: 8
Output voltages: [0.35568, 0.062812, 0.34212, 0.31671, 0.18284, 0.1991, 0.14662, 0.26258, 0.72023, 0.25011]
Predicted label: 8
Correct prediction
Energy consumption = 199.129401 pJ
sum error= 47
Actual label: 2
Output voltages: [0.32716, 0.29437, 0.73834, 0.3412, 0.16409, 0.041658, 0.22208, 0.34461, 0.36269, 0.21847]
Predicted label: 2
Correct prediction
Energy consumption = 192.203835 pJ
sum error= 47
Actual label: 7
Output voltages: [0.26206, 0.26421, 0.19385, 0.17501, 0.14592, 0.20987, 0.03945, 0.71746, 0.50624, 0.32558]
Predicted label: 7
Correct prediction
Energy consumption = 194.005967 pJ
sum error= 47
Actual label: 3
Output voltages: [0.32904, 0.13402, 0.33584, 0.7381, 0.20771, 0.18774, 0.12089, 0.17405, 0.52168, 0.24366]
Predicted label: 3
Correct prediction
Energy consumption = 176.648369 pJ
sum error= 47
Actual label: 1
Output voltages: [0.28147, 0.76505, 0.097436, 0.31767, 0.1591, 0.21827, 0.28967, 0.16062, 0.2871, 0.26425]
Predicted label: 1
Correct prediction
Energy consumption = 215.197280 pJ
sum error= 47
Actual label: 7
Output voltages: [0.36791, 0.15822, 0.21997, 0.36577, 0.097387, 0.16651, 0.041501, 0.75747, 0.3971, 0.32893]
Predicted label: 7
Correct prediction
Energy consumption = 192.372588 pJ
sum error= 47
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 137 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 137 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 137 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.19353, 0.048288, 0.12552, 0.32081, 0.18035, 0.66289, 0.32786, 0.16213, 0.54427, 0.25749]
Predicted label: 5
Correct prediction
Energy consumption = 191.172944 pJ
sum error= 47
Actual label: 8
Output voltages: [0.21475, 0.15236, 0.29262, 0.23699, 0.16821, 0.21504, 0.17102, 0.12461, 0.74184, 0.3487]
Predicted label: 8
Correct prediction
Energy consumption = 189.356687 pJ
sum error= 47
Actual label: 2
Output voltages: [0.33107, 0.24762, 0.71687, 0.3837, 0.099639, 0.031931, 0.28456, 0.31704, 0.41461, 0.18491]
Predicted label: 2
Correct prediction
Energy consumption = 186.189178 pJ
sum error= 47
Actual label: 6
Output voltages: [0.30763, 0.183, 0.25274, 0.13641, 0.33282, 0.39484, 0.7209, 0.068277, 0.39742, 0.12919]
Predicted label: 6
Correct prediction
Energy consumption = 189.109215 pJ
sum error= 47
Actual label: 2
Output voltages: [0.383, 0.1381, 0.71582, 0.37224, 0.13549, 0.041442, 0.21173, 0.20697, 0.46616, 0.11884]
Predicted label: 2
Correct prediction
Energy consumption = 190.924242 pJ
sum error= 47
Actual label: 2
Output voltages: [0.35891, 0.40643, 0.69608, 0.36737, 0.096068, 0.025394, 0.29556, 0.1794, 0.34839, 0.25265]
Predicted label: 2
Correct prediction
Energy consumption = 187.690203 pJ
sum error= 47
Actual label: 5
Output voltages: [0.22523, 0.043923, 0.074567, 0.31043, 0.25012, 0.68544, 0.31915, 0.18479, 0.57631, 0.27093]
Predicted label: 5
Correct prediction
Energy consumption = 186.272050 pJ
sum error= 47
Actual label: 6
Output voltages: [0.27883, 0.12772, 0.30127, 0.11778, 0.26109, 0.42056, 0.65696, 0.047199, 0.4157, 0.17536]
Predicted label: 6
Correct prediction
Energy consumption = 182.665230 pJ
sum error= 47
Actual label: 5
Output voltages: [0.32309, 0.17027, 0.083224, 0.36253, 0.12572, 0.55049, 0.51735, 0.071681, 0.53714, 0.095152]
Predicted label: 5
Correct prediction
Energy consumption = 188.571815 pJ
sum error= 47
Actual label: 0
Output voltages: [0.73679, 0.25872, 0.24326, 0.2348, 0.13227, 0.21598, 0.34577, 0.18833, 0.32088, 0.27405]
Predicted label: 0
Correct prediction
Energy consumption = 187.817818 pJ
sum error= 47
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 138 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 138 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 138 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37649, 0.16176, 0.19229, 0.28503, 0.36242, 0.19964, 0.17761, 0.15688, 0.32679, 0.69062]
Predicted label: 9
Correct prediction
Energy consumption = 202.538244 pJ
sum error= 47
Actual label: 2
Output voltages: [0.35529, 0.24873, 0.70433, 0.40921, 0.13718, 0.038115, 0.2792, 0.16129, 0.49299, 0.16447]
Predicted label: 2
Correct prediction
Energy consumption = 185.967426 pJ
sum error= 47
Actual label: 4
Output voltages: [0.18468, 0.15739, 0.27333, 0.11497, 0.758, 0.092733, 0.28693, 0.23258, 0.21349, 0.28094]
Predicted label: 4
Correct prediction
Energy consumption = 196.707525 pJ
sum error= 47
Actual label: 3
Output voltages: [0.41646, 0.2342, 0.30252, 0.71779, 0.14169, 0.29413, 0.34318, 0.14503, 0.30186, 0.070669]
Predicted label: 3
Correct prediction
Energy consumption = 192.067769 pJ
sum error= 47
Actual label: 3
Output voltages: [0.22123, 0.34862, 0.28804, 0.75646, 0.089964, 0.16246, 0.090337, 0.27767, 0.3717, 0.34424]
Predicted label: 3
Correct prediction
Energy consumption = 183.723973 pJ
sum error= 47
Actual label: 9
Output voltages: [0.3467, 0.1667, 0.28749, 0.22069, 0.29968, 0.14087, 0.10112, 0.19128, 0.36956, 0.70277]
Predicted label: 9
Correct prediction
Energy consumption = 194.757943 pJ
sum error= 47
Actual label: 7
Output voltages: [0.29203, 0.16934, 0.25527, 0.2363, 0.23399, 0.16139, 0.049313, 0.7536, 0.27042, 0.37222]
Predicted label: 7
Correct prediction
Energy consumption = 195.575496 pJ
sum error= 47
Actual label: 6
Output voltages: [0.26895, 0.27822, 0.34924, 0.073302, 0.3845, 0.33531, 0.74727, 0.091326, 0.333, 0.093422]
Predicted label: 6
Correct prediction
Energy consumption = 193.949770 pJ
sum error= 47
Actual label: 6
Output voltages: [0.34764, 0.17733, 0.36533, 0.12775, 0.22839, 0.32697, 0.70811, 0.060372, 0.43373, 0.23355]
Predicted label: 6
Correct prediction
Energy consumption = 188.590562 pJ
sum error= 47
Actual label: 8
Output voltages: [0.22287, 0.17506, 0.24668, 0.38533, 0.13062, 0.20492, 0.20199, 0.14009, 0.74219, 0.21048]
Predicted label: 8
Correct prediction
Energy consumption = 184.984083 pJ
sum error= 47
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 139 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 139 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 139 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73492, 0.22121, 0.28281, 0.20594, 0.184, 0.13443, 0.41629, 0.1703, 0.27327, 0.32069]
Predicted label: 0
Correct prediction
Energy consumption = 197.449618 pJ
sum error= 47
Actual label: 4
Output voltages: [0.17823, 0.14976, 0.30336, 0.13145, 0.72177, 0.23885, 0.22726, 0.17546, 0.32679, 0.41372]
Predicted label: 4
Correct prediction
Energy consumption = 208.041515 pJ
sum error= 47
Actual label: 1
Output voltages: [0.27325, 0.75994, 0.29886, 0.26812, 0.17665, 0.087055, 0.25787, 0.15225, 0.36481, 0.21783]
Predicted label: 1
Correct prediction
Energy consumption = 216.761903 pJ
sum error= 47
Actual label: 5
Output voltages: [0.29999, 0.053705, 0.22843, 0.54931, 0.10172, 0.46485, 0.19675, 0.26781, 0.40381, 0.14756]
Predicted label: 3
Wrong prediction!
Energy consumption = 198.196737 pJ
sum error= 48
Actual label: 8
Output voltages: [0.23755, 0.20402, 0.3195, 0.4009, 0.12499, 0.1448, 0.15748, 0.18117, 0.71998, 0.30812]
Predicted label: 8
Correct prediction
Energy consumption = 206.365115 pJ
sum error= 48
Actual label: 2
Output voltages: [0.37601, 0.13421, 0.60218, 0.47843, 0.19702, 0.030908, 0.20885, 0.24591, 0.48085, 0.19136]
Predicted label: 2
Correct prediction
Energy consumption = 186.665310 pJ
sum error= 48
Actual label: 9
Output voltages: [0.31519, 0.15182, 0.19677, 0.26835, 0.34179, 0.099035, 0.064405, 0.20858, 0.3726, 0.64835]
Predicted label: 9
Correct prediction
Energy consumption = 195.842872 pJ
sum error= 48
Actual label: 1
Output voltages: [0.10657, 0.75012, 0.22867, 0.36258, 0.30943, 0.25319, 0.2362, 0.15666, 0.2373, 0.34966]
Predicted label: 1
Correct prediction
Energy consumption = 209.892290 pJ
sum error= 48
Actual label: 8
Output voltages: [0.22605, 0.18945, 0.3107, 0.3623, 0.088274, 0.19177, 0.17803, 0.18891, 0.73457, 0.27892]
Predicted label: 8
Correct prediction
Energy consumption = 203.143965 pJ
sum error= 48
Actual label: 0
Output voltages: [0.73494, 0.27296, 0.19361, 0.17386, 0.16851, 0.279, 0.44431, 0.19661, 0.2572, 0.23051]
Predicted label: 0
Correct prediction
Energy consumption = 199.631576 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 140 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 140 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 140 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.26472, 0.1691, 0.20738, 0.13951, 0.36216, 0.36244, 0.70821, 0.12396, 0.47334, 0.096753]
Predicted label: 6
Correct prediction
Energy consumption = 198.585964 pJ
sum error= 48
Actual label: 7
Output voltages: [0.36776, 0.24086, 0.16478, 0.2537, 0.19187, 0.14065, 0.064191, 0.73355, 0.30491, 0.40835]
Predicted label: 7
Correct prediction
Energy consumption = 202.901737 pJ
sum error= 48
Actual label: 2
Output voltages: [0.34502, 0.22091, 0.69687, 0.28735, 0.13466, 0.027331, 0.20396, 0.47611, 0.39049, 0.16505]
Predicted label: 2
Correct prediction
Energy consumption = 188.630750 pJ
sum error= 48
Actual label: 1
Output voltages: [0.30506, 0.67177, 0.25963, 0.24073, 0.20325, 0.14409, 0.5629, 0.042833, 0.37134, 0.18551]
Predicted label: 1
Correct prediction
Energy consumption = 201.345281 pJ
sum error= 48
Actual label: 0
Output voltages: [0.59977, 0.19364, 0.26401, 0.23486, 0.22924, 0.081971, 0.37048, 0.17895, 0.46799, 0.26848]
Predicted label: 0
Correct prediction
Energy consumption = 204.701542 pJ
sum error= 48
Actual label: 5
Output voltages: [0.28665, 0.076879, 0.072381, 0.3074, 0.20149, 0.71486, 0.43758, 0.083777, 0.52966, 0.13515]
Predicted label: 5
Correct prediction
Energy consumption = 190.238136 pJ
sum error= 48
Actual label: 5
Output voltages: [0.28204, 0.15683, 0.1312, 0.30805, 0.15127, 0.72343, 0.28889, 0.13247, 0.57572, 0.21799]
Predicted label: 5
Correct prediction
Energy consumption = 189.240237 pJ
sum error= 48
Actual label: 2
Output voltages: [0.40081, 0.17368, 0.74578, 0.29864, 0.18244, 0.036761, 0.26515, 0.30489, 0.43551, 0.21703]
Predicted label: 2
Correct prediction
Energy consumption = 183.510023 pJ
sum error= 48
Actual label: 0
Output voltages: [0.69983, 0.14605, 0.25031, 0.12162, 0.20409, 0.17955, 0.41955, 0.24795, 0.23554, 0.34284]
Predicted label: 0
Correct prediction
Energy consumption = 188.504018 pJ
sum error= 48
Actual label: 2
Output voltages: [0.48338, 0.37032, 0.69915, 0.21467, 0.13776, 0.023309, 0.34167, 0.3051, 0.38524, 0.24843]
Predicted label: 2
Correct prediction
Energy consumption = 184.652949 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 141 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 141 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 141 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.3682, 0.32715, 0.61551, 0.37917, 0.23469, 0.039866, 0.41777, 0.28515, 0.30985, 0.084377]
Predicted label: 2
Correct prediction
Energy consumption = 202.878574 pJ
sum error= 48
Actual label: 0
Output voltages: [0.66985, 0.1543, 0.21266, 0.26035, 0.2441, 0.17349, 0.3367, 0.14262, 0.42611, 0.37479]
Predicted label: 0
Correct prediction
Energy consumption = 211.667488 pJ
sum error= 48
Actual label: 2
Output voltages: [0.30308, 0.402, 0.70903, 0.32234, 0.17655, 0.025938, 0.26288, 0.26482, 0.34641, 0.22937]
Predicted label: 2
Correct prediction
Energy consumption = 192.551631 pJ
sum error= 48
Actual label: 4
Output voltages: [0.17556, 0.29365, 0.24366, 0.10284, 0.73744, 0.088213, 0.35369, 0.17682, 0.29113, 0.33068]
Predicted label: 4
Correct prediction
Energy consumption = 202.601513 pJ
sum error= 48
Actual label: 9
Output voltages: [0.49054, 0.29167, 0.11333, 0.37496, 0.26065, 0.23792, 0.10684, 0.33631, 0.22648, 0.59537]
Predicted label: 9
Correct prediction
Energy consumption = 216.863626 pJ
sum error= 48
Actual label: 8
Output voltages: [0.2085, 0.10941, 0.27126, 0.21181, 0.19078, 0.31023, 0.49895, 0.063926, 0.65802, 0.20637]
Predicted label: 8
Correct prediction
Energy consumption = 193.887074 pJ
sum error= 48
Actual label: 0
Output voltages: [0.73126, 0.25047, 0.2244, 0.24223, 0.15533, 0.18197, 0.43223, 0.14528, 0.27864, 0.31287]
Predicted label: 0
Correct prediction
Energy consumption = 199.286056 pJ
sum error= 48
Actual label: 9
Output voltages: [0.30564, 0.088602, 0.18674, 0.33621, 0.27167, 0.28324, 0.11762, 0.37137, 0.37463, 0.63641]
Predicted label: 9
Correct prediction
Energy consumption = 195.728614 pJ
sum error= 48
Actual label: 9
Output voltages: [0.37907, 0.096146, 0.20495, 0.27947, 0.3412, 0.23612, 0.11383, 0.28686, 0.28957, 0.67889]
Predicted label: 9
Correct prediction
Energy consumption = 186.900075 pJ
sum error= 48
Actual label: 4
Output voltages: [0.15625, 0.15274, 0.25362, 0.12189, 0.75971, 0.11742, 0.28881, 0.30068, 0.25056, 0.31649]
Predicted label: 4
Correct prediction
Energy consumption = 182.719676 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 142 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 142 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 142 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.33168, 0.2313, 0.24603, 0.12249, 0.277, 0.3942, 0.7295, 0.12357, 0.38925, 0.12745]
Predicted label: 6
Correct prediction
Energy consumption = 196.461538 pJ
sum error= 48
Actual label: 5
Output voltages: [0.2584, 0.044749, 0.10589, 0.36393, 0.26942, 0.63284, 0.29817, 0.10738, 0.51804, 0.25206]
Predicted label: 5
Correct prediction
Energy consumption = 186.690606 pJ
sum error= 48
Actual label: 4
Output voltages: [0.2529, 0.17859, 0.22226, 0.20361, 0.73683, 0.18578, 0.29965, 0.18599, 0.17473, 0.3201]
Predicted label: 4
Correct prediction
Energy consumption = 202.949424 pJ
sum error= 48
Actual label: 9
Output voltages: [0.30479, 0.069993, 0.27261, 0.31052, 0.30157, 0.12096, 0.082994, 0.29831, 0.43192, 0.59167]
Predicted label: 9
Correct prediction
Energy consumption = 186.741480 pJ
sum error= 48
Actual label: 1
Output voltages: [0.17671, 0.76201, 0.15579, 0.28647, 0.18019, 0.16193, 0.42248, 0.12268, 0.38588, 0.20121]
Predicted label: 1
Correct prediction
Energy consumption = 212.727586 pJ
sum error= 48
Actual label: 8
Output voltages: [0.25497, 0.21786, 0.23673, 0.22286, 0.42293, 0.19335, 0.43126, 0.045283, 0.53045, 0.18701]
Predicted label: 8
Correct prediction
Energy consumption = 196.363283 pJ
sum error= 48
Actual label: 3
Output voltages: [0.31282, 0.20563, 0.33575, 0.75618, 0.15515, 0.12422, 0.14044, 0.1943, 0.4531, 0.22259]
Predicted label: 3
Correct prediction
Energy consumption = 183.494366 pJ
sum error= 48
Actual label: 4
Output voltages: [0.17509, 0.13603, 0.3602, 0.10807, 0.7007, 0.086076, 0.3876, 0.13587, 0.32152, 0.27818]
Predicted label: 4
Correct prediction
Energy consumption = 189.684691 pJ
sum error= 48
Actual label: 9
Output voltages: [0.35418, 0.13929, 0.28623, 0.26186, 0.38286, 0.12436, 0.11471, 0.15543, 0.30554, 0.69799]
Predicted label: 9
Correct prediction
Energy consumption = 192.705078 pJ
sum error= 48
Actual label: 9
Output voltages: [0.38822, 0.13123, 0.25765, 0.23477, 0.40915, 0.12963, 0.21755, 0.16827, 0.32155, 0.68178]
Predicted label: 9
Correct prediction
Energy consumption = 192.654580 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 143 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 143 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 143 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23367, 0.76436, 0.16421, 0.31639, 0.10309, 0.15939, 0.37184, 0.10681, 0.36814, 0.20069]
Predicted label: 1
Correct prediction
Energy consumption = 209.037661 pJ
sum error= 48
Actual label: 2
Output voltages: [0.37843, 0.33049, 0.69027, 0.33539, 0.095348, 0.023496, 0.25698, 0.33052, 0.40022, 0.25067]
Predicted label: 2
Correct prediction
Energy consumption = 190.966608 pJ
sum error= 48
Actual label: 2
Output voltages: [0.36983, 0.30397, 0.7343, 0.31423, 0.11123, 0.028806, 0.34922, 0.1805, 0.41971, 0.18122]
Predicted label: 2
Correct prediction
Energy consumption = 178.160990 pJ
sum error= 48
Actual label: 8
Output voltages: [0.23082, 0.43786, 0.17627, 0.38386, 0.15401, 0.11062, 0.17183, 0.23106, 0.64314, 0.19613]
Predicted label: 8
Correct prediction
Energy consumption = 200.008116 pJ
sum error= 48
Actual label: 1
Output voltages: [0.22259, 0.76777, 0.21699, 0.23152, 0.22475, 0.10662, 0.39804, 0.072081, 0.31042, 0.2357]
Predicted label: 1
Correct prediction
Energy consumption = 205.513482 pJ
sum error= 48
Actual label: 9
Output voltages: [0.32231, 0.061178, 0.24883, 0.22599, 0.36567, 0.19913, 0.084434, 0.29217, 0.36367, 0.60848]
Predicted label: 9
Correct prediction
Energy consumption = 206.681795 pJ
sum error= 48
Actual label: 6
Output voltages: [0.3093, 0.20603, 0.17144, 0.25789, 0.21891, 0.35546, 0.6258, 0.080532, 0.55839, 0.13807]
Predicted label: 6
Correct prediction
Energy consumption = 193.884052 pJ
sum error= 48
Actual label: 4
Output voltages: [0.16985, 0.24767, 0.22238, 0.18167, 0.63625, 0.17157, 0.20352, 0.16934, 0.29069, 0.48864]
Predicted label: 4
Correct prediction
Energy consumption = 208.844033 pJ
sum error= 48
Actual label: 0
Output voltages: [0.69634, 0.23369, 0.2499, 0.14832, 0.21295, 0.23443, 0.49717, 0.22337, 0.27546, 0.21987]
Predicted label: 0
Correct prediction
Energy consumption = 201.934980 pJ
sum error= 48
Actual label: 9
Output voltages: [0.32313, 0.19221, 0.20869, 0.27853, 0.38872, 0.069737, 0.064996, 0.11336, 0.37277, 0.63167]
Predicted label: 9
Correct prediction
Energy consumption = 197.258090 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 144 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 144 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 144 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19977, 0.20515, 0.26269, 0.16427, 0.71166, 0.10738, 0.32069, 0.14967, 0.31124, 0.29713]
Predicted label: 4
Correct prediction
Energy consumption = 190.255887 pJ
sum error= 48
Actual label: 8
Output voltages: [0.18364, 0.14264, 0.33361, 0.34267, 0.17888, 0.12569, 0.12035, 0.19652, 0.64792, 0.41153]
Predicted label: 8
Correct prediction
Energy consumption = 203.244886 pJ
sum error= 48
Actual label: 3
Output voltages: [0.347, 0.17466, 0.32706, 0.75922, 0.2156, 0.17133, 0.15642, 0.19774, 0.43246, 0.26983]
Predicted label: 3
Correct prediction
Energy consumption = 184.752118 pJ
sum error= 48
Actual label: 8
Output voltages: [0.21536, 0.20036, 0.28605, 0.30448, 0.15282, 0.21185, 0.20976, 0.15641, 0.75299, 0.26636]
Predicted label: 8
Correct prediction
Energy consumption = 183.873849 pJ
sum error= 48
Actual label: 6
Output voltages: [0.52587, 0.14192, 0.26296, 0.094793, 0.37761, 0.15034, 0.61118, 0.18073, 0.25293, 0.19738]
Predicted label: 6
Correct prediction
Energy consumption = 207.119669 pJ
sum error= 48
Actual label: 0
Output voltages: [0.73892, 0.22944, 0.289, 0.18937, 0.16433, 0.17474, 0.37938, 0.16022, 0.33428, 0.3277]
Predicted label: 0
Correct prediction
Energy consumption = 193.469484 pJ
sum error= 48
Actual label: 2
Output voltages: [0.40477, 0.22211, 0.72591, 0.29032, 0.13561, 0.032359, 0.31293, 0.24199, 0.49032, 0.19316]
Predicted label: 2
Correct prediction
Energy consumption = 180.603755 pJ
sum error= 48
Actual label: 5
Output voltages: [0.24646, 0.056057, 0.052092, 0.36319, 0.27692, 0.69472, 0.45122, 0.11791, 0.47791, 0.28139]
Predicted label: 5
Correct prediction
Energy consumption = 196.067404 pJ
sum error= 48
Actual label: 1
Output voltages: [0.22021, 0.76611, 0.26306, 0.23215, 0.27005, 0.073039, 0.40531, 0.13141, 0.2786, 0.24599]
Predicted label: 1
Correct prediction
Energy consumption = 209.142746 pJ
sum error= 48
Actual label: 9
Output voltages: [0.37361, 0.11745, 0.16588, 0.30066, 0.25132, 0.15526, 0.07046, 0.3393, 0.35384, 0.68166]
Predicted label: 9
Correct prediction
Energy consumption = 195.393398 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 145 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 145 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 145 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.36319, 0.24476, 0.27139, 0.15228, 0.3225, 0.30564, 0.73273, 0.070108, 0.33063, 0.22741]
Predicted label: 6
Correct prediction
Energy consumption = 191.027708 pJ
sum error= 48
Actual label: 2
Output voltages: [0.52233, 0.18515, 0.69202, 0.38337, 0.10791, 0.042488, 0.2888, 0.27113, 0.45525, 0.18904]
Predicted label: 2
Correct prediction
Energy consumption = 196.403593 pJ
sum error= 48
Actual label: 9
Output voltages: [0.37682, 0.11682, 0.20012, 0.2438, 0.3816, 0.19322, 0.098424, 0.24161, 0.3275, 0.67907]
Predicted label: 9
Correct prediction
Energy consumption = 198.661474 pJ
sum error= 48
Actual label: 4
Output voltages: [0.18768, 0.24938, 0.26984, 0.25334, 0.73752, 0.12604, 0.22232, 0.18208, 0.14977, 0.43757]
Predicted label: 4
Correct prediction
Energy consumption = 191.273326 pJ
sum error= 48
Actual label: 0
Output voltages: [0.68596, 0.26406, 0.23539, 0.1853, 0.12503, 0.15113, 0.38131, 0.2608, 0.41262, 0.20722]
Predicted label: 0
Correct prediction
Energy consumption = 202.864425 pJ
sum error= 48
Actual label: 9
Output voltages: [0.32661, 0.12492, 0.24677, 0.28802, 0.50549, 0.073017, 0.069887, 0.17801, 0.28272, 0.60956]
Predicted label: 9
Correct prediction
Energy consumption = 191.954500 pJ
sum error= 48
Actual label: 6
Output voltages: [0.29813, 0.27535, 0.34362, 0.086101, 0.34518, 0.26417, 0.74298, 0.14205, 0.3319, 0.10055]
Predicted label: 6
Correct prediction
Energy consumption = 197.791185 pJ
sum error= 48
Actual label: 0
Output voltages: [0.74934, 0.26966, 0.23275, 0.16023, 0.17327, 0.20324, 0.36915, 0.15585, 0.29203, 0.26192]
Predicted label: 0
Correct prediction
Energy consumption = 190.375360 pJ
sum error= 48
Actual label: 6
Output voltages: [0.31744, 0.1643, 0.33598, 0.12697, 0.23394, 0.36661, 0.72017, 0.070989, 0.3729, 0.2348]
Predicted label: 6
Correct prediction
Energy consumption = 188.328960 pJ
sum error= 48
Actual label: 2
Output voltages: [0.28397, 0.25828, 0.72254, 0.37315, 0.19505, 0.04371, 0.19328, 0.36082, 0.39595, 0.17679]
Predicted label: 2
Correct prediction
Energy consumption = 192.529948 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 146 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 146 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 146 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.17907, 0.05312, 0.13535, 0.31932, 0.19582, 0.62765, 0.28419, 0.11543, 0.57411, 0.26508]
Predicted label: 5
Correct prediction
Energy consumption = 182.229484 pJ
sum error= 48
Actual label: 4
Output voltages: [0.14357, 0.15351, 0.33852, 0.095372, 0.76314, 0.10188, 0.32192, 0.31104, 0.21654, 0.30534]
Predicted label: 4
Correct prediction
Energy consumption = 195.820706 pJ
sum error= 48
Actual label: 2
Output voltages: [0.45543, 0.11737, 0.61165, 0.528, 0.1335, 0.051558, 0.12345, 0.19921, 0.43394, 0.16869]
Predicted label: 2
Correct prediction
Energy consumption = 196.779330 pJ
sum error= 48
Actual label: 3
Output voltages: [0.2593, 0.21516, 0.25834, 0.75369, 0.1463, 0.19565, 0.11073, 0.21419, 0.41887, 0.24837]
Predicted label: 3
Correct prediction
Energy consumption = 182.231361 pJ
sum error= 48
Actual label: 8
Output voltages: [0.23072, 0.25766, 0.2494, 0.23441, 0.1025, 0.23828, 0.15028, 0.25523, 0.72575, 0.31486]
Predicted label: 8
Correct prediction
Energy consumption = 203.693778 pJ
sum error= 48
Actual label: 4
Output voltages: [0.1429, 0.23004, 0.36283, 0.1947, 0.67113, 0.04755, 0.38456, 0.20674, 0.27815, 0.16805]
Predicted label: 4
Correct prediction
Energy consumption = 199.891564 pJ
sum error= 48
Actual label: 5
Output voltages: [0.41061, 0.13566, 0.085643, 0.46554, 0.095856, 0.72799, 0.16047, 0.21747, 0.48211, 0.23013]
Predicted label: 5
Correct prediction
Energy consumption = 196.626520 pJ
sum error= 48
Actual label: 5
Output voltages: [0.23512, 0.072338, 0.045597, 0.34351, 0.29994, 0.64007, 0.25798, 0.23391, 0.42398, 0.37718]
Predicted label: 5
Correct prediction
Energy consumption = 189.587746 pJ
sum error= 48
Actual label: 0
Output voltages: [0.6473, 0.17567, 0.35148, 0.15407, 0.1149, 0.14004, 0.4473, 0.1202, 0.29825, 0.2858]
Predicted label: 0
Correct prediction
Energy consumption = 192.597169 pJ
sum error= 48
Actual label: 3
Output voltages: [0.26393, 0.20412, 0.28296, 0.68481, 0.17939, 0.43418, 0.38264, 0.21616, 0.20936, 0.076665]
Predicted label: 3
Correct prediction
Energy consumption = 197.652165 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 147 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 147 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 147 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.27374, 0.082431, 0.25424, 0.42477, 0.075713, 0.35831, 0.12041, 0.17949, 0.73348, 0.1586]
Predicted label: 8
Correct prediction
Energy consumption = 189.887531 pJ
sum error= 48
Actual label: 5
Output voltages: [0.21929, 0.076217, 0.10204, 0.39973, 0.16847, 0.70169, 0.25824, 0.15344, 0.48847, 0.26187]
Predicted label: 5
Correct prediction
Energy consumption = 191.818111 pJ
sum error= 48
Actual label: 3
Output voltages: [0.35558, 0.071452, 0.28609, 0.74517, 0.17082, 0.32438, 0.16487, 0.16305, 0.39954, 0.20509]
Predicted label: 3
Correct prediction
Energy consumption = 180.884712 pJ
sum error= 48
Actual label: 5
Output voltages: [0.2501, 0.11512, 0.063723, 0.31059, 0.18306, 0.7258, 0.32196, 0.15719, 0.41834, 0.26512]
Predicted label: 5
Correct prediction
Energy consumption = 189.208571 pJ
sum error= 48
Actual label: 8
Output voltages: [0.2456, 0.25122, 0.34168, 0.32722, 0.15464, 0.13828, 0.18364, 0.18027, 0.73969, 0.27415]
Predicted label: 8
Correct prediction
Energy consumption = 196.308386 pJ
sum error= 48
Actual label: 6
Output voltages: [0.40305, 0.24115, 0.20332, 0.16975, 0.28629, 0.2885, 0.71089, 0.12865, 0.40178, 0.16763]
Predicted label: 6
Correct prediction
Energy consumption = 204.089705 pJ
sum error= 48
Actual label: 5
Output voltages: [0.42004, 0.084316, 0.0839, 0.39626, 0.17253, 0.72525, 0.34496, 0.20334, 0.39932, 0.30256]
Predicted label: 5
Correct prediction
Energy consumption = 191.415976 pJ
sum error= 48
Actual label: 7
Output voltages: [0.27509, 0.24013, 0.23061, 0.22611, 0.2272, 0.069401, 0.086834, 0.76252, 0.24489, 0.27505]
Predicted label: 7
Correct prediction
Energy consumption = 198.780260 pJ
sum error= 48
Actual label: 6
Output voltages: [0.3262, 0.30538, 0.16636, 0.24982, 0.24956, 0.35004, 0.71507, 0.11136, 0.48298, 0.099735]
Predicted label: 6
Correct prediction
Energy consumption = 200.428042 pJ
sum error= 48
Actual label: 3
Output voltages: [0.24729, 0.19678, 0.31874, 0.74446, 0.20749, 0.12725, 0.099601, 0.20369, 0.5006, 0.23899]
Predicted label: 3
Correct prediction
Energy consumption = 180.794868 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 148 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 148 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 148 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.3061, 0.13957, 0.25512, 0.74845, 0.27586, 0.13164, 0.14299, 0.24511, 0.44974, 0.24691]
Predicted label: 3
Correct prediction
Energy consumption = 187.485741 pJ
sum error= 48
Actual label: 9
Output voltages: [0.35712, 0.15373, 0.14613, 0.34644, 0.31657, 0.30814, 0.069873, 0.39284, 0.24533, 0.63093]
Predicted label: 9
Correct prediction
Energy consumption = 193.359522 pJ
sum error= 48
Actual label: 6
Output voltages: [0.29947, 0.21385, 0.31349, 0.12032, 0.24087, 0.40864, 0.72527, 0.088758, 0.42647, 0.13466]
Predicted label: 6
Correct prediction
Energy consumption = 187.584123 pJ
sum error= 48
Actual label: 1
Output voltages: [0.27823, 0.76437, 0.22279, 0.33143, 0.17598, 0.13642, 0.33637, 0.063512, 0.30772, 0.28317]
Predicted label: 1
Correct prediction
Energy consumption = 211.397501 pJ
sum error= 48
Actual label: 1
Output voltages: [0.1793, 0.75995, 0.087943, 0.2455, 0.25423, 0.27655, 0.38215, 0.1589, 0.3226, 0.2382]
Predicted label: 1
Correct prediction
Energy consumption = 209.581044 pJ
sum error= 48
Actual label: 2
Output voltages: [0.38749, 0.148, 0.73756, 0.36073, 0.16031, 0.041144, 0.20752, 0.30233, 0.40242, 0.20388]
Predicted label: 2
Correct prediction
Energy consumption = 186.675981 pJ
sum error= 48
Actual label: 9
Output voltages: [0.34533, 0.11807, 0.23409, 0.24311, 0.27546, 0.13409, 0.10714, 0.20865, 0.35264, 0.71069]
Predicted label: 9
Correct prediction
Energy consumption = 193.202931 pJ
sum error= 48
Actual label: 0
Output voltages: [0.73701, 0.24611, 0.31476, 0.17571, 0.14038, 0.17222, 0.4069, 0.16874, 0.27014, 0.23985]
Predicted label: 0
Correct prediction
Energy consumption = 192.212056 pJ
sum error= 48
Actual label: 4
Output voltages: [0.2087, 0.18576, 0.38911, 0.067616, 0.74221, 0.053357, 0.3924, 0.19507, 0.25492, 0.25028]
Predicted label: 4
Correct prediction
Energy consumption = 192.329779 pJ
sum error= 48
Actual label: 3
Output voltages: [0.30738, 0.11544, 0.30768, 0.75035, 0.26366, 0.21942, 0.16717, 0.19732, 0.45835, 0.21669]
Predicted label: 3
Correct prediction
Energy consumption = 180.006168 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 149 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 149 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 149 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35889, 0.17338, 0.31248, 0.7549, 0.18113, 0.17439, 0.23298, 0.20195, 0.43045, 0.19041]
Predicted label: 3
Correct prediction
Energy consumption = 186.117005 pJ
sum error= 48
Actual label: 6
Output voltages: [0.24476, 0.20199, 0.33817, 0.070339, 0.40181, 0.30394, 0.74544, 0.05387, 0.38495, 0.1298]
Predicted label: 6
Correct prediction
Energy consumption = 188.136724 pJ
sum error= 48
Actual label: 9
Output voltages: [0.29021, 0.089353, 0.17131, 0.29526, 0.23643, 0.17739, 0.045322, 0.37187, 0.34154, 0.64941]
Predicted label: 9
Correct prediction
Energy consumption = 201.756817 pJ
sum error= 48
Actual label: 5
Output voltages: [0.20154, 0.081602, 0.10374, 0.30145, 0.24215, 0.66072, 0.2319, 0.12213, 0.48448, 0.2996]
Predicted label: 5
Correct prediction
Energy consumption = 184.985627 pJ
sum error= 48
Actual label: 7
Output voltages: [0.62599, 0.18554, 0.25012, 0.1194, 0.14709, 0.096182, 0.16092, 0.50096, 0.41385, 0.31398]
Predicted label: 0
Wrong prediction!
Energy consumption = 200.800242 pJ
sum error= 49
Actual label: 3
Output voltages: [0.37526, 0.33921, 0.33321, 0.74639, 0.097808, 0.26669, 0.24206, 0.23256, 0.28275, 0.16107]
Predicted label: 3
Correct prediction
Energy consumption = 206.119383 pJ
sum error= 49
Actual label: 7
Output voltages: [0.34271, 0.29303, 0.30784, 0.19058, 0.15413, 0.044096, 0.053342, 0.71067, 0.26045, 0.41831]
Predicted label: 7
Correct prediction
Energy consumption = 205.481110 pJ
sum error= 49
Actual label: 7
Output voltages: [0.42008, 0.22854, 0.28268, 0.26022, 0.16963, 0.076034, 0.048608, 0.74692, 0.3698, 0.27694]
Predicted label: 7
Correct prediction
Energy consumption = 188.665702 pJ
sum error= 49
Actual label: 7
Output voltages: [0.30644, 0.30689, 0.26178, 0.27654, 0.153, 0.080576, 0.037087, 0.74918, 0.30485, 0.22071]
Predicted label: 7
Correct prediction
Energy consumption = 188.639239 pJ
sum error= 49
Actual label: 8
Output voltages: [0.35011, 0.17933, 0.28334, 0.31622, 0.11323, 0.39061, 0.15843, 0.2162, 0.74605, 0.20746]
Predicted label: 8
Correct prediction
Energy consumption = 182.853413 pJ
sum error= 49
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 150 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 150 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 150 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37994, 0.33704, 0.41179, 0.62762, 0.10965, 0.036315, 0.070412, 0.38646, 0.38256, 0.29939]
Predicted label: 3
Wrong prediction!
Energy consumption = 207.190992 pJ
sum error= 50
Actual label: 9
Output voltages: [0.36931, 0.095535, 0.29726, 0.27538, 0.35118, 0.16535, 0.2161, 0.16027, 0.26232, 0.70315]
Predicted label: 9
Correct prediction
Energy consumption = 197.862912 pJ
sum error= 50
Actual label: 8
Output voltages: [0.28427, 0.22097, 0.21219, 0.3396, 0.11133, 0.28919, 0.29004, 0.07635, 0.70608, 0.258]
Predicted label: 8
Correct prediction
Energy consumption = 197.913565 pJ
sum error= 50
Actual label: 3
Output voltages: [0.37473, 0.19605, 0.25976, 0.75449, 0.19767, 0.31011, 0.19517, 0.19382, 0.39125, 0.30005]
Predicted label: 3
Correct prediction
Energy consumption = 190.229157 pJ
sum error= 50
Actual label: 0
Output voltages: [0.73851, 0.19825, 0.27099, 0.25187, 0.1429, 0.1811, 0.37312, 0.19182, 0.30614, 0.32615]
Predicted label: 0
Correct prediction
Energy consumption = 194.936338 pJ
sum error= 50
Actual label: 7
Output voltages: [0.41666, 0.36783, 0.48355, 0.35703, 0.083178, 0.027894, 0.11252, 0.52935, 0.24223, 0.33838]
Predicted label: 7
Correct prediction
Energy consumption = 203.530119 pJ
sum error= 50
Actual label: 2
Output voltages: [0.34161, 0.27811, 0.74353, 0.27382, 0.14644, 0.03081, 0.27267, 0.2521, 0.40061, 0.18312]
Predicted label: 2
Correct prediction
Energy consumption = 179.609585 pJ
sum error= 50
Actual label: 7
Output voltages: [0.34282, 0.34823, 0.46305, 0.29451, 0.093095, 0.031693, 0.058843, 0.68193, 0.27401, 0.34156]
Predicted label: 7
Correct prediction
Energy consumption = 192.435671 pJ
sum error= 50
Actual label: 9
Output voltages: [0.19353, 0.11805, 0.1909, 0.29692, 0.24784, 0.30045, 0.18914, 0.19383, 0.51794, 0.45616]
Predicted label: 8
Wrong prediction!
Energy consumption = 195.342337 pJ
sum error= 51
Actual label: 4
Output voltages: [0.12767, 0.11463, 0.27001, 0.14022, 0.56069, 0.12593, 0.23651, 0.24497, 0.51321, 0.31746]
Predicted label: 4
Correct prediction
Energy consumption = 194.051612 pJ
sum error= 51
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 151 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 151 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 151 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2193, 0.054893, 0.11588, 0.39759, 0.17729, 0.66268, 0.27087, 0.23542, 0.48864, 0.30716]
Predicted label: 5
Correct prediction
Energy consumption = 190.630033 pJ
sum error= 51
Actual label: 4
Output voltages: [0.11957, 0.18138, 0.26704, 0.056622, 0.7284, 0.12067, 0.27567, 0.18487, 0.39163, 0.20908]
Predicted label: 4
Correct prediction
Energy consumption = 191.067311 pJ
sum error= 51
Actual label: 9
Output voltages: [0.39553, 0.17569, 0.18706, 0.31955, 0.32544, 0.21026, 0.19851, 0.27543, 0.24003, 0.72309]
Predicted label: 9
Correct prediction
Energy consumption = 195.943829 pJ
sum error= 51
Actual label: 3
Output voltages: [0.30248, 0.15838, 0.24626, 0.74689, 0.20128, 0.3323, 0.21148, 0.19533, 0.43175, 0.15368]
Predicted label: 3
Correct prediction
Energy consumption = 190.236442 pJ
sum error= 51
Actual label: 2
Output voltages: [0.31922, 0.27356, 0.69601, 0.35249, 0.076899, 0.039894, 0.3026, 0.18791, 0.51982, 0.21937]
Predicted label: 2
Correct prediction
Energy consumption = 186.256582 pJ
sum error= 51
Actual label: 1
Output voltages: [0.22752, 0.75224, 0.26118, 0.26351, 0.24889, 0.064087, 0.36111, 0.12768, 0.37025, 0.20425]
Predicted label: 1
Correct prediction
Energy consumption = 206.819002 pJ
sum error= 51
Actual label: 4
Output voltages: [0.26114, 0.20208, 0.27329, 0.24573, 0.73007, 0.13845, 0.2683, 0.22314, 0.16248, 0.4433]
Predicted label: 4
Correct prediction
Energy consumption = 202.107202 pJ
sum error= 51
Actual label: 0
Output voltages: [0.72809, 0.26636, 0.23211, 0.17748, 0.1638, 0.22267, 0.44463, 0.16324, 0.2486, 0.31166]
Predicted label: 0
Correct prediction
Energy consumption = 198.486468 pJ
sum error= 51
Actual label: 2
Output voltages: [0.27551, 0.31462, 0.72799, 0.36929, 0.17645, 0.027392, 0.24205, 0.27888, 0.38248, 0.20648]
Predicted label: 2
Correct prediction
Energy consumption = 196.736567 pJ
sum error= 51
Actual label: 3
Output voltages: [0.38179, 0.19908, 0.28749, 0.76177, 0.16022, 0.2492, 0.15976, 0.14869, 0.4136, 0.20537]
Predicted label: 3
Correct prediction
Energy consumption = 180.125623 pJ
sum error= 51
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 152 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 152 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 152 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.39429, 0.085556, 0.40068, 0.14509, 0.088119, 0.1128, 0.059052, 0.66811, 0.54763, 0.26365]
Predicted label: 7
Correct prediction
Energy consumption = 190.287776 pJ
sum error= 51
Actual label: 5
Output voltages: [0.25971, 0.045404, 0.14827, 0.43729, 0.20197, 0.66499, 0.23016, 0.18894, 0.508, 0.30659]
Predicted label: 5
Correct prediction
Energy consumption = 192.842843 pJ
sum error= 51
Actual label: 7
Output voltages: [0.30338, 0.3617, 0.052808, 0.33724, 0.30161, 0.13246, 0.055884, 0.35683, 0.3064, 0.46378]
Predicted label: 9
Wrong prediction!
Energy consumption = 221.804566 pJ
sum error= 52
Actual label: 8
Output voltages: [0.18455, 0.12597, 0.24409, 0.24345, 0.22518, 0.39785, 0.3868, 0.13146, 0.6722, 0.19073]
Predicted label: 8
Correct prediction
Energy consumption = 199.245436 pJ
sum error= 52
Actual label: 8
Output voltages: [0.19103, 0.18791, 0.21491, 0.40629, 0.11066, 0.26182, 0.11485, 0.28338, 0.73778, 0.22558]
Predicted label: 8
Correct prediction
Energy consumption = 193.610819 pJ
sum error= 52
Actual label: 5
Output voltages: [0.49912, 0.081472, 0.16223, 0.34945, 0.066314, 0.6804, 0.2732, 0.18551, 0.42021, 0.19028]
Predicted label: 5
Correct prediction
Energy consumption = 195.656713 pJ
sum error= 52
Actual label: 0
Output voltages: [0.55147, 0.14328, 0.22238, 0.34439, 0.16567, 0.17588, 0.25418, 0.061265, 0.61163, 0.32434]
Predicted label: 8
Wrong prediction!
Energy consumption = 195.441171 pJ
sum error= 53
Actual label: 1
Output voltages: [0.20644, 0.4902, 0.31984, 0.31019, 0.17036, 0.33298, 0.50334, 0.058053, 0.26392, 0.14259]
Predicted label: 6
Wrong prediction!
Energy consumption = 202.427756 pJ
sum error= 54
Actual label: 1
Output voltages: [0.30712, 0.76292, 0.19724, 0.27857, 0.13524, 0.14372, 0.42644, 0.055932, 0.3544, 0.22787]
Predicted label: 1
Correct prediction
Energy consumption = 206.034538 pJ
sum error= 54
Actual label: 4
Output voltages: [0.16215, 0.16749, 0.30096, 0.073799, 0.73955, 0.13336, 0.36054, 0.18394, 0.3031, 0.32126]
Predicted label: 4
Correct prediction
Energy consumption = 195.383042 pJ
sum error= 54
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 153 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 153 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 153 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.25816, 0.22612, 0.18466, 0.30727, 0.052768, 0.31089, 0.063399, 0.43225, 0.66717, 0.31105]
Predicted label: 8
Correct prediction
Energy consumption = 198.391098 pJ
sum error= 54
Actual label: 3
Output voltages: [0.2634, 0.092968, 0.25108, 0.73956, 0.22151, 0.38008, 0.18008, 0.096975, 0.43183, 0.18469]
Predicted label: 3
Correct prediction
Energy consumption = 188.543370 pJ
sum error= 54
Actual label: 9
Output voltages: [0.31629, 0.13837, 0.21881, 0.23001, 0.32098, 0.10416, 0.070224, 0.15311, 0.41944, 0.65796]
Predicted label: 9
Correct prediction
Energy consumption = 190.014821 pJ
sum error= 54
Actual label: 0
Output voltages: [0.66212, 0.27028, 0.20515, 0.14803, 0.20375, 0.20579, 0.5236, 0.23858, 0.24824, 0.2159]
Predicted label: 0
Correct prediction
Energy consumption = 197.023695 pJ
sum error= 54
Actual label: 0
Output voltages: [0.62977, 0.2162, 0.26874, 0.14498, 0.2993, 0.083122, 0.49575, 0.17229, 0.30391, 0.18349]
Predicted label: 0
Correct prediction
Energy consumption = 196.911278 pJ
sum error= 54
Actual label: 0
Output voltages: [0.72423, 0.18791, 0.29539, 0.19619, 0.16804, 0.19966, 0.37744, 0.15986, 0.34449, 0.33008]
Predicted label: 0
Correct prediction
Energy consumption = 196.409356 pJ
sum error= 54
Actual label: 6
Output voltages: [0.24289, 0.1713, 0.41262, 0.13896, 0.18824, 0.36194, 0.69277, 0.057989, 0.48443, 0.18552]
Predicted label: 6
Correct prediction
Energy consumption = 189.015003 pJ
sum error= 54
Actual label: 6
Output voltages: [0.32024, 0.19092, 0.24523, 0.10388, 0.31314, 0.33471, 0.7247, 0.10993, 0.44918, 0.094661]
Predicted label: 6
Correct prediction
Energy consumption = 183.054190 pJ
sum error= 54
Actual label: 2
Output voltages: [0.29415, 0.31798, 0.5982, 0.42774, 0.23111, 0.030387, 0.20414, 0.22341, 0.41044, 0.20452]
Predicted label: 2
Correct prediction
Energy consumption = 195.507841 pJ
sum error= 54
Actual label: 3
Output voltages: [0.37632, 0.14348, 0.269, 0.75643, 0.19381, 0.24012, 0.17873, 0.19617, 0.38011, 0.20505]
Predicted label: 3
Correct prediction
Energy consumption = 183.367828 pJ
sum error= 54
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 154 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 154 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 154 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.36268, 0.22906, 0.16895, 0.29268, 0.20456, 0.16367, 0.054755, 0.75896, 0.23254, 0.30231]
Predicted label: 7
Correct prediction
Energy consumption = 196.091082 pJ
sum error= 54
Actual label: 8
Output voltages: [0.27939, 0.2178, 0.29518, 0.38521, 0.20086, 0.14009, 0.26386, 0.12563, 0.72023, 0.23982]
Predicted label: 8
Correct prediction
Energy consumption = 203.244413 pJ
sum error= 54
Actual label: 4
Output voltages: [0.21884, 0.12989, 0.33535, 0.12293, 0.75801, 0.11085, 0.26721, 0.25762, 0.22893, 0.29714]
Predicted label: 4
Correct prediction
Energy consumption = 202.387178 pJ
sum error= 54
Actual label: 7
Output voltages: [0.3287, 0.14523, 0.25738, 0.56675, 0.17678, 0.094749, 0.042705, 0.5795, 0.3617, 0.36089]
Predicted label: 7
Correct prediction
Energy consumption = 183.037129 pJ
sum error= 54
Actual label: 7
Output voltages: [0.28172, 0.29037, 0.24448, 0.31334, 0.11313, 0.13209, 0.044756, 0.75798, 0.37781, 0.35698]
Predicted label: 7
Correct prediction
Energy consumption = 194.647908 pJ
sum error= 54
Actual label: 9
Output voltages: [0.30612, 0.1057, 0.18286, 0.39007, 0.27869, 0.27804, 0.061687, 0.34781, 0.27401, 0.66583]
Predicted label: 9
Correct prediction
Energy consumption = 194.735885 pJ
sum error= 54
Actual label: 2
Output voltages: [0.35883, 0.12121, 0.58237, 0.45913, 0.13566, 0.044587, 0.23923, 0.18423, 0.51566, 0.24047]
Predicted label: 2
Correct prediction
Energy consumption = 195.332519 pJ
sum error= 54
Actual label: 4
Output voltages: [0.32028, 0.22994, 0.16794, 0.30032, 0.56172, 0.086406, 0.15322, 0.17477, 0.24282, 0.47]
Predicted label: 4
Correct prediction
Energy consumption = 206.941124 pJ
sum error= 54
Actual label: 1
Output voltages: [0.24753, 0.76269, 0.21355, 0.28663, 0.15682, 0.096754, 0.29157, 0.19507, 0.3188, 0.28707]
Predicted label: 1
Correct prediction
Energy consumption = 219.588255 pJ
sum error= 54
Actual label: 4
Output voltages: [0.29649, 0.31872, 0.40924, 0.074768, 0.38966, 0.1572, 0.5811, 0.11275, 0.39537, 0.076272]
Predicted label: 6
Wrong prediction!
Energy consumption = 191.853478 pJ
sum error= 55
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 155 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 155 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 155 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2371, 0.06488, 0.076531, 0.28462, 0.16974, 0.71906, 0.28034, 0.16109, 0.53416, 0.231]
Predicted label: 5
Correct prediction
Energy consumption = 196.692573 pJ
sum error= 55
Actual label: 2
Output voltages: [0.28539, 0.42301, 0.6048, 0.52552, 0.078802, 0.041523, 0.22126, 0.18801, 0.28584, 0.24495]
Predicted label: 2
Correct prediction
Energy consumption = 207.310555 pJ
sum error= 55
Actual label: 4
Output voltages: [0.12308, 0.19103, 0.22228, 0.11993, 0.72935, 0.09532, 0.29322, 0.3014, 0.23961, 0.33179]
Predicted label: 4
Correct prediction
Energy consumption = 202.396445 pJ
sum error= 55
Actual label: 9
Output voltages: [0.22811, 0.052661, 0.28536, 0.47021, 0.35841, 0.26713, 0.11849, 0.088645, 0.46371, 0.3817]
Predicted label: 3
Wrong prediction!
Energy consumption = 199.980494 pJ
sum error= 56
Actual label: 9
Output voltages: [0.17469, 0.2241, 0.17, 0.21242, 0.22894, 0.079113, 0.051324, 0.31719, 0.47758, 0.56792]
Predicted label: 9
Correct prediction
Energy consumption = 207.937385 pJ
sum error= 56
Actual label: 1
Output voltages: [0.19957, 0.757, 0.26942, 0.2201, 0.25536, 0.05941, 0.33943, 0.13127, 0.34596, 0.21286]
Predicted label: 1
Correct prediction
Energy consumption = 208.221070 pJ
sum error= 56
Actual label: 8
Output voltages: [0.26654, 0.17806, 0.34341, 0.17537, 0.20944, 0.12108, 0.20546, 0.13151, 0.72611, 0.36277]
Predicted label: 8
Correct prediction
Energy consumption = 192.190223 pJ
sum error= 56
Actual label: 4
Output voltages: [0.18144, 0.17738, 0.25579, 0.14146, 0.7406, 0.11008, 0.29951, 0.21501, 0.27223, 0.21717]
Predicted label: 4
Correct prediction
Energy consumption = 192.320599 pJ
sum error= 56
Actual label: 0
Output voltages: [0.71603, 0.2249, 0.18554, 0.19525, 0.16989, 0.18862, 0.38711, 0.22926, 0.39838, 0.31728]
Predicted label: 0
Correct prediction
Energy consumption = 206.195755 pJ
sum error= 56
Actual label: 9
Output voltages: [0.26254, 0.16905, 0.1552, 0.58821, 0.241, 0.31316, 0.10272, 0.18104, 0.33244, 0.47359]
Predicted label: 3
Wrong prediction!
Energy consumption = 203.064712 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 156 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 156 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 156 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26694, 0.21128, 0.31139, 0.32172, 0.13774, 0.16091, 0.31871, 0.065746, 0.71369, 0.28209]
Predicted label: 8
Correct prediction
Energy consumption = 194.573161 pJ
sum error= 57
Actual label: 4
Output voltages: [0.22244, 0.23171, 0.28596, 0.18894, 0.74584, 0.060613, 0.30647, 0.25513, 0.20608, 0.30569]
Predicted label: 4
Correct prediction
Energy consumption = 198.019113 pJ
sum error= 57
Actual label: 8
Output voltages: [0.49198, 0.11727, 0.39265, 0.30513, 0.21142, 0.17558, 0.32866, 0.12818, 0.61511, 0.23517]
Predicted label: 8
Correct prediction
Energy consumption = 208.117003 pJ
sum error= 57
Actual label: 7
Output voltages: [0.27868, 0.27581, 0.28566, 0.15355, 0.19766, 0.063247, 0.039344, 0.7469, 0.39218, 0.30301]
Predicted label: 7
Correct prediction
Energy consumption = 196.263763 pJ
sum error= 57
Actual label: 7
Output voltages: [0.35219, 0.26106, 0.18209, 0.29762, 0.15784, 0.088055, 0.036519, 0.74028, 0.31574, 0.38158]
Predicted label: 7
Correct prediction
Energy consumption = 192.442158 pJ
sum error= 57
Actual label: 0
Output voltages: [0.72077, 0.19752, 0.24041, 0.13949, 0.22683, 0.18748, 0.48037, 0.17619, 0.27567, 0.28218]
Predicted label: 0
Correct prediction
Energy consumption = 197.450272 pJ
sum error= 57
Actual label: 7
Output voltages: [0.29605, 0.28927, 0.21718, 0.29148, 0.18092, 0.066692, 0.039504, 0.58713, 0.2387, 0.5169]
Predicted label: 7
Correct prediction
Energy consumption = 203.324375 pJ
sum error= 57
Actual label: 8
Output voltages: [0.23805, 0.18765, 0.26788, 0.28261, 0.15462, 0.25526, 0.18688, 0.21869, 0.75076, 0.28024]
Predicted label: 8
Correct prediction
Energy consumption = 189.379221 pJ
sum error= 57
Actual label: 8
Output voltages: [0.22844, 0.15662, 0.27297, 0.31227, 0.11301, 0.27738, 0.20126, 0.090188, 0.73462, 0.26567]
Predicted label: 8
Correct prediction
Energy consumption = 192.123729 pJ
sum error= 57
Actual label: 6
Output voltages: [0.2822, 0.10521, 0.38339, 0.070529, 0.46663, 0.31875, 0.65235, 0.10052, 0.30944, 0.17287]
Predicted label: 6
Correct prediction
Energy consumption = 193.140897 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 157 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 157 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 157 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.51621, 0.26975, 0.3596, 0.13941, 0.29072, 0.060788, 0.4888, 0.15598, 0.36669, 0.17893]
Predicted label: 0
Correct prediction
Energy consumption = 201.942533 pJ
sum error= 57
Actual label: 4
Output voltages: [0.10174, 0.19787, 0.26556, 0.20122, 0.72206, 0.16492, 0.21028, 0.24567, 0.24231, 0.36656]
Predicted label: 4
Correct prediction
Energy consumption = 200.451922 pJ
sum error= 57
Actual label: 8
Output voltages: [0.21187, 0.21271, 0.29941, 0.27879, 0.16217, 0.13939, 0.16527, 0.13257, 0.7385, 0.33277]
Predicted label: 8
Correct prediction
Energy consumption = 200.339990 pJ
sum error= 57
Actual label: 8
Output voltages: [0.32948, 0.19035, 0.42966, 0.31003, 0.14291, 0.11393, 0.29376, 0.08227, 0.70858, 0.32586]
Predicted label: 8
Correct prediction
Energy consumption = 195.420429 pJ
sum error= 57
Actual label: 2
Output voltages: [0.34996, 0.26461, 0.75235, 0.25581, 0.1744, 0.031743, 0.32295, 0.25109, 0.38241, 0.17739]
Predicted label: 2
Correct prediction
Energy consumption = 184.746734 pJ
sum error= 57
Actual label: 4
Output voltages: [0.16446, 0.1865, 0.27536, 0.17321, 0.75461, 0.060878, 0.22418, 0.28119, 0.24764, 0.20902]
Predicted label: 4
Correct prediction
Energy consumption = 189.221962 pJ
sum error= 57
Actual label: 7
Output voltages: [0.40523, 0.33276, 0.33919, 0.40223, 0.078754, 0.037639, 0.066803, 0.66121, 0.26439, 0.31988]
Predicted label: 7
Correct prediction
Energy consumption = 199.168463 pJ
sum error= 57
Actual label: 6
Output voltages: [0.22434, 0.22642, 0.30865, 0.10654, 0.32331, 0.3785, 0.73843, 0.11647, 0.39511, 0.12683]
Predicted label: 6
Correct prediction
Energy consumption = 193.759200 pJ
sum error= 57
Actual label: 6
Output voltages: [0.26581, 0.24076, 0.27829, 0.16274, 0.26098, 0.39054, 0.74745, 0.10686, 0.38575, 0.16113]
Predicted label: 6
Correct prediction
Energy consumption = 187.215450 pJ
sum error= 57
Actual label: 6
Output voltages: [0.37148, 0.21875, 0.17976, 0.22848, 0.23423, 0.41746, 0.66193, 0.10395, 0.46988, 0.17206]
Predicted label: 6
Correct prediction
Energy consumption = 188.752469 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 158 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 158 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 158 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16148, 0.11469, 0.25967, 0.18772, 0.74225, 0.05146, 0.15778, 0.23164, 0.31431, 0.25514]
Predicted label: 4
Correct prediction
Energy consumption = 198.876141 pJ
sum error= 57
Actual label: 7
Output voltages: [0.30866, 0.12414, 0.38444, 0.44794, 0.15408, 0.069936, 0.037949, 0.49471, 0.43283, 0.45479]
Predicted label: 7
Correct prediction
Energy consumption = 188.420917 pJ
sum error= 57
Actual label: 1
Output voltages: [0.15731, 0.75818, 0.14975, 0.21688, 0.17209, 0.18408, 0.47547, 0.13437, 0.36151, 0.15033]
Predicted label: 1
Correct prediction
Energy consumption = 208.516828 pJ
sum error= 57
Actual label: 8
Output voltages: [0.27632, 0.22349, 0.27042, 0.34654, 0.11294, 0.14195, 0.22098, 0.17664, 0.72498, 0.29168]
Predicted label: 8
Correct prediction
Energy consumption = 197.067432 pJ
sum error= 57
Actual label: 8
Output voltages: [0.35984, 0.1924, 0.3024, 0.3758, 0.22503, 0.11987, 0.22168, 0.056151, 0.68756, 0.33507]
Predicted label: 8
Correct prediction
Energy consumption = 196.093130 pJ
sum error= 57
Actual label: 2
Output voltages: [0.3967, 0.24482, 0.73894, 0.34171, 0.17319, 0.031244, 0.22329, 0.30166, 0.36146, 0.20156]
Predicted label: 2
Correct prediction
Energy consumption = 182.871953 pJ
sum error= 57
Actual label: 3
Output voltages: [0.37432, 0.23647, 0.29838, 0.7591, 0.1508, 0.12533, 0.12106, 0.22478, 0.40693, 0.28214]
Predicted label: 3
Correct prediction
Energy consumption = 188.584898 pJ
sum error= 57
Actual label: 6
Output voltages: [0.31989, 0.082523, 0.20891, 0.21032, 0.29859, 0.40786, 0.65323, 0.042984, 0.44027, 0.27806]
Predicted label: 6
Correct prediction
Energy consumption = 187.423604 pJ
sum error= 57
Actual label: 3
Output voltages: [0.38296, 0.18692, 0.32113, 0.7588, 0.23197, 0.20609, 0.18052, 0.21252, 0.41847, 0.19417]
Predicted label: 3
Correct prediction
Energy consumption = 180.831430 pJ
sum error= 57
Actual label: 0
Output voltages: [0.62721, 0.22386, 0.39539, 0.13128, 0.070896, 0.17917, 0.43239, 0.10296, 0.30775, 0.3308]
Predicted label: 0
Correct prediction
Energy consumption = 187.175674 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 159 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 159 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 159 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.67576, 0.21415, 0.28928, 0.21693, 0.2327, 0.070104, 0.35088, 0.15398, 0.4439, 0.25389]
Predicted label: 0
Correct prediction
Energy consumption = 195.830263 pJ
sum error= 57
Actual label: 3
Output voltages: [0.30678, 0.23957, 0.33769, 0.74302, 0.12703, 0.093244, 0.16979, 0.15778, 0.54662, 0.17292]
Predicted label: 3
Correct prediction
Energy consumption = 194.415405 pJ
sum error= 57
Actual label: 7
Output voltages: [0.33925, 0.34347, 0.3074, 0.3995, 0.075396, 0.053098, 0.053449, 0.74056, 0.38784, 0.2533]
Predicted label: 7
Correct prediction
Energy consumption = 195.336687 pJ
sum error= 57
Actual label: 6
Output voltages: [0.33761, 0.2661, 0.29708, 0.074668, 0.31689, 0.33773, 0.73011, 0.13946, 0.44221, 0.068033]
Predicted label: 6
Correct prediction
Energy consumption = 195.129096 pJ
sum error= 57
Actual label: 9
Output voltages: [0.26563, 0.15087, 0.25243, 0.248, 0.48581, 0.13512, 0.14587, 0.17238, 0.2968, 0.59863]
Predicted label: 9
Correct prediction
Energy consumption = 200.772125 pJ
sum error= 57
Actual label: 7
Output voltages: [0.36784, 0.26113, 0.41824, 0.44519, 0.067095, 0.03605, 0.085883, 0.65032, 0.3529, 0.28117]
Predicted label: 7
Correct prediction
Energy consumption = 197.092493 pJ
sum error= 57
Actual label: 9
Output voltages: [0.36847, 0.17053, 0.20858, 0.25536, 0.34237, 0.09415, 0.18482, 0.28181, 0.29318, 0.66453]
Predicted label: 9
Correct prediction
Energy consumption = 201.005917 pJ
sum error= 57
Actual label: 9
Output voltages: [0.30328, 0.18698, 0.22719, 0.23314, 0.26156, 0.10166, 0.058115, 0.24489, 0.4493, 0.63244]
Predicted label: 9
Correct prediction
Energy consumption = 192.970107 pJ
sum error= 57
Actual label: 5
Output voltages: [0.25505, 0.054652, 0.13564, 0.3836, 0.16651, 0.68021, 0.21625, 0.1529, 0.56715, 0.25989]
Predicted label: 5
Correct prediction
Energy consumption = 185.330931 pJ
sum error= 57
Actual label: 4
Output voltages: [0.1776, 0.11078, 0.26665, 0.13413, 0.67217, 0.15629, 0.24593, 0.2686, 0.32728, 0.41665]
Predicted label: 4
Correct prediction
Energy consumption = 193.584466 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 160 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 160 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 160 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23725, 0.056627, 0.2527, 0.68088, 0.21881, 0.44489, 0.13702, 0.14816, 0.46363, 0.19197]
Predicted label: 3
Correct prediction
Energy consumption = 184.272984 pJ
sum error= 57
Actual label: 3
Output voltages: [0.34346, 0.048776, 0.41463, 0.59729, 0.072647, 0.20489, 0.090701, 0.35454, 0.57479, 0.18672]
Predicted label: 3
Correct prediction
Energy consumption = 186.166980 pJ
sum error= 57
Actual label: 6
Output voltages: [0.2995, 0.19706, 0.18395, 0.21179, 0.28275, 0.4472, 0.69837, 0.10328, 0.43238, 0.10977]
Predicted label: 6
Correct prediction
Energy consumption = 198.491994 pJ
sum error= 57
Actual label: 1
Output voltages: [0.19227, 0.7587, 0.22251, 0.31032, 0.13616, 0.15925, 0.35975, 0.13186, 0.36628, 0.24556]
Predicted label: 1
Correct prediction
Energy consumption = 205.106684 pJ
sum error= 57
Actual label: 2
Output voltages: [0.4377, 0.23399, 0.67822, 0.40215, 0.12965, 0.035328, 0.29404, 0.17702, 0.47603, 0.17213]
Predicted label: 2
Correct prediction
Energy consumption = 189.757430 pJ
sum error= 57
Actual label: 3
Output voltages: [0.27684, 0.20126, 0.36657, 0.75019, 0.20815, 0.12054, 0.15778, 0.12774, 0.4545, 0.23818]
Predicted label: 3
Correct prediction
Energy consumption = 182.994871 pJ
sum error= 57
Actual label: 7
Output voltages: [0.25636, 0.27261, 0.28463, 0.22524, 0.15926, 0.13965, 0.04545, 0.74397, 0.32905, 0.3567]
Predicted label: 7
Correct prediction
Energy consumption = 200.826997 pJ
sum error= 57
Actual label: 3
Output voltages: [0.22207, 0.28279, 0.26169, 0.75731, 0.18939, 0.21813, 0.15193, 0.13683, 0.37569, 0.34401]
Predicted label: 3
Correct prediction
Energy consumption = 195.685426 pJ
sum error= 57
Actual label: 3
Output voltages: [0.33386, 0.17285, 0.2701, 0.76202, 0.18313, 0.21855, 0.23031, 0.1802, 0.39859, 0.24305]
Predicted label: 3
Correct prediction
Energy consumption = 177.054256 pJ
sum error= 57
Actual label: 2
Output voltages: [0.40605, 0.061762, 0.60206, 0.33437, 0.28576, 0.049669, 0.32913, 0.21345, 0.4371, 0.18327]
Predicted label: 2
Correct prediction
Energy consumption = 189.989188 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 161 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 161 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 161 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7103, 0.22147, 0.24686, 0.1744, 0.13375, 0.24974, 0.4166, 0.16729, 0.34805, 0.29253]
Predicted label: 0
Correct prediction
Energy consumption = 203.080895 pJ
sum error= 57
Actual label: 3
Output voltages: [0.43847, 0.14237, 0.18134, 0.66289, 0.12118, 0.36981, 0.38586, 0.089033, 0.44714, 0.12135]
Predicted label: 3
Correct prediction
Energy consumption = 198.420880 pJ
sum error= 57
Actual label: 3
Output voltages: [0.30978, 0.18309, 0.19994, 0.7378, 0.10632, 0.42225, 0.096615, 0.28387, 0.43978, 0.14325]
Predicted label: 3
Correct prediction
Energy consumption = 182.891847 pJ
sum error= 57
Actual label: 8
Output voltages: [0.21651, 0.19882, 0.29161, 0.22419, 0.15855, 0.18394, 0.17298, 0.13809, 0.72958, 0.36078]
Predicted label: 8
Correct prediction
Energy consumption = 193.988417 pJ
sum error= 57
Actual label: 4
Output voltages: [0.31183, 0.19096, 0.27525, 0.2464, 0.66964, 0.058018, 0.38182, 0.18872, 0.16439, 0.41529]
Predicted label: 4
Correct prediction
Energy consumption = 200.251815 pJ
sum error= 57
Actual label: 3
Output voltages: [0.33645, 0.23808, 0.38668, 0.7474, 0.24531, 0.13061, 0.11858, 0.17957, 0.39035, 0.16182]
Predicted label: 3
Correct prediction
Energy consumption = 189.874863 pJ
sum error= 57
Actual label: 6
Output voltages: [0.32182, 0.16213, 0.33142, 0.11403, 0.31351, 0.32414, 0.72598, 0.063702, 0.42638, 0.19737]
Predicted label: 6
Correct prediction
Energy consumption = 186.151231 pJ
sum error= 57
Actual label: 3
Output voltages: [0.30422, 0.13132, 0.45266, 0.68199, 0.14661, 0.13226, 0.13171, 0.14999, 0.50157, 0.19717]
Predicted label: 3
Correct prediction
Energy consumption = 191.702722 pJ
sum error= 57
Actual label: 5
Output voltages: [0.22343, 0.11888, 0.062319, 0.39665, 0.23198, 0.71348, 0.18092, 0.16808, 0.51832, 0.15259]
Predicted label: 5
Correct prediction
Energy consumption = 188.276962 pJ
sum error= 57
Actual label: 0
Output voltages: [0.7152, 0.16512, 0.22096, 0.22677, 0.21873, 0.20003, 0.37634, 0.13248, 0.33483, 0.33339]
Predicted label: 0
Correct prediction
Energy consumption = 197.651947 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 162 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 162 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 162 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.38663, 0.19881, 0.6139, 0.4792, 0.16304, 0.034339, 0.25529, 0.19512, 0.52543, 0.22079]
Predicted label: 2
Correct prediction
Energy consumption = 187.030903 pJ
sum error= 57
Actual label: 0
Output voltages: [0.53764, 0.20985, 0.22932, 0.086935, 0.26249, 0.30298, 0.66346, 0.14671, 0.27576, 0.17109]
Predicted label: 6
Wrong prediction!
Energy consumption = 197.441388 pJ
sum error= 58
Actual label: 9
Output voltages: [0.39321, 0.11402, 0.21145, 0.27563, 0.34189, 0.20263, 0.080578, 0.28912, 0.30025, 0.69017]
Predicted label: 9
Correct prediction
Energy consumption = 193.765451 pJ
sum error= 58
Actual label: 0
Output voltages: [0.73058, 0.285, 0.28108, 0.16864, 0.11895, 0.16047, 0.35939, 0.17145, 0.30195, 0.29438]
Predicted label: 0
Correct prediction
Energy consumption = 191.020279 pJ
sum error= 58
Actual label: 7
Output voltages: [0.26636, 0.3167, 0.25947, 0.17131, 0.092525, 0.047334, 0.047713, 0.7179, 0.40458, 0.4091]
Predicted label: 7
Correct prediction
Energy consumption = 196.003180 pJ
sum error= 58
Actual label: 4
Output voltages: [0.18989, 0.13548, 0.32911, 0.20969, 0.75859, 0.097763, 0.2757, 0.29176, 0.2142, 0.29161]
Predicted label: 4
Correct prediction
Energy consumption = 201.581576 pJ
sum error= 58
Actual label: 6
Output voltages: [0.3016, 0.11544, 0.17512, 0.27386, 0.32119, 0.3614, 0.64455, 0.042172, 0.49538, 0.26968]
Predicted label: 6
Correct prediction
Energy consumption = 190.867898 pJ
sum error= 58
Actual label: 9
Output voltages: [0.46624, 0.077028, 0.38213, 0.21557, 0.29617, 0.14837, 0.22611, 0.22754, 0.27584, 0.64397]
Predicted label: 9
Correct prediction
Energy consumption = 201.879683 pJ
sum error= 58
Actual label: 3
Output voltages: [0.30055, 0.079268, 0.26475, 0.75191, 0.19826, 0.3453, 0.19925, 0.15961, 0.38834, 0.21489]
Predicted label: 3
Correct prediction
Energy consumption = 188.027232 pJ
sum error= 58
Actual label: 5
Output voltages: [0.211, 0.058547, 0.10945, 0.35413, 0.21475, 0.6904, 0.25866, 0.084132, 0.54774, 0.24203]
Predicted label: 5
Correct prediction
Energy consumption = 182.508391 pJ
sum error= 58
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 163 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 163 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 163 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.2301, 0.75791, 0.33951, 0.22298, 0.18545, 0.057361, 0.40199, 0.1413, 0.29797, 0.19607]
Predicted label: 1
Correct prediction
Energy consumption = 213.640379 pJ
sum error= 58
Actual label: 9
Output voltages: [0.37625, 0.12622, 0.19658, 0.22274, 0.27027, 0.2194, 0.10112, 0.25732, 0.41128, 0.65044]
Predicted label: 9
Correct prediction
Energy consumption = 198.253261 pJ
sum error= 58
Actual label: 6
Output voltages: [0.31861, 0.19711, 0.28922, 0.10044, 0.36711, 0.29834, 0.73635, 0.10018, 0.36342, 0.10334]
Predicted label: 6
Correct prediction
Energy consumption = 193.328025 pJ
sum error= 58
Actual label: 1
Output voltages: [0.16979, 0.75509, 0.31805, 0.21855, 0.1638, 0.095929, 0.39985, 0.10265, 0.39138, 0.211]
Predicted label: 1
Correct prediction
Energy consumption = 208.445871 pJ
sum error= 58
Actual label: 4
Output voltages: [0.065713, 0.3085, 0.15904, 0.11774, 0.62919, 0.087518, 0.14008, 0.1935, 0.4136, 0.30398]
Predicted label: 4
Correct prediction
Energy consumption = 203.342488 pJ
sum error= 58
Actual label: 5
Output voltages: [0.27131, 0.095317, 0.052497, 0.33268, 0.30201, 0.71804, 0.41928, 0.05243, 0.43117, 0.18255]
Predicted label: 5
Correct prediction
Energy consumption = 196.256334 pJ
sum error= 58
Actual label: 4
Output voltages: [0.11705, 0.17655, 0.32812, 0.23364, 0.74708, 0.075001, 0.18697, 0.37602, 0.2162, 0.15267]
Predicted label: 4
Correct prediction
Energy consumption = 190.013127 pJ
sum error= 58
Actual label: 5
Output voltages: [0.2425, 0.064264, 0.055374, 0.46759, 0.31908, 0.62501, 0.38844, 0.060338, 0.39978, 0.26018]
Predicted label: 5
Correct prediction
Energy consumption = 194.007874 pJ
sum error= 58
Actual label: 0
Output voltages: [0.6484, 0.19654, 0.29165, 0.17865, 0.17914, 0.063347, 0.37286, 0.18056, 0.39337, 0.27117]
Predicted label: 0
Correct prediction
Energy consumption = 205.995929 pJ
sum error= 58
Actual label: 5
Output voltages: [0.20597, 0.054259, 0.099563, 0.42719, 0.23645, 0.67818, 0.27633, 0.17028, 0.49378, 0.24157]
Predicted label: 5
Correct prediction
Energy consumption = 186.380147 pJ
sum error= 58
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 164 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 164 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 164 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.40846, 0.055405, 0.21201, 0.24225, 0.31823, 0.24391, 0.06856, 0.40206, 0.38957, 0.60971]
Predicted label: 9
Correct prediction
Energy consumption = 197.884106 pJ
sum error= 58
Actual label: 5
Output voltages: [0.27229, 0.053161, 0.19498, 0.26155, 0.2008, 0.53985, 0.40123, 0.21124, 0.46834, 0.19252]
Predicted label: 5
Correct prediction
Energy consumption = 195.197461 pJ
sum error= 58
Actual label: 2
Output voltages: [0.32287, 0.21089, 0.73724, 0.30627, 0.22295, 0.047795, 0.33663, 0.21709, 0.39498, 0.20868]
Predicted label: 2
Correct prediction
Energy consumption = 198.501612 pJ
sum error= 58
Actual label: 1
Output voltages: [0.23958, 0.76196, 0.35091, 0.23926, 0.19652, 0.052872, 0.39544, 0.1069, 0.30523, 0.21538]
Predicted label: 1
Correct prediction
Energy consumption = 205.710075 pJ
sum error= 58
Actual label: 2
Output voltages: [0.36084, 0.32287, 0.70787, 0.36101, 0.13687, 0.027383, 0.3365, 0.19092, 0.39858, 0.20381]
Predicted label: 2
Correct prediction
Energy consumption = 190.735608 pJ
sum error= 58
Actual label: 9
Output voltages: [0.42839, 0.10671, 0.24723, 0.27461, 0.30419, 0.22165, 0.15672, 0.29514, 0.27738, 0.70135]
Predicted label: 9
Correct prediction
Energy consumption = 204.139300 pJ
sum error= 58
Actual label: 1
Output voltages: [0.22175, 0.74095, 0.23848, 0.12161, 0.4421, 0.091468, 0.36907, 0.11697, 0.2355, 0.31573]
Predicted label: 1
Correct prediction
Energy consumption = 204.259239 pJ
sum error= 58
Actual label: 9
Output voltages: [0.37991, 0.1488, 0.19729, 0.20307, 0.42746, 0.19433, 0.12476, 0.14757, 0.30392, 0.6902]
Predicted label: 9
Correct prediction
Energy consumption = 191.194866 pJ
sum error= 58
Actual label: 9
Output voltages: [0.31476, 0.10676, 0.15712, 0.27684, 0.26569, 0.13478, 0.058288, 0.28308, 0.41888, 0.68703]
Predicted label: 9
Correct prediction
Energy consumption = 185.421550 pJ
sum error= 58
Actual label: 4
Output voltages: [0.20594, 0.076289, 0.34841, 0.17801, 0.7392, 0.063741, 0.2642, 0.279, 0.30341, 0.23984]
Predicted label: 4
Correct prediction
Energy consumption = 198.014189 pJ
sum error= 58
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 165 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 165 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 165 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.63013, 0.26593, 0.40851, 0.20806, 0.073715, 0.092872, 0.4594, 0.15163, 0.41871, 0.26278]
Predicted label: 0
Correct prediction
Energy consumption = 200.022541 pJ
sum error= 58
Actual label: 8
Output voltages: [0.2, 0.26654, 0.30335, 0.26603, 0.16326, 0.16468, 0.1976, 0.15171, 0.74599, 0.31134]
Predicted label: 8
Correct prediction
Energy consumption = 191.591177 pJ
sum error= 58
Actual label: 4
Output voltages: [0.21723, 0.092001, 0.29686, 0.20503, 0.75166, 0.16086, 0.28126, 0.2251, 0.19393, 0.34707]
Predicted label: 4
Correct prediction
Energy consumption = 196.449083 pJ
sum error= 58
Actual label: 5
Output voltages: [0.27702, 0.048855, 0.054234, 0.38474, 0.23847, 0.68854, 0.23633, 0.2289, 0.46776, 0.32266]
Predicted label: 5
Correct prediction
Energy consumption = 187.509013 pJ
sum error= 58
Actual label: 2
Output voltages: [0.27856, 0.26566, 0.73591, 0.34754, 0.16649, 0.045334, 0.19595, 0.36842, 0.3324, 0.25015]
Predicted label: 2
Correct prediction
Energy consumption = 204.949057 pJ
sum error= 58
Actual label: 9
Output voltages: [0.40385, 0.082072, 0.17423, 0.19794, 0.31367, 0.23659, 0.14775, 0.22834, 0.3958, 0.63574]
Predicted label: 9
Correct prediction
Energy consumption = 193.480343 pJ
sum error= 58
Actual label: 2
Output voltages: [0.35452, 0.30645, 0.72931, 0.36725, 0.14498, 0.035175, 0.31859, 0.1847, 0.40442, 0.21243]
Predicted label: 2
Correct prediction
Energy consumption = 188.254796 pJ
sum error= 58
Actual label: 1
Output voltages: [0.15203, 0.7641, 0.20186, 0.27946, 0.25392, 0.14295, 0.47493, 0.10836, 0.28656, 0.20886]
Predicted label: 1
Correct prediction
Energy consumption = 210.749092 pJ
sum error= 58
Actual label: 2
Output voltages: [0.31576, 0.45108, 0.72159, 0.29603, 0.16117, 0.02441, 0.26198, 0.20761, 0.26198, 0.20685]
Predicted label: 2
Correct prediction
Energy consumption = 189.029293 pJ
sum error= 58
Actual label: 1
Output voltages: [0.20253, 0.76566, 0.17221, 0.24224, 0.32628, 0.090053, 0.36285, 0.16927, 0.26028, 0.26615]
Predicted label: 1
Correct prediction
Energy consumption = 204.108964 pJ
sum error= 58
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 166 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 166 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 166 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34302, 0.35665, 0.44643, 0.32672, 0.1193, 0.037893, 0.045326, 0.69114, 0.29826, 0.35251]
Predicted label: 7
Correct prediction
Energy consumption = 194.111073 pJ
sum error= 58
Actual label: 3
Output voltages: [0.33524, 0.16846, 0.3987, 0.73017, 0.17493, 0.07006, 0.15163, 0.11447, 0.47466, 0.28138]
Predicted label: 3
Correct prediction
Energy consumption = 182.707793 pJ
sum error= 58
Actual label: 6
Output voltages: [0.28629, 0.17692, 0.28589, 0.12892, 0.33753, 0.40649, 0.73037, 0.062293, 0.41692, 0.10997]
Predicted label: 6
Correct prediction
Energy consumption = 187.382878 pJ
sum error= 58
Actual label: 8
Output voltages: [0.21699, 0.18313, 0.24717, 0.28451, 0.16233, 0.25422, 0.12776, 0.23845, 0.74655, 0.28293]
Predicted label: 8
Correct prediction
Energy consumption = 198.655679 pJ
sum error= 58
Actual label: 8
Output voltages: [0.25717, 0.24558, 0.34586, 0.30414, 0.15272, 0.16906, 0.2941, 0.1412, 0.73411, 0.27494]
Predicted label: 8
Correct prediction
Energy consumption = 194.957104 pJ
sum error= 58
Actual label: 4
Output voltages: [0.15415, 0.20318, 0.29946, 0.15294, 0.7542, 0.15736, 0.30451, 0.2232, 0.23036, 0.34356]
Predicted label: 4
Correct prediction
Energy consumption = 203.901746 pJ
sum error= 58
Actual label: 9
Output voltages: [0.33141, 0.16991, 0.21707, 0.27882, 0.36039, 0.17821, 0.19417, 0.19398, 0.31671, 0.7233]
Predicted label: 9
Correct prediction
Energy consumption = 193.263659 pJ
sum error= 58
Actual label: 1
Output voltages: [0.23375, 0.75104, 0.36645, 0.30212, 0.25149, 0.054646, 0.32503, 0.093899, 0.30726, 0.22308]
Predicted label: 1
Correct prediction
Energy consumption = 208.608513 pJ
sum error= 58
Actual label: 9
Output voltages: [0.29326, 0.11964, 0.23664, 0.32983, 0.25677, 0.11806, 0.063577, 0.29301, 0.37166, 0.64654]
Predicted label: 9
Correct prediction
Energy consumption = 198.654653 pJ
sum error= 58
Actual label: 8
Output voltages: [0.19366, 0.18781, 0.24798, 0.34796, 0.097072, 0.23678, 0.15077, 0.13575, 0.74314, 0.31603]
Predicted label: 8
Correct prediction
Energy consumption = 187.281964 pJ
sum error= 58
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 167 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 167 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 167 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.31321, 0.062805, 0.10126, 0.32509, 0.2265, 0.63041, 0.24728, 0.091603, 0.56042, 0.26665]
Predicted label: 5
Correct prediction
Energy consumption = 190.613189 pJ
sum error= 58
Actual label: 7
Output voltages: [0.13791, 0.12777, 0.22059, 0.48492, 0.17975, 0.2393, 0.046193, 0.53766, 0.37809, 0.45314]
Predicted label: 7
Correct prediction
Energy consumption = 197.265883 pJ
sum error= 58
Actual label: 5
Output voltages: [0.21726, 0.10945, 0.094022, 0.34975, 0.20323, 0.68405, 0.23316, 0.13649, 0.49404, 0.29397]
Predicted label: 5
Correct prediction
Energy consumption = 187.374244 pJ
sum error= 58
Actual label: 1
Output voltages: [0.24634, 0.73396, 0.22403, 0.29073, 0.26846, 0.041279, 0.19649, 0.30431, 0.26229, 0.36231]
Predicted label: 1
Correct prediction
Energy consumption = 216.713300 pJ
sum error= 58
Actual label: 1
Output voltages: [0.21188, 0.76789, 0.2437, 0.39313, 0.096206, 0.15081, 0.30485, 0.14759, 0.2935, 0.25149]
Predicted label: 1
Correct prediction
Energy consumption = 206.122913 pJ
sum error= 58
Actual label: 8
Output voltages: [0.24906, 0.19289, 0.29402, 0.35701, 0.12326, 0.27179, 0.21483, 0.12347, 0.74635, 0.25131]
Predicted label: 8
Correct prediction
Energy consumption = 194.294472 pJ
sum error= 58
Actual label: 6
Output voltages: [0.32313, 0.059736, 0.11672, 0.26882, 0.32285, 0.57637, 0.58955, 0.050472, 0.45664, 0.25074]
Predicted label: 6
Correct prediction
Energy consumption = 193.690841 pJ
sum error= 58
Actual label: 5
Output voltages: [0.26381, 0.12346, 0.079694, 0.33483, 0.18928, 0.66876, 0.28147, 0.083344, 0.5043, 0.24364]
Predicted label: 5
Correct prediction
Energy consumption = 185.409719 pJ
sum error= 58
Actual label: 2
Output voltages: [0.60828, 0.43168, 0.40917, 0.077891, 0.26765, 0.043275, 0.27108, 0.34682, 0.23263, 0.33909]
Predicted label: 0
Wrong prediction!
Energy consumption = 208.396256 pJ
sum error= 59
Actual label: 4
Output voltages: [0.1107, 0.19944, 0.28503, 0.087957, 0.74475, 0.095779, 0.23847, 0.27218, 0.29032, 0.33171]
Predicted label: 4
Correct prediction
Energy consumption = 195.747411 pJ
sum error= 59
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 168 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 168 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 168 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13767, 0.13228, 0.26799, 0.23881, 0.73302, 0.07739, 0.13679, 0.2347, 0.27474, 0.27399]
Predicted label: 4
Correct prediction
Energy consumption = 193.034395 pJ
sum error= 59
Actual label: 3
Output voltages: [0.24333, 0.25536, 0.35245, 0.53671, 0.050944, 0.096733, 0.066102, 0.6346, 0.39661, 0.35313]
Predicted label: 7
Wrong prediction!
Energy consumption = 188.990128 pJ
sum error= 60
Actual label: 2
Output voltages: [0.48518, 0.27446, 0.67984, 0.45535, 0.070974, 0.060944, 0.30453, 0.24064, 0.30756, 0.24764]
Predicted label: 2
Correct prediction
Energy consumption = 194.970518 pJ
sum error= 60
Actual label: 3
Output voltages: [0.3558, 0.193, 0.29596, 0.76193, 0.15312, 0.11404, 0.14657, 0.19202, 0.43054, 0.2288]
Predicted label: 3
Correct prediction
Energy consumption = 176.971630 pJ
sum error= 60
Actual label: 5
Output voltages: [0.31848, 0.24231, 0.057353, 0.42984, 0.1215, 0.7294, 0.24964, 0.071621, 0.44874, 0.24136]
Predicted label: 5
Correct prediction
Energy consumption = 199.281211 pJ
sum error= 60
Actual label: 6
Output voltages: [0.26718, 0.23618, 0.26278, 0.15824, 0.30702, 0.41425, 0.74538, 0.10555, 0.40001, 0.13162]
Predicted label: 6
Correct prediction
Energy consumption = 187.061215 pJ
sum error= 60
Actual label: 8
Output voltages: [0.27273, 0.15256, 0.28184, 0.20024, 0.15442, 0.37866, 0.48153, 0.12898, 0.59554, 0.10413]
Predicted label: 8
Correct prediction
Energy consumption = 198.850831 pJ
sum error= 60
Actual label: 8
Output voltages: [0.25182, 0.35794, 0.2494, 0.24533, 0.18343, 0.11172, 0.24575, 0.081772, 0.73308, 0.38374]
Predicted label: 8
Correct prediction
Energy consumption = 195.747815 pJ
sum error= 60
Actual label: 6
Output voltages: [0.31376, 0.21217, 0.18256, 0.15523, 0.30733, 0.41974, 0.72588, 0.16363, 0.48595, 0.10395]
Predicted label: 6
Correct prediction
Energy consumption = 196.809413 pJ
sum error= 60
Actual label: 2
Output voltages: [0.35766, 0.21942, 0.68903, 0.35528, 0.15725, 0.032389, 0.28226, 0.32948, 0.39126, 0.16012]
Predicted label: 2
Correct prediction
Energy consumption = 197.557595 pJ
sum error= 60
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 169 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 169 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 169 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.31256, 0.19886, 0.26364, 0.75776, 0.15362, 0.26921, 0.13924, 0.22543, 0.34268, 0.26416]
Predicted label: 3
Correct prediction
Energy consumption = 188.843004 pJ
sum error= 60
Actual label: 1
Output voltages: [0.22112, 0.66576, 0.30912, 0.26635, 0.089231, 0.076267, 0.27354, 0.22756, 0.46903, 0.17323]
Predicted label: 1
Correct prediction
Energy consumption = 207.615519 pJ
sum error= 60
Actual label: 0
Output voltages: [0.69259, 0.28167, 0.4076, 0.14756, 0.070092, 0.15741, 0.36292, 0.15397, 0.27438, 0.30211]
Predicted label: 0
Correct prediction
Energy consumption = 200.934210 pJ
sum error= 60
Actual label: 5
Output voltages: [0.19311, 0.092276, 0.072671, 0.47653, 0.15757, 0.65461, 0.22123, 0.13545, 0.48943, 0.23522]
Predicted label: 5
Correct prediction
Energy consumption = 192.781204 pJ
sum error= 60
Actual label: 8
Output voltages: [0.28451, 0.26256, 0.4205, 0.52712, 0.06366, 0.086887, 0.21766, 0.30047, 0.66813, 0.18767]
Predicted label: 8
Correct prediction
Energy consumption = 204.716310 pJ
sum error= 60
Actual label: 9
Output voltages: [0.26037, 0.20101, 0.17408, 0.21583, 0.17566, 0.17819, 0.055462, 0.23967, 0.58877, 0.53027]
Predicted label: 8
Wrong prediction!
Energy consumption = 198.952696 pJ
sum error= 61
Actual label: 2
Output voltages: [0.4727, 0.33858, 0.64514, 0.30394, 0.14481, 0.026622, 0.31088, 0.2748, 0.3128, 0.2738]
Predicted label: 2
Correct prediction
Energy consumption = 194.448331 pJ
sum error= 61
Actual label: 9
Output voltages: [0.29446, 0.08675, 0.18546, 0.26243, 0.41774, 0.10855, 0.083685, 0.20452, 0.37312, 0.59974]
Predicted label: 9
Correct prediction
Energy consumption = 189.703378 pJ
sum error= 61
Actual label: 6
Output voltages: [0.25616, 0.22049, 0.37273, 0.069871, 0.27474, 0.32768, 0.74422, 0.061507, 0.43309, 0.15351]
Predicted label: 6
Correct prediction
Energy consumption = 188.266009 pJ
sum error= 61
Actual label: 7
Output voltages: [0.34956, 0.25169, 0.23191, 0.29851, 0.11371, 0.094368, 0.049741, 0.74705, 0.35085, 0.41036]
Predicted label: 7
Correct prediction
Energy consumption = 205.406519 pJ
sum error= 61
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 170 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 170 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 170 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74301, 0.26771, 0.2034, 0.23697, 0.11701, 0.27086, 0.35485, 0.16336, 0.27859, 0.25462]
Predicted label: 0
Correct prediction
Energy consumption = 202.332768 pJ
sum error= 61
Actual label: 4
Output voltages: [0.22422, 0.15073, 0.16964, 0.15794, 0.50576, 0.2042, 0.17699, 0.24028, 0.35037, 0.53796]
Predicted label: 9
Wrong prediction!
Energy consumption = 206.757701 pJ
sum error= 62
Actual label: 8
Output voltages: [0.2995, 0.14907, 0.27814, 0.31945, 0.066007, 0.4234, 0.203, 0.14449, 0.72958, 0.18275]
Predicted label: 8
Correct prediction
Energy consumption = 201.038211 pJ
sum error= 62
Actual label: 7
Output voltages: [0.35475, 0.29272, 0.36653, 0.41991, 0.05568, 0.042362, 0.047657, 0.68855, 0.34421, 0.31944]
Predicted label: 7
Correct prediction
Energy consumption = 190.258241 pJ
sum error= 62
Actual label: 1
Output voltages: [0.10676, 0.75307, 0.14853, 0.26832, 0.23353, 0.14704, 0.29902, 0.1351, 0.35553, 0.28891]
Predicted label: 1
Correct prediction
Energy consumption = 215.644987 pJ
sum error= 62
Actual label: 7
Output voltages: [0.25408, 0.3543, 0.24353, 0.32785, 0.14387, 0.051067, 0.04518, 0.74829, 0.25628, 0.32945]
Predicted label: 7
Correct prediction
Energy consumption = 195.920826 pJ
sum error= 62
Actual label: 4
Output voltages: [0.10397, 0.2108, 0.2666, 0.13456, 0.71923, 0.13294, 0.20803, 0.22417, 0.3116, 0.39477]
Predicted label: 4
Correct prediction
Energy consumption = 192.072339 pJ
sum error= 62
Actual label: 1
Output voltages: [0.21021, 0.74383, 0.28355, 0.33172, 0.35654, 0.075179, 0.22618, 0.08757, 0.17388, 0.33828]
Predicted label: 1
Correct prediction
Energy consumption = 212.299883 pJ
sum error= 62
Actual label: 0
Output voltages: [0.71903, 0.24253, 0.28468, 0.15234, 0.12373, 0.18158, 0.42299, 0.16229, 0.30626, 0.28707]
Predicted label: 0
Correct prediction
Energy consumption = 189.346903 pJ
sum error= 62
Actual label: 9
Output voltages: [0.052058, 0.22576, 0.19013, 0.49608, 0.31761, 0.20803, 0.14397, 0.14172, 0.40526, 0.4263]
Predicted label: 3
Wrong prediction!
Energy consumption = 200.907532 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 171 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 171 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 171 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.27084, 0.2601, 0.17882, 0.16792, 0.20186, 0.11594, 0.040785, 0.74807, 0.35835, 0.37272]
Predicted label: 7
Correct prediction
Energy consumption = 196.999358 pJ
sum error= 63
Actual label: 2
Output voltages: [0.36684, 0.28909, 0.71016, 0.35863, 0.087908, 0.033317, 0.32749, 0.2026, 0.45537, 0.17682]
Predicted label: 2
Correct prediction
Energy consumption = 186.122650 pJ
sum error= 63
Actual label: 0
Output voltages: [0.67146, 0.26912, 0.42182, 0.19043, 0.05952, 0.10162, 0.32003, 0.13026, 0.39213, 0.30009]
Predicted label: 0
Correct prediction
Energy consumption = 198.608006 pJ
sum error= 63
Actual label: 0
Output voltages: [0.74178, 0.27722, 0.22495, 0.22397, 0.178, 0.259, 0.40789, 0.13777, 0.2911, 0.35275]
Predicted label: 0
Correct prediction
Energy consumption = 189.411727 pJ
sum error= 63
Actual label: 9
Output voltages: [0.40046, 0.17125, 0.20907, 0.23301, 0.33609, 0.18652, 0.12365, 0.18925, 0.35754, 0.73292]
Predicted label: 9
Correct prediction
Energy consumption = 193.656607 pJ
sum error= 63
Actual label: 1
Output voltages: [0.28743, 0.76701, 0.25974, 0.34335, 0.094261, 0.17298, 0.39909, 0.081771, 0.32282, 0.24762]
Predicted label: 1
Correct prediction
Energy consumption = 213.256297 pJ
sum error= 63
Actual label: 7
Output voltages: [0.23064, 0.42434, 0.3787, 0.19645, 0.13449, 0.045517, 0.060763, 0.58932, 0.38602, 0.35674]
Predicted label: 7
Correct prediction
Energy consumption = 202.567229 pJ
sum error= 63
Actual label: 8
Output voltages: [0.50167, 0.12787, 0.23871, 0.34351, 0.222, 0.27141, 0.3485, 0.067717, 0.60253, 0.278]
Predicted label: 8
Correct prediction
Energy consumption = 194.972600 pJ
sum error= 63
Actual label: 7
Output voltages: [0.26675, 0.11213, 0.41337, 0.52992, 0.33029, 0.048935, 0.04955, 0.49619, 0.30082, 0.32625]
Predicted label: 3
Wrong prediction!
Energy consumption = 191.450237 pJ
sum error= 64
Actual label: 8
Output voltages: [0.2227, 0.23629, 0.30971, 0.24947, 0.19022, 0.18668, 0.21337, 0.17322, 0.75139, 0.30502]
Predicted label: 8
Correct prediction
Energy consumption = 185.822912 pJ
sum error= 64
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 172 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 172 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 172 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.14842, 0.1473, 0.23319, 0.12108, 0.75397, 0.19816, 0.36367, 0.28146, 0.29347, 0.23951]
Predicted label: 4
Correct prediction
Energy consumption = 198.005478 pJ
sum error= 64
Actual label: 7
Output voltages: [0.24227, 0.26006, 0.23056, 0.31365, 0.34261, 0.0371, 0.046299, 0.49549, 0.42103, 0.44027]
Predicted label: 7
Correct prediction
Energy consumption = 210.202430 pJ
sum error= 64
Actual label: 2
Output voltages: [0.20996, 0.19648, 0.64963, 0.46268, 0.18112, 0.055858, 0.21942, 0.42449, 0.37575, 0.16577]
Predicted label: 2
Correct prediction
Energy consumption = 194.696943 pJ
sum error= 64
Actual label: 0
Output voltages: [0.73301, 0.2101, 0.26079, 0.18304, 0.17651, 0.17176, 0.46538, 0.18212, 0.31352, 0.23581]
Predicted label: 0
Correct prediction
Energy consumption = 193.129592 pJ
sum error= 64
Actual label: 4
Output voltages: [0.16228, 0.13602, 0.31272, 0.16567, 0.73574, 0.057037, 0.31242, 0.31669, 0.25337, 0.22928]
Predicted label: 4
Correct prediction
Energy consumption = 197.552220 pJ
sum error= 64
Actual label: 6
Output voltages: [0.32629, 0.25833, 0.22158, 0.18403, 0.2146, 0.38677, 0.68883, 0.15429, 0.51094, 0.11176]
Predicted label: 6
Correct prediction
Energy consumption = 193.821912 pJ
sum error= 64
Actual label: 0
Output voltages: [0.73652, 0.23972, 0.26321, 0.16044, 0.1673, 0.18583, 0.40446, 0.17512, 0.25599, 0.29871]
Predicted label: 0
Correct prediction
Energy consumption = 189.646116 pJ
sum error= 64
Actual label: 3
Output voltages: [0.25264, 0.32555, 0.25669, 0.7115, 0.046645, 0.18442, 0.076545, 0.3091, 0.58894, 0.1849]
Predicted label: 3
Correct prediction
Energy consumption = 189.717207 pJ
sum error= 64
Actual label: 1
Output voltages: [0.18073, 0.77214, 0.26457, 0.33012, 0.14503, 0.14496, 0.40047, 0.21806, 0.27854, 0.25263]
Predicted label: 1
Correct prediction
Energy consumption = 214.186563 pJ
sum error= 64
Actual label: 1
Output voltages: [0.14574, 0.73791, 0.26322, 0.31545, 0.17291, 0.058528, 0.28912, 0.14321, 0.41142, 0.26725]
Predicted label: 1
Correct prediction
Energy consumption = 203.799560 pJ
sum error= 64
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 173 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 173 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 173 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30374, 0.25619, 0.15029, 0.61505, 0.05289, 0.3057, 0.27611, 0.12056, 0.52366, 0.21199]
Predicted label: 3
Correct prediction
Energy consumption = 209.986375 pJ
sum error= 64
Actual label: 3
Output voltages: [0.28017, 0.1065, 0.383, 0.70583, 0.17166, 0.25364, 0.10968, 0.13682, 0.54556, 0.25465]
Predicted label: 3
Correct prediction
Energy consumption = 182.891454 pJ
sum error= 64
Actual label: 9
Output voltages: [0.41084, 0.11813, 0.21491, 0.36047, 0.22474, 0.24956, 0.1071, 0.13759, 0.40899, 0.62647]
Predicted label: 9
Correct prediction
Energy consumption = 196.322281 pJ
sum error= 64
Actual label: 6
Output voltages: [0.34279, 0.3281, 0.29366, 0.084226, 0.27124, 0.34893, 0.73924, 0.054278, 0.26317, 0.24263]
Predicted label: 6
Correct prediction
Energy consumption = 185.158313 pJ
sum error= 64
Actual label: 7
Output voltages: [0.47211, 0.21896, 0.14944, 0.13096, 0.19966, 0.18828, 0.091793, 0.73472, 0.35861, 0.31295]
Predicted label: 7
Correct prediction
Energy consumption = 193.284701 pJ
sum error= 64
Actual label: 4
Output voltages: [0.20673, 0.24709, 0.23068, 0.22318, 0.75294, 0.066147, 0.31587, 0.28388, 0.18848, 0.29594]
Predicted label: 4
Correct prediction
Energy consumption = 199.732920 pJ
sum error= 64
Actual label: 1
Output voltages: [0.256, 0.7676, 0.27385, 0.23131, 0.27657, 0.15377, 0.3693, 0.086471, 0.27364, 0.28435]
Predicted label: 1
Correct prediction
Energy consumption = 212.611538 pJ
sum error= 64
Actual label: 5
Output voltages: [0.1717, 0.11748, 0.40958, 0.29836, 0.1219, 0.30437, 0.41806, 0.1522, 0.50312, 0.11634]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.028969 pJ
sum error= 65
Actual label: 3
Output voltages: [0.34842, 0.21799, 0.29794, 0.76249, 0.22185, 0.1762, 0.19795, 0.20281, 0.40236, 0.22099]
Predicted label: 3
Correct prediction
Energy consumption = 184.773267 pJ
sum error= 65
Actual label: 0
Output voltages: [0.71351, 0.23484, 0.29998, 0.22289, 0.20028, 0.081698, 0.41722, 0.17448, 0.32195, 0.24363]
Predicted label: 0
Correct prediction
Energy consumption = 199.499505 pJ
sum error= 65
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 174 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 174 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 174 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.33875, 0.096533, 0.22837, 0.27594, 0.19196, 0.3939, 0.32807, 0.11809, 0.70896, 0.092735]
Predicted label: 8
Correct prediction
Energy consumption = 197.794482 pJ
sum error= 65
Actual label: 7
Output voltages: [0.27853, 0.52341, 0.23773, 0.36806, 0.076841, 0.052288, 0.062011, 0.60489, 0.45353, 0.23435]
Predicted label: 7
Correct prediction
Energy consumption = 204.420489 pJ
sum error= 65
Actual label: 3
Output voltages: [0.40884, 0.17774, 0.2834, 0.7642, 0.16926, 0.16937, 0.21444, 0.18807, 0.37888, 0.19372]
Predicted label: 3
Correct prediction
Energy consumption = 186.747438 pJ
sum error= 65
Actual label: 9
Output voltages: [0.3405, 0.16153, 0.21269, 0.30503, 0.31117, 0.22267, 0.17677, 0.27653, 0.29918, 0.68299]
Predicted label: 9
Correct prediction
Energy consumption = 194.476112 pJ
sum error= 65
Actual label: 6
Output voltages: [0.29407, 0.23618, 0.29184, 0.17329, 0.25458, 0.40019, 0.74023, 0.094951, 0.452, 0.15399]
Predicted label: 6
Correct prediction
Energy consumption = 186.373577 pJ
sum error= 65
Actual label: 9
Output voltages: [0.36731, 0.15774, 0.20048, 0.25956, 0.33521, 0.1682, 0.10549, 0.23413, 0.34253, 0.69834]
Predicted label: 9
Correct prediction
Energy consumption = 188.696069 pJ
sum error= 65
Actual label: 3
Output voltages: [0.36251, 0.25714, 0.29428, 0.74639, 0.12468, 0.21734, 0.30186, 0.23017, 0.3517, 0.13034]
Predicted label: 3
Correct prediction
Energy consumption = 186.808607 pJ
sum error= 65
Actual label: 5
Output voltages: [0.40585, 0.15117, 0.045945, 0.39662, 0.21351, 0.66185, 0.27472, 0.086711, 0.51796, 0.12896]
Predicted label: 5
Correct prediction
Energy consumption = 190.857014 pJ
sum error= 65
Actual label: 0
Output voltages: [0.59012, 0.18892, 0.26549, 0.12233, 0.22452, 0.064292, 0.39883, 0.25185, 0.36502, 0.28885]
Predicted label: 0
Correct prediction
Energy consumption = 193.609969 pJ
sum error= 65
Actual label: 2
Output voltages: [0.37491, 0.28049, 0.71752, 0.29995, 0.098645, 0.028653, 0.27238, 0.3407, 0.42516, 0.26082]
Predicted label: 2
Correct prediction
Energy consumption = 182.911156 pJ
sum error= 65
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 175 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 175 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 175 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25214, 0.28453, 0.35849, 0.42325, 0.17557, 0.035067, 0.051516, 0.69331, 0.38533, 0.27823]
Predicted label: 7
Correct prediction
Energy consumption = 191.782289 pJ
sum error= 65
Actual label: 4
Output voltages: [0.18019, 0.24542, 0.37119, 0.37302, 0.68181, 0.059769, 0.20117, 0.20713, 0.12662, 0.25409]
Predicted label: 4
Correct prediction
Energy consumption = 200.447035 pJ
sum error= 65
Actual label: 5
Output voltages: [0.20554, 0.051997, 0.14449, 0.4123, 0.21913, 0.70656, 0.27784, 0.21193, 0.49615, 0.28105]
Predicted label: 5
Correct prediction
Energy consumption = 194.660528 pJ
sum error= 65
Actual label: 1
Output voltages: [0.22302, 0.7598, 0.22276, 0.36168, 0.21981, 0.17687, 0.31978, 0.12145, 0.27839, 0.28838]
Predicted label: 1
Correct prediction
Energy consumption = 210.475705 pJ
sum error= 65
Actual label: 7
Output voltages: [0.26211, 0.35171, 0.5772, 0.51259, 0.21619, 0.02693, 0.16079, 0.36262, 0.30399, 0.13618]
Predicted label: 2
Wrong prediction!
Energy consumption = 197.393149 pJ
sum error= 66
Actual label: 5
Output voltages: [0.34864, 0.070659, 0.24078, 0.27468, 0.071537, 0.6042, 0.30671, 0.24562, 0.47057, 0.25094]
Predicted label: 5
Correct prediction
Energy consumption = 199.554208 pJ
sum error= 66
Actual label: 8
Output voltages: [0.24494, 0.12532, 0.19177, 0.40579, 0.082616, 0.39802, 0.21535, 0.088247, 0.72517, 0.2614]
Predicted label: 8
Correct prediction
Energy consumption = 181.250413 pJ
sum error= 66
Actual label: 0
Output voltages: [0.69583, 0.20617, 0.18674, 0.22856, 0.17177, 0.18436, 0.41903, 0.20239, 0.34832, 0.31391]
Predicted label: 0
Correct prediction
Energy consumption = 204.089354 pJ
sum error= 66
Actual label: 8
Output voltages: [0.29329, 0.13876, 0.32034, 0.33199, 0.16568, 0.25412, 0.17284, 0.13384, 0.75073, 0.29264]
Predicted label: 8
Correct prediction
Energy consumption = 186.910837 pJ
sum error= 66
Actual label: 8
Output voltages: [0.26048, 0.12198, 0.20408, 0.15667, 0.29569, 0.33338, 0.38546, 0.090248, 0.6604, 0.23261]
Predicted label: 8
Correct prediction
Energy consumption = 185.072705 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 176 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 176 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 176 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20302, 0.7544, 0.19053, 0.25165, 0.25174, 0.16825, 0.3613, 0.074137, 0.40948, 0.2416]
Predicted label: 1
Correct prediction
Energy consumption = 208.513641 pJ
sum error= 66
Actual label: 5
Output voltages: [0.21667, 0.052239, 0.088323, 0.30024, 0.27558, 0.66939, 0.23641, 0.18471, 0.46101, 0.33018]
Predicted label: 5
Correct prediction
Energy consumption = 200.876089 pJ
sum error= 66
Actual label: 0
Output voltages: [0.65835, 0.19157, 0.2266, 0.15615, 0.17291, 0.20357, 0.37058, 0.17092, 0.40221, 0.37713]
Predicted label: 0
Correct prediction
Energy consumption = 205.386785 pJ
sum error= 66
Actual label: 3
Output voltages: [0.29862, 0.21753, 0.2761, 0.7671, 0.17559, 0.24608, 0.18652, 0.19967, 0.39149, 0.26037]
Predicted label: 3
Correct prediction
Energy consumption = 189.910298 pJ
sum error= 66
Actual label: 0
Output voltages: [0.72074, 0.20876, 0.28236, 0.15073, 0.20089, 0.16212, 0.47486, 0.19282, 0.31432, 0.18486]
Predicted label: 0
Correct prediction
Energy consumption = 196.206066 pJ
sum error= 66
Actual label: 3
Output voltages: [0.21778, 0.08211, 0.29008, 0.70517, 0.22553, 0.36028, 0.22614, 0.19746, 0.48608, 0.14684]
Predicted label: 3
Correct prediction
Energy consumption = 190.370377 pJ
sum error= 66
Actual label: 1
Output voltages: [0.2355, 0.73907, 0.25995, 0.2341, 0.37201, 0.18902, 0.47372, 0.13193, 0.22602, 0.12242]
Predicted label: 1
Correct prediction
Energy consumption = 203.638407 pJ
sum error= 66
Actual label: 4
Output voltages: [0.17824, 0.1955, 0.28702, 0.24209, 0.75856, 0.061114, 0.26587, 0.27754, 0.17669, 0.30115]
Predicted label: 4
Correct prediction
Energy consumption = 191.118897 pJ
sum error= 66
Actual label: 0
Output voltages: [0.71227, 0.26715, 0.24342, 0.1718, 0.17148, 0.15824, 0.42289, 0.15332, 0.34656, 0.21589]
Predicted label: 0
Correct prediction
Energy consumption = 196.436099 pJ
sum error= 66
Actual label: 3
Output voltages: [0.27121, 0.12324, 0.51929, 0.61946, 0.20131, 0.045306, 0.15295, 0.20416, 0.52552, 0.21452]
Predicted label: 3
Correct prediction
Energy consumption = 183.622806 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 177 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 177 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 177 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25403, 0.32203, 0.40109, 0.29407, 0.10894, 0.058759, 0.036496, 0.74089, 0.35991, 0.34021]
Predicted label: 7
Correct prediction
Energy consumption = 192.223299 pJ
sum error= 66
Actual label: 2
Output voltages: [0.32934, 0.30259, 0.7364, 0.32123, 0.13714, 0.029037, 0.2467, 0.33004, 0.39629, 0.23243]
Predicted label: 2
Correct prediction
Energy consumption = 187.940647 pJ
sum error= 66
Actual label: 7
Output voltages: [0.16479, 0.068502, 0.058995, 0.32708, 0.47989, 0.42926, 0.15107, 0.62298, 0.29512, 0.27446]
Predicted label: 7
Correct prediction
Energy consumption = 201.423737 pJ
sum error= 66
Actual label: 1
Output voltages: [0.35993, 0.72313, 0.1234, 0.19161, 0.21683, 0.27335, 0.5346, 0.057059, 0.29082, 0.236]
Predicted label: 1
Correct prediction
Energy consumption = 210.534095 pJ
sum error= 66
Actual label: 8
Output voltages: [0.26667, 0.072887, 0.20907, 0.36018, 0.12107, 0.43228, 0.22475, 0.08537, 0.71375, 0.22895]
Predicted label: 8
Correct prediction
Energy consumption = 200.056119 pJ
sum error= 66
Actual label: 0
Output voltages: [0.69694, 0.18955, 0.23569, 0.13789, 0.1434, 0.23987, 0.36191, 0.13623, 0.42047, 0.30652]
Predicted label: 0
Correct prediction
Energy consumption = 195.981678 pJ
sum error= 66
Actual label: 7
Output voltages: [0.40211, 0.29139, 0.41838, 0.38377, 0.075066, 0.032583, 0.053799, 0.61883, 0.28665, 0.37048]
Predicted label: 7
Correct prediction
Energy consumption = 197.378273 pJ
sum error= 66
Actual label: 0
Output voltages: [0.74016, 0.2537, 0.28395, 0.15188, 0.1871, 0.17518, 0.3786, 0.1821, 0.24709, 0.28041]
Predicted label: 0
Correct prediction
Energy consumption = 195.442877 pJ
sum error= 66
Actual label: 4
Output voltages: [0.20823, 0.28583, 0.30414, 0.14482, 0.72134, 0.070968, 0.39704, 0.21835, 0.089196, 0.38245]
Predicted label: 4
Correct prediction
Energy consumption = 202.298959 pJ
sum error= 66
Actual label: 3
Output voltages: [0.31788, 0.24676, 0.34048, 0.74657, 0.18591, 0.11869, 0.15069, 0.12695, 0.41424, 0.26009]
Predicted label: 3
Correct prediction
Energy consumption = 186.736702 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 178 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 178 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 178 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17052, 0.76688, 0.2322, 0.24774, 0.15849, 0.1466, 0.46858, 0.1768, 0.31259, 0.18926]
Predicted label: 1
Correct prediction
Energy consumption = 213.385606 pJ
sum error= 66
Actual label: 9
Output voltages: [0.43492, 0.17011, 0.24293, 0.15698, 0.43522, 0.062653, 0.27715, 0.12034, 0.29522, 0.60342]
Predicted label: 9
Correct prediction
Energy consumption = 201.225269 pJ
sum error= 66
Actual label: 8
Output voltages: [0.2784, 0.11032, 0.32224, 0.15922, 0.19184, 0.24203, 0.15223, 0.21128, 0.70152, 0.37428]
Predicted label: 8
Correct prediction
Energy consumption = 199.522224 pJ
sum error= 66
Actual label: 7
Output voltages: [0.34324, 0.26235, 0.18479, 0.23251, 0.16198, 0.17328, 0.043259, 0.73946, 0.32765, 0.43208]
Predicted label: 7
Correct prediction
Energy consumption = 192.394724 pJ
sum error= 66
Actual label: 7
Output voltages: [0.31428, 0.26037, 0.23725, 0.22781, 0.15467, 0.11986, 0.037271, 0.75596, 0.39064, 0.348]
Predicted label: 7
Correct prediction
Energy consumption = 189.161130 pJ
sum error= 66
Actual label: 1
Output voltages: [0.20115, 0.6406, 0.25688, 0.38491, 0.27341, 0.10524, 0.22851, 0.13124, 0.33405, 0.22519]
Predicted label: 1
Correct prediction
Energy consumption = 212.777264 pJ
sum error= 66
Actual label: 4
Output voltages: [0.14546, 0.17725, 0.20665, 0.13867, 0.74537, 0.12541, 0.25653, 0.22233, 0.28546, 0.19993]
Predicted label: 4
Correct prediction
Energy consumption = 197.091515 pJ
sum error= 66
Actual label: 9
Output voltages: [0.38524, 0.090603, 0.20996, 0.26259, 0.35004, 0.22266, 0.12617, 0.29184, 0.31759, 0.6754]
Predicted label: 9
Correct prediction
Energy consumption = 189.274617 pJ
sum error= 66
Actual label: 9
Output voltages: [0.34407, 0.16798, 0.14884, 0.29133, 0.41229, 0.20848, 0.17567, 0.1327, 0.33309, 0.66253]
Predicted label: 9
Correct prediction
Energy consumption = 201.353246 pJ
sum error= 66
Actual label: 3
Output voltages: [0.41629, 0.22521, 0.33029, 0.74274, 0.10317, 0.1779, 0.20696, 0.17189, 0.38056, 0.18901]
Predicted label: 3
Correct prediction
Energy consumption = 192.572751 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 179 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 179 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 179 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.4131, 0.35159, 0.42144, 0.061232, 0.21964, 0.035856, 0.10285, 0.5219, 0.40893, 0.24681]
Predicted label: 7
Wrong prediction!
Energy consumption = 198.678418 pJ
sum error= 67
Actual label: 1
Output voltages: [0.16081, 0.76938, 0.13372, 0.30391, 0.16853, 0.081838, 0.37303, 0.18293, 0.34719, 0.2132]
Predicted label: 1
Correct prediction
Energy consumption = 208.159553 pJ
sum error= 67
Actual label: 7
Output voltages: [0.29531, 0.20616, 0.25194, 0.49077, 0.17585, 0.068297, 0.043686, 0.71278, 0.33544, 0.3623]
Predicted label: 7
Correct prediction
Energy consumption = 190.213656 pJ
sum error= 67
Actual label: 9
Output voltages: [0.39941, 0.089565, 0.25442, 0.21389, 0.37669, 0.18292, 0.097948, 0.22598, 0.26309, 0.72688]
Predicted label: 9
Correct prediction
Energy consumption = 185.303299 pJ
sum error= 67
Actual label: 0
Output voltages: [0.69675, 0.24608, 0.29352, 0.15885, 0.14142, 0.14512, 0.41065, 0.20089, 0.31392, 0.28639]
Predicted label: 0
Correct prediction
Energy consumption = 193.401950 pJ
sum error= 67
Actual label: 2
Output voltages: [0.4196, 0.20647, 0.74242, 0.32358, 0.15768, 0.035091, 0.27221, 0.28869, 0.41388, 0.1612]
Predicted label: 2
Correct prediction
Energy consumption = 178.591059 pJ
sum error= 67
Actual label: 0
Output voltages: [0.73771, 0.21643, 0.28006, 0.11842, 0.17295, 0.17106, 0.41522, 0.13804, 0.23926, 0.288]
Predicted label: 0
Correct prediction
Energy consumption = 189.911387 pJ
sum error= 67
Actual label: 3
Output voltages: [0.41304, 0.14866, 0.20299, 0.71234, 0.13876, 0.34532, 0.25724, 0.19884, 0.40096, 0.23982]
Predicted label: 3
Correct prediction
Energy consumption = 199.549920 pJ
sum error= 67
Actual label: 3
Output voltages: [0.23201, 0.12266, 0.23608, 0.74685, 0.21808, 0.25815, 0.20049, 0.17497, 0.40448, 0.23046]
Predicted label: 3
Correct prediction
Energy consumption = 183.789768 pJ
sum error= 67
Actual label: 7
Output voltages: [0.28136, 0.2049, 0.22729, 0.27724, 0.1494, 0.063608, 0.042492, 0.7469, 0.38007, 0.37722]
Predicted label: 7
Correct prediction
Energy consumption = 197.906762 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 180 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 180 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 180 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29989, 0.13341, 0.34416, 0.13573, 0.39991, 0.16136, 0.65088, 0.10774, 0.25703, 0.28018]
Predicted label: 6
Correct prediction
Energy consumption = 189.601525 pJ
sum error= 67
Actual label: 9
Output voltages: [0.36907, 0.08851, 0.2591, 0.29873, 0.24227, 0.23974, 0.11687, 0.15723, 0.40666, 0.5952]
Predicted label: 9
Correct prediction
Energy consumption = 195.951313 pJ
sum error= 67
Actual label: 2
Output voltages: [0.33562, 0.28847, 0.73804, 0.28785, 0.13799, 0.03141, 0.25684, 0.28713, 0.36341, 0.21215]
Predicted label: 2
Correct prediction
Energy consumption = 190.520107 pJ
sum error= 67
Actual label: 3
Output voltages: [0.30481, 0.21568, 0.25647, 0.75957, 0.2024, 0.23794, 0.14754, 0.2086, 0.37032, 0.27126]
Predicted label: 3
Correct prediction
Energy consumption = 182.544261 pJ
sum error= 67
Actual label: 3
Output voltages: [0.32052, 0.18929, 0.32478, 0.75847, 0.20127, 0.1194, 0.12321, 0.19209, 0.46914, 0.24959]
Predicted label: 3
Correct prediction
Energy consumption = 171.910908 pJ
sum error= 67
Actual label: 7
Output voltages: [0.3595, 0.25757, 0.21686, 0.24874, 0.17162, 0.12567, 0.057619, 0.7574, 0.26317, 0.3135]
Predicted label: 7
Correct prediction
Energy consumption = 191.521537 pJ
sum error= 67
Actual label: 7
Output voltages: [0.35934, 0.31893, 0.44182, 0.30512, 0.10975, 0.033298, 0.052563, 0.71037, 0.25649, 0.36152]
Predicted label: 7
Correct prediction
Energy consumption = 196.250839 pJ
sum error= 67
Actual label: 0
Output voltages: [0.71954, 0.19572, 0.28976, 0.28038, 0.068266, 0.29585, 0.39898, 0.16416, 0.30872, 0.2229]
Predicted label: 0
Correct prediction
Energy consumption = 194.372722 pJ
sum error= 67
Actual label: 0
Output voltages: [0.56259, 0.14832, 0.36938, 0.10349, 0.46828, 0.044437, 0.45703, 0.17219, 0.24319, 0.27991]
Predicted label: 0
Correct prediction
Energy consumption = 188.666152 pJ
sum error= 67
Actual label: 7
Output voltages: [0.31006, 0.42781, 0.27692, 0.34075, 0.17836, 0.03273, 0.051067, 0.57763, 0.21823, 0.40539]
Predicted label: 7
Correct prediction
Energy consumption = 204.446111 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 181 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 181 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 181 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24632, 0.063966, 0.16732, 0.3939, 0.14708, 0.69594, 0.27072, 0.17307, 0.55002, 0.23371]
Predicted label: 5
Correct prediction
Energy consumption = 187.943835 pJ
sum error= 67
Actual label: 2
Output voltages: [0.4266, 0.065125, 0.54291, 0.54787, 0.15098, 0.066187, 0.16569, 0.18415, 0.47876, 0.2341]
Predicted label: 3
Wrong prediction!
Energy consumption = 193.189395 pJ
sum error= 68
Actual label: 9
Output voltages: [0.44232, 0.11193, 0.16116, 0.28301, 0.32469, 0.28325, 0.18225, 0.33916, 0.26936, 0.67652]
Predicted label: 9
Correct prediction
Energy consumption = 205.382909 pJ
sum error= 68
Actual label: 8
Output voltages: [0.37446, 0.063239, 0.25729, 0.42151, 0.10592, 0.40988, 0.16667, 0.07035, 0.70139, 0.2241]
Predicted label: 8
Correct prediction
Energy consumption = 197.389376 pJ
sum error= 68
Actual label: 7
Output voltages: [0.25298, 0.35146, 0.38348, 0.17747, 0.094333, 0.059354, 0.04836, 0.66387, 0.539, 0.12569]
Predicted label: 7
Correct prediction
Energy consumption = 190.627773 pJ
sum error= 68
Actual label: 4
Output voltages: [0.1624, 0.1348, 0.33352, 0.15653, 0.75452, 0.067047, 0.26986, 0.2677, 0.21778, 0.32514]
Predicted label: 4
Correct prediction
Energy consumption = 196.885329 pJ
sum error= 68
Actual label: 4
Output voltages: [0.15261, 0.15659, 0.31189, 0.1731, 0.73396, 0.069118, 0.24896, 0.24872, 0.20334, 0.33752]
Predicted label: 4
Correct prediction
Energy consumption = 188.623443 pJ
sum error= 68
Actual label: 2
Output voltages: [0.40119, 0.33637, 0.73443, 0.38201, 0.14042, 0.039109, 0.30735, 0.20159, 0.41499, 0.19061]
Predicted label: 2
Correct prediction
Energy consumption = 187.627265 pJ
sum error= 68
Actual label: 6
Output voltages: [0.35357, 0.21035, 0.22433, 0.18813, 0.30366, 0.47254, 0.73442, 0.077887, 0.37657, 0.16624]
Predicted label: 6
Correct prediction
Energy consumption = 193.452401 pJ
sum error= 68
Actual label: 6
Output voltages: [0.34496, 0.20631, 0.23232, 0.14465, 0.30338, 0.37931, 0.6902, 0.10478, 0.45158, 0.1001]
Predicted label: 6
Correct prediction
Energy consumption = 183.141484 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 182 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 182 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 182 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.25899, 0.7412, 0.21177, 0.16023, 0.41353, 0.11729, 0.35474, 0.17944, 0.17552, 0.29671]
Predicted label: 1
Correct prediction
Energy consumption = 206.017452 pJ
sum error= 68
Actual label: 9
Output voltages: [0.37935, 0.10714, 0.20417, 0.24027, 0.32952, 0.26535, 0.12769, 0.25431, 0.34153, 0.68301]
Predicted label: 9
Correct prediction
Energy consumption = 196.729183 pJ
sum error= 68
Actual label: 6
Output voltages: [0.33315, 0.14834, 0.17551, 0.29014, 0.22967, 0.54682, 0.6249, 0.074042, 0.43061, 0.12822]
Predicted label: 6
Correct prediction
Energy consumption = 202.820255 pJ
sum error= 68
Actual label: 8
Output voltages: [0.16289, 0.21878, 0.32755, 0.21397, 0.23396, 0.1738, 0.36534, 0.059814, 0.62811, 0.35739]
Predicted label: 8
Correct prediction
Energy consumption = 192.917321 pJ
sum error= 68
Actual label: 2
Output voltages: [0.35313, 0.28249, 0.73026, 0.29997, 0.11392, 0.029421, 0.26712, 0.27136, 0.4364, 0.246]
Predicted label: 2
Correct prediction
Energy consumption = 192.655683 pJ
sum error= 68
Actual label: 9
Output voltages: [0.28773, 0.14757, 0.21174, 0.27587, 0.36628, 0.13494, 0.092885, 0.15937, 0.34738, 0.66444]
Predicted label: 9
Correct prediction
Energy consumption = 196.172685 pJ
sum error= 68
Actual label: 0
Output voltages: [0.72493, 0.26356, 0.29418, 0.19445, 0.13262, 0.13838, 0.43298, 0.17633, 0.29279, 0.27657]
Predicted label: 0
Correct prediction
Energy consumption = 191.324274 pJ
sum error= 68
Actual label: 8
Output voltages: [0.2323, 0.23216, 0.32152, 0.31221, 0.20081, 0.20382, 0.3078, 0.098161, 0.73321, 0.26557]
Predicted label: 8
Correct prediction
Energy consumption = 195.323605 pJ
sum error= 68
Actual label: 3
Output voltages: [0.33779, 0.21666, 0.19976, 0.64994, 0.087364, 0.33743, 0.15817, 0.44386, 0.28403, 0.20558]
Predicted label: 3
Correct prediction
Energy consumption = 208.789823 pJ
sum error= 68
Actual label: 1
Output voltages: [0.31475, 0.75606, 0.21603, 0.20933, 0.20017, 0.060891, 0.24958, 0.23041, 0.2929, 0.34116]
Predicted label: 1
Correct prediction
Energy consumption = 212.136158 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 183 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 183 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 183 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1485, 0.7673, 0.21471, 0.22141, 0.24644, 0.16002, 0.43987, 0.11989, 0.35478, 0.21723]
Predicted label: 1
Correct prediction
Energy consumption = 211.325675 pJ
sum error= 68
Actual label: 6
Output voltages: [0.30462, 0.15659, 0.2545, 0.16277, 0.27756, 0.37135, 0.70736, 0.046615, 0.40424, 0.21176]
Predicted label: 6
Correct prediction
Energy consumption = 184.930764 pJ
sum error= 68
Actual label: 3
Output voltages: [0.34763, 0.14879, 0.25004, 0.75502, 0.22664, 0.3103, 0.12693, 0.17237, 0.3777, 0.21421]
Predicted label: 3
Correct prediction
Energy consumption = 194.458959 pJ
sum error= 68
Actual label: 5
Output voltages: [0.2518, 0.059443, 0.13645, 0.42355, 0.16415, 0.67099, 0.20193, 0.2067, 0.51349, 0.28237]
Predicted label: 5
Correct prediction
Energy consumption = 181.627075 pJ
sum error= 68
Actual label: 1
Output voltages: [0.18788, 0.76496, 0.28267, 0.27859, 0.32243, 0.06571, 0.39473, 0.19364, 0.19834, 0.20331]
Predicted label: 1
Correct prediction
Energy consumption = 216.384224 pJ
sum error= 68
Actual label: 1
Output voltages: [0.26547, 0.76384, 0.2019, 0.31922, 0.14117, 0.15671, 0.36946, 0.06827, 0.33493, 0.24692]
Predicted label: 1
Correct prediction
Energy consumption = 210.742811 pJ
sum error= 68
Actual label: 1
Output voltages: [0.11293, 0.76529, 0.23503, 0.34632, 0.17746, 0.067735, 0.33532, 0.16603, 0.32794, 0.24777]
Predicted label: 1
Correct prediction
Energy consumption = 204.456608 pJ
sum error= 68
Actual label: 3
Output voltages: [0.32718, 0.16918, 0.25733, 0.75744, 0.20352, 0.37806, 0.20018, 0.1623, 0.38345, 0.20841]
Predicted label: 3
Correct prediction
Energy consumption = 185.043487 pJ
sum error= 68
Actual label: 1
Output voltages: [0.21195, 0.54234, 0.47132, 0.34476, 0.35895, 0.033862, 0.27976, 0.086304, 0.30097, 0.31326]
Predicted label: 1
Correct prediction
Energy consumption = 203.179789 pJ
sum error= 68
Actual label: 2
Output voltages: [0.31308, 0.31503, 0.6443, 0.47238, 0.096157, 0.033898, 0.23493, 0.20354, 0.43409, 0.20238]
Predicted label: 2
Correct prediction
Energy consumption = 183.408721 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 184 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 184 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 184 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32418, 0.19532, 0.30784, 0.75015, 0.13842, 0.18523, 0.26476, 0.18187, 0.35146, 0.15868]
Predicted label: 3
Correct prediction
Energy consumption = 194.029996 pJ
sum error= 68
Actual label: 0
Output voltages: [0.74529, 0.23215, 0.17909, 0.16375, 0.21084, 0.23838, 0.42281, 0.17311, 0.27019, 0.30752]
Predicted label: 0
Correct prediction
Energy consumption = 199.399541 pJ
sum error= 68
Actual label: 2
Output voltages: [0.24064, 0.31652, 0.67797, 0.31934, 0.08167, 0.038952, 0.28428, 0.17349, 0.50218, 0.23]
Predicted label: 2
Correct prediction
Energy consumption = 198.707961 pJ
sum error= 68
Actual label: 0
Output voltages: [0.70551, 0.13435, 0.31651, 0.26785, 0.19694, 0.096099, 0.33469, 0.17111, 0.34827, 0.34962]
Predicted label: 0
Correct prediction
Energy consumption = 199.661079 pJ
sum error= 68
Actual label: 1
Output voltages: [0.12272, 0.76918, 0.23816, 0.35139, 0.14283, 0.093513, 0.30376, 0.21796, 0.36606, 0.24927]
Predicted label: 1
Correct prediction
Energy consumption = 214.478858 pJ
sum error= 68
Actual label: 3
Output voltages: [0.27769, 0.18634, 0.27171, 0.76213, 0.15267, 0.17069, 0.1238, 0.20961, 0.4465, 0.2555]
Predicted label: 3
Correct prediction
Energy consumption = 179.682597 pJ
sum error= 68
Actual label: 5
Output voltages: [0.15857, 0.10331, 0.12204, 0.37454, 0.21729, 0.6021, 0.18575, 0.084312, 0.55479, 0.25066]
Predicted label: 5
Correct prediction
Energy consumption = 176.254566 pJ
sum error= 68
Actual label: 5
Output voltages: [0.39859, 0.060036, 0.11578, 0.21837, 0.11484, 0.54952, 0.33301, 0.10144, 0.51873, 0.2522]
Predicted label: 5
Correct prediction
Energy consumption = 187.106455 pJ
sum error= 68
Actual label: 7
Output voltages: [0.27194, 0.30023, 0.46428, 0.20747, 0.14241, 0.039136, 0.047616, 0.74782, 0.36364, 0.28888]
Predicted label: 7
Correct prediction
Energy consumption = 193.788867 pJ
sum error= 68
Actual label: 4
Output voltages: [0.2526, 0.086166, 0.30252, 0.30384, 0.65167, 0.11058, 0.1341, 0.11118, 0.28872, 0.40846]
Predicted label: 4
Correct prediction
Energy consumption = 182.897704 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 185 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 185 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 185 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26841, 0.19702, 0.30413, 0.29223, 0.10602, 0.084331, 0.12092, 0.2019, 0.69317, 0.39911]
Predicted label: 8
Correct prediction
Energy consumption = 199.631536 pJ
sum error= 68
Actual label: 9
Output voltages: [0.35809, 0.1262, 0.19653, 0.219, 0.39453, 0.15418, 0.075236, 0.20275, 0.34311, 0.694]
Predicted label: 9
Correct prediction
Energy consumption = 194.475900 pJ
sum error= 68
Actual label: 6
Output voltages: [0.30995, 0.2083, 0.11146, 0.24284, 0.33377, 0.47732, 0.7067, 0.076226, 0.42317, 0.1648]
Predicted label: 6
Correct prediction
Energy consumption = 200.994853 pJ
sum error= 68
Actual label: 9
Output voltages: [0.44904, 0.097401, 0.20472, 0.18771, 0.38935, 0.15791, 0.2164, 0.3164, 0.27447, 0.58749]
Predicted label: 9
Correct prediction
Energy consumption = 200.675166 pJ
sum error= 68
Actual label: 6
Output voltages: [0.3021, 0.25724, 0.31098, 0.061504, 0.33561, 0.36689, 0.74398, 0.063095, 0.39533, 0.16142]
Predicted label: 6
Correct prediction
Energy consumption = 188.789458 pJ
sum error= 68
Actual label: 8
Output voltages: [0.18742, 0.14214, 0.25621, 0.33363, 0.10978, 0.18635, 0.12187, 0.12197, 0.71407, 0.36832]
Predicted label: 8
Correct prediction
Energy consumption = 192.667973 pJ
sum error= 68
Actual label: 3
Output voltages: [0.28995, 0.22774, 0.50412, 0.69702, 0.20866, 0.044982, 0.11932, 0.135, 0.43087, 0.21067]
Predicted label: 3
Correct prediction
Energy consumption = 180.015912 pJ
sum error= 68
Actual label: 6
Output voltages: [0.2362, 0.14673, 0.38301, 0.10818, 0.4432, 0.31029, 0.66785, 0.072368, 0.3677, 0.17565]
Predicted label: 6
Correct prediction
Energy consumption = 196.769479 pJ
sum error= 68
Actual label: 6
Output voltages: [0.27042, 0.14435, 0.30235, 0.093742, 0.33966, 0.35693, 0.72322, 0.051897, 0.42878, 0.13905]
Predicted label: 6
Correct prediction
Energy consumption = 183.334701 pJ
sum error= 68
Actual label: 8
Output voltages: [0.15827, 0.15149, 0.32006, 0.20179, 0.18828, 0.18969, 0.27094, 0.12027, 0.74375, 0.31782]
Predicted label: 8
Correct prediction
Energy consumption = 180.931019 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 186 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 186 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 186 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2219, 0.046378, 0.080987, 0.3697, 0.24381, 0.72778, 0.28247, 0.21242, 0.47766, 0.30041]
Predicted label: 5
Correct prediction
Energy consumption = 189.791357 pJ
sum error= 68
Actual label: 1
Output voltages: [0.24416, 0.73456, 0.18826, 0.37689, 0.16037, 0.13481, 0.15246, 0.36178, 0.36989, 0.23163]
Predicted label: 1
Correct prediction
Energy consumption = 212.079137 pJ
sum error= 68
Actual label: 4
Output voltages: [0.11473, 0.15309, 0.2882, 0.18465, 0.72068, 0.059558, 0.14512, 0.23426, 0.27961, 0.38826]
Predicted label: 4
Correct prediction
Energy consumption = 206.573387 pJ
sum error= 68
Actual label: 2
Output voltages: [0.33271, 0.18017, 0.73091, 0.41165, 0.17683, 0.036165, 0.24559, 0.31698, 0.40602, 0.21694]
Predicted label: 2
Correct prediction
Energy consumption = 184.841453 pJ
sum error= 68
Actual label: 4
Output voltages: [0.15753, 0.17978, 0.29819, 0.15118, 0.74948, 0.061916, 0.18391, 0.24665, 0.25, 0.29872]
Predicted label: 4
Correct prediction
Energy consumption = 196.370810 pJ
sum error= 68
Actual label: 4
Output voltages: [0.14207, 0.20532, 0.17014, 0.24043, 0.69988, 0.11183, 0.26634, 0.22822, 0.26201, 0.34446]
Predicted label: 4
Correct prediction
Energy consumption = 190.270983 pJ
sum error= 68
Actual label: 5
Output voltages: [0.25146, 0.041133, 0.13596, 0.32417, 0.25395, 0.64729, 0.28067, 0.17793, 0.5978, 0.2723]
Predicted label: 5
Correct prediction
Energy consumption = 186.946600 pJ
sum error= 68
Actual label: 1
Output voltages: [0.16223, 0.76092, 0.27322, 0.28436, 0.2465, 0.085094, 0.38528, 0.15545, 0.32225, 0.22785]
Predicted label: 1
Correct prediction
Energy consumption = 217.726381 pJ
sum error= 68
Actual label: 1
Output voltages: [0.086901, 0.67936, 0.21667, 0.29781, 0.40343, 0.075907, 0.15622, 0.25511, 0.34099, 0.24579]
Predicted label: 1
Correct prediction
Energy consumption = 196.164490 pJ
sum error= 68
Actual label: 9
Output voltages: [0.33943, 0.13873, 0.19524, 0.35792, 0.31939, 0.18021, 0.07307, 0.27652, 0.28779, 0.6828]
Predicted label: 9
Correct prediction
Energy consumption = 194.536061 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 187 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 187 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 187 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73852, 0.26346, 0.27667, 0.19122, 0.14087, 0.18706, 0.41737, 0.17085, 0.3426, 0.25515]
Predicted label: 0
Correct prediction
Energy consumption = 195.522116 pJ
sum error= 68
Actual label: 2
Output voltages: [0.33753, 0.25044, 0.60529, 0.39555, 0.14591, 0.040579, 0.29863, 0.15286, 0.5852, 0.22487]
Predicted label: 2
Correct prediction
Energy consumption = 185.812675 pJ
sum error= 68
Actual label: 4
Output voltages: [0.15507, 0.19584, 0.31551, 0.1738, 0.74226, 0.049806, 0.21572, 0.26992, 0.25234, 0.32495]
Predicted label: 4
Correct prediction
Energy consumption = 199.559171 pJ
sum error= 68
Actual label: 9
Output voltages: [0.3738, 0.15787, 0.18531, 0.32773, 0.25123, 0.19691, 0.13723, 0.27366, 0.32091, 0.70297]
Predicted label: 9
Correct prediction
Energy consumption = 192.128036 pJ
sum error= 68
Actual label: 5
Output voltages: [0.1829, 0.057896, 0.082712, 0.39958, 0.29211, 0.68844, 0.43357, 0.1381, 0.48941, 0.31191]
Predicted label: 5
Correct prediction
Energy consumption = 190.795559 pJ
sum error= 68
Actual label: 7
Output voltages: [0.38669, 0.31798, 0.25467, 0.23622, 0.12438, 0.089979, 0.062703, 0.75371, 0.32935, 0.3069]
Predicted label: 7
Correct prediction
Energy consumption = 201.354633 pJ
sum error= 68
Actual label: 1
Output voltages: [0.10847, 0.76866, 0.26172, 0.30576, 0.20856, 0.086784, 0.41373, 0.17916, 0.2949, 0.22411]
Predicted label: 1
Correct prediction
Energy consumption = 205.037628 pJ
sum error= 68
Actual label: 8
Output voltages: [0.26798, 0.2764, 0.23368, 0.41879, 0.069276, 0.2114, 0.21737, 0.11561, 0.727, 0.28532]
Predicted label: 8
Correct prediction
Energy consumption = 197.370431 pJ
sum error= 68
Actual label: 8
Output voltages: [0.29447, 0.21243, 0.31034, 0.74674, 0.15338, 0.11182, 0.23003, 0.28989, 0.44136, 0.15461]
Predicted label: 3
Wrong prediction!
Energy consumption = 194.881061 pJ
sum error= 69
Actual label: 5
Output voltages: [0.22592, 0.06492, 0.13427, 0.44912, 0.17649, 0.67469, 0.31618, 0.13867, 0.43801, 0.25368]
Predicted label: 5
Correct prediction
Energy consumption = 183.458194 pJ
sum error= 69
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 188 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 188 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 188 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.50365, 0.20168, 0.35843, 0.06424, 0.36688, 0.099662, 0.59115, 0.18326, 0.33463, 0.12101]
Predicted label: 6
Correct prediction
Energy consumption = 205.806912 pJ
sum error= 69
Actual label: 9
Output voltages: [0.3297, 0.14447, 0.19498, 0.21317, 0.30447, 0.11401, 0.054626, 0.16985, 0.38939, 0.67087]
Predicted label: 9
Correct prediction
Energy consumption = 195.504876 pJ
sum error= 69
Actual label: 8
Output voltages: [0.31303, 0.12632, 0.33132, 0.37143, 0.12253, 0.27516, 0.17505, 0.14568, 0.74459, 0.35335]
Predicted label: 8
Correct prediction
Energy consumption = 187.657757 pJ
sum error= 69
Actual label: 7
Output voltages: [0.35321, 0.19893, 0.17251, 0.34327, 0.30675, 0.20425, 0.042774, 0.6577, 0.15526, 0.47463]
Predicted label: 7
Correct prediction
Energy consumption = 202.047261 pJ
sum error= 69
Actual label: 1
Output voltages: [0.22004, 0.75846, 0.22925, 0.24737, 0.23111, 0.081891, 0.45236, 0.065446, 0.34307, 0.2326]
Predicted label: 1
Correct prediction
Energy consumption = 213.448414 pJ
sum error= 69
Actual label: 1
Output voltages: [0.23889, 0.70264, 0.27855, 0.16036, 0.3222, 0.1901, 0.45451, 0.065751, 0.35838, 0.19962]
Predicted label: 1
Correct prediction
Energy consumption = 195.077150 pJ
sum error= 69
Actual label: 6
Output voltages: [0.37204, 0.34464, 0.17997, 0.27343, 0.19946, 0.35701, 0.69587, 0.13014, 0.48173, 0.073143]
Predicted label: 6
Correct prediction
Energy consumption = 189.937591 pJ
sum error= 69
Actual label: 7
Output voltages: [0.32901, 0.19396, 0.13561, 0.17399, 0.23674, 0.18245, 0.04362, 0.74523, 0.3268, 0.3762]
Predicted label: 7
Correct prediction
Energy consumption = 204.387018 pJ
sum error= 69
Actual label: 6
Output voltages: [0.31206, 0.28408, 0.16241, 0.28789, 0.25442, 0.38298, 0.70107, 0.069271, 0.46795, 0.10834]
Predicted label: 6
Correct prediction
Energy consumption = 197.883422 pJ
sum error= 69
Actual label: 3
Output voltages: [0.32416, 0.16871, 0.32781, 0.75086, 0.17737, 0.23462, 0.22268, 0.17241, 0.41969, 0.16284]
Predicted label: 3
Correct prediction
Energy consumption = 180.942027 pJ
sum error= 69
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 189 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 189 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 189 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40083, 0.26288, 0.73846, 0.33247, 0.19418, 0.028254, 0.2895, 0.26556, 0.39728, 0.21549]
Predicted label: 2
Correct prediction
Energy consumption = 186.195255 pJ
sum error= 69
Actual label: 2
Output voltages: [0.42125, 0.23756, 0.74078, 0.35515, 0.16295, 0.036307, 0.31184, 0.2322, 0.36406, 0.18387]
Predicted label: 2
Correct prediction
Energy consumption = 181.396286 pJ
sum error= 69
Actual label: 0
Output voltages: [0.7151, 0.27495, 0.24378, 0.18996, 0.075616, 0.2543, 0.36755, 0.13922, 0.32387, 0.29439]
Predicted label: 0
Correct prediction
Energy consumption = 191.880311 pJ
sum error= 69
Actual label: 8
Output voltages: [0.28252, 0.11943, 0.35828, 0.33141, 0.13727, 0.16116, 0.20713, 0.15396, 0.73882, 0.26752]
Predicted label: 8
Correct prediction
Energy consumption = 196.277703 pJ
sum error= 69
Actual label: 9
Output voltages: [0.19169, 0.14929, 0.14025, 0.29086, 0.16911, 0.28575, 0.18533, 0.13266, 0.575, 0.48557]
Predicted label: 8
Wrong prediction!
Energy consumption = 202.835432 pJ
sum error= 70
Actual label: 2
Output voltages: [0.44817, 0.1327, 0.74277, 0.3798, 0.17295, 0.13516, 0.28378, 0.21815, 0.33545, 0.17511]
Predicted label: 2
Correct prediction
Energy consumption = 191.449538 pJ
sum error= 70
Actual label: 5
Output voltages: [0.24693, 0.058226, 0.14714, 0.36207, 0.18797, 0.69872, 0.23135, 0.16312, 0.58641, 0.28881]
Predicted label: 5
Correct prediction
Energy consumption = 179.712782 pJ
sum error= 70
Actual label: 1
Output voltages: [0.18938, 0.76468, 0.21996, 0.22969, 0.33419, 0.15918, 0.35299, 0.11198, 0.31106, 0.24639]
Predicted label: 1
Correct prediction
Energy consumption = 213.273691 pJ
sum error= 70
Actual label: 0
Output voltages: [0.71328, 0.24319, 0.17847, 0.16342, 0.1484, 0.32432, 0.44592, 0.13042, 0.28615, 0.25299]
Predicted label: 0
Correct prediction
Energy consumption = 192.827650 pJ
sum error= 70
Actual label: 8
Output voltages: [0.14655, 0.20626, 0.25806, 0.50854, 0.1702, 0.17488, 0.15394, 0.26135, 0.68439, 0.26383]
Predicted label: 8
Correct prediction
Energy consumption = 200.716542 pJ
sum error= 70
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 190 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 190 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 190 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.29081, 0.50311, 0.26582, 0.21076, 0.42898, 0.12047, 0.40625, 0.084978, 0.3374, 0.12949]
Predicted label: 1
Correct prediction
Energy consumption = 201.396222 pJ
sum error= 70
Actual label: 9
Output voltages: [0.15245, 0.073569, 0.13821, 0.14496, 0.57346, 0.34407, 0.29633, 0.18723, 0.42227, 0.33603]
Predicted label: 4
Wrong prediction!
Energy consumption = 205.865107 pJ
sum error= 71
Actual label: 5
Output voltages: [0.1866, 0.058504, 0.086318, 0.38685, 0.21227, 0.70635, 0.30775, 0.22731, 0.45484, 0.33553]
Predicted label: 5
Correct prediction
Energy consumption = 192.272701 pJ
sum error= 71
Actual label: 7
Output voltages: [0.16482, 0.25876, 0.52774, 0.35188, 0.23605, 0.026638, 0.16938, 0.6306, 0.36584, 0.13639]
Predicted label: 7
Correct prediction
Energy consumption = 192.053745 pJ
sum error= 71
Actual label: 9
Output voltages: [0.30873, 0.16252, 0.23015, 0.21372, 0.43939, 0.094752, 0.09139, 0.19099, 0.28323, 0.67294]
Predicted label: 9
Correct prediction
Energy consumption = 196.822380 pJ
sum error= 71
Actual label: 6
Output voltages: [0.32586, 0.21786, 0.2311, 0.16343, 0.34741, 0.42617, 0.73169, 0.086027, 0.40751, 0.13971]
Predicted label: 6
Correct prediction
Energy consumption = 194.714210 pJ
sum error= 71
Actual label: 9
Output voltages: [0.34644, 0.14794, 0.22441, 0.2422, 0.28187, 0.16355, 0.092985, 0.17824, 0.39975, 0.67153]
Predicted label: 9
Correct prediction
Energy consumption = 191.827979 pJ
sum error= 71
Actual label: 0
Output voltages: [0.72366, 0.22009, 0.33931, 0.24674, 0.15047, 0.17275, 0.33879, 0.17141, 0.38743, 0.25294]
Predicted label: 0
Correct prediction
Energy consumption = 201.195461 pJ
sum error= 71
Actual label: 6
Output voltages: [0.38358, 0.21551, 0.29306, 0.075541, 0.38947, 0.23906, 0.71443, 0.14752, 0.29778, 0.12849]
Predicted label: 6
Correct prediction
Energy consumption = 192.695457 pJ
sum error= 71
Actual label: 1
Output voltages: [0.27237, 0.52426, 0.26614, 0.3968, 0.19628, 0.040324, 0.14159, 0.19347, 0.51212, 0.27744]
Predicted label: 1
Correct prediction
Energy consumption = 205.997985 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 191 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 191 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 191 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25058, 0.050678, 0.12065, 0.34491, 0.19359, 0.67162, 0.33009, 0.19627, 0.50432, 0.30288]
Predicted label: 5
Correct prediction
Energy consumption = 189.557860 pJ
sum error= 71
Actual label: 5
Output voltages: [0.53168, 0.10842, 0.16188, 0.34391, 0.099092, 0.58962, 0.46376, 0.10298, 0.40536, 0.19068]
Predicted label: 5
Correct prediction
Energy consumption = 193.682595 pJ
sum error= 71
Actual label: 8
Output voltages: [0.28363, 0.22898, 0.18599, 0.27085, 0.16028, 0.44973, 0.21063, 0.10133, 0.73642, 0.20005]
Predicted label: 8
Correct prediction
Energy consumption = 202.026379 pJ
sum error= 71
Actual label: 3
Output voltages: [0.38055, 0.13305, 0.2571, 0.75121, 0.10438, 0.16653, 0.21135, 0.23899, 0.46804, 0.23185]
Predicted label: 3
Correct prediction
Energy consumption = 190.958325 pJ
sum error= 71
Actual label: 8
Output voltages: [0.22967, 0.16338, 0.27515, 0.32738, 0.12151, 0.33138, 0.23222, 0.18128, 0.75125, 0.21613]
Predicted label: 8
Correct prediction
Energy consumption = 186.587938 pJ
sum error= 71
Actual label: 2
Output voltages: [0.36247, 0.271, 0.70782, 0.36846, 0.11481, 0.027685, 0.23274, 0.30462, 0.45286, 0.22019]
Predicted label: 2
Correct prediction
Energy consumption = 191.297218 pJ
sum error= 71
Actual label: 6
Output voltages: [0.3486, 0.25144, 0.2151, 0.22528, 0.26359, 0.35485, 0.6973, 0.12825, 0.51806, 0.091459]
Predicted label: 6
Correct prediction
Energy consumption = 193.482511 pJ
sum error= 71
Actual label: 5
Output voltages: [0.23469, 0.040754, 0.13513, 0.31012, 0.19478, 0.65709, 0.32131, 0.16399, 0.5912, 0.23527]
Predicted label: 5
Correct prediction
Energy consumption = 186.488173 pJ
sum error= 71
Actual label: 0
Output voltages: [0.65228, 0.22949, 0.25127, 0.19111, 0.20001, 0.071168, 0.42909, 0.19305, 0.32998, 0.30071]
Predicted label: 0
Correct prediction
Energy consumption = 208.102518 pJ
sum error= 71
Actual label: 7
Output voltages: [0.2609, 0.25959, 0.25451, 0.3641, 0.098771, 0.080222, 0.04113, 0.74615, 0.39928, 0.37791]
Predicted label: 7
Correct prediction
Energy consumption = 196.406184 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 192 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 192 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 192 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.1863, 0.2371, 0.30529, 0.23852, 0.73844, 0.049715, 0.18142, 0.35704, 0.1534, 0.31526]
Predicted label: 4
Correct prediction
Energy consumption = 199.263006 pJ
sum error= 71
Actual label: 6
Output voltages: [0.28471, 0.28805, 0.30419, 0.095639, 0.36238, 0.34875, 0.7508, 0.062519, 0.33156, 0.15775]
Predicted label: 6
Correct prediction
Energy consumption = 191.695416 pJ
sum error= 71
Actual label: 1
Output voltages: [0.21931, 0.75781, 0.25623, 0.24348, 0.15652, 0.14005, 0.44546, 0.068405, 0.36347, 0.18635]
Predicted label: 1
Correct prediction
Energy consumption = 207.982884 pJ
sum error= 71
Actual label: 3
Output voltages: [0.31939, 0.23755, 0.32793, 0.75998, 0.17747, 0.13883, 0.15212, 0.16171, 0.43008, 0.20351]
Predicted label: 3
Correct prediction
Energy consumption = 179.272487 pJ
sum error= 71
Actual label: 4
Output voltages: [0.14812, 0.12614, 0.34677, 0.15165, 0.68053, 0.10015, 0.2461, 0.15914, 0.31814, 0.41982]
Predicted label: 4
Correct prediction
Energy consumption = 197.764785 pJ
sum error= 71
Actual label: 7
Output voltages: [0.29968, 0.25355, 0.27174, 0.25749, 0.16218, 0.05039, 0.049916, 0.75522, 0.28461, 0.35278]
Predicted label: 7
Correct prediction
Energy consumption = 201.997305 pJ
sum error= 71
Actual label: 3
Output voltages: [0.23329, 0.10337, 0.26766, 0.73197, 0.31844, 0.28766, 0.19126, 0.19475, 0.46914, 0.20121]
Predicted label: 3
Correct prediction
Energy consumption = 184.051750 pJ
sum error= 71
Actual label: 2
Output voltages: [0.39747, 0.36798, 0.70921, 0.33666, 0.11163, 0.028415, 0.29963, 0.25144, 0.42872, 0.21364]
Predicted label: 2
Correct prediction
Energy consumption = 189.305116 pJ
sum error= 71
Actual label: 3
Output voltages: [0.25858, 0.18213, 0.30949, 0.75585, 0.19405, 0.22219, 0.10522, 0.25484, 0.45249, 0.2207]
Predicted label: 3
Correct prediction
Energy consumption = 174.138863 pJ
sum error= 71
Actual label: 4
Output voltages: [0.23841, 0.18929, 0.2143, 0.21007, 0.71921, 0.076254, 0.23139, 0.23888, 0.23469, 0.37271]
Predicted label: 4
Correct prediction
Energy consumption = 200.365207 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 193 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 193 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 193 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31065, 0.19015, 0.72763, 0.30693, 0.35613, 0.036078, 0.21192, 0.27258, 0.34167, 0.18961]
Predicted label: 2
Correct prediction
Energy consumption = 188.693570 pJ
sum error= 71
Actual label: 5
Output voltages: [0.2156, 0.071502, 0.15418, 0.41218, 0.21451, 0.73809, 0.3525, 0.22648, 0.51324, 0.20643]
Predicted label: 5
Correct prediction
Energy consumption = 193.669248 pJ
sum error= 71
Actual label: 2
Output voltages: [0.3661, 0.22344, 0.73898, 0.36754, 0.18071, 0.033417, 0.21207, 0.40568, 0.38659, 0.18552]
Predicted label: 2
Correct prediction
Energy consumption = 185.943805 pJ
sum error= 71
Actual label: 7
Output voltages: [0.25517, 0.20404, 0.3633, 0.44983, 0.20975, 0.035574, 0.053097, 0.63291, 0.34719, 0.31472]
Predicted label: 7
Correct prediction
Energy consumption = 182.003388 pJ
sum error= 71
Actual label: 1
Output voltages: [0.23992, 0.76402, 0.25771, 0.28217, 0.19414, 0.10209, 0.33068, 0.13353, 0.3, 0.22203]
Predicted label: 1
Correct prediction
Energy consumption = 208.885741 pJ
sum error= 71
Actual label: 7
Output voltages: [0.31397, 0.23277, 0.22224, 0.22243, 0.17095, 0.089747, 0.040707, 0.75405, 0.36556, 0.34126]
Predicted label: 7
Correct prediction
Energy consumption = 193.929299 pJ
sum error= 71
Actual label: 2
Output voltages: [0.43011, 0.20356, 0.72981, 0.35454, 0.15013, 0.035681, 0.26145, 0.26978, 0.39818, 0.13555]
Predicted label: 2
Correct prediction
Energy consumption = 185.578081 pJ
sum error= 71
Actual label: 6
Output voltages: [0.2996, 0.20223, 0.19332, 0.19587, 0.29052, 0.41123, 0.71566, 0.11169, 0.48918, 0.13332]
Predicted label: 6
Correct prediction
Energy consumption = 195.388398 pJ
sum error= 71
Actual label: 4
Output voltages: [0.3067, 0.088865, 0.3513, 0.11893, 0.72688, 0.085747, 0.45891, 0.17516, 0.20652, 0.22693]
Predicted label: 4
Correct prediction
Energy consumption = 200.710659 pJ
sum error= 71
Actual label: 1
Output voltages: [0.2229, 0.77033, 0.18231, 0.32908, 0.20251, 0.18141, 0.34065, 0.1838, 0.28269, 0.24151]
Predicted label: 1
Correct prediction
Energy consumption = 206.597738 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 194 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 194 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 194 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.38, 0.083562, 0.046581, 0.25645, 0.21096, 0.73301, 0.35604, 0.14711, 0.50436, 0.22087]
Predicted label: 5
Correct prediction
Energy consumption = 195.615308 pJ
sum error= 71
Actual label: 7
Output voltages: [0.29337, 0.090599, 0.51806, 0.30747, 0.19163, 0.086532, 0.072133, 0.66908, 0.33311, 0.26647]
Predicted label: 7
Correct prediction
Energy consumption = 194.409109 pJ
sum error= 71
Actual label: 8
Output voltages: [0.17079, 0.16583, 0.36185, 0.19431, 0.28473, 0.14692, 0.21849, 0.10307, 0.72934, 0.27971]
Predicted label: 8
Correct prediction
Energy consumption = 202.342129 pJ
sum error= 71
Actual label: 6
Output voltages: [0.34873, 0.2891, 0.19204, 0.22784, 0.2218, 0.36297, 0.70878, 0.13503, 0.47252, 0.10225]
Predicted label: 6
Correct prediction
Energy consumption = 193.618902 pJ
sum error= 71
Actual label: 0
Output voltages: [0.7149, 0.23858, 0.27269, 0.18087, 0.10473, 0.15037, 0.42581, 0.18728, 0.29968, 0.29567]
Predicted label: 0
Correct prediction
Energy consumption = 185.881049 pJ
sum error= 71
Actual label: 1
Output voltages: [0.19522, 0.70248, 0.32201, 0.36648, 0.25994, 0.074926, 0.43747, 0.069681, 0.32693, 0.18439]
Predicted label: 1
Correct prediction
Energy consumption = 209.507194 pJ
sum error= 71
Actual label: 8
Output voltages: [0.19737, 0.19272, 0.28256, 0.28275, 0.12234, 0.23584, 0.19212, 0.16549, 0.75164, 0.23724]
Predicted label: 8
Correct prediction
Energy consumption = 192.501500 pJ
sum error= 71
Actual label: 2
Output voltages: [0.36072, 0.17971, 0.74915, 0.25987, 0.13556, 0.037261, 0.26372, 0.37256, 0.42968, 0.13485]
Predicted label: 2
Correct prediction
Energy consumption = 182.209081 pJ
sum error= 71
Actual label: 5
Output voltages: [0.30841, 0.071918, 0.051781, 0.36029, 0.34408, 0.59261, 0.14324, 0.32912, 0.37592, 0.31549]
Predicted label: 5
Correct prediction
Energy consumption = 197.089875 pJ
sum error= 71
Actual label: 7
Output voltages: [0.42769, 0.22463, 0.35874, 0.27078, 0.1746, 0.052433, 0.049764, 0.70297, 0.28052, 0.30706]
Predicted label: 7
Correct prediction
Energy consumption = 195.492273 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 195 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 195 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 195 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.348, 0.19906, 0.19079, 0.2822, 0.17376, 0.11776, 0.046495, 0.76362, 0.30949, 0.31555]
Predicted label: 7
Correct prediction
Energy consumption = 198.573667 pJ
sum error= 71
Actual label: 6
Output voltages: [0.27348, 0.24288, 0.28408, 0.091021, 0.37966, 0.36806, 0.73353, 0.14459, 0.34887, 0.077642]
Predicted label: 6
Correct prediction
Energy consumption = 199.276556 pJ
sum error= 71
Actual label: 9
Output voltages: [0.32356, 0.10271, 0.24441, 0.44418, 0.35959, 0.16911, 0.066185, 0.12188, 0.3306, 0.53481]
Predicted label: 9
Correct prediction
Energy consumption = 210.007309 pJ
sum error= 71
Actual label: 3
Output voltages: [0.31568, 0.22363, 0.25826, 0.74493, 0.13403, 0.31028, 0.12597, 0.18088, 0.48408, 0.25849]
Predicted label: 3
Correct prediction
Energy consumption = 189.647762 pJ
sum error= 71
Actual label: 5
Output voltages: [0.28147, 0.063175, 0.18325, 0.35048, 0.13222, 0.6425, 0.25684, 0.15194, 0.52258, 0.32564]
Predicted label: 5
Correct prediction
Energy consumption = 195.863757 pJ
sum error= 71
Actual label: 8
Output voltages: [0.31486, 0.23383, 0.4111, 0.45776, 0.14155, 0.058874, 0.28413, 0.053517, 0.6096, 0.2771]
Predicted label: 8
Correct prediction
Energy consumption = 201.917581 pJ
sum error= 71
Actual label: 4
Output voltages: [0.27182, 0.13044, 0.36137, 0.14151, 0.7303, 0.040866, 0.30686, 0.23282, 0.22359, 0.36882]
Predicted label: 4
Correct prediction
Energy consumption = 191.251115 pJ
sum error= 71
Actual label: 2
Output voltages: [0.33905, 0.232, 0.74071, 0.27233, 0.28662, 0.044715, 0.31886, 0.227, 0.36251, 0.15916]
Predicted label: 2
Correct prediction
Energy consumption = 185.231827 pJ
sum error= 71
Actual label: 4
Output voltages: [0.12337, 0.18494, 0.30032, 0.1386, 0.76426, 0.078869, 0.28559, 0.3409, 0.19646, 0.27715]
Predicted label: 4
Correct prediction
Energy consumption = 197.100954 pJ
sum error= 71
Actual label: 0
Output voltages: [0.73301, 0.25501, 0.23699, 0.20099, 0.20605, 0.12174, 0.41174, 0.15911, 0.27015, 0.34739]
Predicted label: 0
Correct prediction
Energy consumption = 204.596517 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 196 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 196 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 196 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2287, 0.20662, 0.35522, 0.29089, 0.13207, 0.23678, 0.24831, 0.095583, 0.74494, 0.284]
Predicted label: 8
Correct prediction
Energy consumption = 194.702226 pJ
sum error= 71
Actual label: 8
Output voltages: [0.24339, 0.18666, 0.34313, 0.28154, 0.14393, 0.19007, 0.24798, 0.10428, 0.73503, 0.23308]
Predicted label: 8
Correct prediction
Energy consumption = 196.684579 pJ
sum error= 71
Actual label: 3
Output voltages: [0.25139, 0.19858, 0.2781, 0.75477, 0.11957, 0.20896, 0.1417, 0.26148, 0.51919, 0.19913]
Predicted label: 3
Correct prediction
Energy consumption = 183.679210 pJ
sum error= 71
Actual label: 4
Output voltages: [0.23303, 0.14688, 0.31801, 0.17515, 0.72849, 0.054439, 0.28016, 0.34015, 0.17225, 0.36295]
Predicted label: 4
Correct prediction
Energy consumption = 199.884412 pJ
sum error= 71
Actual label: 9
Output voltages: [0.38811, 0.19355, 0.20681, 0.31296, 0.35076, 0.15356, 0.13308, 0.33074, 0.23322, 0.67534]
Predicted label: 9
Correct prediction
Energy consumption = 199.992562 pJ
sum error= 71
Actual label: 2
Output voltages: [0.39581, 0.39547, 0.70353, 0.32293, 0.22027, 0.035988, 0.24633, 0.29406, 0.30726, 0.17604]
Predicted label: 2
Correct prediction
Energy consumption = 198.552430 pJ
sum error= 71
Actual label: 7
Output voltages: [0.38547, 0.15035, 0.20589, 0.32626, 0.10662, 0.14091, 0.039044, 0.75093, 0.46411, 0.31214]
Predicted label: 7
Correct prediction
Energy consumption = 193.974983 pJ
sum error= 71
Actual label: 5
Output voltages: [0.26144, 0.061405, 0.1105, 0.35339, 0.22194, 0.7192, 0.28373, 0.14417, 0.52568, 0.25125]
Predicted label: 5
Correct prediction
Energy consumption = 183.016184 pJ
sum error= 71
Actual label: 8
Output voltages: [0.15122, 0.32474, 0.19147, 0.35184, 0.15459, 0.25725, 0.22544, 0.060508, 0.70016, 0.32835]
Predicted label: 8
Correct prediction
Energy consumption = 200.214334 pJ
sum error= 71
Actual label: 6
Output voltages: [0.47932, 0.28859, 0.23472, 0.14907, 0.28236, 0.21545, 0.66898, 0.091199, 0.33371, 0.16301]
Predicted label: 6
Correct prediction
Energy consumption = 199.132553 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 197 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 197 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 197 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24806, 0.055456, 0.10894, 0.33617, 0.26326, 0.71215, 0.24432, 0.22728, 0.55205, 0.31703]
Predicted label: 5
Correct prediction
Energy consumption = 186.279597 pJ
sum error= 71
Actual label: 6
Output voltages: [0.26311, 0.18194, 0.29653, 0.062703, 0.27401, 0.36118, 0.72847, 0.069998, 0.4636, 0.15027]
Predicted label: 6
Correct prediction
Energy consumption = 182.208417 pJ
sum error= 71
Actual label: 0
Output voltages: [0.73662, 0.21272, 0.25064, 0.24995, 0.15785, 0.13388, 0.2685, 0.1812, 0.40184, 0.31432]
Predicted label: 0
Correct prediction
Energy consumption = 192.920338 pJ
sum error= 71
Actual label: 8
Output voltages: [0.35849, 0.079222, 0.31532, 0.42822, 0.14354, 0.34112, 0.22713, 0.099559, 0.72148, 0.2355]
Predicted label: 8
Correct prediction
Energy consumption = 195.407101 pJ
sum error= 71
Actual label: 6
Output voltages: [0.29378, 0.19037, 0.25574, 0.12607, 0.3317, 0.34211, 0.73343, 0.069853, 0.42278, 0.13338]
Predicted label: 6
Correct prediction
Energy consumption = 190.518745 pJ
sum error= 71
Actual label: 7
Output voltages: [0.28147, 0.28346, 0.32249, 0.19982, 0.23497, 0.060552, 0.044296, 0.7628, 0.27522, 0.25542]
Predicted label: 7
Correct prediction
Energy consumption = 192.109375 pJ
sum error= 71
Actual label: 3
Output voltages: [0.29369, 0.14688, 0.27922, 0.72611, 0.17558, 0.3598, 0.13788, 0.19459, 0.43341, 0.25229]
Predicted label: 3
Correct prediction
Energy consumption = 192.963995 pJ
sum error= 71
Actual label: 6
Output voltages: [0.37962, 0.20634, 0.2123, 0.0954, 0.34871, 0.4221, 0.733, 0.10396, 0.35334, 0.15541]
Predicted label: 6
Correct prediction
Energy consumption = 187.516248 pJ
sum error= 71
Actual label: 4
Output voltages: [0.12749, 0.15813, 0.21853, 0.13383, 0.75437, 0.11499, 0.26899, 0.32508, 0.32139, 0.18508]
Predicted label: 4
Correct prediction
Energy consumption = 202.920353 pJ
sum error= 71
Actual label: 9
Output voltages: [0.42599, 0.12359, 0.19922, 0.20644, 0.39883, 0.24916, 0.19943, 0.29815, 0.23113, 0.68612]
Predicted label: 9
Correct prediction
Energy consumption = 191.505523 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 198 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 198 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 198 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15034, 0.14885, 0.28473, 0.22782, 0.74796, 0.045757, 0.20796, 0.28163, 0.22329, 0.23328]
Predicted label: 4
Correct prediction
Energy consumption = 198.171841 pJ
sum error= 71
Actual label: 6
Output voltages: [0.32895, 0.22883, 0.2697, 0.12028, 0.31133, 0.29308, 0.72714, 0.055734, 0.28574, 0.25742]
Predicted label: 6
Correct prediction
Energy consumption = 196.577475 pJ
sum error= 71
Actual label: 6
Output voltages: [0.29696, 0.087556, 0.23867, 0.21205, 0.2499, 0.385, 0.56123, 0.066403, 0.57434, 0.11821]
Predicted label: 8
Wrong prediction!
Energy consumption = 185.373248 pJ
sum error= 72
Actual label: 3
Output voltages: [0.32846, 0.25785, 0.41793, 0.72733, 0.12962, 0.076774, 0.18604, 0.12787, 0.44966, 0.17872]
Predicted label: 3
Correct prediction
Energy consumption = 190.933296 pJ
sum error= 72
Actual label: 2
Output voltages: [0.52278, 0.24815, 0.55133, 0.19629, 0.042671, 0.18101, 0.37043, 0.14441, 0.36819, 0.23411]
Predicted label: 2
Correct prediction
Energy consumption = 192.098169 pJ
sum error= 72
Actual label: 4
Output voltages: [0.12645, 0.16686, 0.18846, 0.11847, 0.7525, 0.12264, 0.32984, 0.23987, 0.23573, 0.2477]
Predicted label: 4
Correct prediction
Energy consumption = 196.860920 pJ
sum error= 72
Actual label: 1
Output voltages: [0.23329, 0.76643, 0.2872, 0.24813, 0.28883, 0.09152, 0.32964, 0.13748, 0.26861, 0.27436]
Predicted label: 1
Correct prediction
Energy consumption = 207.165967 pJ
sum error= 72
Actual label: 0
Output voltages: [0.72638, 0.17111, 0.27933, 0.15878, 0.16627, 0.14771, 0.36551, 0.22682, 0.23058, 0.37116]
Predicted label: 0
Correct prediction
Energy consumption = 189.846059 pJ
sum error= 72
Actual label: 1
Output voltages: [0.19635, 0.73768, 0.42017, 0.18982, 0.36576, 0.066877, 0.35092, 0.070423, 0.23905, 0.25891]
Predicted label: 1
Correct prediction
Energy consumption = 209.071228 pJ
sum error= 72
Actual label: 4
Output voltages: [0.28309, 0.2839, 0.27776, 0.19157, 0.70307, 0.072884, 0.39957, 0.18324, 0.13745, 0.33368]
Predicted label: 4
Correct prediction
Energy consumption = 203.167595 pJ
sum error= 72
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 199 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 199 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 199 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.36202, 0.2218, 0.25401, 0.081312, 0.32443, 0.377, 0.73046, 0.12377, 0.30884, 0.10009]
Predicted label: 6
Correct prediction
Energy consumption = 192.498741 pJ
sum error= 72
Actual label: 2
Output voltages: [0.4036, 0.22132, 0.73807, 0.31415, 0.12507, 0.031978, 0.21029, 0.35001, 0.37914, 0.19798]
Predicted label: 2
Correct prediction
Energy consumption = 192.530093 pJ
sum error= 72
Actual label: 9
Output voltages: [0.29623, 0.12395, 0.20287, 0.16936, 0.25154, 0.14537, 0.083877, 0.17975, 0.57097, 0.59087]
Predicted label: 9
Correct prediction
Energy consumption = 189.276279 pJ
sum error= 72
Actual label: 1
Output voltages: [0.26447, 0.64933, 0.32987, 0.18234, 0.20048, 0.048431, 0.28148, 0.13426, 0.40367, 0.22027]
Predicted label: 1
Correct prediction
Energy consumption = 193.220280 pJ
sum error= 72
Actual label: 1
Output voltages: [0.23256, 0.77074, 0.24537, 0.2552, 0.23179, 0.088089, 0.31316, 0.10347, 0.28219, 0.29648]
Predicted label: 1
Correct prediction
Energy consumption = 209.265435 pJ
sum error= 72
Actual label: 0
Output voltages: [0.74292, 0.30317, 0.23956, 0.2982, 0.076623, 0.24569, 0.31322, 0.13448, 0.32543, 0.27211]
Predicted label: 0
Correct prediction
Energy consumption = 202.501308 pJ
sum error= 72
Actual label: 6
Output voltages: [0.30605, 0.14882, 0.19926, 0.19067, 0.29185, 0.46414, 0.69454, 0.06063, 0.47504, 0.15485]
Predicted label: 6
Correct prediction
Energy consumption = 183.939896 pJ
sum error= 72
Actual label: 3
Output voltages: [0.36773, 0.19611, 0.27668, 0.76389, 0.15553, 0.19629, 0.15002, 0.16218, 0.41857, 0.23731]
Predicted label: 3
Correct prediction
Energy consumption = 182.768444 pJ
sum error= 72
Actual label: 9
Output voltages: [0.41099, 0.146, 0.20549, 0.31517, 0.35648, 0.17231, 0.16799, 0.18115, 0.28769, 0.72337]
Predicted label: 9
Correct prediction
Energy consumption = 200.986646 pJ
sum error= 72
Actual label: 5
Output voltages: [0.21447, 0.049198, 0.17077, 0.40463, 0.15734, 0.62867, 0.15629, 0.21978, 0.55439, 0.33178]
Predicted label: 5
Correct prediction
Energy consumption = 187.920794 pJ
sum error= 72
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 200 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 200 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 200 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27918, 0.13772, 0.21069, 0.18585, 0.32344, 0.45394, 0.69133, 0.067558, 0.44264, 0.13691]
Predicted label: 6
Correct prediction
Energy consumption = 192.585100 pJ
sum error= 72
Actual label: 5
Output voltages: [0.22846, 0.063423, 0.15877, 0.28605, 0.11859, 0.62701, 0.21606, 0.16901, 0.64766, 0.22587]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.573120 pJ
sum error= 73
Actual label: 6
Output voltages: [0.3472, 0.23087, 0.25057, 0.15248, 0.29766, 0.38736, 0.73197, 0.078851, 0.39169, 0.13843]
Predicted label: 6
Correct prediction
Energy consumption = 189.605100 pJ
sum error= 73
Actual label: 5
Output voltages: [0.22653, 0.051905, 0.054926, 0.33512, 0.26862, 0.72448, 0.34025, 0.12838, 0.46496, 0.21688]
Predicted label: 5
Correct prediction
Energy consumption = 191.533794 pJ
sum error= 73
Actual label: 8
Output voltages: [0.24377, 0.19561, 0.33139, 0.3765, 0.10631, 0.20668, 0.19775, 0.19371, 0.73643, 0.27967]
Predicted label: 8
Correct prediction
Energy consumption = 196.630828 pJ
sum error= 73
Actual label: 4
Output voltages: [0.22639, 0.15771, 0.33712, 0.10958, 0.74801, 0.064475, 0.38896, 0.18648, 0.20545, 0.26205]
Predicted label: 4
Correct prediction
Energy consumption = 200.937084 pJ
sum error= 73
Actual label: 6
Output voltages: [0.30269, 0.16178, 0.22735, 0.17445, 0.28747, 0.36003, 0.68615, 0.081594, 0.45131, 0.18255]
Predicted label: 6
Correct prediction
Energy consumption = 188.728323 pJ
sum error= 73
Actual label: 4
Output voltages: [0.13992, 0.18178, 0.30428, 0.10801, 0.76244, 0.13492, 0.2666, 0.2295, 0.27974, 0.31421]
Predicted label: 4
Correct prediction
Energy consumption = 194.086921 pJ
sum error= 73
Actual label: 3
Output voltages: [0.28344, 0.16589, 0.32256, 0.75173, 0.21923, 0.1472, 0.11636, 0.21335, 0.43878, 0.25254]
Predicted label: 3
Correct prediction
Energy consumption = 186.512308 pJ
sum error= 73
Actual label: 9
Output voltages: [0.40271, 0.097217, 0.23381, 0.24986, 0.19001, 0.16649, 0.17528, 0.30528, 0.41072, 0.62191]
Predicted label: 9
Correct prediction
Energy consumption = 192.366767 pJ
sum error= 73
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 201 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 201 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 201 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20473, 0.75613, 0.27612, 0.27, 0.24855, 0.13271, 0.42321, 0.10085, 0.23021, 0.22825]
Predicted label: 1
Correct prediction
Energy consumption = 209.769529 pJ
sum error= 73
Actual label: 3
Output voltages: [0.2376, 0.30905, 0.30408, 0.75456, 0.1408, 0.098571, 0.090705, 0.2884, 0.37896, 0.30657]
Predicted label: 3
Correct prediction
Energy consumption = 195.285127 pJ
sum error= 73
Actual label: 4
Output voltages: [0.13516, 0.21553, 0.30169, 0.088007, 0.73839, 0.058984, 0.23224, 0.23581, 0.2843, 0.32485]
Predicted label: 4
Correct prediction
Energy consumption = 200.741051 pJ
sum error= 73
Actual label: 1
Output voltages: [0.21768, 0.75775, 0.20287, 0.32498, 0.25125, 0.1331, 0.27441, 0.079463, 0.30668, 0.31482]
Predicted label: 1
Correct prediction
Energy consumption = 209.072358 pJ
sum error= 73
Actual label: 9
Output voltages: [0.36301, 0.17385, 0.21633, 0.31225, 0.3554, 0.20107, 0.17242, 0.19397, 0.29535, 0.69805]
Predicted label: 9
Correct prediction
Energy consumption = 199.614664 pJ
sum error= 73
Actual label: 1
Output voltages: [0.24597, 0.75816, 0.2868, 0.29582, 0.19934, 0.077539, 0.35055, 0.054073, 0.31301, 0.30649]
Predicted label: 1
Correct prediction
Energy consumption = 208.128026 pJ
sum error= 73
Actual label: 7
Output voltages: [0.32418, 0.088859, 0.64599, 0.31831, 0.16342, 0.037349, 0.11854, 0.44502, 0.51573, 0.21123]
Predicted label: 2
Wrong prediction!
Energy consumption = 196.068853 pJ
sum error= 74
Actual label: 1
Output voltages: [0.24332, 0.72974, 0.14435, 0.2426, 0.30036, 0.076795, 0.17415, 0.21151, 0.40704, 0.28646]
Predicted label: 1
Correct prediction
Energy consumption = 214.954276 pJ
sum error= 74
Actual label: 1
Output voltages: [0.40238, 0.42466, 0.35237, 0.27799, 0.054135, 0.045837, 0.18466, 0.42602, 0.49985, 0.23293]
Predicted label: 8
Wrong prediction!
Energy consumption = 210.173396 pJ
sum error= 75
Actual label: 9
Output voltages: [0.34716, 0.15827, 0.19493, 0.23942, 0.43512, 0.14616, 0.081263, 0.22152, 0.28882, 0.67506]
Predicted label: 9
Correct prediction
Energy consumption = 190.326615 pJ
sum error= 75
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 202 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 202 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 202 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.25255, 0.10314, 0.26633, 0.74815, 0.22245, 0.32213, 0.17041, 0.20193, 0.41782, 0.21839]
Predicted label: 3
Correct prediction
Energy consumption = 185.083802 pJ
sum error= 75
Actual label: 5
Output voltages: [0.18646, 0.055773, 0.11927, 0.31799, 0.26011, 0.64472, 0.21272, 0.16579, 0.51728, 0.32056]
Predicted label: 5
Correct prediction
Energy consumption = 183.798732 pJ
sum error= 75
Actual label: 4
Output voltages: [0.14726, 0.13001, 0.3423, 0.1496, 0.75786, 0.11077, 0.27174, 0.24788, 0.23685, 0.27476]
Predicted label: 4
Correct prediction
Energy consumption = 204.360205 pJ
sum error= 75
Actual label: 0
Output voltages: [0.69295, 0.26115, 0.26622, 0.16906, 0.063523, 0.26491, 0.38484, 0.10928, 0.33369, 0.28359]
Predicted label: 0
Correct prediction
Energy consumption = 196.058606 pJ
sum error= 75
Actual label: 7
Output voltages: [0.47266, 0.31682, 0.21944, 0.16179, 0.17845, 0.081908, 0.10798, 0.58928, 0.36335, 0.42749]
Predicted label: 7
Correct prediction
Energy consumption = 211.619300 pJ
sum error= 75
Actual label: 3
Output voltages: [0.37172, 0.16731, 0.25108, 0.73325, 0.1007, 0.25574, 0.28517, 0.19473, 0.40178, 0.15229]
Predicted label: 3
Correct prediction
Energy consumption = 202.371811 pJ
sum error= 75
Actual label: 6
Output voltages: [0.28919, 0.19737, 0.31944, 0.10206, 0.31752, 0.34241, 0.74508, 0.10993, 0.3838, 0.12621]
Predicted label: 6
Correct prediction
Energy consumption = 191.820493 pJ
sum error= 75
Actual label: 1
Output voltages: [0.21192, 0.74821, 0.057973, 0.29395, 0.20648, 0.30798, 0.39122, 0.082766, 0.30329, 0.22932]
Predicted label: 1
Correct prediction
Energy consumption = 210.067680 pJ
sum error= 75
Actual label: 7
Output voltages: [0.20982, 0.3921, 0.33713, 0.26787, 0.21119, 0.083432, 0.037782, 0.68244, 0.40285, 0.14773]
Predicted label: 7
Correct prediction
Energy consumption = 194.678612 pJ
sum error= 75
Actual label: 5
Output voltages: [0.28985, 0.09734, 0.05262, 0.25616, 0.15101, 0.61615, 0.37115, 0.29784, 0.44399, 0.32806]
Predicted label: 5
Correct prediction
Energy consumption = 203.977735 pJ
sum error= 75
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 203 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 203 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 203 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.16507, 0.055856, 0.1301, 0.28214, 0.28437, 0.65011, 0.33576, 0.11324, 0.56124, 0.28048]
Predicted label: 5
Correct prediction
Energy consumption = 189.635372 pJ
sum error= 75
Actual label: 3
Output voltages: [0.28884, 0.12101, 0.32441, 0.7509, 0.22085, 0.16235, 0.16519, 0.2048, 0.50501, 0.25162]
Predicted label: 3
Correct prediction
Energy consumption = 178.307925 pJ
sum error= 75
Actual label: 3
Output voltages: [0.32046, 0.19901, 0.32337, 0.76496, 0.19093, 0.17176, 0.15758, 0.22296, 0.42146, 0.25471]
Predicted label: 3
Correct prediction
Energy consumption = 169.235633 pJ
sum error= 75
Actual label: 0
Output voltages: [0.6891, 0.19588, 0.29137, 0.1954, 0.24751, 0.052461, 0.26593, 0.34381, 0.34772, 0.27364]
Predicted label: 0
Correct prediction
Energy consumption = 198.558883 pJ
sum error= 75
Actual label: 1
Output voltages: [0.20097, 0.77131, 0.1929, 0.37677, 0.1636, 0.22897, 0.32791, 0.21346, 0.30531, 0.2678]
Predicted label: 1
Correct prediction
Energy consumption = 214.886495 pJ
sum error= 75
Actual label: 5
Output voltages: [0.23656, 0.079951, 0.10335, 0.6261, 0.32293, 0.59372, 0.24033, 0.16962, 0.34964, 0.14419]
Predicted label: 3
Wrong prediction!
Energy consumption = 199.118086 pJ
sum error= 76
Actual label: 7
Output voltages: [0.30998, 0.24742, 0.18684, 0.19389, 0.19643, 0.13773, 0.048792, 0.75494, 0.2276, 0.4128]
Predicted label: 7
Correct prediction
Energy consumption = 198.545505 pJ
sum error= 76
Actual label: 5
Output voltages: [0.36074, 0.046173, 0.17941, 0.34086, 0.14234, 0.63134, 0.38326, 0.17932, 0.50438, 0.21925]
Predicted label: 5
Correct prediction
Energy consumption = 189.721923 pJ
sum error= 76
Actual label: 8
Output voltages: [0.21764, 0.43469, 0.23689, 0.35891, 0.080591, 0.13356, 0.24133, 0.10532, 0.71687, 0.32869]
Predicted label: 8
Correct prediction
Energy consumption = 201.528854 pJ
sum error= 76
Actual label: 6
Output voltages: [0.37064, 0.296, 0.33609, 0.15431, 0.15894, 0.27309, 0.71143, 0.10568, 0.42408, 0.2067]
Predicted label: 6
Correct prediction
Energy consumption = 195.099182 pJ
sum error= 76
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 204 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 204 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 204 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.34637, 0.081317, 0.083619, 0.39451, 0.23654, 0.678, 0.38752, 0.0554, 0.47376, 0.15267]
Predicted label: 5
Correct prediction
Energy consumption = 193.797940 pJ
sum error= 76
Actual label: 1
Output voltages: [0.22863, 0.76527, 0.30127, 0.31361, 0.22634, 0.087629, 0.30233, 0.21058, 0.31574, 0.23543]
Predicted label: 1
Correct prediction
Energy consumption = 215.437248 pJ
sum error= 76
Actual label: 0
Output voltages: [0.72422, 0.26912, 0.22061, 0.19311, 0.15089, 0.20789, 0.40919, 0.16802, 0.31638, 0.31242]
Predicted label: 0
Correct prediction
Energy consumption = 202.181897 pJ
sum error= 76
Actual label: 4
Output voltages: [0.10128, 0.29112, 0.19486, 0.13561, 0.52288, 0.17191, 0.42332, 0.12489, 0.46729, 0.25463]
Predicted label: 4
Correct prediction
Energy consumption = 197.503155 pJ
sum error= 76
Actual label: 2
Output voltages: [0.40745, 0.24786, 0.5569, 0.21518, 0.037787, 0.059044, 0.16795, 0.41934, 0.46425, 0.27037]
Predicted label: 2
Correct prediction
Energy consumption = 195.284329 pJ
sum error= 76
Actual label: 3
Output voltages: [0.36297, 0.11783, 0.27867, 0.75232, 0.18863, 0.35971, 0.15213, 0.14181, 0.43699, 0.22674]
Predicted label: 3
Correct prediction
Energy consumption = 180.674849 pJ
sum error= 76
Actual label: 4
Output voltages: [0.13495, 0.13686, 0.25505, 0.1361, 0.7488, 0.11969, 0.25489, 0.29712, 0.3129, 0.2247]
Predicted label: 4
Correct prediction
Energy consumption = 190.359412 pJ
sum error= 76
Actual label: 6
Output voltages: [0.3947, 0.15267, 0.25495, 0.096292, 0.26469, 0.39995, 0.68272, 0.10741, 0.35956, 0.12975]
Predicted label: 6
Correct prediction
Energy consumption = 190.604572 pJ
sum error= 76
Actual label: 7
Output voltages: [0.33179, 0.20458, 0.23911, 0.19937, 0.19207, 0.090101, 0.049076, 0.66586, 0.35642, 0.4814]
Predicted label: 7
Correct prediction
Energy consumption = 203.873457 pJ
sum error= 76
Actual label: 9
Output voltages: [0.41739, 0.16348, 0.26136, 0.28169, 0.44299, 0.071048, 0.17611, 0.14511, 0.23764, 0.6875]
Predicted label: 9
Correct prediction
Energy consumption = 197.231487 pJ
sum error= 76
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 205 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 205 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 205 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.3389, 0.26129, 0.31916, 0.31082, 0.12995, 0.12138, 0.24847, 0.087442, 0.6979, 0.37668]
Predicted label: 8
Correct prediction
Energy consumption = 202.944614 pJ
sum error= 76
Actual label: 1
Output voltages: [0.21716, 0.76618, 0.20381, 0.33691, 0.3059, 0.1188, 0.39462, 0.15612, 0.24824, 0.23117]
Predicted label: 1
Correct prediction
Energy consumption = 208.309288 pJ
sum error= 76
Actual label: 8
Output voltages: [0.2384, 0.14677, 0.28259, 0.17178, 0.49319, 0.18265, 0.37155, 0.074704, 0.53759, 0.18549]
Predicted label: 8
Correct prediction
Energy consumption = 192.337192 pJ
sum error= 76
Actual label: 4
Output voltages: [0.17778, 0.15458, 0.22856, 0.18218, 0.4397, 0.1364, 0.16556, 0.19462, 0.40626, 0.46673]
Predicted label: 9
Wrong prediction!
Energy consumption = 191.101374 pJ
sum error= 77
Actual label: 9
Output voltages: [0.32561, 0.10361, 0.21023, 0.30277, 0.33911, 0.15579, 0.066755, 0.22781, 0.38773, 0.64453]
Predicted label: 9
Correct prediction
Energy consumption = 188.201201 pJ
sum error= 77
Actual label: 2
Output voltages: [0.35805, 0.27285, 0.73494, 0.31749, 0.12095, 0.036364, 0.24365, 0.35869, 0.40532, 0.19616]
Predicted label: 2
Correct prediction
Energy consumption = 187.849883 pJ
sum error= 77
Actual label: 8
Output voltages: [0.32141, 0.19455, 0.30739, 0.44951, 0.11029, 0.12192, 0.16278, 0.091696, 0.70951, 0.27485]
Predicted label: 8
Correct prediction
Energy consumption = 189.447503 pJ
sum error= 77
Actual label: 6
Output voltages: [0.34401, 0.32657, 0.31936, 0.098875, 0.32383, 0.30737, 0.72724, 0.074836, 0.32392, 0.15913]
Predicted label: 6
Correct prediction
Energy consumption = 198.334441 pJ
sum error= 77
Actual label: 2
Output voltages: [0.3633, 0.29837, 0.71133, 0.27476, 0.083281, 0.032257, 0.20366, 0.42344, 0.4135, 0.15478]
Predicted label: 2
Correct prediction
Energy consumption = 188.629327 pJ
sum error= 77
Actual label: 7
Output voltages: [0.30025, 0.37017, 0.29968, 0.35125, 0.12965, 0.040572, 0.049449, 0.72271, 0.21946, 0.36708]
Predicted label: 7
Correct prediction
Energy consumption = 196.634217 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 206 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 206 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 206 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69588, 0.18673, 0.22853, 0.1571, 0.20872, 0.18581, 0.48993, 0.2359, 0.33706, 0.23536]
Predicted label: 0
Correct prediction
Energy consumption = 199.056856 pJ
sum error= 77
Actual label: 0
Output voltages: [0.71624, 0.20757, 0.22955, 0.25723, 0.17011, 0.15294, 0.45473, 0.18272, 0.34218, 0.26431]
Predicted label: 0
Correct prediction
Energy consumption = 198.248829 pJ
sum error= 77
Actual label: 6
Output voltages: [0.27403, 0.25864, 0.33496, 0.071016, 0.37121, 0.30759, 0.75149, 0.067817, 0.343, 0.16675]
Predicted label: 6
Correct prediction
Energy consumption = 189.364511 pJ
sum error= 77
Actual label: 7
Output voltages: [0.22004, 0.29206, 0.48458, 0.32264, 0.19696, 0.031167, 0.14063, 0.62701, 0.41589, 0.082534]
Predicted label: 7
Correct prediction
Energy consumption = 191.513241 pJ
sum error= 77
Actual label: 5
Output voltages: [0.19611, 0.050244, 0.12754, 0.36976, 0.2365, 0.7217, 0.33878, 0.13915, 0.49684, 0.21438]
Predicted label: 5
Correct prediction
Energy consumption = 191.205920 pJ
sum error= 77
Actual label: 8
Output voltages: [0.24606, 0.12003, 0.23913, 0.32136, 0.18625, 0.27172, 0.22848, 0.059689, 0.71649, 0.32784]
Predicted label: 8
Correct prediction
Energy consumption = 195.164920 pJ
sum error= 77
Actual label: 6
Output voltages: [0.40566, 0.17914, 0.1695, 0.16763, 0.32124, 0.46195, 0.67357, 0.11979, 0.41943, 0.075107]
Predicted label: 6
Correct prediction
Energy consumption = 192.378559 pJ
sum error= 77
Actual label: 0
Output voltages: [0.67928, 0.18236, 0.26191, 0.16722, 0.22894, 0.1041, 0.39454, 0.18609, 0.38593, 0.24119]
Predicted label: 0
Correct prediction
Energy consumption = 195.266380 pJ
sum error= 77
Actual label: 9
Output voltages: [0.27938, 0.066523, 0.27931, 0.17474, 0.5146, 0.27207, 0.19718, 0.20542, 0.30072, 0.61502]
Predicted label: 9
Correct prediction
Energy consumption = 203.411469 pJ
sum error= 77
Actual label: 3
Output voltages: [0.3392, 0.18413, 0.28135, 0.75499, 0.18582, 0.22671, 0.26709, 0.15919, 0.35491, 0.17229]
Predicted label: 3
Correct prediction
Energy consumption = 184.451124 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 207 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 207 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 207 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28961, 0.24604, 0.24715, 0.076692, 0.4256, 0.048882, 0.25024, 0.26123, 0.3325, 0.54544]
Predicted label: 9
Wrong prediction!
Energy consumption = 207.651778 pJ
sum error= 78
Actual label: 1
Output voltages: [0.18381, 0.75254, 0.11511, 0.27887, 0.24609, 0.14317, 0.17725, 0.22054, 0.21435, 0.35587]
Predicted label: 1
Correct prediction
Energy consumption = 214.093699 pJ
sum error= 78
Actual label: 3
Output voltages: [0.26873, 0.16675, 0.36694, 0.73537, 0.15978, 0.14646, 0.16697, 0.12696, 0.53888, 0.16775]
Predicted label: 3
Correct prediction
Energy consumption = 187.088806 pJ
sum error= 78
Actual label: 5
Output voltages: [0.49403, 0.21246, 0.070734, 0.31049, 0.13731, 0.62846, 0.49574, 0.17466, 0.36273, 0.16142]
Predicted label: 5
Correct prediction
Energy consumption = 197.319675 pJ
sum error= 78
Actual label: 4
Output voltages: [0.13262, 0.17221, 0.20804, 0.14591, 0.6912, 0.087354, 0.24842, 0.22844, 0.35122, 0.26344]
Predicted label: 4
Correct prediction
Energy consumption = 199.201006 pJ
sum error= 78
Actual label: 3
Output voltages: [0.33479, 0.13764, 0.35103, 0.73935, 0.1924, 0.090958, 0.22152, 0.17196, 0.46486, 0.1762]
Predicted label: 3
Correct prediction
Energy consumption = 189.989357 pJ
sum error= 78
Actual label: 3
Output voltages: [0.31087, 0.18528, 0.3447, 0.75372, 0.20154, 0.1275, 0.12809, 0.14831, 0.41873, 0.24668]
Predicted label: 3
Correct prediction
Energy consumption = 176.744169 pJ
sum error= 78
Actual label: 5
Output voltages: [0.25426, 0.064328, 0.10962, 0.48762, 0.20317, 0.66697, 0.24153, 0.18222, 0.47391, 0.25357]
Predicted label: 5
Correct prediction
Energy consumption = 181.474730 pJ
sum error= 78
Actual label: 5
Output voltages: [0.29472, 0.077775, 0.070028, 0.42283, 0.18806, 0.71349, 0.30536, 0.088558, 0.48206, 0.22978]
Predicted label: 5
Correct prediction
Energy consumption = 186.394917 pJ
sum error= 78
Actual label: 6
Output voltages: [0.32449, 0.24261, 0.21417, 0.18889, 0.32143, 0.36189, 0.72813, 0.12282, 0.45182, 0.099974]
Predicted label: 6
Correct prediction
Energy consumption = 191.869159 pJ
sum error= 78
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 208 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 208 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 208 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23216, 0.19063, 0.2714, 0.74288, 0.1358, 0.24665, 0.072182, 0.29378, 0.53322, 0.18215]
Predicted label: 3
Correct prediction
Energy consumption = 181.133649 pJ
sum error= 78
Actual label: 0
Output voltages: [0.68732, 0.2426, 0.24716, 0.21499, 0.26116, 0.14326, 0.42552, 0.15246, 0.36411, 0.19091]
Predicted label: 0
Correct prediction
Energy consumption = 204.334161 pJ
sum error= 78
Actual label: 2
Output voltages: [0.368, 0.44849, 0.72094, 0.28751, 0.13084, 0.026099, 0.32462, 0.20901, 0.35431, 0.2344]
Predicted label: 2
Correct prediction
Energy consumption = 192.115204 pJ
sum error= 78
Actual label: 3
Output voltages: [0.37352, 0.18206, 0.30386, 0.75577, 0.18449, 0.158, 0.19637, 0.16114, 0.42131, 0.22956]
Predicted label: 3
Correct prediction
Energy consumption = 178.526927 pJ
sum error= 78
Actual label: 4
Output voltages: [0.17242, 0.10395, 0.26618, 0.12382, 0.68909, 0.19602, 0.32086, 0.253, 0.30555, 0.36468]
Predicted label: 4
Correct prediction
Energy consumption = 198.632121 pJ
sum error= 78
Actual label: 2
Output voltages: [0.31148, 0.30703, 0.71836, 0.32289, 0.15144, 0.02465, 0.25717, 0.2259, 0.39157, 0.20232]
Predicted label: 2
Correct prediction
Energy consumption = 187.923311 pJ
sum error= 78
Actual label: 3
Output voltages: [0.22215, 0.22029, 0.28802, 0.74682, 0.14726, 0.15803, 0.10254, 0.21894, 0.40844, 0.33237]
Predicted label: 3
Correct prediction
Energy consumption = 178.031885 pJ
sum error= 78
Actual label: 0
Output voltages: [0.72572, 0.24012, 0.24477, 0.165, 0.15417, 0.15023, 0.40017, 0.17955, 0.33481, 0.23906]
Predicted label: 0
Correct prediction
Energy consumption = 191.397981 pJ
sum error= 78
Actual label: 9
Output voltages: [0.36233, 0.098215, 0.22228, 0.23107, 0.28942, 0.198, 0.11623, 0.27294, 0.38822, 0.69631]
Predicted label: 9
Correct prediction
Energy consumption = 195.359626 pJ
sum error= 78
Actual label: 9
Output voltages: [0.34496, 0.18317, 0.19269, 0.27794, 0.35095, 0.19719, 0.075106, 0.24024, 0.27472, 0.71751]
Predicted label: 9
Correct prediction
Energy consumption = 191.780079 pJ
sum error= 78
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 209 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 209 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 209 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25282, 0.44532, 0.17665, 0.24349, 0.64711, 0.05192, 0.27018, 0.18793, 0.17554, 0.34771]
Predicted label: 4
Correct prediction
Energy consumption = 211.873903 pJ
sum error= 78
Actual label: 7
Output voltages: [0.31678, 0.23508, 0.055911, 0.41948, 0.054181, 0.25876, 0.041313, 0.64487, 0.36881, 0.45901]
Predicted label: 7
Correct prediction
Energy consumption = 201.023538 pJ
sum error= 78
Actual label: 2
Output voltages: [0.37729, 0.28829, 0.72377, 0.36934, 0.1635, 0.027495, 0.30858, 0.24342, 0.43784, 0.22299]
Predicted label: 2
Correct prediction
Energy consumption = 186.634820 pJ
sum error= 78
Actual label: 8
Output voltages: [0.2599, 0.5653, 0.31762, 0.30904, 0.32231, 0.048065, 0.19363, 0.055906, 0.43969, 0.29697]
Predicted label: 1
Wrong prediction!
Energy consumption = 196.534792 pJ
sum error= 79
Actual label: 4
Output voltages: [0.20583, 0.17544, 0.27002, 0.20907, 0.62813, 0.052826, 0.12897, 0.20587, 0.28287, 0.42268]
Predicted label: 4
Correct prediction
Energy consumption = 198.338197 pJ
sum error= 79
Actual label: 7
Output voltages: [0.27555, 0.22932, 0.37931, 0.47997, 0.18318, 0.053881, 0.057196, 0.6685, 0.21325, 0.34475]
Predicted label: 7
Correct prediction
Energy consumption = 192.118872 pJ
sum error= 79
Actual label: 0
Output voltages: [0.73547, 0.23714, 0.28084, 0.21887, 0.19779, 0.1229, 0.40936, 0.17825, 0.30363, 0.30671]
Predicted label: 0
Correct prediction
Energy consumption = 194.878142 pJ
sum error= 79
Actual label: 6
Output voltages: [0.30566, 0.18667, 0.22894, 0.17138, 0.24915, 0.42438, 0.71661, 0.10911, 0.44371, 0.096034]
Predicted label: 6
Correct prediction
Energy consumption = 193.129633 pJ
sum error= 79
Actual label: 2
Output voltages: [0.63671, 0.2217, 0.59503, 0.31138, 0.043521, 0.070889, 0.2551, 0.2946, 0.29889, 0.24028]
Predicted label: 0
Wrong prediction!
Energy consumption = 195.695758 pJ
sum error= 80
Actual label: 8
Output voltages: [0.17392, 0.18013, 0.23557, 0.20949, 0.16226, 0.22318, 0.23373, 0.28693, 0.71527, 0.2486]
Predicted label: 8
Correct prediction
Energy consumption = 190.686314 pJ
sum error= 80
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 210 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 210 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 210 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.26114, 0.047126, 0.19042, 0.2855, 0.21204, 0.62863, 0.27683, 0.12301, 0.63315, 0.24484]
Predicted label: 8
Wrong prediction!
Energy consumption = 193.912681 pJ
sum error= 81
Actual label: 2
Output voltages: [0.33553, 0.19596, 0.68195, 0.36233, 0.14937, 0.032427, 0.26657, 0.24819, 0.53878, 0.19609]
Predicted label: 2
Correct prediction
Energy consumption = 188.375576 pJ
sum error= 81
Actual label: 8
Output voltages: [0.26015, 0.18327, 0.32803, 0.29297, 0.19129, 0.13894, 0.22088, 0.13735, 0.74521, 0.26591]
Predicted label: 8
Correct prediction
Energy consumption = 188.882085 pJ
sum error= 81
Actual label: 5
Output voltages: [0.21036, 0.083068, 0.10368, 0.29463, 0.24835, 0.63233, 0.28637, 0.060479, 0.58743, 0.25651]
Predicted label: 5
Correct prediction
Energy consumption = 183.670152 pJ
sum error= 81
Actual label: 7
Output voltages: [0.33096, 0.26884, 0.26351, 0.35389, 0.11546, 0.064424, 0.051598, 0.75078, 0.23082, 0.33528]
Predicted label: 7
Correct prediction
Energy consumption = 203.510737 pJ
sum error= 81
Actual label: 3
Output voltages: [0.25921, 0.078454, 0.29557, 0.60171, 0.16672, 0.27405, 0.075151, 0.19489, 0.57584, 0.246]
Predicted label: 3
Correct prediction
Energy consumption = 191.596510 pJ
sum error= 81
Actual label: 0
Output voltages: [0.67462, 0.24982, 0.30565, 0.15606, 0.11855, 0.085633, 0.31027, 0.20627, 0.34373, 0.35289]
Predicted label: 0
Correct prediction
Energy consumption = 191.200031 pJ
sum error= 81
Actual label: 8
Output voltages: [0.48414, 0.12097, 0.25557, 0.32394, 0.17871, 0.26695, 0.30052, 0.082442, 0.66526, 0.36245]
Predicted label: 8
Correct prediction
Energy consumption = 192.381624 pJ
sum error= 81
Actual label: 2
Output voltages: [0.37441, 0.2477, 0.70196, 0.37336, 0.17241, 0.028208, 0.30831, 0.16367, 0.46486, 0.21626]
Predicted label: 2
Correct prediction
Energy consumption = 186.326790 pJ
sum error= 81
Actual label: 3
Output voltages: [0.09597, 0.2929, 0.4142, 0.29009, 0.2282, 0.22348, 0.084299, 0.37976, 0.46684, 0.27526]
Predicted label: 8
Wrong prediction!
Energy consumption = 195.202478 pJ
sum error= 82
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 211 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 211 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 211 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35447, 0.28835, 0.72608, 0.34602, 0.10837, 0.037843, 0.3208, 0.17881, 0.48517, 0.24493]
Predicted label: 2
Correct prediction
Energy consumption = 187.142790 pJ
sum error= 82
Actual label: 8
Output voltages: [0.24945, 0.11232, 0.35168, 0.28609, 0.14872, 0.2724, 0.20768, 0.14213, 0.74934, 0.26494]
Predicted label: 8
Correct prediction
Energy consumption = 183.429518 pJ
sum error= 82
Actual label: 2
Output voltages: [0.38218, 0.25024, 0.72717, 0.3276, 0.15044, 0.032088, 0.3013, 0.2619, 0.43497, 0.21731]
Predicted label: 2
Correct prediction
Energy consumption = 188.176444 pJ
sum error= 82
Actual label: 5
Output voltages: [0.20555, 0.076299, 0.075983, 0.3897, 0.23135, 0.71276, 0.33385, 0.12703, 0.5212, 0.20374]
Predicted label: 5
Correct prediction
Energy consumption = 186.525991 pJ
sum error= 82
Actual label: 5
Output voltages: [0.21012, 0.069308, 0.1163, 0.41718, 0.17795, 0.70899, 0.23677, 0.18981, 0.47802, 0.31183]
Predicted label: 5
Correct prediction
Energy consumption = 178.114984 pJ
sum error= 82
Actual label: 7
Output voltages: [0.52659, 0.21893, 0.14798, 0.098027, 0.1472, 0.21998, 0.1728, 0.64866, 0.35232, 0.33178]
Predicted label: 7
Correct prediction
Energy consumption = 198.754278 pJ
sum error= 82
Actual label: 6
Output voltages: [0.25978, 0.14582, 0.21833, 0.20345, 0.30788, 0.32, 0.6496, 0.045814, 0.54537, 0.21332]
Predicted label: 6
Correct prediction
Energy consumption = 185.945864 pJ
sum error= 82
Actual label: 4
Output voltages: [0.10794, 0.18673, 0.2504, 0.15239, 0.75474, 0.10928, 0.36559, 0.31525, 0.23175, 0.24656]
Predicted label: 4
Correct prediction
Energy consumption = 200.116664 pJ
sum error= 82
Actual label: 6
Output voltages: [0.53681, 0.40618, 0.2932, 0.1033, 0.22983, 0.08371, 0.48277, 0.14489, 0.332, 0.21437]
Predicted label: 0
Wrong prediction!
Energy consumption = 211.492348 pJ
sum error= 83
Actual label: 8
Output voltages: [0.20386, 0.24019, 0.2765, 0.28897, 0.16784, 0.27278, 0.27324, 0.12429, 0.73655, 0.18203]
Predicted label: 8
Correct prediction
Energy consumption = 202.380597 pJ
sum error= 83
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 212 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 212 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 212 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.17095, 0.22403, 0.27526, 0.22417, 0.75429, 0.057232, 0.27002, 0.3038, 0.16088, 0.20486]
Predicted label: 4
Correct prediction
Energy consumption = 197.005915 pJ
sum error= 83
Actual label: 8
Output voltages: [0.15966, 0.32227, 0.26699, 0.20707, 0.15053, 0.19792, 0.35178, 0.14709, 0.69452, 0.28035]
Predicted label: 8
Correct prediction
Energy consumption = 204.603980 pJ
sum error= 83
Actual label: 2
Output voltages: [0.34657, 0.33396, 0.72763, 0.35695, 0.12945, 0.030637, 0.17929, 0.36791, 0.32316, 0.2352]
Predicted label: 2
Correct prediction
Energy consumption = 192.548389 pJ
sum error= 83
Actual label: 7
Output voltages: [0.29096, 0.32167, 0.41163, 0.29628, 0.25823, 0.039382, 0.044067, 0.7469, 0.23525, 0.27119]
Predicted label: 7
Correct prediction
Energy consumption = 187.811121 pJ
sum error= 83
Actual label: 4
Output voltages: [0.15605, 0.15373, 0.33886, 0.16355, 0.75674, 0.053085, 0.37226, 0.30273, 0.18607, 0.22226]
Predicted label: 4
Correct prediction
Energy consumption = 189.565955 pJ
sum error= 83
Actual label: 5
Output voltages: [0.29331, 0.10117, 0.05736, 0.40509, 0.24271, 0.4956, 0.36653, 0.21721, 0.35731, 0.44261]
Predicted label: 5
Correct prediction
Energy consumption = 207.976304 pJ
sum error= 83
Actual label: 2
Output voltages: [0.35473, 0.26472, 0.73423, 0.39264, 0.17206, 0.029145, 0.24936, 0.26786, 0.38447, 0.21486]
Predicted label: 2
Correct prediction
Energy consumption = 184.307224 pJ
sum error= 83
Actual label: 0
Output voltages: [0.74455, 0.26206, 0.21386, 0.20413, 0.17539, 0.19439, 0.42287, 0.17544, 0.31329, 0.19682]
Predicted label: 0
Correct prediction
Energy consumption = 192.386743 pJ
sum error= 83
Actual label: 3
Output voltages: [0.29851, 0.21749, 0.29134, 0.75928, 0.17716, 0.13668, 0.13084, 0.15469, 0.41172, 0.2823]
Predicted label: 3
Correct prediction
Energy consumption = 186.105106 pJ
sum error= 83
Actual label: 9
Output voltages: [0.27447, 0.052797, 0.37316, 0.19256, 0.33004, 0.26981, 0.13428, 0.079324, 0.63059, 0.34803]
Predicted label: 8
Wrong prediction!
Energy consumption = 196.234545 pJ
sum error= 84
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 213 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 213 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 213 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.28081, 0.13682, 0.20534, 0.22992, 0.44793, 0.11856, 0.083452, 0.15177, 0.37647, 0.56318]
Predicted label: 9
Wrong prediction!
Energy consumption = 190.768557 pJ
sum error= 85
Actual label: 6
Output voltages: [0.43145, 0.25455, 0.33904, 0.11581, 0.26168, 0.093407, 0.60435, 0.16989, 0.39802, 0.19657]
Predicted label: 6
Correct prediction
Energy consumption = 203.893541 pJ
sum error= 85
Actual label: 7
Output voltages: [0.2003, 0.2417, 0.2028, 0.35761, 0.15896, 0.085174, 0.043682, 0.74473, 0.33198, 0.37426]
Predicted label: 7
Correct prediction
Energy consumption = 204.415399 pJ
sum error= 85
Actual label: 2
Output voltages: [0.38896, 0.35486, 0.68275, 0.34325, 0.13456, 0.022003, 0.31223, 0.2838, 0.35806, 0.2168]
Predicted label: 2
Correct prediction
Energy consumption = 186.061321 pJ
sum error= 85
Actual label: 5
Output voltages: [0.26922, 0.046769, 0.0405, 0.2838, 0.29926, 0.70526, 0.27193, 0.14075, 0.51086, 0.20088]
Predicted label: 5
Correct prediction
Energy consumption = 193.550386 pJ
sum error= 85
Actual label: 6
Output voltages: [0.2933, 0.64045, 0.24636, 0.14203, 0.1942, 0.30661, 0.52447, 0.11397, 0.3871, 0.10842]
Predicted label: 1
Wrong prediction!
Energy consumption = 201.514002 pJ
sum error= 86
Actual label: 1
Output voltages: [0.12408, 0.73416, 0.26097, 0.34693, 0.30928, 0.15591, 0.25797, 0.24332, 0.19391, 0.24857]
Predicted label: 1
Correct prediction
Energy consumption = 208.790165 pJ
sum error= 86
Actual label: 1
Output voltages: [0.21374, 0.76348, 0.26702, 0.22471, 0.25039, 0.082551, 0.40075, 0.13053, 0.28696, 0.21846]
Predicted label: 1
Correct prediction
Energy consumption = 210.608226 pJ
sum error= 86
Actual label: 2
Output voltages: [0.30894, 0.26206, 0.68082, 0.30693, 0.088233, 0.037368, 0.27259, 0.17673, 0.5727, 0.24385]
Predicted label: 2
Correct prediction
Energy consumption = 188.556272 pJ
sum error= 86
Actual label: 3
Output voltages: [0.33339, 0.1348, 0.32087, 0.74805, 0.24052, 0.26098, 0.14548, 0.17609, 0.44991, 0.19015]
Predicted label: 3
Correct prediction
Energy consumption = 177.150341 pJ
sum error= 86
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 214 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 214 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 214 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.35311, 0.27118, 0.31948, 0.067774, 0.34347, 0.29315, 0.7426, 0.094956, 0.23991, 0.20648]
Predicted label: 6
Correct prediction
Energy consumption = 197.882865 pJ
sum error= 86
Actual label: 7
Output voltages: [0.26563, 0.27772, 0.21985, 0.31814, 0.088103, 0.089066, 0.041603, 0.74731, 0.39605, 0.36504]
Predicted label: 7
Correct prediction
Energy consumption = 208.611135 pJ
sum error= 86
Actual label: 8
Output voltages: [0.27164, 0.20435, 0.34214, 0.29081, 0.16086, 0.13763, 0.33294, 0.068449, 0.7165, 0.28446]
Predicted label: 8
Correct prediction
Energy consumption = 192.332959 pJ
sum error= 86
Actual label: 7
Output voltages: [0.34024, 0.30278, 0.44588, 0.29428, 0.13221, 0.026633, 0.055742, 0.68359, 0.33221, 0.29086]
Predicted label: 7
Correct prediction
Energy consumption = 196.027353 pJ
sum error= 86
Actual label: 6
Output voltages: [0.36302, 0.22006, 0.25779, 0.084703, 0.34398, 0.27162, 0.73064, 0.13659, 0.36605, 0.12881]
Predicted label: 6
Correct prediction
Energy consumption = 199.976172 pJ
sum error= 86
Actual label: 4
Output voltages: [0.27305, 0.14924, 0.39502, 0.050188, 0.69433, 0.073379, 0.44624, 0.11322, 0.3389, 0.17854]
Predicted label: 4
Correct prediction
Energy consumption = 190.554360 pJ
sum error= 86
Actual label: 8
Output voltages: [0.26733, 0.19299, 0.28659, 0.28741, 0.17058, 0.19729, 0.22536, 0.11655, 0.74318, 0.33333]
Predicted label: 8
Correct prediction
Energy consumption = 197.247119 pJ
sum error= 86
Actual label: 9
Output voltages: [0.32835, 0.13941, 0.18874, 0.28185, 0.29353, 0.11471, 0.11378, 0.23463, 0.39521, 0.66825]
Predicted label: 9
Correct prediction
Energy consumption = 198.056456 pJ
sum error= 86
Actual label: 4
Output voltages: [0.30833, 0.17493, 0.33989, 0.19583, 0.71526, 0.051583, 0.24647, 0.2379, 0.19481, 0.44202]
Predicted label: 4
Correct prediction
Energy consumption = 192.293984 pJ
sum error= 86
Actual label: 8
Output voltages: [0.25186, 0.40051, 0.52253, 0.21999, 0.15874, 0.031562, 0.1694, 0.31629, 0.50633, 0.27833]
Predicted label: 2
Wrong prediction!
Energy consumption = 190.773856 pJ
sum error= 87
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 215 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 215 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 215 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27594, 0.19756, 0.21367, 0.14367, 0.28996, 0.449, 0.72658, 0.067396, 0.37242, 0.11716]
Predicted label: 6
Correct prediction
Energy consumption = 191.956352 pJ
sum error= 87
Actual label: 3
Output voltages: [0.28367, 0.099664, 0.30315, 0.73794, 0.29352, 0.31447, 0.27597, 0.11951, 0.39702, 0.13565]
Predicted label: 3
Correct prediction
Energy consumption = 188.703021 pJ
sum error= 87
Actual label: 8
Output voltages: [0.30326, 0.20103, 0.28527, 0.37492, 0.13154, 0.22356, 0.23097, 0.10984, 0.73244, 0.21591]
Predicted label: 8
Correct prediction
Energy consumption = 201.005156 pJ
sum error= 87
Actual label: 3
Output voltages: [0.20794, 0.075397, 0.28798, 0.71726, 0.29874, 0.40407, 0.18905, 0.16327, 0.4071, 0.18953]
Predicted label: 3
Correct prediction
Energy consumption = 191.493956 pJ
sum error= 87
Actual label: 1
Output voltages: [0.16285, 0.75911, 0.27625, 0.2451, 0.28175, 0.055008, 0.40766, 0.1574, 0.28808, 0.23286]
Predicted label: 1
Correct prediction
Energy consumption = 209.446085 pJ
sum error= 87
Actual label: 0
Output voltages: [0.68423, 0.21849, 0.24771, 0.13723, 0.21792, 0.1913, 0.5064, 0.13279, 0.28389, 0.1884]
Predicted label: 0
Correct prediction
Energy consumption = 200.885855 pJ
sum error= 87
Actual label: 6
Output voltages: [0.36975, 0.26772, 0.23284, 0.16865, 0.33628, 0.31444, 0.72259, 0.087239, 0.33826, 0.12612]
Predicted label: 6
Correct prediction
Energy consumption = 186.778661 pJ
sum error= 87
Actual label: 2
Output voltages: [0.31832, 0.32993, 0.71001, 0.32386, 0.1642, 0.023743, 0.29305, 0.2646, 0.37556, 0.21232]
Predicted label: 2
Correct prediction
Energy consumption = 189.907388 pJ
sum error= 87
Actual label: 2
Output voltages: [0.30835, 0.25904, 0.67904, 0.43199, 0.12045, 0.028709, 0.15766, 0.37539, 0.41647, 0.20327]
Predicted label: 2
Correct prediction
Energy consumption = 182.587662 pJ
sum error= 87
Actual label: 5
Output voltages: [0.24573, 0.11281, 0.088139, 0.31047, 0.22003, 0.71813, 0.27322, 0.11149, 0.52082, 0.21786]
Predicted label: 5
Correct prediction
Energy consumption = 187.056609 pJ
sum error= 87
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 216 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 216 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 216 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31854, 0.23821, 0.28397, 0.15032, 0.30479, 0.45606, 0.72973, 0.09111, 0.39052, 0.077138]
Predicted label: 6
Correct prediction
Energy consumption = 191.590963 pJ
sum error= 87
Actual label: 9
Output voltages: [0.30841, 0.11782, 0.15055, 0.2994, 0.48891, 0.24433, 0.19794, 0.24975, 0.22407, 0.63158]
Predicted label: 9
Correct prediction
Energy consumption = 194.054393 pJ
sum error= 87
Actual label: 5
Output voltages: [0.2745, 0.048191, 0.080016, 0.26085, 0.3116, 0.60676, 0.40472, 0.12459, 0.51434, 0.30788]
Predicted label: 5
Correct prediction
Energy consumption = 199.056995 pJ
sum error= 87
Actual label: 8
Output voltages: [0.2189, 0.19814, 0.31528, 0.30273, 0.1192, 0.14631, 0.25771, 0.17178, 0.72988, 0.24225]
Predicted label: 8
Correct prediction
Energy consumption = 192.183146 pJ
sum error= 87
Actual label: 1
Output voltages: [0.18209, 0.7686, 0.24356, 0.25331, 0.2209, 0.096616, 0.36732, 0.13528, 0.2986, 0.24632]
Predicted label: 1
Correct prediction
Energy consumption = 210.415490 pJ
sum error= 87
Actual label: 4
Output voltages: [0.12798, 0.19328, 0.28296, 0.10034, 0.75887, 0.066494, 0.31743, 0.30104, 0.2186, 0.25285]
Predicted label: 4
Correct prediction
Energy consumption = 194.353837 pJ
sum error= 87
Actual label: 1
Output voltages: [0.20784, 0.6771, 0.18727, 0.39939, 0.26821, 0.090954, 0.24783, 0.1234, 0.29037, 0.34574]
Predicted label: 1
Correct prediction
Energy consumption = 210.851323 pJ
sum error= 87
Actual label: 7
Output voltages: [0.34924, 0.2212, 0.30259, 0.18481, 0.18106, 0.084516, 0.037439, 0.74428, 0.39478, 0.35966]
Predicted label: 7
Correct prediction
Energy consumption = 194.047529 pJ
sum error= 87
Actual label: 8
Output voltages: [0.27283, 0.17564, 0.45375, 0.36354, 0.14649, 0.12374, 0.26465, 0.20168, 0.70579, 0.20468]
Predicted label: 8
Correct prediction
Energy consumption = 200.321174 pJ
sum error= 87
Actual label: 4
Output voltages: [0.25567, 0.11517, 0.25213, 0.1741, 0.54766, 0.076891, 0.10667, 0.19162, 0.31678, 0.57851]
Predicted label: 9
Wrong prediction!
Energy consumption = 204.573465 pJ
sum error= 88
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 217 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 217 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 217 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.28245, 0.18744, 0.36875, 0.051801, 0.32168, 0.39088, 0.72554, 0.091293, 0.40624, 0.099867]
Predicted label: 6
Correct prediction
Energy consumption = 190.258530 pJ
sum error= 88
Actual label: 1
Output voltages: [0.159, 0.75601, 0.21448, 0.43892, 0.21757, 0.15041, 0.20598, 0.14254, 0.24779, 0.34347]
Predicted label: 1
Correct prediction
Energy consumption = 213.599248 pJ
sum error= 88
Actual label: 8
Output voltages: [0.19405, 0.21604, 0.2814, 0.29878, 0.15517, 0.19731, 0.2783, 0.15703, 0.7453, 0.25565]
Predicted label: 8
Correct prediction
Energy consumption = 199.829262 pJ
sum error= 88
Actual label: 4
Output voltages: [0.1247, 0.14561, 0.23231, 0.11669, 0.72378, 0.14858, 0.23637, 0.25613, 0.38846, 0.22488]
Predicted label: 4
Correct prediction
Energy consumption = 196.639398 pJ
sum error= 88
Actual label: 3
Output voltages: [0.39594, 0.24695, 0.14898, 0.71125, 0.079178, 0.50202, 0.21076, 0.20004, 0.31565, 0.15238]
Predicted label: 3
Correct prediction
Energy consumption = 206.216470 pJ
sum error= 88
Actual label: 1
Output voltages: [0.22434, 0.75885, 0.13914, 0.30361, 0.30397, 0.066524, 0.21644, 0.19779, 0.2481, 0.29471]
Predicted label: 1
Correct prediction
Energy consumption = 216.792373 pJ
sum error= 88
Actual label: 2
Output voltages: [0.36408, 0.25628, 0.72694, 0.30384, 0.30082, 0.040474, 0.22976, 0.26946, 0.28275, 0.16232]
Predicted label: 2
Correct prediction
Energy consumption = 196.983159 pJ
sum error= 88
Actual label: 8
Output voltages: [0.30048, 0.14493, 0.35843, 0.28412, 0.17103, 0.15854, 0.36203, 0.12868, 0.70731, 0.21558]
Predicted label: 8
Correct prediction
Energy consumption = 198.550704 pJ
sum error= 88
Actual label: 0
Output voltages: [0.68365, 0.31393, 0.29213, 0.1753, 0.14052, 0.10699, 0.41655, 0.20625, 0.30698, 0.24944]
Predicted label: 0
Correct prediction
Energy consumption = 198.377398 pJ
sum error= 88
Actual label: 8
Output voltages: [0.30948, 0.17981, 0.37058, 0.43381, 0.10056, 0.10937, 0.17668, 0.13575, 0.70854, 0.32046]
Predicted label: 8
Correct prediction
Energy consumption = 188.725269 pJ
sum error= 88
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 218 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 218 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 218 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.26865, 0.04347, 0.066327, 0.37693, 0.2869, 0.73929, 0.27484, 0.25881, 0.53034, 0.25515]
Predicted label: 5
Correct prediction
Energy consumption = 186.738637 pJ
sum error= 88
Actual label: 9
Output voltages: [0.4237, 0.097446, 0.25718, 0.25023, 0.36893, 0.18929, 0.1339, 0.17735, 0.29622, 0.69472]
Predicted label: 9
Correct prediction
Energy consumption = 198.667639 pJ
sum error= 88
Actual label: 1
Output voltages: [0.2941, 0.31433, 0.49189, 0.57384, 0.096652, 0.1285, 0.12141, 0.17921, 0.42195, 0.1784]
Predicted label: 3
Wrong prediction!
Energy consumption = 201.056858 pJ
sum error= 89
Actual label: 4
Output voltages: [0.22494, 0.20237, 0.27381, 0.09222, 0.72975, 0.10959, 0.46968, 0.17748, 0.23784, 0.19881]
Predicted label: 4
Correct prediction
Energy consumption = 199.543977 pJ
sum error= 89
Actual label: 2
Output voltages: [0.35547, 0.22123, 0.71612, 0.36546, 0.22818, 0.037246, 0.28758, 0.19205, 0.45299, 0.21731]
Predicted label: 2
Correct prediction
Energy consumption = 192.782180 pJ
sum error= 89
Actual label: 0
Output voltages: [0.66721, 0.29294, 0.1615, 0.17056, 0.1307, 0.20397, 0.31456, 0.20813, 0.41502, 0.23206]
Predicted label: 0
Correct prediction
Energy consumption = 213.854909 pJ
sum error= 89
Actual label: 2
Output voltages: [0.40811, 0.14178, 0.54083, 0.54549, 0.16369, 0.046552, 0.17412, 0.12712, 0.51826, 0.22474]
Predicted label: 3
Wrong prediction!
Energy consumption = 195.360347 pJ
sum error= 90
Actual label: 7
Output voltages: [0.28027, 0.23973, 0.32328, 0.23347, 0.14008, 0.071068, 0.041296, 0.76251, 0.43485, 0.30253]
Predicted label: 7
Correct prediction
Energy consumption = 195.018587 pJ
sum error= 90
Actual label: 0
Output voltages: [0.73634, 0.19698, 0.18653, 0.2864, 0.16637, 0.16592, 0.40284, 0.14218, 0.35496, 0.332]
Predicted label: 0
Correct prediction
Energy consumption = 197.152494 pJ
sum error= 90
Actual label: 9
Output voltages: [0.25882, 0.52211, 0.10648, 0.23438, 0.30758, 0.19385, 0.10261, 0.23777, 0.45117, 0.46163]
Predicted label: 1
Wrong prediction!
Energy consumption = 203.798969 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 219 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 219 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 219 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.67631, 0.2727, 0.26892, 0.19661, 0.21553, 0.12262, 0.44973, 0.12516, 0.37524, 0.23135]
Predicted label: 0
Correct prediction
Energy consumption = 208.821110 pJ
sum error= 91
Actual label: 2
Output voltages: [0.37398, 0.26596, 0.72684, 0.35331, 0.16941, 0.032985, 0.34576, 0.14896, 0.49605, 0.24837]
Predicted label: 2
Correct prediction
Energy consumption = 184.144816 pJ
sum error= 91
Actual label: 5
Output voltages: [0.34284, 0.055262, 0.20704, 0.35592, 0.10512, 0.63692, 0.32792, 0.1548, 0.56212, 0.18103]
Predicted label: 5
Correct prediction
Energy consumption = 190.778195 pJ
sum error= 91
Actual label: 7
Output voltages: [0.29875, 0.21584, 0.42398, 0.20714, 0.059394, 0.098358, 0.044442, 0.67391, 0.49992, 0.35295]
Predicted label: 7
Correct prediction
Energy consumption = 187.803250 pJ
sum error= 91
Actual label: 6
Output voltages: [0.25042, 0.2019, 0.35951, 0.065626, 0.29374, 0.3287, 0.72843, 0.06014, 0.37332, 0.12982]
Predicted label: 6
Correct prediction
Energy consumption = 189.211152 pJ
sum error= 91
Actual label: 7
Output voltages: [0.43326, 0.1335, 0.50276, 0.11652, 0.070069, 0.047752, 0.10926, 0.67049, 0.45445, 0.22018]
Predicted label: 7
Correct prediction
Energy consumption = 189.901789 pJ
sum error= 91
Actual label: 9
Output voltages: [0.38638, 0.12849, 0.20348, 0.21982, 0.29307, 0.19085, 0.10482, 0.24667, 0.37813, 0.66853]
Predicted label: 9
Correct prediction
Energy consumption = 189.765605 pJ
sum error= 91
Actual label: 4
Output voltages: [0.21393, 0.32313, 0.30522, 0.18226, 0.56607, 0.070574, 0.43624, 0.15001, 0.33537, 0.071588]
Predicted label: 4
Correct prediction
Energy consumption = 198.686592 pJ
sum error= 91
Actual label: 2
Output voltages: [0.31119, 0.41116, 0.69904, 0.1457, 0.21017, 0.022471, 0.23931, 0.3124, 0.34409, 0.17207]
Predicted label: 2
Correct prediction
Energy consumption = 199.486338 pJ
sum error= 91
Actual label: 6
Output voltages: [0.35744, 0.19797, 0.18716, 0.24868, 0.24729, 0.43027, 0.67634, 0.10626, 0.47911, 0.1029]
Predicted label: 6
Correct prediction
Energy consumption = 188.932216 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 220 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 220 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 220 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33108, 0.29459, 0.58563, 0.2772, 0.3413, 0.063152, 0.52324, 0.1925, 0.31005, 0.084612]
Predicted label: 2
Correct prediction
Energy consumption = 191.810186 pJ
sum error= 91
Actual label: 4
Output voltages: [0.13028, 0.12574, 0.19443, 0.24289, 0.73833, 0.22517, 0.21152, 0.18243, 0.27004, 0.41628]
Predicted label: 4
Correct prediction
Energy consumption = 203.022761 pJ
sum error= 91
Actual label: 4
Output voltages: [0.16619, 0.15612, 0.23632, 0.13626, 0.71195, 0.071039, 0.25954, 0.26253, 0.38029, 0.15142]
Predicted label: 4
Correct prediction
Energy consumption = 198.262750 pJ
sum error= 91
Actual label: 8
Output voltages: [0.26524, 0.21128, 0.33266, 0.31244, 0.13037, 0.17817, 0.24906, 0.14733, 0.73286, 0.32265]
Predicted label: 8
Correct prediction
Energy consumption = 198.420650 pJ
sum error= 91
Actual label: 0
Output voltages: [0.66883, 0.16231, 0.18948, 0.25084, 0.16893, 0.18281, 0.28046, 0.24989, 0.46191, 0.31569]
Predicted label: 0
Correct prediction
Energy consumption = 207.132772 pJ
sum error= 91
Actual label: 4
Output voltages: [0.16301, 0.19221, 0.2516, 0.17635, 0.73131, 0.061953, 0.33093, 0.24307, 0.20824, 0.24161]
Predicted label: 4
Correct prediction
Energy consumption = 198.882680 pJ
sum error= 91
Actual label: 4
Output voltages: [0.13423, 0.19398, 0.23614, 0.148, 0.74225, 0.073004, 0.29107, 0.33238, 0.17763, 0.27322]
Predicted label: 4
Correct prediction
Energy consumption = 195.415616 pJ
sum error= 91
Actual label: 5
Output voltages: [0.20895, 0.057092, 0.093357, 0.31493, 0.22636, 0.7152, 0.31465, 0.14562, 0.50895, 0.22598]
Predicted label: 5
Correct prediction
Energy consumption = 188.686990 pJ
sum error= 91
Actual label: 8
Output voltages: [0.2844, 0.22131, 0.31475, 0.39343, 0.10726, 0.13574, 0.19566, 0.21051, 0.72248, 0.2587]
Predicted label: 8
Correct prediction
Energy consumption = 202.298719 pJ
sum error= 91
Actual label: 0
Output voltages: [0.73102, 0.19264, 0.2735, 0.18271, 0.16785, 0.14688, 0.30147, 0.2535, 0.3515, 0.22883]
Predicted label: 0
Correct prediction
Energy consumption = 201.657492 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 221 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 221 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 221 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29758, 0.21187, 0.31108, 0.078993, 0.35223, 0.34174, 0.74319, 0.10929, 0.34018, 0.10889]
Predicted label: 6
Correct prediction
Energy consumption = 194.965503 pJ
sum error= 91
Actual label: 8
Output voltages: [0.24679, 0.12356, 0.32285, 0.27831, 0.15271, 0.23247, 0.17576, 0.15058, 0.74206, 0.27755]
Predicted label: 8
Correct prediction
Energy consumption = 191.509908 pJ
sum error= 91
Actual label: 9
Output voltages: [0.31335, 0.11975, 0.21026, 0.17887, 0.28333, 0.22814, 0.12987, 0.23338, 0.42303, 0.66228]
Predicted label: 9
Correct prediction
Energy consumption = 188.732552 pJ
sum error= 91
Actual label: 8
Output voltages: [0.17012, 0.22489, 0.27224, 0.33435, 0.12783, 0.25934, 0.16493, 0.19101, 0.75119, 0.28615]
Predicted label: 8
Correct prediction
Energy consumption = 189.099592 pJ
sum error= 91
Actual label: 5
Output voltages: [0.27059, 0.054541, 0.11425, 0.37094, 0.15654, 0.67845, 0.35386, 0.21938, 0.45953, 0.22183]
Predicted label: 5
Correct prediction
Energy consumption = 185.463331 pJ
sum error= 91
Actual label: 6
Output voltages: [0.2951, 0.1209, 0.33422, 0.15143, 0.25817, 0.36328, 0.66107, 0.039431, 0.43077, 0.21435]
Predicted label: 6
Correct prediction
Energy consumption = 185.392781 pJ
sum error= 91
Actual label: 9
Output voltages: [0.37412, 0.10595, 0.15579, 0.2581, 0.3956, 0.27092, 0.22651, 0.27677, 0.26585, 0.68503]
Predicted label: 9
Correct prediction
Energy consumption = 202.463432 pJ
sum error= 91
Actual label: 0
Output voltages: [0.74175, 0.26272, 0.28606, 0.13714, 0.18076, 0.18987, 0.37661, 0.1949, 0.20507, 0.26135]
Predicted label: 0
Correct prediction
Energy consumption = 194.700011 pJ
sum error= 91
Actual label: 4
Output voltages: [0.11771, 0.1248, 0.21116, 0.17728, 0.72583, 0.16793, 0.22239, 0.20556, 0.35271, 0.28628]
Predicted label: 4
Correct prediction
Energy consumption = 202.347694 pJ
sum error= 91
Actual label: 8
Output voltages: [0.27938, 0.1651, 0.39357, 0.13634, 0.17584, 0.11892, 0.1665, 0.12419, 0.72191, 0.38902]
Predicted label: 8
Correct prediction
Energy consumption = 189.546781 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 222 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 222 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 222 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.29617, 0.19438, 0.20609, 0.28896, 0.17214, 0.12574, 0.039996, 0.75082, 0.40334, 0.3285]
Predicted label: 7
Correct prediction
Energy consumption = 200.067746 pJ
sum error= 91
Actual label: 1
Output voltages: [0.25595, 0.66701, 0.21846, 0.12429, 0.24338, 0.17926, 0.31805, 0.14431, 0.44433, 0.38921]
Predicted label: 1
Correct prediction
Energy consumption = 207.119027 pJ
sum error= 91
Actual label: 3
Output voltages: [0.36399, 0.15231, 0.17941, 0.72359, 0.13919, 0.40901, 0.18432, 0.24966, 0.31591, 0.070846]
Predicted label: 3
Correct prediction
Energy consumption = 197.837364 pJ
sum error= 91
Actual label: 4
Output voltages: [0.15795, 0.16329, 0.28213, 0.13213, 0.75007, 0.066595, 0.23196, 0.24292, 0.27815, 0.24169]
Predicted label: 4
Correct prediction
Energy consumption = 192.561179 pJ
sum error= 91
Actual label: 5
Output voltages: [0.34079, 0.086921, 0.17358, 0.36951, 0.15978, 0.58129, 0.4907, 0.10118, 0.44988, 0.26396]
Predicted label: 5
Correct prediction
Energy consumption = 202.191437 pJ
sum error= 91
Actual label: 8
Output voltages: [0.26494, 0.18002, 0.3364, 0.28783, 0.18299, 0.11107, 0.19885, 0.083093, 0.61014, 0.44266]
Predicted label: 8
Correct prediction
Energy consumption = 200.023749 pJ
sum error= 91
Actual label: 0
Output voltages: [0.69527, 0.22735, 0.19925, 0.15361, 0.20063, 0.15813, 0.5025, 0.18587, 0.28208, 0.22948]
Predicted label: 0
Correct prediction
Energy consumption = 193.969946 pJ
sum error= 91
Actual label: 9
Output voltages: [0.40905, 0.12885, 0.16258, 0.28506, 0.33949, 0.28442, 0.1544, 0.29966, 0.27303, 0.69524]
Predicted label: 9
Correct prediction
Energy consumption = 190.865335 pJ
sum error= 91
Actual label: 1
Output voltages: [0.18332, 0.75966, 0.080711, 0.18169, 0.34975, 0.21953, 0.43835, 0.14129, 0.27259, 0.21994]
Predicted label: 1
Correct prediction
Energy consumption = 208.140532 pJ
sum error= 91
Actual label: 3
Output voltages: [0.2971, 0.19528, 0.36149, 0.72987, 0.10831, 0.078914, 0.11005, 0.22269, 0.48732, 0.25892]
Predicted label: 3
Correct prediction
Energy consumption = 186.002324 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 223 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 223 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 223 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29065, 0.19223, 0.32784, 0.75632, 0.23192, 0.17289, 0.16696, 0.10882, 0.41875, 0.28772]
Predicted label: 3
Correct prediction
Energy consumption = 184.601525 pJ
sum error= 91
Actual label: 6
Output voltages: [0.28248, 0.22584, 0.33653, 0.10572, 0.30142, 0.32464, 0.74894, 0.055441, 0.40218, 0.18979]
Predicted label: 6
Correct prediction
Energy consumption = 185.246897 pJ
sum error= 91
Actual label: 9
Output voltages: [0.37313, 0.16049, 0.19941, 0.20565, 0.47614, 0.12214, 0.2453, 0.16129, 0.2939, 0.64228]
Predicted label: 9
Correct prediction
Energy consumption = 201.392858 pJ
sum error= 91
Actual label: 8
Output voltages: [0.20731, 0.11226, 0.31177, 0.17906, 0.23757, 0.18556, 0.21145, 0.14478, 0.72439, 0.30427]
Predicted label: 8
Correct prediction
Energy consumption = 188.534346 pJ
sum error= 91
Actual label: 7
Output voltages: [0.35416, 0.33147, 0.36415, 0.29889, 0.11266, 0.038831, 0.047329, 0.74217, 0.27933, 0.28745]
Predicted label: 7
Correct prediction
Energy consumption = 201.365643 pJ
sum error= 91
Actual label: 1
Output voltages: [0.26804, 0.67075, 0.32517, 0.17192, 0.42637, 0.062034, 0.38171, 0.087218, 0.2534, 0.19428]
Predicted label: 1
Correct prediction
Energy consumption = 200.506127 pJ
sum error= 91
Actual label: 0
Output voltages: [0.73371, 0.26447, 0.25528, 0.15636, 0.20184, 0.19607, 0.4452, 0.17058, 0.25952, 0.21586]
Predicted label: 0
Correct prediction
Energy consumption = 198.065891 pJ
sum error= 91
Actual label: 5
Output voltages: [0.21878, 0.086661, 0.30975, 0.20777, 0.13913, 0.5431, 0.48194, 0.066972, 0.59168, 0.18136]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.031474 pJ
sum error= 92
Actual label: 7
Output voltages: [0.36067, 0.28351, 0.35435, 0.43609, 0.060031, 0.036325, 0.053006, 0.67333, 0.36074, 0.29726]
Predicted label: 7
Correct prediction
Energy consumption = 200.638416 pJ
sum error= 92
Actual label: 1
Output voltages: [0.18993, 0.76273, 0.074486, 0.33283, 0.21708, 0.19322, 0.36475, 0.17644, 0.32952, 0.21878]
Predicted label: 1
Correct prediction
Energy consumption = 209.379418 pJ
sum error= 92
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 224 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 224 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 224 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37108, 0.24669, 0.21269, 0.25922, 0.1609, 0.14976, 0.046422, 0.76443, 0.32521, 0.36808]
Predicted label: 7
Correct prediction
Energy consumption = 202.236648 pJ
sum error= 92
Actual label: 5
Output voltages: [0.3634, 0.043583, 0.070854, 0.32972, 0.17771, 0.73962, 0.38054, 0.17354, 0.50977, 0.15884]
Predicted label: 5
Correct prediction
Energy consumption = 193.101709 pJ
sum error= 92
Actual label: 2
Output voltages: [0.33921, 0.24013, 0.71401, 0.34684, 0.11761, 0.028211, 0.19742, 0.33276, 0.41572, 0.17091]
Predicted label: 2
Correct prediction
Energy consumption = 197.528164 pJ
sum error= 92
Actual label: 7
Output voltages: [0.29226, 0.2396, 0.062911, 0.23604, 0.18541, 0.19552, 0.040645, 0.64137, 0.43351, 0.44987]
Predicted label: 7
Correct prediction
Energy consumption = 193.651778 pJ
sum error= 92
Actual label: 9
Output voltages: [0.30216, 0.16822, 0.15231, 0.31446, 0.28607, 0.12088, 0.1068, 0.22287, 0.39841, 0.64585]
Predicted label: 9
Correct prediction
Energy consumption = 189.717919 pJ
sum error= 92
Actual label: 1
Output voltages: [0.20683, 0.76815, 0.15828, 0.25196, 0.22236, 0.18822, 0.32119, 0.14785, 0.32507, 0.23102]
Predicted label: 1
Correct prediction
Energy consumption = 215.155153 pJ
sum error= 92
Actual label: 8
Output voltages: [0.17945, 0.31504, 0.20113, 0.30668, 0.074909, 0.33039, 0.3282, 0.12852, 0.67949, 0.26945]
Predicted label: 8
Correct prediction
Energy consumption = 195.170898 pJ
sum error= 92
Actual label: 5
Output voltages: [0.21823, 0.047506, 0.11873, 0.3182, 0.24304, 0.68863, 0.29704, 0.23814, 0.49283, 0.32126]
Predicted label: 5
Correct prediction
Energy consumption = 184.054402 pJ
sum error= 92
Actual label: 2
Output voltages: [0.43722, 0.2348, 0.71401, 0.35552, 0.1316, 0.028482, 0.30358, 0.35449, 0.42359, 0.24209]
Predicted label: 2
Correct prediction
Energy consumption = 190.886103 pJ
sum error= 92
Actual label: 4
Output voltages: [0.13605, 0.12931, 0.3511, 0.19583, 0.75962, 0.074135, 0.25874, 0.29111, 0.20219, 0.24419]
Predicted label: 4
Correct prediction
Energy consumption = 188.007112 pJ
sum error= 92
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 225 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 225 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 225 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32007, 0.13181, 0.1884, 0.30765, 0.35529, 0.13672, 0.11383, 0.17662, 0.37825, 0.66102]
Predicted label: 9
Correct prediction
Energy consumption = 195.872572 pJ
sum error= 92
Actual label: 4
Output voltages: [0.17593, 0.12161, 0.28228, 0.15122, 0.72451, 0.14434, 0.21349, 0.24057, 0.25274, 0.47202]
Predicted label: 4
Correct prediction
Energy consumption = 197.180615 pJ
sum error= 92
Actual label: 7
Output voltages: [0.25439, 0.28522, 0.27612, 0.35852, 0.12962, 0.051552, 0.036074, 0.7442, 0.34499, 0.34149]
Predicted label: 7
Correct prediction
Energy consumption = 198.716554 pJ
sum error= 92
Actual label: 2
Output voltages: [0.29493, 0.19852, 0.74326, 0.24512, 0.15656, 0.037005, 0.20742, 0.34785, 0.45028, 0.14923]
Predicted label: 2
Correct prediction
Energy consumption = 183.638278 pJ
sum error= 92
Actual label: 2
Output voltages: [0.39228, 0.059475, 0.71837, 0.41209, 0.13855, 0.066706, 0.16719, 0.24535, 0.47696, 0.20553]
Predicted label: 2
Correct prediction
Energy consumption = 176.023578 pJ
sum error= 92
Actual label: 3
Output voltages: [0.27993, 0.15998, 0.28375, 0.75658, 0.16072, 0.16292, 0.20587, 0.18976, 0.42605, 0.23517]
Predicted label: 3
Correct prediction
Energy consumption = 183.494897 pJ
sum error= 92
Actual label: 4
Output voltages: [0.15695, 0.12362, 0.30128, 0.1375, 0.76049, 0.098629, 0.33997, 0.28204, 0.21891, 0.25169]
Predicted label: 4
Correct prediction
Energy consumption = 195.523234 pJ
sum error= 92
Actual label: 9
Output voltages: [0.4104, 0.10033, 0.19991, 0.25744, 0.27472, 0.18982, 0.09243, 0.36075, 0.37275, 0.70463]
Predicted label: 9
Correct prediction
Energy consumption = 193.695681 pJ
sum error= 92
Actual label: 1
Output voltages: [0.15571, 0.66388, 0.31621, 0.19905, 0.38171, 0.0797, 0.4031, 0.11578, 0.32957, 0.20822]
Predicted label: 1
Correct prediction
Energy consumption = 212.229068 pJ
sum error= 92
Actual label: 9
Output voltages: [0.36521, 0.10711, 0.15542, 0.32264, 0.37043, 0.25582, 0.081885, 0.28777, 0.299, 0.67302]
Predicted label: 9
Correct prediction
Energy consumption = 199.558325 pJ
sum error= 92
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 226 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 226 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 226 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.37357, 0.16794, 0.71393, 0.36816, 0.17355, 0.037867, 0.22031, 0.24676, 0.43618, 0.15495]
Predicted label: 2
Correct prediction
Energy consumption = 190.989736 pJ
sum error= 92
Actual label: 1
Output voltages: [0.25246, 0.74337, 0.25629, 0.22564, 0.34396, 0.1137, 0.43304, 0.063341, 0.29042, 0.22455]
Predicted label: 1
Correct prediction
Energy consumption = 207.432376 pJ
sum error= 92
Actual label: 7
Output voltages: [0.26464, 0.30304, 0.28786, 0.35416, 0.13322, 0.046999, 0.038214, 0.74585, 0.32373, 0.3146]
Predicted label: 7
Correct prediction
Energy consumption = 194.426966 pJ
sum error= 92
Actual label: 9
Output voltages: [0.46273, 0.055983, 0.2569, 0.11446, 0.36607, 0.16851, 0.10611, 0.12558, 0.36306, 0.67618]
Predicted label: 9
Correct prediction
Energy consumption = 188.703138 pJ
sum error= 92
Actual label: 4
Output voltages: [0.20638, 0.12924, 0.34208, 0.32104, 0.74841, 0.16401, 0.31044, 0.24163, 0.16635, 0.31888]
Predicted label: 4
Correct prediction
Energy consumption = 198.150789 pJ
sum error= 92
Actual label: 4
Output voltages: [0.15647, 0.18192, 0.22384, 0.19864, 0.74729, 0.11801, 0.25271, 0.26969, 0.20394, 0.30349]
Predicted label: 4
Correct prediction
Energy consumption = 197.143901 pJ
sum error= 92
Actual label: 1
Output voltages: [0.25943, 0.45302, 0.28725, 0.42296, 0.20166, 0.30332, 0.49258, 0.17774, 0.18271, 0.062282]
Predicted label: 6
Wrong prediction!
Energy consumption = 205.826173 pJ
sum error= 93
Actual label: 6
Output voltages: [0.32186, 0.22257, 0.25063, 0.094778, 0.28235, 0.33656, 0.73756, 0.084451, 0.40725, 0.1566]
Predicted label: 6
Correct prediction
Energy consumption = 184.909983 pJ
sum error= 93
Actual label: 7
Output voltages: [0.41485, 0.20632, 0.11493, 0.19703, 0.27293, 0.15819, 0.10533, 0.66825, 0.33381, 0.3703]
Predicted label: 7
Correct prediction
Energy consumption = 198.040174 pJ
sum error= 93
Actual label: 2
Output voltages: [0.37433, 0.36962, 0.70293, 0.31436, 0.11065, 0.026162, 0.30166, 0.24484, 0.38253, 0.21868]
Predicted label: 2
Correct prediction
Energy consumption = 189.926183 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 227 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 227 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 227 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.23908, 0.29577, 0.49251, 0.18769, 0.13168, 0.039706, 0.048762, 0.73533, 0.36791, 0.28211]
Predicted label: 7
Correct prediction
Energy consumption = 200.232565 pJ
sum error= 93
Actual label: 8
Output voltages: [0.19117, 0.23126, 0.31427, 0.26457, 0.16024, 0.11615, 0.16231, 0.15764, 0.73806, 0.31064]
Predicted label: 8
Correct prediction
Energy consumption = 199.600758 pJ
sum error= 93
Actual label: 8
Output voltages: [0.51158, 0.11077, 0.26187, 0.26503, 0.17323, 0.20607, 0.35311, 0.11668, 0.61809, 0.20491]
Predicted label: 8
Correct prediction
Energy consumption = 197.460336 pJ
sum error= 93
Actual label: 1
Output voltages: [0.15738, 0.73976, 0.30231, 0.20075, 0.31599, 0.054584, 0.34373, 0.21744, 0.28354, 0.22965]
Predicted label: 1
Correct prediction
Energy consumption = 204.970125 pJ
sum error= 93
Actual label: 9
Output voltages: [0.3419, 0.11779, 0.24422, 0.24193, 0.33591, 0.16923, 0.07544, 0.20748, 0.37742, 0.66859]
Predicted label: 9
Correct prediction
Energy consumption = 194.192255 pJ
sum error= 93
Actual label: 7
Output voltages: [0.29529, 0.26498, 0.23581, 0.38351, 0.12762, 0.11201, 0.045703, 0.75794, 0.27521, 0.38869]
Predicted label: 7
Correct prediction
Energy consumption = 195.899431 pJ
sum error= 93
Actual label: 1
Output voltages: [0.23482, 0.68052, 0.1555, 0.3942, 0.15079, 0.20018, 0.22303, 0.056112, 0.4815, 0.37996]
Predicted label: 1
Correct prediction
Energy consumption = 210.771497 pJ
sum error= 93
Actual label: 1
Output voltages: [0.16568, 0.74115, 0.068992, 0.19879, 0.3091, 0.28931, 0.38712, 0.1588, 0.31684, 0.17315]
Predicted label: 1
Correct prediction
Energy consumption = 204.665280 pJ
sum error= 93
Actual label: 7
Output voltages: [0.38131, 0.1729, 0.30969, 0.239, 0.096563, 0.076153, 0.042134, 0.75153, 0.4248, 0.28859]
Predicted label: 7
Correct prediction
Energy consumption = 197.412077 pJ
sum error= 93
Actual label: 5
Output voltages: [0.26987, 0.054976, 0.090094, 0.45834, 0.16571, 0.68763, 0.25263, 0.2708, 0.49661, 0.21249]
Predicted label: 5
Correct prediction
Energy consumption = 181.332069 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 228 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 228 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 228 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26468, 0.1429, 0.051813, 0.52931, 0.30802, 0.51736, 0.28803, 0.26762, 0.29997, 0.11127]
Predicted label: 3
Correct prediction
Energy consumption = 212.230157 pJ
sum error= 93
Actual label: 3
Output voltages: [0.34446, 0.16821, 0.29704, 0.75704, 0.19744, 0.19053, 0.20592, 0.17794, 0.44075, 0.22237]
Predicted label: 3
Correct prediction
Energy consumption = 182.596086 pJ
sum error= 93
Actual label: 5
Output voltages: [0.2338, 0.051439, 0.102, 0.36891, 0.21123, 0.65103, 0.31859, 0.11775, 0.51506, 0.25516]
Predicted label: 5
Correct prediction
Energy consumption = 190.813087 pJ
sum error= 93
Actual label: 1
Output voltages: [0.16423, 0.74834, 0.1887, 0.30396, 0.27505, 0.13022, 0.20085, 0.10752, 0.41729, 0.31043]
Predicted label: 1
Correct prediction
Energy consumption = 214.386831 pJ
sum error= 93
Actual label: 3
Output voltages: [0.31439, 0.14198, 0.34921, 0.75071, 0.16986, 0.27252, 0.17414, 0.15159, 0.41541, 0.21924]
Predicted label: 3
Correct prediction
Energy consumption = 186.259614 pJ
sum error= 93
Actual label: 7
Output voltages: [0.32129, 0.16047, 0.3001, 0.20896, 0.23935, 0.057816, 0.047163, 0.7632, 0.32692, 0.25175]
Predicted label: 7
Correct prediction
Energy consumption = 195.670562 pJ
sum error= 93
Actual label: 6
Output voltages: [0.39366, 0.2076, 0.29702, 0.0988, 0.34361, 0.22212, 0.71175, 0.098125, 0.3134, 0.21085]
Predicted label: 6
Correct prediction
Energy consumption = 197.442209 pJ
sum error= 93
Actual label: 1
Output voltages: [0.18252, 0.76005, 0.29481, 0.31347, 0.19351, 0.063313, 0.32453, 0.18464, 0.31225, 0.22149]
Predicted label: 1
Correct prediction
Energy consumption = 203.172812 pJ
sum error= 93
Actual label: 3
Output voltages: [0.44947, 0.17688, 0.23113, 0.74619, 0.099987, 0.29965, 0.22829, 0.19339, 0.36877, 0.099249]
Predicted label: 3
Correct prediction
Energy consumption = 188.405247 pJ
sum error= 93
Actual label: 8
Output voltages: [0.35011, 0.14301, 0.39492, 0.1866, 0.16554, 0.12357, 0.21899, 0.15168, 0.71912, 0.28791]
Predicted label: 8
Correct prediction
Energy consumption = 190.707273 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 229 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 229 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 229 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26041, 0.31243, 0.28782, 0.24774, 0.19169, 0.041918, 0.046406, 0.74906, 0.28368, 0.35036]
Predicted label: 7
Correct prediction
Energy consumption = 199.980255 pJ
sum error= 93
Actual label: 5
Output voltages: [0.36342, 0.094581, 0.091817, 0.4413, 0.1108, 0.68042, 0.22873, 0.16406, 0.54279, 0.27272]
Predicted label: 5
Correct prediction
Energy consumption = 195.339231 pJ
sum error= 93
Actual label: 9
Output voltages: [0.42328, 0.18559, 0.18154, 0.43697, 0.34904, 0.22519, 0.11866, 0.14289, 0.32396, 0.66815]
Predicted label: 9
Correct prediction
Energy consumption = 194.808377 pJ
sum error= 93
Actual label: 9
Output voltages: [0.44967, 0.13139, 0.48863, 0.076343, 0.27256, 0.046318, 0.5142, 0.12052, 0.36054, 0.29802]
Predicted label: 6
Wrong prediction!
Energy consumption = 201.986926 pJ
sum error= 94
Actual label: 0
Output voltages: [0.74109, 0.23614, 0.21728, 0.22865, 0.067905, 0.29407, 0.29187, 0.15789, 0.32884, 0.23122]
Predicted label: 0
Correct prediction
Energy consumption = 194.888308 pJ
sum error= 94
Actual label: 0
Output voltages: [0.74076, 0.26639, 0.25568, 0.13535, 0.16088, 0.21669, 0.37638, 0.13657, 0.2607, 0.29834]
Predicted label: 0
Correct prediction
Energy consumption = 187.587070 pJ
sum error= 94
Actual label: 2
Output voltages: [0.30304, 0.40025, 0.66224, 0.35306, 0.094956, 0.033924, 0.28805, 0.21181, 0.43948, 0.21459]
Predicted label: 2
Correct prediction
Energy consumption = 194.146567 pJ
sum error= 94
Actual label: 8
Output voltages: [0.24678, 0.22869, 0.33715, 0.30283, 0.12851, 0.16464, 0.25215, 0.12143, 0.73969, 0.31352]
Predicted label: 8
Correct prediction
Energy consumption = 189.975216 pJ
sum error= 94
Actual label: 8
Output voltages: [0.32096, 0.15262, 0.24924, 0.4449, 0.14207, 0.23702, 0.27594, 0.068324, 0.69977, 0.26028]
Predicted label: 8
Correct prediction
Energy consumption = 192.622756 pJ
sum error= 94
Actual label: 2
Output voltages: [0.40986, 0.30881, 0.67127, 0.22953, 0.046635, 0.044428, 0.24196, 0.46664, 0.4478, 0.2248]
Predicted label: 2
Correct prediction
Energy consumption = 186.164854 pJ
sum error= 94
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 230 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 230 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 230 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33192, 0.14274, 0.31623, 0.75052, 0.26922, 0.13402, 0.15934, 0.30063, 0.3967, 0.20149]
Predicted label: 3
Correct prediction
Energy consumption = 192.030184 pJ
sum error= 94
Actual label: 7
Output voltages: [0.35907, 0.31697, 0.28273, 0.30097, 0.14108, 0.053354, 0.043184, 0.74628, 0.30746, 0.30132]
Predicted label: 7
Correct prediction
Energy consumption = 193.833852 pJ
sum error= 94
Actual label: 1
Output voltages: [0.23712, 0.71712, 0.31407, 0.28695, 0.24632, 0.040311, 0.25303, 0.21165, 0.35287, 0.2497]
Predicted label: 1
Correct prediction
Energy consumption = 206.646875 pJ
sum error= 94
Actual label: 3
Output voltages: [0.31779, 0.18962, 0.32099, 0.76004, 0.23992, 0.20871, 0.20118, 0.18973, 0.36749, 0.22835]
Predicted label: 3
Correct prediction
Energy consumption = 182.037923 pJ
sum error= 94
Actual label: 0
Output voltages: [0.67764, 0.13342, 0.26636, 0.081135, 0.1261, 0.26721, 0.41715, 0.1327, 0.29522, 0.30838]
Predicted label: 0
Correct prediction
Energy consumption = 188.616264 pJ
sum error= 94
Actual label: 3
Output voltages: [0.33928, 0.19005, 0.31279, 0.74701, 0.13988, 0.2089, 0.069881, 0.16113, 0.53533, 0.13905]
Predicted label: 3
Correct prediction
Energy consumption = 195.304649 pJ
sum error= 94
Actual label: 4
Output voltages: [0.10946, 0.23821, 0.22848, 0.12032, 0.74112, 0.071927, 0.22226, 0.2081, 0.28347, 0.26715]
Predicted label: 4
Correct prediction
Energy consumption = 195.185453 pJ
sum error= 94
Actual label: 4
Output voltages: [0.1874, 0.15347, 0.26506, 0.26298, 0.73344, 0.045961, 0.16147, 0.27086, 0.26374, 0.24388]
Predicted label: 4
Correct prediction
Energy consumption = 188.794403 pJ
sum error= 94
Actual label: 3
Output voltages: [0.35535, 0.12276, 0.23073, 0.60094, 0.083099, 0.40393, 0.068437, 0.25882, 0.55377, 0.16803]
Predicted label: 3
Correct prediction
Energy consumption = 200.596429 pJ
sum error= 94
Actual label: 8
Output voltages: [0.17891, 0.10856, 0.24572, 0.38205, 0.097711, 0.32835, 0.2093, 0.063567, 0.71941, 0.28981]
Predicted label: 8
Correct prediction
Energy consumption = 187.171649 pJ
sum error= 94
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 231 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 231 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 231 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3418, 0.19005, 0.14751, 0.20209, 0.41616, 0.15875, 0.23406, 0.21837, 0.30037, 0.65397]
Predicted label: 9
Correct prediction
Energy consumption = 207.974257 pJ
sum error= 94
Actual label: 2
Output voltages: [0.40276, 0.22183, 0.70039, 0.28404, 0.1928, 0.026028, 0.31647, 0.29892, 0.4115, 0.20524]
Predicted label: 2
Correct prediction
Energy consumption = 193.759757 pJ
sum error= 94
Actual label: 3
Output voltages: [0.25838, 0.17765, 0.34533, 0.7443, 0.19087, 0.15173, 0.14649, 0.16587, 0.4583, 0.2464]
Predicted label: 3
Correct prediction
Energy consumption = 180.571278 pJ
sum error= 94
Actual label: 9
Output voltages: [0.31811, 0.15896, 0.12059, 0.44858, 0.26747, 0.22641, 0.085519, 0.27808, 0.28581, 0.65988]
Predicted label: 9
Correct prediction
Energy consumption = 196.619390 pJ
sum error= 94
Actual label: 7
Output voltages: [0.3423, 0.22782, 0.50688, 0.22382, 0.1152, 0.048412, 0.045114, 0.70624, 0.40823, 0.32582]
Predicted label: 7
Correct prediction
Energy consumption = 189.220704 pJ
sum error= 94
Actual label: 1
Output voltages: [0.2886, 0.75407, 0.30292, 0.26504, 0.20702, 0.071046, 0.27424, 0.063118, 0.38907, 0.28366]
Predicted label: 1
Correct prediction
Energy consumption = 213.766678 pJ
sum error= 94
Actual label: 1
Output voltages: [0.26005, 0.75596, 0.37343, 0.31952, 0.24168, 0.053336, 0.27891, 0.12236, 0.30112, 0.24014]
Predicted label: 1
Correct prediction
Energy consumption = 201.991534 pJ
sum error= 94
Actual label: 7
Output voltages: [0.37261, 0.34384, 0.28933, 0.35507, 0.12828, 0.058334, 0.055112, 0.74062, 0.20928, 0.35199]
Predicted label: 7
Correct prediction
Energy consumption = 199.407337 pJ
sum error= 94
Actual label: 0
Output voltages: [0.57664, 0.18543, 0.25051, 0.11715, 0.16628, 0.22813, 0.53493, 0.1282, 0.33047, 0.31196]
Predicted label: 0
Correct prediction
Energy consumption = 198.596572 pJ
sum error= 94
Actual label: 4
Output voltages: [0.23321, 0.15185, 0.33605, 0.13474, 0.74111, 0.067684, 0.44416, 0.19068, 0.22076, 0.23613]
Predicted label: 4
Correct prediction
Energy consumption = 188.571454 pJ
sum error= 94
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 232 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 232 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 232 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33532, 0.21215, 0.16656, 0.26718, 0.36908, 0.17927, 0.089343, 0.26347, 0.24658, 0.68309]
Predicted label: 9
Correct prediction
Energy consumption = 206.867930 pJ
sum error= 94
Actual label: 6
Output voltages: [0.32044, 0.22611, 0.29419, 0.10879, 0.33926, 0.32316, 0.75145, 0.10874, 0.39172, 0.13722]
Predicted label: 6
Correct prediction
Energy consumption = 194.054811 pJ
sum error= 94
Actual label: 5
Output voltages: [0.26972, 0.062377, 0.2019, 0.35219, 0.19558, 0.70996, 0.29469, 0.2094, 0.57376, 0.25709]
Predicted label: 5
Correct prediction
Energy consumption = 190.306003 pJ
sum error= 94
Actual label: 9
Output voltages: [0.41177, 0.13339, 0.18339, 0.24067, 0.34246, 0.22546, 0.14598, 0.33712, 0.27741, 0.69648]
Predicted label: 9
Correct prediction
Energy consumption = 198.770294 pJ
sum error= 94
Actual label: 1
Output voltages: [0.18005, 0.76453, 0.20755, 0.32316, 0.21904, 0.074525, 0.32862, 0.18124, 0.31127, 0.25697]
Predicted label: 1
Correct prediction
Energy consumption = 215.361939 pJ
sum error= 94
Actual label: 7
Output voltages: [0.27049, 0.34729, 0.46121, 0.65315, 0.12437, 0.062561, 0.16379, 0.39967, 0.35125, 0.22288]
Predicted label: 3
Wrong prediction!
Energy consumption = 191.999081 pJ
sum error= 95
Actual label: 0
Output voltages: [0.53283, 0.10342, 0.17433, 0.18708, 0.19664, 0.36799, 0.35036, 0.050602, 0.51311, 0.23153]
Predicted label: 0
Correct prediction
Energy consumption = 191.160086 pJ
sum error= 95
Actual label: 2
Output voltages: [0.33534, 0.29759, 0.6817, 0.3436, 0.10772, 0.031414, 0.28846, 0.23703, 0.50632, 0.23525]
Predicted label: 2
Correct prediction
Energy consumption = 195.559553 pJ
sum error= 95
Actual label: 0
Output voltages: [0.72917, 0.23315, 0.25852, 0.18727, 0.14292, 0.20291, 0.42804, 0.19931, 0.30342, 0.23732]
Predicted label: 0
Correct prediction
Energy consumption = 188.160826 pJ
sum error= 95
Actual label: 0
Output voltages: [0.66627, 0.17575, 0.54483, 0.23444, 0.074008, 0.057271, 0.31714, 0.37035, 0.31006, 0.13975]
Predicted label: 0
Correct prediction
Energy consumption = 181.648958 pJ
sum error= 95
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 233 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 233 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 233 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.14084, 0.14668, 0.30573, 0.17726, 0.75501, 0.097228, 0.301, 0.28138, 0.22153, 0.27263]
Predicted label: 4
Correct prediction
Energy consumption = 200.664101 pJ
sum error= 95
Actual label: 6
Output voltages: [0.24723, 0.16255, 0.3799, 0.053803, 0.43157, 0.34103, 0.71339, 0.06021, 0.30628, 0.09199]
Predicted label: 6
Correct prediction
Energy consumption = 191.263801 pJ
sum error= 95
Actual label: 7
Output voltages: [0.31466, 0.23942, 0.22103, 0.37295, 0.1327, 0.098607, 0.043285, 0.75728, 0.28198, 0.35621]
Predicted label: 7
Correct prediction
Energy consumption = 199.347083 pJ
sum error= 95
Actual label: 0
Output voltages: [0.67271, 0.25643, 0.31814, 0.21198, 0.081968, 0.10425, 0.39798, 0.17918, 0.32797, 0.33388]
Predicted label: 0
Correct prediction
Energy consumption = 197.809044 pJ
sum error= 95
Actual label: 7
Output voltages: [0.27234, 0.19006, 0.42942, 0.25179, 0.17155, 0.045798, 0.037468, 0.68687, 0.45827, 0.32566]
Predicted label: 7
Correct prediction
Energy consumption = 189.770455 pJ
sum error= 95
Actual label: 1
Output voltages: [0.19632, 0.76275, 0.25294, 0.2979, 0.31088, 0.090224, 0.30168, 0.15513, 0.2908, 0.28666]
Predicted label: 1
Correct prediction
Energy consumption = 210.963533 pJ
sum error= 95
Actual label: 4
Output voltages: [0.09451, 0.19394, 0.23804, 0.15504, 0.74779, 0.052597, 0.29473, 0.31961, 0.25303, 0.20653]
Predicted label: 4
Correct prediction
Energy consumption = 194.866658 pJ
sum error= 95
Actual label: 6
Output voltages: [0.29597, 0.19588, 0.3002, 0.092645, 0.33948, 0.37396, 0.72625, 0.05506, 0.36768, 0.17944]
Predicted label: 6
Correct prediction
Energy consumption = 181.733931 pJ
sum error= 95
Actual label: 4
Output voltages: [0.24638, 0.21194, 0.34017, 0.32811, 0.73121, 0.064265, 0.18472, 0.23683, 0.14058, 0.37312]
Predicted label: 4
Correct prediction
Energy consumption = 194.908233 pJ
sum error= 95
Actual label: 5
Output voltages: [0.22593, 0.10281, 0.079673, 0.37327, 0.18314, 0.65969, 0.15545, 0.20101, 0.52248, 0.25996]
Predicted label: 5
Correct prediction
Energy consumption = 199.918430 pJ
sum error= 95
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 234 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 234 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 234 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.12468, 0.14612, 0.29849, 0.10315, 0.75782, 0.10538, 0.3132, 0.23438, 0.26348, 0.22503]
Predicted label: 4
Correct prediction
Energy consumption = 195.907734 pJ
sum error= 95
Actual label: 9
Output voltages: [0.43454, 0.062649, 0.2609, 0.17915, 0.40739, 0.16731, 0.18574, 0.17399, 0.27654, 0.69181]
Predicted label: 9
Correct prediction
Energy consumption = 198.147373 pJ
sum error= 95
Actual label: 9
Output voltages: [0.32175, 0.063022, 0.24645, 0.22502, 0.30981, 0.1252, 0.054309, 0.35117, 0.3744, 0.64914]
Predicted label: 9
Correct prediction
Energy consumption = 195.686026 pJ
sum error= 95
Actual label: 1
Output voltages: [0.33086, 0.69225, 0.45859, 0.29419, 0.18617, 0.028431, 0.23897, 0.2565, 0.29447, 0.24418]
Predicted label: 1
Correct prediction
Energy consumption = 208.991210 pJ
sum error= 95
Actual label: 7
Output voltages: [0.35336, 0.29598, 0.17885, 0.26024, 0.1214, 0.11339, 0.042104, 0.7436, 0.4409, 0.3013]
Predicted label: 7
Correct prediction
Energy consumption = 196.999990 pJ
sum error= 95
Actual label: 9
Output voltages: [0.32863, 0.083093, 0.17011, 0.29446, 0.2671, 0.17296, 0.059369, 0.40621, 0.41532, 0.60643]
Predicted label: 9
Correct prediction
Energy consumption = 194.720809 pJ
sum error= 95
Actual label: 5
Output voltages: [0.20477, 0.040854, 0.11972, 0.35552, 0.27613, 0.6702, 0.27286, 0.17242, 0.58556, 0.23399]
Predicted label: 5
Correct prediction
Energy consumption = 177.743020 pJ
sum error= 95
Actual label: 3
Output voltages: [0.42985, 0.14262, 0.3361, 0.74155, 0.24671, 0.19491, 0.15097, 0.16528, 0.48362, 0.21377]
Predicted label: 3
Correct prediction
Energy consumption = 183.142767 pJ
sum error= 95
Actual label: 3
Output voltages: [0.26106, 0.27406, 0.30106, 0.75353, 0.15238, 0.1469, 0.088948, 0.27947, 0.36164, 0.33569]
Predicted label: 3
Correct prediction
Energy consumption = 191.472674 pJ
sum error= 95
Actual label: 8
Output voltages: [0.21534, 0.14383, 0.27068, 0.27704, 0.17101, 0.26915, 0.19163, 0.14458, 0.74905, 0.27208]
Predicted label: 8
Correct prediction
Energy consumption = 186.661712 pJ
sum error= 95
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 235 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 235 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 235 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33304, 0.24574, 0.75633, 0.3299, 0.23572, 0.049871, 0.24062, 0.23137, 0.37037, 0.17777]
Predicted label: 2
Correct prediction
Energy consumption = 187.800251 pJ
sum error= 95
Actual label: 3
Output voltages: [0.4366, 0.29849, 0.22771, 0.609, 0.15653, 0.42848, 0.43193, 0.33458, 0.17711, 0.039448]
Predicted label: 3
Correct prediction
Energy consumption = 185.292922 pJ
sum error= 95
Actual label: 6
Output voltages: [0.27141, 0.11076, 0.35178, 0.066161, 0.25271, 0.42761, 0.70209, 0.063642, 0.42276, 0.17484]
Predicted label: 6
Correct prediction
Energy consumption = 182.475026 pJ
sum error= 95
Actual label: 2
Output voltages: [0.41138, 0.22974, 0.70916, 0.33891, 0.22215, 0.035758, 0.34646, 0.21874, 0.48889, 0.18441]
Predicted label: 2
Correct prediction
Energy consumption = 183.506576 pJ
sum error= 95
Actual label: 2
Output voltages: [0.37707, 0.32935, 0.73538, 0.36617, 0.15972, 0.033437, 0.31416, 0.17926, 0.39698, 0.28727]
Predicted label: 2
Correct prediction
Energy consumption = 179.866274 pJ
sum error= 95
Actual label: 1
Output voltages: [0.2036, 0.72969, 0.21557, 0.23306, 0.26652, 0.075129, 0.46672, 0.048639, 0.38998, 0.22433]
Predicted label: 1
Correct prediction
Energy consumption = 206.426433 pJ
sum error= 95
Actual label: 1
Output voltages: [0.21105, 0.77012, 0.20861, 0.33678, 0.17356, 0.17529, 0.37212, 0.11254, 0.30341, 0.26531]
Predicted label: 1
Correct prediction
Energy consumption = 204.802722 pJ
sum error= 95
Actual label: 1
Output voltages: [0.20985, 0.76285, 0.34917, 0.18864, 0.19884, 0.05585, 0.36732, 0.12177, 0.31023, 0.2375]
Predicted label: 1
Correct prediction
Energy consumption = 200.898508 pJ
sum error= 95
Actual label: 1
Output voltages: [0.2478, 0.65254, 0.31026, 0.31619, 0.35922, 0.10704, 0.40612, 0.067446, 0.24664, 0.1458]
Predicted label: 1
Correct prediction
Energy consumption = 203.521156 pJ
sum error= 95
Actual label: 1
Output voltages: [0.26206, 0.75426, 0.26122, 0.2426, 0.21924, 0.070454, 0.25738, 0.16297, 0.44386, 0.24907]
Predicted label: 1
Correct prediction
Energy consumption = 204.708710 pJ
sum error= 95
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 236 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 236 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 236 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29302, 0.24464, 0.27191, 0.16378, 0.32406, 0.38102, 0.7536, 0.087365, 0.39404, 0.15673]
Predicted label: 6
Correct prediction
Energy consumption = 190.709724 pJ
sum error= 95
Actual label: 9
Output voltages: [0.32144, 0.13628, 0.24708, 0.27699, 0.62396, 0.071474, 0.1244, 0.17241, 0.25741, 0.57163]
Predicted label: 4
Wrong prediction!
Energy consumption = 194.496816 pJ
sum error= 96
Actual label: 8
Output voltages: [0.22349, 0.36759, 0.32619, 0.24529, 0.20841, 0.12624, 0.34243, 0.055156, 0.67447, 0.31532]
Predicted label: 8
Correct prediction
Energy consumption = 201.856882 pJ
sum error= 96
Actual label: 4
Output voltages: [0.16262, 0.16286, 0.16793, 0.087268, 0.68777, 0.21215, 0.24146, 0.42214, 0.33765, 0.22635]
Predicted label: 4
Correct prediction
Energy consumption = 199.040259 pJ
sum error= 96
Actual label: 3
Output voltages: [0.31992, 0.19163, 0.26012, 0.75758, 0.24996, 0.20659, 0.20242, 0.20087, 0.37673, 0.23347]
Predicted label: 3
Correct prediction
Energy consumption = 192.182138 pJ
sum error= 96
Actual label: 7
Output voltages: [0.35142, 0.28486, 0.27841, 0.11427, 0.17377, 0.12374, 0.047923, 0.74773, 0.42472, 0.27155]
Predicted label: 7
Correct prediction
Energy consumption = 189.499639 pJ
sum error= 96
Actual label: 1
Output voltages: [0.24184, 0.76115, 0.20948, 0.31607, 0.27044, 0.055002, 0.26832, 0.17199, 0.27256, 0.29644]
Predicted label: 1
Correct prediction
Energy consumption = 212.752343 pJ
sum error= 96
Actual label: 6
Output voltages: [0.34453, 0.19529, 0.21206, 0.21369, 0.30784, 0.45819, 0.69335, 0.12159, 0.4698, 0.085691]
Predicted label: 6
Correct prediction
Energy consumption = 200.435941 pJ
sum error= 96
Actual label: 4
Output voltages: [0.15202, 0.15359, 0.25641, 0.148, 0.75118, 0.06753, 0.2385, 0.28483, 0.26593, 0.24452]
Predicted label: 4
Correct prediction
Energy consumption = 195.790354 pJ
sum error= 96
Actual label: 5
Output voltages: [0.19147, 0.13309, 0.04704, 0.43, 0.36025, 0.55658, 0.29537, 0.23711, 0.4177, 0.35159]
Predicted label: 5
Correct prediction
Energy consumption = 192.351305 pJ
sum error= 96
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 237 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 237 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 237 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.58554, 0.15017, 0.24234, 0.084099, 0.19511, 0.31629, 0.50938, 0.089926, 0.32403, 0.28426]
Predicted label: 0
Correct prediction
Energy consumption = 202.146913 pJ
sum error= 96
Actual label: 4
Output voltages: [0.21951, 0.14625, 0.3757, 0.18501, 0.72639, 0.058221, 0.20235, 0.16479, 0.22039, 0.41777]
Predicted label: 4
Correct prediction
Energy consumption = 188.312866 pJ
sum error= 96
Actual label: 7
Output voltages: [0.3036, 0.23852, 0.29153, 0.22892, 0.16643, 0.061211, 0.081431, 0.75333, 0.24582, 0.3858]
Predicted label: 7
Correct prediction
Energy consumption = 195.567280 pJ
sum error= 96
Actual label: 4
Output voltages: [0.14254, 0.15728, 0.29571, 0.20387, 0.74137, 0.046902, 0.19354, 0.27433, 0.24689, 0.24143]
Predicted label: 4
Correct prediction
Energy consumption = 187.592691 pJ
sum error= 96
Actual label: 2
Output voltages: [0.37076, 0.32589, 0.70964, 0.29131, 0.13403, 0.02896, 0.27602, 0.26221, 0.46791, 0.26793]
Predicted label: 2
Correct prediction
Energy consumption = 195.983705 pJ
sum error= 96
Actual label: 4
Output voltages: [0.14167, 0.1391, 0.35196, 0.16636, 0.75146, 0.12027, 0.28588, 0.14639, 0.25237, 0.39367]
Predicted label: 4
Correct prediction
Energy consumption = 197.002206 pJ
sum error= 96
Actual label: 0
Output voltages: [0.71636, 0.16051, 0.27211, 0.13643, 0.17847, 0.22756, 0.40333, 0.16463, 0.38093, 0.16628]
Predicted label: 0
Correct prediction
Energy consumption = 194.801753 pJ
sum error= 96
Actual label: 7
Output voltages: [0.31377, 0.28202, 0.33175, 0.32638, 0.14385, 0.10248, 0.031676, 0.71867, 0.39838, 0.38346]
Predicted label: 7
Correct prediction
Energy consumption = 191.052471 pJ
sum error= 96
Actual label: 0
Output voltages: [0.66083, 0.11592, 0.24546, 0.19513, 0.11469, 0.2902, 0.35718, 0.15403, 0.47426, 0.18262]
Predicted label: 0
Correct prediction
Energy consumption = 207.879993 pJ
sum error= 96
Actual label: 1
Output voltages: [0.18637, 0.75806, 0.31511, 0.2868, 0.14181, 0.056047, 0.41503, 0.12988, 0.32814, 0.19123]
Predicted label: 1
Correct prediction
Energy consumption = 205.305222 pJ
sum error= 96
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 238 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 238 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 238 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.48436, 0.07912, 0.32951, 0.21041, 0.229, 0.16631, 0.27105, 0.13444, 0.3606, 0.57999]
Predicted label: 9
Correct prediction
Energy consumption = 206.683469 pJ
sum error= 96
Actual label: 8
Output voltages: [0.17358, 0.2599, 0.22942, 0.20443, 0.16012, 0.16386, 0.14229, 0.27586, 0.74136, 0.34826]
Predicted label: 8
Correct prediction
Energy consumption = 193.135475 pJ
sum error= 96
Actual label: 8
Output voltages: [0.28062, 0.07504, 0.41538, 0.37402, 0.151, 0.1314, 0.14737, 0.23166, 0.70823, 0.2843]
Predicted label: 8
Correct prediction
Energy consumption = 190.981652 pJ
sum error= 96
Actual label: 6
Output voltages: [0.28286, 0.25912, 0.35606, 0.08075, 0.35489, 0.28789, 0.7498, 0.063486, 0.36453, 0.14231]
Predicted label: 6
Correct prediction
Energy consumption = 194.488402 pJ
sum error= 96
Actual label: 0
Output voltages: [0.68805, 0.18477, 0.26167, 0.20721, 0.18494, 0.11872, 0.39173, 0.17485, 0.32776, 0.42813]
Predicted label: 0
Correct prediction
Energy consumption = 201.278116 pJ
sum error= 96
Actual label: 0
Output voltages: [0.72299, 0.27001, 0.27578, 0.12862, 0.091768, 0.13067, 0.39116, 0.25841, 0.3317, 0.25004]
Predicted label: 0
Correct prediction
Energy consumption = 182.311516 pJ
sum error= 96
Actual label: 4
Output voltages: [0.098761, 0.24641, 0.18602, 0.076207, 0.74679, 0.13118, 0.2052, 0.3553, 0.35952, 0.22753]
Predicted label: 4
Correct prediction
Energy consumption = 207.421714 pJ
sum error= 96
Actual label: 9
Output voltages: [0.25462, 0.59767, 0.17195, 0.22929, 0.27196, 0.10828, 0.1452, 0.13106, 0.30449, 0.48752]
Predicted label: 1
Wrong prediction!
Energy consumption = 214.579704 pJ
sum error= 97
Actual label: 6
Output voltages: [0.30805, 0.18378, 0.27327, 0.12066, 0.34854, 0.35807, 0.73592, 0.078506, 0.43297, 0.10244]
Predicted label: 6
Correct prediction
Energy consumption = 197.607758 pJ
sum error= 97
Actual label: 8
Output voltages: [0.23197, 0.16186, 0.29866, 0.2828, 0.17852, 0.204, 0.24124, 0.10686, 0.73698, 0.32193]
Predicted label: 8
Correct prediction
Energy consumption = 192.902690 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 239 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 239 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 239 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33546, 0.36448, 0.72669, 0.31367, 0.15937, 0.021005, 0.30318, 0.23244, 0.34383, 0.25204]
Predicted label: 2
Correct prediction
Energy consumption = 192.852638 pJ
sum error= 97
Actual label: 2
Output voltages: [0.30517, 0.29335, 0.72758, 0.30912, 0.1802, 0.031558, 0.3126, 0.22493, 0.41447, 0.20353]
Predicted label: 2
Correct prediction
Energy consumption = 181.432341 pJ
sum error= 97
Actual label: 3
Output voltages: [0.35393, 0.24054, 0.29589, 0.75721, 0.10238, 0.099018, 0.16011, 0.19904, 0.41885, 0.27516]
Predicted label: 3
Correct prediction
Energy consumption = 194.976885 pJ
sum error= 97
Actual label: 8
Output voltages: [0.2724, 0.087279, 0.26164, 0.45802, 0.15539, 0.29622, 0.19257, 0.057621, 0.65438, 0.29314]
Predicted label: 8
Correct prediction
Energy consumption = 190.909155 pJ
sum error= 97
Actual label: 4
Output voltages: [0.2164, 0.18903, 0.31083, 0.16644, 0.72331, 0.11266, 0.19106, 0.2372, 0.20858, 0.4526]
Predicted label: 4
Correct prediction
Energy consumption = 192.816999 pJ
sum error= 97
Actual label: 8
Output voltages: [0.31239, 0.11016, 0.2765, 0.41816, 0.20381, 0.17725, 0.34648, 0.050725, 0.64168, 0.2029]
Predicted label: 8
Correct prediction
Energy consumption = 202.533105 pJ
sum error= 97
Actual label: 2
Output voltages: [0.51107, 0.20276, 0.7173, 0.25952, 0.11441, 0.060478, 0.3359, 0.26965, 0.2981, 0.10237]
Predicted label: 2
Correct prediction
Energy consumption = 193.250537 pJ
sum error= 97
Actual label: 2
Output voltages: [0.33687, 0.29377, 0.72175, 0.31224, 0.065691, 0.030909, 0.25676, 0.23634, 0.45828, 0.23213]
Predicted label: 2
Correct prediction
Energy consumption = 184.616728 pJ
sum error= 97
Actual label: 1
Output voltages: [0.20889, 0.7102, 0.23053, 0.23708, 0.21177, 0.10059, 0.24896, 0.12106, 0.47238, 0.21829]
Predicted label: 1
Correct prediction
Energy consumption = 200.653024 pJ
sum error= 97
Actual label: 7
Output voltages: [0.29368, 0.25368, 0.25681, 0.30525, 0.10236, 0.083596, 0.045925, 0.7582, 0.35661, 0.34917]
Predicted label: 7
Correct prediction
Energy consumption = 194.100280 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 240 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 240 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 240 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.26583, 0.04274, 0.15109, 0.38051, 0.15072, 0.70485, 0.18527, 0.29089, 0.5468, 0.20719]
Predicted label: 5
Correct prediction
Energy consumption = 191.605180 pJ
sum error= 97
Actual label: 4
Output voltages: [0.11901, 0.17926, 0.30472, 0.16638, 0.75234, 0.056715, 0.2949, 0.34242, 0.20881, 0.26707]
Predicted label: 4
Correct prediction
Energy consumption = 199.415254 pJ
sum error= 97
Actual label: 4
Output voltages: [0.14494, 0.15904, 0.29138, 0.16701, 0.75777, 0.080636, 0.27016, 0.30769, 0.23141, 0.28621]
Predicted label: 4
Correct prediction
Energy consumption = 194.598391 pJ
sum error= 97
Actual label: 0
Output voltages: [0.72705, 0.21363, 0.1906, 0.22623, 0.16962, 0.29464, 0.4411, 0.11936, 0.23815, 0.26168]
Predicted label: 0
Correct prediction
Energy consumption = 201.917463 pJ
sum error= 97
Actual label: 4
Output voltages: [0.20377, 0.17519, 0.2782, 0.15511, 0.74953, 0.1419, 0.44057, 0.16126, 0.19414, 0.25433]
Predicted label: 4
Correct prediction
Energy consumption = 194.097558 pJ
sum error= 97
Actual label: 3
Output voltages: [0.48818, 0.20295, 0.39503, 0.7265, 0.12056, 0.1714, 0.13367, 0.26429, 0.32996, 0.13866]
Predicted label: 3
Correct prediction
Energy consumption = 197.265833 pJ
sum error= 97
Actual label: 9
Output voltages: [0.35119, 0.42641, 0.1843, 0.25324, 0.33856, 0.049593, 0.19599, 0.1306, 0.44406, 0.50519]
Predicted label: 9
Correct prediction
Energy consumption = 204.536478 pJ
sum error= 97
Actual label: 7
Output voltages: [0.30627, 0.24673, 0.17813, 0.25497, 0.11669, 0.11272, 0.044666, 0.75212, 0.41677, 0.3848]
Predicted label: 7
Correct prediction
Energy consumption = 203.133254 pJ
sum error= 97
Actual label: 3
Output voltages: [0.23405, 0.17218, 0.17376, 0.64297, 0.23984, 0.24587, 0.10848, 0.16837, 0.45378, 0.31146]
Predicted label: 3
Correct prediction
Energy consumption = 204.712241 pJ
sum error= 97
Actual label: 1
Output voltages: [0.27562, 0.68987, 0.28797, 0.22505, 0.31405, 0.043449, 0.21922, 0.19574, 0.36312, 0.3227]
Predicted label: 1
Correct prediction
Energy consumption = 207.192612 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 241 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 241 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 241 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73138, 0.17421, 0.25976, 0.30077, 0.11023, 0.14972, 0.29443, 0.19547, 0.36932, 0.24399]
Predicted label: 0
Correct prediction
Energy consumption = 207.412101 pJ
sum error= 97
Actual label: 1
Output voltages: [0.24136, 0.7751, 0.19667, 0.25462, 0.18918, 0.13122, 0.39167, 0.13215, 0.29486, 0.26989]
Predicted label: 1
Correct prediction
Energy consumption = 212.696584 pJ
sum error= 97
Actual label: 2
Output voltages: [0.27636, 0.38537, 0.72074, 0.31514, 0.18605, 0.038139, 0.2794, 0.14565, 0.37391, 0.25523]
Predicted label: 2
Correct prediction
Energy consumption = 188.652716 pJ
sum error= 97
Actual label: 5
Output voltages: [0.28857, 0.060412, 0.086835, 0.3844, 0.19679, 0.74288, 0.29567, 0.24679, 0.51413, 0.23654]
Predicted label: 5
Correct prediction
Energy consumption = 193.737173 pJ
sum error= 97
Actual label: 9
Output voltages: [0.28238, 0.10594, 0.23942, 0.23358, 0.49983, 0.04127, 0.081789, 0.16858, 0.43916, 0.45724]
Predicted label: 4
Wrong prediction!
Energy consumption = 201.562481 pJ
sum error= 98
Actual label: 2
Output voltages: [0.37194, 0.11773, 0.64172, 0.27422, 0.25501, 0.028374, 0.31054, 0.25368, 0.46819, 0.21108]
Predicted label: 2
Correct prediction
Energy consumption = 195.276014 pJ
sum error= 98
Actual label: 1
Output voltages: [0.22042, 0.74732, 0.18625, 0.28874, 0.196, 0.15708, 0.47268, 0.08435, 0.35106, 0.15979]
Predicted label: 1
Correct prediction
Energy consumption = 207.187517 pJ
sum error= 98
Actual label: 0
Output voltages: [0.59568, 0.19186, 0.31489, 0.18804, 0.2358, 0.071739, 0.50101, 0.16175, 0.29027, 0.25673]
Predicted label: 0
Correct prediction
Energy consumption = 201.020974 pJ
sum error= 98
Actual label: 1
Output voltages: [0.22882, 0.7633, 0.15618, 0.21934, 0.39245, 0.13526, 0.37093, 0.10352, 0.22789, 0.26887]
Predicted label: 1
Correct prediction
Energy consumption = 208.650778 pJ
sum error= 98
Actual label: 8
Output voltages: [0.25802, 0.16368, 0.2736, 0.38368, 0.12922, 0.25382, 0.18542, 0.11626, 0.73931, 0.28726]
Predicted label: 8
Correct prediction
Energy consumption = 190.942546 pJ
sum error= 98
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 242 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 242 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 242 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.35934, 0.10475, 0.23017, 0.22915, 0.36548, 0.20634, 0.17874, 0.24358, 0.28492, 0.69066]
Predicted label: 9
Correct prediction
Energy consumption = 196.691085 pJ
sum error= 98
Actual label: 1
Output voltages: [0.20096, 0.72602, 0.15546, 0.41887, 0.19014, 0.17689, 0.26635, 0.14529, 0.24072, 0.38926]
Predicted label: 1
Correct prediction
Energy consumption = 221.882595 pJ
sum error= 98
Actual label: 6
Output voltages: [0.30887, 0.14114, 0.11982, 0.072798, 0.54293, 0.19829, 0.50221, 0.26602, 0.26933, 0.27464]
Predicted label: 4
Wrong prediction!
Energy consumption = 205.537243 pJ
sum error= 99
Actual label: 8
Output voltages: [0.19442, 0.20098, 0.27384, 0.23689, 0.17211, 0.20071, 0.14875, 0.12537, 0.73471, 0.36534]
Predicted label: 8
Correct prediction
Energy consumption = 194.319163 pJ
sum error= 99
Actual label: 3
Output voltages: [0.36554, 0.19167, 0.28542, 0.76226, 0.1734, 0.24681, 0.1773, 0.23772, 0.37097, 0.24078]
Predicted label: 3
Correct prediction
Energy consumption = 189.145442 pJ
sum error= 99
Actual label: 8
Output voltages: [0.15959, 0.23412, 0.22288, 0.25844, 0.15488, 0.20884, 0.13792, 0.34737, 0.7174, 0.28096]
Predicted label: 8
Correct prediction
Energy consumption = 202.094543 pJ
sum error= 99
Actual label: 9
Output voltages: [0.36242, 0.075857, 0.17692, 0.31279, 0.31754, 0.1715, 0.070635, 0.34299, 0.34478, 0.58066]
Predicted label: 9
Correct prediction
Energy consumption = 200.028704 pJ
sum error= 99
Actual label: 3
Output voltages: [0.30606, 0.189, 0.36137, 0.74905, 0.14229, 0.12431, 0.15269, 0.11173, 0.44651, 0.22592]
Predicted label: 3
Correct prediction
Energy consumption = 178.061374 pJ
sum error= 99
Actual label: 6
Output voltages: [0.27568, 0.16963, 0.28937, 0.10739, 0.33163, 0.33693, 0.72947, 0.065877, 0.41813, 0.13991]
Predicted label: 6
Correct prediction
Energy consumption = 194.816196 pJ
sum error= 99
Actual label: 2
Output voltages: [0.31987, 0.52041, 0.64148, 0.34626, 0.14383, 0.02697, 0.24657, 0.2823, 0.25355, 0.17775]
Predicted label: 2
Correct prediction
Energy consumption = 192.810017 pJ
sum error= 99
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 243 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 243 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 243 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.19938, 0.14107, 0.27952, 0.37251, 0.10673, 0.23181, 0.22563, 0.14466, 0.733, 0.23604]
Predicted label: 8
Correct prediction
Energy consumption = 200.340840 pJ
sum error= 99
Actual label: 3
Output voltages: [0.52892, 0.11926, 0.33402, 0.74739, 0.18983, 0.22644, 0.10672, 0.20187, 0.41412, 0.14408]
Predicted label: 3
Correct prediction
Energy consumption = 189.619149 pJ
sum error= 99
Actual label: 2
Output voltages: [0.36446, 0.42812, 0.73411, 0.27296, 0.15236, 0.026294, 0.32054, 0.26987, 0.33505, 0.25858]
Predicted label: 2
Correct prediction
Energy consumption = 183.105359 pJ
sum error= 99
Actual label: 2
Output voltages: [0.16721, 0.43762, 0.61099, 0.37685, 0.13513, 0.035588, 0.23163, 0.23902, 0.42605, 0.20367]
Predicted label: 2
Correct prediction
Energy consumption = 185.117729 pJ
sum error= 99
Actual label: 1
Output voltages: [0.19194, 0.75082, 0.34257, 0.2902, 0.093887, 0.085667, 0.26465, 0.17121, 0.39205, 0.24002]
Predicted label: 1
Correct prediction
Energy consumption = 205.113610 pJ
sum error= 99
Actual label: 0
Output voltages: [0.74574, 0.28657, 0.23753, 0.19653, 0.15507, 0.23469, 0.41344, 0.18464, 0.27065, 0.20283]
Predicted label: 0
Correct prediction
Energy consumption = 197.299681 pJ
sum error= 99
Actual label: 4
Output voltages: [0.2391, 0.11883, 0.37636, 0.12825, 0.74135, 0.090931, 0.29777, 0.15441, 0.22585, 0.36254]
Predicted label: 4
Correct prediction
Energy consumption = 199.061921 pJ
sum error= 99
Actual label: 2
Output voltages: [0.29823, 0.42085, 0.61586, 0.29722, 0.28952, 0.043605, 0.25443, 0.28175, 0.31576, 0.13137]
Predicted label: 2
Correct prediction
Energy consumption = 191.836763 pJ
sum error= 99
Actual label: 9
Output voltages: [0.34934, 0.13352, 0.18872, 0.20597, 0.26892, 0.16277, 0.058471, 0.25526, 0.38917, 0.6677]
Predicted label: 9
Correct prediction
Energy consumption = 198.667474 pJ
sum error= 99
Actual label: 2
Output voltages: [0.4186, 0.24747, 0.72997, 0.34416, 0.090483, 0.041659, 0.28709, 0.21955, 0.4557, 0.1697]
Predicted label: 2
Correct prediction
Energy consumption = 186.498173 pJ
sum error= 99
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 244 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 244 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 244 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.12325, 0.17532, 0.30986, 0.18674, 0.7623, 0.12025, 0.27745, 0.34154, 0.23241, 0.21931]
Predicted label: 4
Correct prediction
Energy consumption = 193.102972 pJ
sum error= 99
Actual label: 3
Output voltages: [0.29189, 0.28014, 0.3466, 0.7274, 0.13389, 0.05214, 0.10109, 0.32269, 0.28747, 0.28091]
Predicted label: 3
Correct prediction
Energy consumption = 192.950527 pJ
sum error= 99
Actual label: 7
Output voltages: [0.41903, 0.20418, 0.37528, 0.20096, 0.091472, 0.073245, 0.059203, 0.74493, 0.42508, 0.24388]
Predicted label: 7
Correct prediction
Energy consumption = 199.059615 pJ
sum error= 99
Actual label: 9
Output voltages: [0.35028, 0.12011, 0.23456, 0.22407, 0.28298, 0.18061, 0.11262, 0.26691, 0.37696, 0.67577]
Predicted label: 9
Correct prediction
Energy consumption = 188.538579 pJ
sum error= 99
Actual label: 1
Output voltages: [0.27343, 0.76763, 0.25277, 0.29176, 0.15972, 0.14907, 0.40809, 0.082654, 0.26554, 0.23607]
Predicted label: 1
Correct prediction
Energy consumption = 214.515109 pJ
sum error= 99
Actual label: 5
Output voltages: [0.2509, 0.068409, 0.04985, 0.30766, 0.31472, 0.66985, 0.23162, 0.31881, 0.40252, 0.34038]
Predicted label: 5
Correct prediction
Energy consumption = 198.159608 pJ
sum error= 99
Actual label: 2
Output voltages: [0.35021, 0.40247, 0.69061, 0.39724, 0.12614, 0.02884, 0.33787, 0.16431, 0.36072, 0.19383]
Predicted label: 2
Correct prediction
Energy consumption = 189.521713 pJ
sum error= 99
Actual label: 4
Output voltages: [0.33292, 0.18637, 0.17367, 0.27182, 0.60543, 0.072053, 0.14246, 0.34411, 0.15142, 0.49268]
Predicted label: 4
Correct prediction
Energy consumption = 203.572667 pJ
sum error= 99
Actual label: 9
Output voltages: [0.31015, 0.14622, 0.18582, 0.24682, 0.29975, 0.14965, 0.1137, 0.19945, 0.38335, 0.69373]
Predicted label: 9
Correct prediction
Energy consumption = 189.039406 pJ
sum error= 99
Actual label: 0
Output voltages: [0.63245, 0.21704, 0.19648, 0.18421, 0.17172, 0.13638, 0.41234, 0.23613, 0.41434, 0.32595]
Predicted label: 0
Correct prediction
Energy consumption = 207.677870 pJ
sum error= 99
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 245 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 245 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 245 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26027, 0.13331, 0.15839, 0.64894, 0.21395, 0.45395, 0.24546, 0.20296, 0.37147, 0.15099]
Predicted label: 3
Correct prediction
Energy consumption = 202.401982 pJ
sum error= 99
Actual label: 8
Output voltages: [0.18188, 0.22858, 0.2646, 0.28402, 0.16343, 0.2453, 0.17092, 0.19087, 0.75235, 0.31083]
Predicted label: 8
Correct prediction
Energy consumption = 195.968728 pJ
sum error= 99
Actual label: 5
Output voltages: [0.19989, 0.057222, 0.11838, 0.35442, 0.22145, 0.73572, 0.27555, 0.26012, 0.53451, 0.2693]
Predicted label: 5
Correct prediction
Energy consumption = 184.690744 pJ
sum error= 99
Actual label: 3
Output voltages: [0.30698, 0.2345, 0.27947, 0.76659, 0.18507, 0.18328, 0.14023, 0.22696, 0.39561, 0.32627]
Predicted label: 3
Correct prediction
Energy consumption = 187.186120 pJ
sum error= 99
Actual label: 6
Output voltages: [0.3569, 0.090548, 0.20692, 0.33012, 0.088347, 0.60006, 0.51769, 0.10167, 0.50172, 0.1902]
Predicted label: 5
Wrong prediction!
Energy consumption = 202.596369 pJ
sum error= 100
Actual label: 0
Output voltages: [0.5719, 0.24347, 0.36445, 0.13116, 0.13536, 0.091485, 0.52174, 0.18797, 0.33658, 0.2435]
Predicted label: 0
Correct prediction
Energy consumption = 196.029448 pJ
sum error= 100
Actual label: 9
Output voltages: [0.27045, 0.10059, 0.21394, 0.25538, 0.21036, 0.16037, 0.070181, 0.23392, 0.48806, 0.63071]
Predicted label: 9
Correct prediction
Energy consumption = 188.007689 pJ
sum error= 100
Actual label: 4
Output voltages: [0.082895, 0.15735, 0.20516, 0.072798, 0.63725, 0.14592, 0.28828, 0.28448, 0.46434, 0.23486]
Predicted label: 4
Correct prediction
Energy consumption = 192.479410 pJ
sum error= 100
Actual label: 6
Output voltages: [0.31305, 0.21447, 0.26367, 0.14114, 0.32195, 0.37176, 0.74307, 0.073755, 0.382, 0.14814]
Predicted label: 6
Correct prediction
Energy consumption = 189.326923 pJ
sum error= 100
Actual label: 2
Output voltages: [0.31271, 0.40481, 0.7181, 0.34171, 0.12014, 0.031767, 0.19309, 0.35308, 0.28654, 0.27408]
Predicted label: 2
Correct prediction
Energy consumption = 204.047130 pJ
sum error= 100
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 246 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 246 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 246 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25, 0.055085, 0.063317, 0.39661, 0.3527, 0.66427, 0.44929, 0.076676, 0.43769, 0.27383]
Predicted label: 5
Correct prediction
Energy consumption = 195.070744 pJ
sum error= 100
Actual label: 0
Output voltages: [0.73195, 0.24153, 0.32259, 0.21189, 0.17804, 0.096045, 0.36978, 0.18207, 0.30436, 0.2829]
Predicted label: 0
Correct prediction
Energy consumption = 202.709672 pJ
sum error= 100
Actual label: 2
Output voltages: [0.5821, 0.15791, 0.40393, 0.14982, 0.17316, 0.086963, 0.41861, 0.096006, 0.45339, 0.24902]
Predicted label: 0
Wrong prediction!
Energy consumption = 197.397472 pJ
sum error= 101
Actual label: 7
Output voltages: [0.35651, 0.30996, 0.34203, 0.22257, 0.18465, 0.044867, 0.036076, 0.70046, 0.2348, 0.42096]
Predicted label: 7
Correct prediction
Energy consumption = 197.799599 pJ
sum error= 101
Actual label: 4
Output voltages: [0.21192, 0.086216, 0.31535, 0.1483, 0.74051, 0.1676, 0.30512, 0.1578, 0.24984, 0.43884]
Predicted label: 4
Correct prediction
Energy consumption = 200.786276 pJ
sum error= 101
Actual label: 6
Output voltages: [0.2971, 0.16597, 0.25835, 0.15809, 0.33056, 0.44346, 0.72558, 0.055658, 0.39065, 0.13879]
Predicted label: 6
Correct prediction
Energy consumption = 187.385678 pJ
sum error= 101
Actual label: 6
Output voltages: [0.2606, 0.15289, 0.29726, 0.12847, 0.30105, 0.43218, 0.72885, 0.058919, 0.38556, 0.22473]
Predicted label: 6
Correct prediction
Energy consumption = 176.067641 pJ
sum error= 101
Actual label: 8
Output voltages: [0.19713, 0.22482, 0.2738, 0.3211, 0.1401, 0.20679, 0.1932, 0.17449, 0.74512, 0.32172]
Predicted label: 8
Correct prediction
Energy consumption = 191.020756 pJ
sum error= 101
Actual label: 6
Output voltages: [0.31907, 0.25676, 0.26422, 0.14934, 0.27814, 0.41006, 0.74838, 0.10146, 0.34397, 0.18425]
Predicted label: 6
Correct prediction
Energy consumption = 196.778672 pJ
sum error= 101
Actual label: 6
Output voltages: [0.38481, 0.24542, 0.30067, 0.080624, 0.33779, 0.31576, 0.73466, 0.16591, 0.32796, 0.098796]
Predicted label: 6
Correct prediction
Energy consumption = 196.442371 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 247 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 247 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 247 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.28815, 0.16587, 0.31648, 0.23161, 0.18208, 0.18195, 0.16501, 0.18605, 0.73152, 0.37171]
Predicted label: 8
Correct prediction
Energy consumption = 194.428055 pJ
sum error= 101
Actual label: 6
Output voltages: [0.26624, 0.21324, 0.36513, 0.094709, 0.40633, 0.26381, 0.73743, 0.10833, 0.37709, 0.087222]
Predicted label: 6
Correct prediction
Energy consumption = 195.744327 pJ
sum error= 101
Actual label: 9
Output voltages: [0.3028, 0.13762, 0.1599, 0.30633, 0.35253, 0.12532, 0.075597, 0.19078, 0.3932, 0.63535]
Predicted label: 9
Correct prediction
Energy consumption = 195.946387 pJ
sum error= 101
Actual label: 1
Output voltages: [0.26003, 0.7447, 0.1131, 0.20403, 0.25747, 0.16342, 0.40138, 0.14405, 0.3607, 0.20141]
Predicted label: 1
Correct prediction
Energy consumption = 214.636603 pJ
sum error= 101
Actual label: 7
Output voltages: [0.30957, 0.28784, 0.32135, 0.34221, 0.12866, 0.050519, 0.037985, 0.65851, 0.47435, 0.29439]
Predicted label: 7
Correct prediction
Energy consumption = 207.089932 pJ
sum error= 101
Actual label: 2
Output voltages: [0.31373, 0.35631, 0.71139, 0.36961, 0.084678, 0.041036, 0.28793, 0.17211, 0.46433, 0.21975]
Predicted label: 2
Correct prediction
Energy consumption = 186.209182 pJ
sum error= 101
Actual label: 5
Output voltages: [0.23904, 0.10356, 0.082704, 0.50048, 0.23117, 0.59589, 0.33792, 0.17107, 0.44474, 0.27888]
Predicted label: 5
Correct prediction
Energy consumption = 189.932346 pJ
sum error= 101
Actual label: 9
Output voltages: [0.32853, 0.14317, 0.18493, 0.19742, 0.3444, 0.17803, 0.16127, 0.28481, 0.34441, 0.65414]
Predicted label: 9
Correct prediction
Energy consumption = 193.868825 pJ
sum error= 101
Actual label: 9
Output voltages: [0.35418, 0.11025, 0.2186, 0.24765, 0.32781, 0.19575, 0.073681, 0.21542, 0.36775, 0.68315]
Predicted label: 9
Correct prediction
Energy consumption = 196.359967 pJ
sum error= 101
Actual label: 0
Output voltages: [0.69598, 0.23523, 0.21542, 0.21991, 0.14183, 0.16834, 0.35719, 0.22049, 0.31741, 0.35064]
Predicted label: 0
Correct prediction
Energy consumption = 197.773350 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 248 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 248 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 248 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.40338, 0.30754, 0.45058, 0.21328, 0.19082, 0.040933, 0.059267, 0.62657, 0.18902, 0.44509]
Predicted label: 7
Correct prediction
Energy consumption = 197.220903 pJ
sum error= 101
Actual label: 2
Output voltages: [0.3649, 0.21601, 0.70146, 0.38188, 0.14886, 0.029907, 0.29903, 0.2613, 0.50029, 0.19372]
Predicted label: 2
Correct prediction
Energy consumption = 185.269120 pJ
sum error= 101
Actual label: 7
Output voltages: [0.25065, 0.25521, 0.32808, 0.36998, 0.068727, 0.049184, 0.041731, 0.73214, 0.43755, 0.32421]
Predicted label: 7
Correct prediction
Energy consumption = 202.573674 pJ
sum error= 101
Actual label: 6
Output voltages: [0.29468, 0.17778, 0.29315, 0.12397, 0.36273, 0.33302, 0.73035, 0.052491, 0.38431, 0.17536]
Predicted label: 6
Correct prediction
Energy consumption = 190.697849 pJ
sum error= 101
Actual label: 7
Output voltages: [0.23942, 0.20664, 0.13374, 0.20989, 0.20545, 0.17434, 0.037819, 0.72942, 0.43753, 0.38934]
Predicted label: 7
Correct prediction
Energy consumption = 203.161035 pJ
sum error= 101
Actual label: 0
Output voltages: [0.74228, 0.24833, 0.19655, 0.23142, 0.13457, 0.30811, 0.36663, 0.1346, 0.27918, 0.2252]
Predicted label: 0
Correct prediction
Energy consumption = 202.665823 pJ
sum error= 101
Actual label: 6
Output voltages: [0.27478, 0.21112, 0.34112, 0.062505, 0.37459, 0.33577, 0.7447, 0.069667, 0.34089, 0.11989]
Predicted label: 6
Correct prediction
Energy consumption = 182.261733 pJ
sum error= 101
Actual label: 5
Output voltages: [0.23636, 0.10691, 0.080604, 0.30386, 0.18995, 0.73196, 0.23772, 0.14008, 0.52805, 0.26347]
Predicted label: 5
Correct prediction
Energy consumption = 194.466589 pJ
sum error= 101
Actual label: 2
Output voltages: [0.34311, 0.37058, 0.5316, 0.12158, 0.30985, 0.021575, 0.24767, 0.37049, 0.35563, 0.17849]
Predicted label: 2
Correct prediction
Energy consumption = 212.418442 pJ
sum error= 101
Actual label: 4
Output voltages: [0.2048, 0.13275, 0.30266, 0.12814, 0.74991, 0.14074, 0.26862, 0.16355, 0.2101, 0.38774]
Predicted label: 4
Correct prediction
Energy consumption = 196.525479 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 249 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 249 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 249 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.29284, 0.301, 0.43156, 0.14042, 0.20332, 0.037837, 0.035413, 0.70997, 0.3303, 0.25393]
Predicted label: 7
Correct prediction
Energy consumption = 199.475377 pJ
sum error= 101
Actual label: 2
Output voltages: [0.39487, 0.36296, 0.71802, 0.41036, 0.13639, 0.030766, 0.21969, 0.2744, 0.29579, 0.24058]
Predicted label: 2
Correct prediction
Energy consumption = 185.695518 pJ
sum error= 101
Actual label: 0
Output voltages: [0.73185, 0.29827, 0.26159, 0.18849, 0.1496, 0.098681, 0.37292, 0.25429, 0.31657, 0.30976]
Predicted label: 0
Correct prediction
Energy consumption = 189.675180 pJ
sum error= 101
Actual label: 9
Output voltages: [0.37093, 0.13818, 0.17391, 0.26867, 0.33436, 0.17179, 0.096141, 0.21155, 0.3291, 0.68444]
Predicted label: 9
Correct prediction
Energy consumption = 195.714496 pJ
sum error= 101
Actual label: 9
Output voltages: [0.39424, 0.12633, 0.22204, 0.32296, 0.307, 0.21996, 0.14067, 0.25386, 0.303, 0.71275]
Predicted label: 9
Correct prediction
Energy consumption = 191.919983 pJ
sum error= 101
Actual label: 2
Output voltages: [0.39637, 0.21389, 0.72507, 0.37489, 0.22043, 0.034426, 0.2176, 0.22629, 0.38604, 0.21512]
Predicted label: 2
Correct prediction
Energy consumption = 187.406905 pJ
sum error= 101
Actual label: 2
Output voltages: [0.25649, 0.226, 0.71659, 0.40934, 0.11428, 0.036162, 0.18167, 0.31164, 0.3875, 0.17226]
Predicted label: 2
Correct prediction
Energy consumption = 182.197771 pJ
sum error= 101
Actual label: 9
Output voltages: [0.31658, 0.14968, 0.18389, 0.31015, 0.27794, 0.17564, 0.075773, 0.15735, 0.40727, 0.62029]
Predicted label: 9
Correct prediction
Energy consumption = 189.469306 pJ
sum error= 101
Actual label: 4
Output voltages: [0.1456, 0.1718, 0.24959, 0.15746, 0.75381, 0.20932, 0.25619, 0.28119, 0.19668, 0.35779]
Predicted label: 4
Correct prediction
Energy consumption = 193.465352 pJ
sum error= 101
Actual label: 4
Output voltages: [0.10299, 0.15952, 0.32951, 0.13095, 0.76117, 0.080346, 0.28003, 0.3209, 0.20539, 0.347]
Predicted label: 4
Correct prediction
Energy consumption = 188.809539 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 250 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 250 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 250 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.3478, 0.34791, 0.72673, 0.3316, 0.1413, 0.025033, 0.2728, 0.29882, 0.34853, 0.21636]
Predicted label: 2
Correct prediction
Energy consumption = 191.155494 pJ
sum error= 101
Actual label: 3
Output voltages: [0.45997, 0.20562, 0.26937, 0.76435, 0.091636, 0.28059, 0.10979, 0.30045, 0.34699, 0.21404]
Predicted label: 3
Correct prediction
Energy consumption = 184.519493 pJ
sum error= 101
Actual label: 3
Output voltages: [0.3571, 0.23277, 0.30569, 0.75617, 0.1429, 0.15508, 0.19912, 0.13408, 0.43786, 0.18352]
Predicted label: 3
Correct prediction
Energy consumption = 180.970180 pJ
sum error= 101
Actual label: 2
Output voltages: [0.39546, 0.18386, 0.73531, 0.37461, 0.2019, 0.046138, 0.22338, 0.23509, 0.41915, 0.11944]
Predicted label: 2
Correct prediction
Energy consumption = 179.917372 pJ
sum error= 101
Actual label: 1
Output voltages: [0.16638, 0.76328, 0.2393, 0.35638, 0.1796, 0.1523, 0.30661, 0.16157, 0.207, 0.28465]
Predicted label: 1
Correct prediction
Energy consumption = 213.964848 pJ
sum error= 101
Actual label: 7
Output voltages: [0.37662, 0.21521, 0.1566, 0.15336, 0.21319, 0.22085, 0.057588, 0.74381, 0.35207, 0.36103]
Predicted label: 7
Correct prediction
Energy consumption = 203.268291 pJ
sum error= 101
Actual label: 0
Output voltages: [0.69061, 0.2153, 0.21603, 0.15003, 0.22881, 0.15174, 0.51196, 0.14392, 0.27801, 0.25422]
Predicted label: 0
Correct prediction
Energy consumption = 193.906351 pJ
sum error= 101
Actual label: 7
Output voltages: [0.27562, 0.21136, 0.41393, 0.61384, 0.13902, 0.048271, 0.051785, 0.47193, 0.3898, 0.26401]
Predicted label: 3
Wrong prediction!
Energy consumption = 189.677049 pJ
sum error= 102
Actual label: 6
Output voltages: [0.26617, 0.25327, 0.31608, 0.15553, 0.23289, 0.36334, 0.72253, 0.20952, 0.38041, 0.10449]
Predicted label: 6
Correct prediction
Energy consumption = 198.544555 pJ
sum error= 102
Actual label: 4
Output voltages: [0.099736, 0.16807, 0.20828, 0.18432, 0.73897, 0.11972, 0.26225, 0.25586, 0.26226, 0.24562]
Predicted label: 4
Correct prediction
Energy consumption = 193.147762 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 251 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 251 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 251 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20652, 0.7566, 0.20328, 0.15373, 0.29524, 0.13536, 0.382, 0.14247, 0.32178, 0.18186]
Predicted label: 1
Correct prediction
Energy consumption = 205.635559 pJ
sum error= 102
Actual label: 3
Output voltages: [0.35695, 0.13818, 0.33597, 0.75416, 0.2215, 0.15004, 0.24288, 0.16543, 0.42647, 0.20424]
Predicted label: 3
Correct prediction
Energy consumption = 187.455373 pJ
sum error= 102
Actual label: 8
Output voltages: [0.28291, 0.1405, 0.31807, 0.30674, 0.10112, 0.18469, 0.16482, 0.076569, 0.70231, 0.40095]
Predicted label: 8
Correct prediction
Energy consumption = 193.341813 pJ
sum error= 102
Actual label: 7
Output voltages: [0.30701, 0.23821, 0.34808, 0.4347, 0.19022, 0.035288, 0.090932, 0.58917, 0.43477, 0.19419]
Predicted label: 7
Correct prediction
Energy consumption = 193.026490 pJ
sum error= 102
Actual label: 4
Output voltages: [0.28288, 0.24872, 0.31864, 0.086262, 0.69456, 0.047809, 0.3234, 0.23638, 0.16054, 0.46628]
Predicted label: 4
Correct prediction
Energy consumption = 201.161635 pJ
sum error= 102
Actual label: 5
Output voltages: [0.31055, 0.044045, 0.2147, 0.25949, 0.16575, 0.62761, 0.36723, 0.1109, 0.55455, 0.1657]
Predicted label: 5
Correct prediction
Energy consumption = 195.384613 pJ
sum error= 102
Actual label: 9
Output voltages: [0.38978, 0.13027, 0.39781, 0.24928, 0.31233, 0.063724, 0.24906, 0.16916, 0.34287, 0.60564]
Predicted label: 9
Correct prediction
Energy consumption = 197.707636 pJ
sum error= 102
Actual label: 2
Output voltages: [0.42151, 0.26187, 0.68695, 0.42979, 0.152, 0.033051, 0.27013, 0.24759, 0.4302, 0.19108]
Predicted label: 2
Correct prediction
Energy consumption = 184.767586 pJ
sum error= 102
Actual label: 5
Output voltages: [0.22035, 0.052615, 0.092832, 0.35195, 0.24845, 0.73225, 0.30684, 0.22012, 0.52286, 0.27113]
Predicted label: 5
Correct prediction
Energy consumption = 184.371117 pJ
sum error= 102
Actual label: 1
Output voltages: [0.13723, 0.76534, 0.17939, 0.34341, 0.24325, 0.15871, 0.32536, 0.1461, 0.28246, 0.25189]
Predicted label: 1
Correct prediction
Energy consumption = 210.814240 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 252 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 252 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 252 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.28543, 0.3374, 0.267, 0.3174, 0.11245, 0.11846, 0.31436, 0.16517, 0.66212, 0.19631]
Predicted label: 8
Correct prediction
Energy consumption = 209.849000 pJ
sum error= 102
Actual label: 7
Output voltages: [0.50932, 0.25468, 0.25836, 0.15623, 0.21408, 0.096305, 0.10632, 0.59105, 0.32687, 0.28234]
Predicted label: 7
Correct prediction
Energy consumption = 200.871991 pJ
sum error= 102
Actual label: 3
Output voltages: [0.22318, 0.15375, 0.2437, 0.74568, 0.30782, 0.22499, 0.19461, 0.22433, 0.44266, 0.24528]
Predicted label: 3
Correct prediction
Energy consumption = 194.102963 pJ
sum error= 102
Actual label: 7
Output voltages: [0.21993, 0.16976, 0.1355, 0.14133, 0.32076, 0.24886, 0.077239, 0.7271, 0.34766, 0.28737]
Predicted label: 7
Correct prediction
Energy consumption = 203.606061 pJ
sum error= 102
Actual label: 1
Output voltages: [0.11143, 0.75956, 0.18364, 0.22245, 0.27619, 0.18874, 0.45916, 0.10852, 0.35278, 0.22269]
Predicted label: 1
Correct prediction
Energy consumption = 211.876507 pJ
sum error= 102
Actual label: 5
Output voltages: [0.29569, 0.13839, 0.11493, 0.42025, 0.13859, 0.55352, 0.28629, 0.050054, 0.47857, 0.33298]
Predicted label: 5
Correct prediction
Energy consumption = 200.990987 pJ
sum error= 102
Actual label: 5
Output voltages: [0.25137, 0.071095, 0.22128, 0.54114, 0.17315, 0.52152, 0.22906, 0.13821, 0.56231, 0.26035]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.667236 pJ
sum error= 103
Actual label: 0
Output voltages: [0.70203, 0.24067, 0.26687, 0.20142, 0.20219, 0.096906, 0.48922, 0.14435, 0.27895, 0.29776]
Predicted label: 0
Correct prediction
Energy consumption = 195.420737 pJ
sum error= 103
Actual label: 9
Output voltages: [0.41198, 0.15533, 0.2708, 0.19773, 0.48874, 0.069584, 0.23109, 0.22815, 0.2656, 0.60268]
Predicted label: 9
Correct prediction
Energy consumption = 200.994162 pJ
sum error= 103
Actual label: 1
Output voltages: [0.17158, 0.75447, 0.24918, 0.22181, 0.2199, 0.077539, 0.44287, 0.12901, 0.351, 0.17971]
Predicted label: 1
Correct prediction
Energy consumption = 206.095969 pJ
sum error= 103
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 253 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 253 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 253 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.23739, 0.26326, 0.24508, 0.17095, 0.74044, 0.095418, 0.25998, 0.28351, 0.21335, 0.34166]
Predicted label: 4
Correct prediction
Energy consumption = 210.221823 pJ
sum error= 103
Actual label: 0
Output voltages: [0.73447, 0.27327, 0.24606, 0.19079, 0.11836, 0.19358, 0.39718, 0.15737, 0.28676, 0.24374]
Predicted label: 0
Correct prediction
Energy consumption = 194.051321 pJ
sum error= 103
Actual label: 6
Output voltages: [0.35451, 0.38956, 0.20617, 0.26682, 0.10652, 0.307, 0.64204, 0.095956, 0.5018, 0.075014]
Predicted label: 6
Correct prediction
Energy consumption = 195.368249 pJ
sum error= 103
Actual label: 3
Output voltages: [0.2412, 0.32658, 0.34029, 0.73877, 0.21488, 0.17325, 0.13022, 0.22292, 0.46182, 0.20469]
Predicted label: 3
Correct prediction
Energy consumption = 198.120808 pJ
sum error= 103
Actual label: 3
Output voltages: [0.19363, 0.17978, 0.11798, 0.66486, 0.18578, 0.48769, 0.22322, 0.19529, 0.46224, 0.18122]
Predicted label: 3
Correct prediction
Energy consumption = 183.671293 pJ
sum error= 103
Actual label: 6
Output voltages: [0.36834, 0.31321, 0.29649, 0.055553, 0.33177, 0.31801, 0.71707, 0.087588, 0.32871, 0.1483]
Predicted label: 6
Correct prediction
Energy consumption = 202.235307 pJ
sum error= 103
Actual label: 0
Output voltages: [0.73488, 0.24582, 0.24879, 0.15855, 0.19213, 0.13925, 0.40383, 0.21266, 0.27284, 0.28831]
Predicted label: 0
Correct prediction
Energy consumption = 185.923580 pJ
sum error= 103
Actual label: 4
Output voltages: [0.16324, 0.1348, 0.28379, 0.15318, 0.73988, 0.060753, 0.17502, 0.24412, 0.34299, 0.25342]
Predicted label: 4
Correct prediction
Energy consumption = 196.687000 pJ
sum error= 103
Actual label: 9
Output voltages: [0.30315, 0.14074, 0.2308, 0.27605, 0.32629, 0.22797, 0.1523, 0.2153, 0.35691, 0.69616]
Predicted label: 9
Correct prediction
Energy consumption = 186.906582 pJ
sum error= 103
Actual label: 7
Output voltages: [0.36001, 0.15662, 0.28212, 0.43716, 0.20836, 0.051136, 0.037187, 0.63195, 0.30006, 0.32846]
Predicted label: 7
Correct prediction
Energy consumption = 183.260138 pJ
sum error= 103
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 254 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 254 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 254 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.32193, 0.049168, 0.14929, 0.36078, 0.1271, 0.68231, 0.25416, 0.19377, 0.56404, 0.20706]
Predicted label: 5
Correct prediction
Energy consumption = 191.809517 pJ
sum error= 103
Actual label: 1
Output voltages: [0.26804, 0.76253, 0.29496, 0.28543, 0.27846, 0.085407, 0.36307, 0.11381, 0.28208, 0.2371]
Predicted label: 1
Correct prediction
Energy consumption = 217.192706 pJ
sum error= 103
Actual label: 6
Output voltages: [0.4016, 0.21387, 0.28457, 0.17125, 0.2029, 0.35869, 0.6904, 0.074482, 0.3894, 0.15404]
Predicted label: 6
Correct prediction
Energy consumption = 187.429398 pJ
sum error= 103
Actual label: 8
Output voltages: [0.25282, 0.15524, 0.27991, 0.42345, 0.11333, 0.24411, 0.17784, 0.094993, 0.72557, 0.22169]
Predicted label: 8
Correct prediction
Energy consumption = 193.309093 pJ
sum error= 103
Actual label: 9
Output voltages: [0.36203, 0.074428, 0.18033, 0.32042, 0.29965, 0.14101, 0.050559, 0.34534, 0.38792, 0.60403]
Predicted label: 9
Correct prediction
Energy consumption = 197.277560 pJ
sum error= 103
Actual label: 5
Output voltages: [0.28049, 0.089322, 0.11579, 0.45817, 0.16362, 0.68514, 0.20279, 0.19097, 0.53195, 0.27186]
Predicted label: 5
Correct prediction
Energy consumption = 185.747101 pJ
sum error= 103
Actual label: 5
Output voltages: [0.27038, 0.14554, 0.077852, 0.34776, 0.29653, 0.75388, 0.36532, 0.13432, 0.3648, 0.2522]
Predicted label: 5
Correct prediction
Energy consumption = 182.528297 pJ
sum error= 103
Actual label: 7
Output voltages: [0.33136, 0.14972, 0.4721, 0.30494, 0.14694, 0.031133, 0.06028, 0.70361, 0.35607, 0.26696]
Predicted label: 7
Correct prediction
Energy consumption = 191.476322 pJ
sum error= 103
Actual label: 9
Output voltages: [0.34189, 0.13091, 0.20535, 0.25196, 0.39748, 0.17058, 0.08415, 0.20659, 0.35071, 0.64296]
Predicted label: 9
Correct prediction
Energy consumption = 185.679275 pJ
sum error= 103
Actual label: 3
Output voltages: [0.28875, 0.23523, 0.26281, 0.75212, 0.15263, 0.15893, 0.12396, 0.14917, 0.49777, 0.28317]
Predicted label: 3
Correct prediction
Energy consumption = 188.586248 pJ
sum error= 103
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 255 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 255 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 255 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.32548, 0.13147, 0.3234, 0.42126, 0.12655, 0.15282, 0.19948, 0.088513, 0.67925, 0.2976]
Predicted label: 8
Correct prediction
Energy consumption = 203.953708 pJ
sum error= 103
Actual label: 3
Output voltages: [0.31148, 0.17201, 0.36094, 0.72758, 0.13706, 0.25052, 0.17659, 0.12596, 0.48473, 0.18941]
Predicted label: 3
Correct prediction
Energy consumption = 189.729898 pJ
sum error= 103
Actual label: 8
Output voltages: [0.2564, 0.16556, 0.36167, 0.18621, 0.20552, 0.11658, 0.19849, 0.18558, 0.73521, 0.33332]
Predicted label: 8
Correct prediction
Energy consumption = 197.791353 pJ
sum error= 103
Actual label: 1
Output voltages: [0.09959, 0.75743, 0.19964, 0.25369, 0.32095, 0.22488, 0.39353, 0.12913, 0.31133, 0.20894]
Predicted label: 1
Correct prediction
Energy consumption = 213.003845 pJ
sum error= 103
Actual label: 5
Output voltages: [0.23051, 0.065337, 0.055588, 0.36926, 0.26634, 0.74055, 0.33089, 0.10725, 0.49375, 0.19359]
Predicted label: 5
Correct prediction
Energy consumption = 190.656938 pJ
sum error= 103
Actual label: 3
Output voltages: [0.38824, 0.17307, 0.25044, 0.76121, 0.16835, 0.27798, 0.18269, 0.20252, 0.39533, 0.19295]
Predicted label: 3
Correct prediction
Energy consumption = 187.039181 pJ
sum error= 103
Actual label: 5
Output voltages: [0.22011, 0.047846, 0.15605, 0.34992, 0.19816, 0.57672, 0.31357, 0.14935, 0.60253, 0.26178]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.901953 pJ
sum error= 104
Actual label: 0
Output voltages: [0.7158, 0.23151, 0.31044, 0.19464, 0.19754, 0.13774, 0.39973, 0.16654, 0.38741, 0.18075]
Predicted label: 0
Correct prediction
Energy consumption = 199.903466 pJ
sum error= 104
Actual label: 5
Output voltages: [0.17995, 0.090966, 0.089233, 0.41557, 0.20414, 0.67999, 0.23871, 0.11308, 0.52573, 0.23311]
Predicted label: 5
Correct prediction
Energy consumption = 194.101956 pJ
sum error= 104
Actual label: 5
Output voltages: [0.21237, 0.053787, 0.14855, 0.48598, 0.28078, 0.55756, 0.22426, 0.12809, 0.50795, 0.25327]
Predicted label: 5
Correct prediction
Energy consumption = 188.118760 pJ
sum error= 104
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 256 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 256 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 256 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34632, 0.16983, 0.32176, 0.67752, 0.092716, 0.36795, 0.32427, 0.13127, 0.3345, 0.072441]
Predicted label: 3
Correct prediction
Energy consumption = 197.686802 pJ
sum error= 104
Actual label: 8
Output voltages: [0.21794, 0.25698, 0.31613, 0.23586, 0.1733, 0.18176, 0.21637, 0.16603, 0.75506, 0.30362]
Predicted label: 8
Correct prediction
Energy consumption = 193.764323 pJ
sum error= 104
Actual label: 6
Output voltages: [0.31015, 0.1507, 0.19206, 0.21726, 0.32272, 0.43883, 0.66713, 0.085616, 0.47822, 0.17859]
Predicted label: 6
Correct prediction
Energy consumption = 196.995497 pJ
sum error= 104
Actual label: 7
Output voltages: [0.33714, 0.26197, 0.35223, 0.26688, 0.081727, 0.049676, 0.048537, 0.72877, 0.41935, 0.3951]
Predicted label: 7
Correct prediction
Energy consumption = 203.128629 pJ
sum error= 104
Actual label: 7
Output voltages: [0.33058, 0.40559, 0.38498, 0.32179, 0.12403, 0.044447, 0.047648, 0.71826, 0.34116, 0.3242]
Predicted label: 7
Correct prediction
Energy consumption = 190.819725 pJ
sum error= 104
Actual label: 7
Output voltages: [0.33177, 0.21434, 0.21802, 0.28705, 0.12838, 0.11981, 0.043042, 0.76105, 0.38103, 0.34094]
Predicted label: 7
Correct prediction
Energy consumption = 193.000088 pJ
sum error= 104
Actual label: 3
Output voltages: [0.25945, 0.26172, 0.35182, 0.74837, 0.12761, 0.077582, 0.12295, 0.16441, 0.43634, 0.23529]
Predicted label: 3
Correct prediction
Energy consumption = 186.492573 pJ
sum error= 104
Actual label: 7
Output voltages: [0.26913, 0.24433, 0.22103, 0.2945, 0.13768, 0.066439, 0.035614, 0.74386, 0.39858, 0.32624]
Predicted label: 7
Correct prediction
Energy consumption = 193.113705 pJ
sum error= 104
Actual label: 0
Output voltages: [0.72736, 0.22163, 0.20163, 0.19451, 0.12551, 0.37552, 0.39967, 0.10824, 0.22427, 0.27025]
Predicted label: 0
Correct prediction
Energy consumption = 201.751493 pJ
sum error= 104
Actual label: 5
Output voltages: [0.24869, 0.047191, 0.082296, 0.41432, 0.19276, 0.68024, 0.23745, 0.27624, 0.47509, 0.29147]
Predicted label: 5
Correct prediction
Energy consumption = 190.246220 pJ
sum error= 104
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 257 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 257 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 257 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31776, 0.11082, 0.21691, 0.27267, 0.32424, 0.18728, 0.13134, 0.21441, 0.40654, 0.65316]
Predicted label: 9
Correct prediction
Energy consumption = 197.174030 pJ
sum error= 104
Actual label: 0
Output voltages: [0.72355, 0.20446, 0.21101, 0.21756, 0.24203, 0.13241, 0.41953, 0.17613, 0.37536, 0.26286]
Predicted label: 0
Correct prediction
Energy consumption = 208.976333 pJ
sum error= 104
Actual label: 2
Output voltages: [0.38783, 0.23215, 0.72088, 0.29287, 0.20381, 0.030693, 0.21303, 0.26304, 0.37045, 0.18626]
Predicted label: 2
Correct prediction
Energy consumption = 198.448864 pJ
sum error= 104
Actual label: 5
Output voltages: [0.27326, 0.18266, 0.12954, 0.3514, 0.073774, 0.57473, 0.15511, 0.13979, 0.67862, 0.234]
Predicted label: 8
Wrong prediction!
Energy consumption = 203.584249 pJ
sum error= 105
Actual label: 5
Output voltages: [0.26982, 0.11648, 0.073098, 0.45432, 0.16287, 0.69298, 0.16758, 0.32325, 0.42535, 0.34256]
Predicted label: 5
Correct prediction
Energy consumption = 189.014909 pJ
sum error= 105
Actual label: 3
Output voltages: [0.31121, 0.2195, 0.27932, 0.76, 0.14027, 0.096016, 0.12398, 0.20429, 0.39286, 0.27068]
Predicted label: 3
Correct prediction
Energy consumption = 176.008324 pJ
sum error= 105
Actual label: 1
Output voltages: [0.27437, 0.75779, 0.38267, 0.24152, 0.14699, 0.056173, 0.34057, 0.089835, 0.35103, 0.26834]
Predicted label: 1
Correct prediction
Energy consumption = 204.982722 pJ
sum error= 105
Actual label: 7
Output voltages: [0.21709, 0.36688, 0.26184, 0.1501, 0.18035, 0.046583, 0.039545, 0.6867, 0.37313, 0.34953]
Predicted label: 7
Correct prediction
Energy consumption = 201.659852 pJ
sum error= 105
Actual label: 7
Output voltages: [0.34499, 0.34488, 0.62619, 0.26601, 0.11699, 0.0248, 0.069026, 0.5823, 0.321, 0.37349]
Predicted label: 2
Wrong prediction!
Energy consumption = 193.073268 pJ
sum error= 106
Actual label: 8
Output voltages: [0.24012, 0.20811, 0.33379, 0.24906, 0.16507, 0.17124, 0.22771, 0.17841, 0.7513, 0.30397]
Predicted label: 8
Correct prediction
Energy consumption = 189.678339 pJ
sum error= 106
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 258 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 258 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 258 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.35008, 0.16798, 0.22732, 0.19658, 0.33558, 0.4041, 0.70538, 0.089609, 0.45283, 0.13709]
Predicted label: 6
Correct prediction
Energy consumption = 193.336637 pJ
sum error= 106
Actual label: 5
Output voltages: [0.22827, 0.090705, 0.081181, 0.28993, 0.18464, 0.6937, 0.19906, 0.10901, 0.51931, 0.29113]
Predicted label: 5
Correct prediction
Energy consumption = 190.440596 pJ
sum error= 106
Actual label: 9
Output voltages: [0.39302, 0.13637, 0.21635, 0.44259, 0.2508, 0.18088, 0.047132, 0.41574, 0.37036, 0.53932]
Predicted label: 9
Correct prediction
Energy consumption = 199.286898 pJ
sum error= 106
Actual label: 3
Output voltages: [0.21711, 0.17321, 0.35985, 0.72699, 0.15573, 0.16907, 0.12052, 0.13829, 0.53496, 0.2432]
Predicted label: 3
Correct prediction
Energy consumption = 179.230803 pJ
sum error= 106
Actual label: 8
Output voltages: [0.19987, 0.16634, 0.33855, 0.31416, 0.1479, 0.20413, 0.28951, 0.13633, 0.73997, 0.26873]
Predicted label: 8
Correct prediction
Energy consumption = 191.440830 pJ
sum error= 106
Actual label: 9
Output voltages: [0.33514, 0.16273, 0.18968, 0.2936, 0.29271, 0.23349, 0.18935, 0.27221, 0.33794, 0.70419]
Predicted label: 9
Correct prediction
Energy consumption = 196.621366 pJ
sum error= 106
Actual label: 5
Output voltages: [0.22888, 0.071064, 0.083294, 0.44456, 0.24445, 0.73726, 0.31338, 0.1927, 0.46911, 0.26714]
Predicted label: 5
Correct prediction
Energy consumption = 187.936166 pJ
sum error= 106
Actual label: 3
Output voltages: [0.35157, 0.10443, 0.17569, 0.70708, 0.13009, 0.42931, 0.10119, 0.2627, 0.43023, 0.23434]
Predicted label: 3
Correct prediction
Energy consumption = 185.911839 pJ
sum error= 106
Actual label: 7
Output voltages: [0.43889, 0.2785, 0.056825, 0.26761, 0.18772, 0.31279, 0.047687, 0.73403, 0.35584, 0.43998]
Predicted label: 7
Correct prediction
Energy consumption = 194.366965 pJ
sum error= 106
Actual label: 9
Output voltages: [0.56006, 0.15956, 0.15754, 0.26139, 0.28734, 0.22194, 0.19215, 0.17053, 0.32495, 0.65915]
Predicted label: 9
Correct prediction
Energy consumption = 197.685102 pJ
sum error= 106
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 259 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 259 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 259 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.24811, 0.74043, 0.33125, 0.2556, 0.2312, 0.043491, 0.34511, 0.13836, 0.33824, 0.23188]
Predicted label: 1
Correct prediction
Energy consumption = 214.581543 pJ
sum error= 106
Actual label: 7
Output voltages: [0.27524, 0.28807, 0.34228, 0.30079, 0.14105, 0.044784, 0.048801, 0.75634, 0.30914, 0.31754]
Predicted label: 7
Correct prediction
Energy consumption = 196.817596 pJ
sum error= 106
Actual label: 0
Output voltages: [0.74148, 0.24707, 0.35881, 0.23907, 0.11885, 0.11575, 0.33628, 0.22743, 0.29015, 0.20727]
Predicted label: 0
Correct prediction
Energy consumption = 193.681604 pJ
sum error= 106
Actual label: 0
Output voltages: [0.70882, 0.2139, 0.2149, 0.29688, 0.14981, 0.1322, 0.33027, 0.14882, 0.412, 0.31659]
Predicted label: 0
Correct prediction
Energy consumption = 186.818091 pJ
sum error= 106
Actual label: 3
Output voltages: [0.28831, 0.085168, 0.25191, 0.74262, 0.28296, 0.407, 0.24863, 0.15986, 0.3741, 0.17392]
Predicted label: 3
Correct prediction
Energy consumption = 189.111546 pJ
sum error= 106
Actual label: 7
Output voltages: [0.30962, 0.20267, 0.16977, 0.2482, 0.17797, 0.12313, 0.044438, 0.75976, 0.38307, 0.3534]
Predicted label: 7
Correct prediction
Energy consumption = 199.125203 pJ
sum error= 106
Actual label: 2
Output voltages: [0.31239, 0.33277, 0.72234, 0.2759, 0.1612, 0.030476, 0.25527, 0.35081, 0.38638, 0.2442]
Predicted label: 2
Correct prediction
Energy consumption = 189.549651 pJ
sum error= 106
Actual label: 5
Output voltages: [0.2489, 0.13799, 0.2892, 0.57422, 0.10636, 0.48705, 0.15685, 0.10507, 0.55957, 0.22253]
Predicted label: 3
Wrong prediction!
Energy consumption = 180.681516 pJ
sum error= 107
Actual label: 8
Output voltages: [0.28235, 0.29398, 0.49798, 0.28564, 0.1191, 0.086393, 0.26925, 0.17749, 0.69029, 0.24495]
Predicted label: 8
Correct prediction
Energy consumption = 191.771974 pJ
sum error= 107
Actual label: 1
Output voltages: [0.25249, 0.7564, 0.2646, 0.31036, 0.1996, 0.062134, 0.27917, 0.11891, 0.40083, 0.23133]
Predicted label: 1
Correct prediction
Energy consumption = 202.830324 pJ
sum error= 107
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 260 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 260 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 260 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.19337, 0.24738, 0.22885, 0.30569, 0.21238, 0.23917, 0.25027, 0.20446, 0.74872, 0.22558]
Predicted label: 8
Correct prediction
Energy consumption = 205.993105 pJ
sum error= 107
Actual label: 6
Output voltages: [0.29741, 0.18875, 0.34235, 0.1165, 0.27202, 0.34457, 0.72795, 0.058656, 0.40263, 0.20501]
Predicted label: 6
Correct prediction
Energy consumption = 193.682680 pJ
sum error= 107
Actual label: 2
Output voltages: [0.30579, 0.39363, 0.67255, 0.39313, 0.14359, 0.03339, 0.20151, 0.25402, 0.35102, 0.18975]
Predicted label: 2
Correct prediction
Energy consumption = 193.304719 pJ
sum error= 107
Actual label: 9
Output voltages: [0.26482, 0.11807, 0.23173, 0.18285, 0.25607, 0.15941, 0.077122, 0.18856, 0.51604, 0.61977]
Predicted label: 9
Correct prediction
Energy consumption = 198.957417 pJ
sum error= 107
Actual label: 5
Output voltages: [0.2598, 0.069884, 0.13789, 0.5595, 0.15184, 0.56525, 0.29197, 0.21058, 0.37273, 0.25826]
Predicted label: 5
Correct prediction
Energy consumption = 190.638509 pJ
sum error= 107
Actual label: 7
Output voltages: [0.33174, 0.22625, 0.12196, 0.25915, 0.18989, 0.12635, 0.044595, 0.74286, 0.30987, 0.42639]
Predicted label: 7
Correct prediction
Energy consumption = 198.482174 pJ
sum error= 107
Actual label: 5
Output voltages: [0.29371, 0.045009, 0.13332, 0.35103, 0.17375, 0.70452, 0.30259, 0.19861, 0.50503, 0.25833]
Predicted label: 5
Correct prediction
Energy consumption = 191.417832 pJ
sum error= 107
Actual label: 7
Output voltages: [0.25185, 0.11582, 0.48638, 0.26018, 0.38499, 0.041131, 0.10187, 0.42362, 0.44785, 0.30246]
Predicted label: 2
Wrong prediction!
Energy consumption = 205.400300 pJ
sum error= 108
Actual label: 8
Output voltages: [0.1918, 0.30465, 0.23409, 0.24219, 0.15178, 0.17961, 0.17658, 0.10222, 0.71684, 0.35927]
Predicted label: 8
Correct prediction
Energy consumption = 209.496610 pJ
sum error= 108
Actual label: 6
Output voltages: [0.41385, 0.17344, 0.16209, 0.1845, 0.28119, 0.52173, 0.68956, 0.12255, 0.32114, 0.16808]
Predicted label: 6
Correct prediction
Energy consumption = 188.368726 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 261 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 261 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 261 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.30363, 0.20116, 0.65182, 0.38321, 0.091147, 0.0393, 0.22868, 0.23038, 0.53517, 0.22802]
Predicted label: 2
Correct prediction
Energy consumption = 184.260733 pJ
sum error= 108
Actual label: 5
Output voltages: [0.4235, 0.21629, 0.070612, 0.5294, 0.094295, 0.65426, 0.31761, 0.068364, 0.40213, 0.10545]
Predicted label: 5
Correct prediction
Energy consumption = 194.680220 pJ
sum error= 108
Actual label: 1
Output voltages: [0.2618, 0.75475, 0.25456, 0.31127, 0.23951, 0.1093, 0.33456, 0.054413, 0.30103, 0.27712]
Predicted label: 1
Correct prediction
Energy consumption = 204.705536 pJ
sum error= 108
Actual label: 4
Output voltages: [0.16455, 0.15558, 0.30932, 0.10947, 0.76471, 0.094058, 0.28735, 0.34459, 0.24363, 0.27234]
Predicted label: 4
Correct prediction
Energy consumption = 192.957250 pJ
sum error= 108
Actual label: 8
Output voltages: [0.22389, 0.24201, 0.35294, 0.32292, 0.11742, 0.17677, 0.22409, 0.13778, 0.74605, 0.2828]
Predicted label: 8
Correct prediction
Energy consumption = 195.798880 pJ
sum error= 108
Actual label: 4
Output voltages: [0.12685, 0.15081, 0.25076, 0.19746, 0.75482, 0.065432, 0.2118, 0.25812, 0.25751, 0.22933]
Predicted label: 4
Correct prediction
Energy consumption = 195.057549 pJ
sum error= 108
Actual label: 5
Output voltages: [0.16702, 0.070503, 0.19018, 0.3092, 0.23366, 0.61956, 0.31605, 0.080022, 0.57455, 0.27046]
Predicted label: 5
Correct prediction
Energy consumption = 187.492735 pJ
sum error= 108
Actual label: 8
Output voltages: [0.19075, 0.2774, 0.25901, 0.3077, 0.12348, 0.22573, 0.18415, 0.1265, 0.74183, 0.34879]
Predicted label: 8
Correct prediction
Energy consumption = 195.600824 pJ
sum error= 108
Actual label: 3
Output voltages: [0.28995, 0.074244, 0.2319, 0.73727, 0.29334, 0.47667, 0.22292, 0.19498, 0.38165, 0.21826]
Predicted label: 3
Correct prediction
Energy consumption = 186.134816 pJ
sum error= 108
Actual label: 0
Output voltages: [0.67974, 0.25042, 0.2707, 0.19676, 0.21046, 0.071727, 0.389, 0.15139, 0.3441, 0.28095]
Predicted label: 0
Correct prediction
Energy consumption = 198.374627 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 262 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 262 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 262 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.279, 0.17789, 0.27074, 0.1213, 0.31194, 0.30864, 0.72658, 0.068517, 0.49021, 0.17744]
Predicted label: 6
Correct prediction
Energy consumption = 189.245294 pJ
sum error= 108
Actual label: 2
Output voltages: [0.3951, 0.12628, 0.7446, 0.29314, 0.2446, 0.046415, 0.25626, 0.27625, 0.42518, 0.15051]
Predicted label: 2
Correct prediction
Energy consumption = 185.338119 pJ
sum error= 108
Actual label: 7
Output voltages: [0.25765, 0.29774, 0.298, 0.39125, 0.21816, 0.037316, 0.052965, 0.72806, 0.32863, 0.29051]
Predicted label: 7
Correct prediction
Energy consumption = 191.289363 pJ
sum error= 108
Actual label: 3
Output voltages: [0.3187, 0.14689, 0.28367, 0.76117, 0.24189, 0.22621, 0.19829, 0.2352, 0.38628, 0.2362]
Predicted label: 3
Correct prediction
Energy consumption = 179.481903 pJ
sum error= 108
Actual label: 3
Output voltages: [0.29164, 0.28932, 0.29537, 0.75495, 0.13118, 0.12586, 0.12422, 0.19353, 0.39789, 0.2295]
Predicted label: 3
Correct prediction
Energy consumption = 184.983169 pJ
sum error= 108
Actual label: 2
Output voltages: [0.32972, 0.40029, 0.68322, 0.33437, 0.13363, 0.026853, 0.21618, 0.27456, 0.32859, 0.17046]
Predicted label: 2
Correct prediction
Energy consumption = 185.686675 pJ
sum error= 108
Actual label: 1
Output voltages: [0.097894, 0.74401, 0.17536, 0.33422, 0.22374, 0.16676, 0.42175, 0.1467, 0.37992, 0.17263]
Predicted label: 1
Correct prediction
Energy consumption = 209.240571 pJ
sum error= 108
Actual label: 0
Output voltages: [0.68563, 0.22961, 0.20971, 0.20148, 0.14882, 0.20199, 0.44608, 0.17638, 0.40134, 0.24685]
Predicted label: 0
Correct prediction
Energy consumption = 193.493730 pJ
sum error= 108
Actual label: 7
Output voltages: [0.28097, 0.18824, 0.40308, 0.44123, 0.19113, 0.041987, 0.063447, 0.65866, 0.29295, 0.29375]
Predicted label: 7
Correct prediction
Energy consumption = 188.811050 pJ
sum error= 108
Actual label: 3
Output voltages: [0.23714, 0.14827, 0.26841, 0.65853, 0.18661, 0.36595, 0.15349, 0.10714, 0.51591, 0.27931]
Predicted label: 3
Correct prediction
Energy consumption = 180.601874 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 263 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 263 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 263 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.24543, 0.22675, 0.18944, 0.18619, 0.70902, 0.13786, 0.1976, 0.20984, 0.19687, 0.47602]
Predicted label: 4
Correct prediction
Energy consumption = 204.533754 pJ
sum error= 108
Actual label: 0
Output voltages: [0.62109, 0.19824, 0.23582, 0.082195, 0.31729, 0.15416, 0.56995, 0.2249, 0.28702, 0.22543]
Predicted label: 0
Correct prediction
Energy consumption = 206.032154 pJ
sum error= 108
Actual label: 3
Output voltages: [0.25919, 0.14819, 0.39373, 0.72333, 0.16966, 0.27301, 0.077948, 0.14187, 0.49638, 0.22121]
Predicted label: 3
Correct prediction
Energy consumption = 189.906498 pJ
sum error= 108
Actual label: 9
Output voltages: [0.29451, 0.12219, 0.17484, 0.24736, 0.21522, 0.23766, 0.084297, 0.18246, 0.50337, 0.58909]
Predicted label: 9
Correct prediction
Energy consumption = 186.396117 pJ
sum error= 108
Actual label: 3
Output voltages: [0.34602, 0.17395, 0.2603, 0.75796, 0.1728, 0.23054, 0.16593, 0.15932, 0.40613, 0.24111]
Predicted label: 3
Correct prediction
Energy consumption = 181.959988 pJ
sum error= 108
Actual label: 2
Output voltages: [0.30008, 0.16717, 0.71807, 0.34819, 0.17689, 0.037671, 0.24767, 0.51572, 0.34415, 0.23398]
Predicted label: 2
Correct prediction
Energy consumption = 187.474478 pJ
sum error= 108
Actual label: 8
Output voltages: [0.38701, 0.16507, 0.33181, 0.28961, 0.14075, 0.26954, 0.23841, 0.095085, 0.71277, 0.32144]
Predicted label: 8
Correct prediction
Energy consumption = 194.872393 pJ
sum error= 108
Actual label: 9
Output voltages: [0.32996, 0.072234, 0.3576, 0.26273, 0.50496, 0.13844, 0.17581, 0.1467, 0.19436, 0.62773]
Predicted label: 9
Correct prediction
Energy consumption = 195.325228 pJ
sum error= 108
Actual label: 0
Output voltages: [0.72063, 0.23269, 0.25435, 0.23612, 0.08388, 0.2538, 0.42986, 0.1475, 0.30724, 0.25534]
Predicted label: 0
Correct prediction
Energy consumption = 191.417595 pJ
sum error= 108
Actual label: 3
Output voltages: [0.2985, 0.13399, 0.2685, 0.7555, 0.22233, 0.2419, 0.19394, 0.17692, 0.42012, 0.22574]
Predicted label: 3
Correct prediction
Energy consumption = 175.511340 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 264 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 264 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 264 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.21309, 0.24681, 0.27865, 0.35391, 0.091931, 0.1852, 0.17304, 0.15972, 0.74631, 0.31471]
Predicted label: 8
Correct prediction
Energy consumption = 196.499699 pJ
sum error= 108
Actual label: 0
Output voltages: [0.73359, 0.093064, 0.23544, 0.22492, 0.069145, 0.27628, 0.35245, 0.2254, 0.36766, 0.185]
Predicted label: 0
Correct prediction
Energy consumption = 195.699709 pJ
sum error= 108
Actual label: 7
Output voltages: [0.29382, 0.25206, 0.15552, 0.17434, 0.25165, 0.095909, 0.047445, 0.72108, 0.30482, 0.41039]
Predicted label: 7
Correct prediction
Energy consumption = 205.372459 pJ
sum error= 108
Actual label: 6
Output voltages: [0.36047, 0.25184, 0.19107, 0.24069, 0.29358, 0.45378, 0.72902, 0.11164, 0.40463, 0.14961]
Predicted label: 6
Correct prediction
Energy consumption = 193.095118 pJ
sum error= 108
Actual label: 5
Output voltages: [0.23142, 0.047393, 0.083299, 0.35338, 0.21254, 0.71676, 0.31636, 0.16373, 0.51236, 0.24361]
Predicted label: 5
Correct prediction
Energy consumption = 186.873715 pJ
sum error= 108
Actual label: 4
Output voltages: [0.20379, 0.11478, 0.26798, 0.24998, 0.71509, 0.056113, 0.19479, 0.4003, 0.25249, 0.26268]
Predicted label: 4
Correct prediction
Energy consumption = 195.517315 pJ
sum error= 108
Actual label: 7
Output voltages: [0.27709, 0.28107, 0.27866, 0.32689, 0.14541, 0.059238, 0.049726, 0.7556, 0.39877, 0.34188]
Predicted label: 7
Correct prediction
Energy consumption = 197.068115 pJ
sum error= 108
Actual label: 3
Output voltages: [0.3983, 0.25078, 0.28236, 0.76234, 0.21558, 0.19584, 0.15649, 0.23743, 0.41847, 0.18306]
Predicted label: 3
Correct prediction
Energy consumption = 190.984258 pJ
sum error= 108
Actual label: 9
Output voltages: [0.46844, 0.10073, 0.28737, 0.35307, 0.35679, 0.098674, 0.075186, 0.19983, 0.32889, 0.55114]
Predicted label: 9
Correct prediction
Energy consumption = 200.282001 pJ
sum error= 108
Actual label: 0
Output voltages: [0.68653, 0.23982, 0.3382, 0.12511, 0.20328, 0.055645, 0.39553, 0.2021, 0.38952, 0.26149]
Predicted label: 0
Correct prediction
Energy consumption = 184.128211 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 265 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 265 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 265 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2026, 0.18512, 0.27848, 0.26237, 0.18782, 0.21594, 0.18908, 0.11259, 0.74941, 0.32954]
Predicted label: 8
Correct prediction
Energy consumption = 199.324126 pJ
sum error= 108
Actual label: 6
Output voltages: [0.37081, 0.19815, 0.18032, 0.19276, 0.29282, 0.41508, 0.70498, 0.072152, 0.43209, 0.18277]
Predicted label: 6
Correct prediction
Energy consumption = 193.154585 pJ
sum error= 108
Actual label: 2
Output voltages: [0.27812, 0.437, 0.69684, 0.27968, 0.16952, 0.023802, 0.19898, 0.34718, 0.30344, 0.15441]
Predicted label: 2
Correct prediction
Energy consumption = 190.713272 pJ
sum error= 108
Actual label: 5
Output voltages: [0.28429, 0.047138, 0.062161, 0.33485, 0.18375, 0.6962, 0.22953, 0.22533, 0.59968, 0.16762]
Predicted label: 5
Correct prediction
Energy consumption = 187.395428 pJ
sum error= 108
Actual label: 6
Output voltages: [0.31, 0.65095, 0.32845, 0.19507, 0.22305, 0.12035, 0.52772, 0.055434, 0.3896, 0.1279]
Predicted label: 1
Wrong prediction!
Energy consumption = 205.482326 pJ
sum error= 109
Actual label: 1
Output voltages: [0.15637, 0.76379, 0.23481, 0.21606, 0.30358, 0.15552, 0.44489, 0.10957, 0.29492, 0.21346]
Predicted label: 1
Correct prediction
Energy consumption = 199.954484 pJ
sum error= 109
Actual label: 0
Output voltages: [0.70726, 0.2092, 0.21877, 0.14093, 0.15309, 0.22559, 0.38694, 0.18506, 0.35768, 0.35191]
Predicted label: 0
Correct prediction
Energy consumption = 199.137904 pJ
sum error= 109
Actual label: 0
Output voltages: [0.73764, 0.25271, 0.23086, 0.16374, 0.17212, 0.16875, 0.42693, 0.18327, 0.25077, 0.2885]
Predicted label: 0
Correct prediction
Energy consumption = 188.146620 pJ
sum error= 109
Actual label: 4
Output voltages: [0.20138, 0.24653, 0.23956, 0.13709, 0.71277, 0.05536, 0.39529, 0.19849, 0.31736, 0.15885]
Predicted label: 4
Correct prediction
Energy consumption = 215.166142 pJ
sum error= 109
Actual label: 4
Output voltages: [0.055527, 0.24153, 0.14687, 0.12178, 0.65164, 0.15584, 0.20643, 0.19099, 0.41681, 0.28221]
Predicted label: 4
Correct prediction
Energy consumption = 197.248191 pJ
sum error= 109
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 266 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 266 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 266 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72035, 0.17226, 0.25768, 0.17218, 0.17574, 0.17742, 0.3584, 0.18264, 0.39597, 0.32268]
Predicted label: 0
Correct prediction
Energy consumption = 200.846841 pJ
sum error= 109
Actual label: 1
Output voltages: [0.18509, 0.76532, 0.18975, 0.24202, 0.23948, 0.088153, 0.42368, 0.13795, 0.34181, 0.21911]
Predicted label: 1
Correct prediction
Energy consumption = 206.718014 pJ
sum error= 109
Actual label: 2
Output voltages: [0.37555, 0.22, 0.73798, 0.34487, 0.17169, 0.040166, 0.29325, 0.25539, 0.38235, 0.17791]
Predicted label: 2
Correct prediction
Energy consumption = 192.461593 pJ
sum error= 109
Actual label: 3
Output voltages: [0.28762, 0.22028, 0.28732, 0.75896, 0.17359, 0.12032, 0.16383, 0.24669, 0.44664, 0.21459]
Predicted label: 3
Correct prediction
Energy consumption = 181.719852 pJ
sum error= 109
Actual label: 2
Output voltages: [0.46309, 0.164, 0.69019, 0.3483, 0.18007, 0.044734, 0.31862, 0.22855, 0.45576, 0.15981]
Predicted label: 2
Correct prediction
Energy consumption = 184.316011 pJ
sum error= 109
Actual label: 7
Output voltages: [0.35263, 0.17894, 0.43979, 0.48115, 0.18959, 0.028572, 0.082401, 0.59442, 0.27729, 0.33319]
Predicted label: 7
Correct prediction
Energy consumption = 183.207993 pJ
sum error= 109
Actual label: 7
Output voltages: [0.2425, 0.16666, 0.27438, 0.42951, 0.14601, 0.13738, 0.046329, 0.75006, 0.33202, 0.36297]
Predicted label: 7
Correct prediction
Energy consumption = 182.900643 pJ
sum error= 109
Actual label: 8
Output voltages: [0.24641, 0.11288, 0.23791, 0.32847, 0.085141, 0.46473, 0.21384, 0.1189, 0.73086, 0.20201]
Predicted label: 8
Correct prediction
Energy consumption = 187.961447 pJ
sum error= 109
Actual label: 5
Output voltages: [0.24952, 0.041247, 0.24549, 0.39353, 0.26241, 0.45545, 0.26823, 0.10179, 0.57686, 0.3059]
Predicted label: 8
Wrong prediction!
Energy consumption = 194.103800 pJ
sum error= 110
Actual label: 2
Output voltages: [0.33492, 0.28058, 0.75098, 0.33624, 0.15465, 0.035948, 0.2455, 0.27916, 0.36162, 0.21338]
Predicted label: 2
Correct prediction
Energy consumption = 187.975987 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 267 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 267 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 267 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.35145, 0.052909, 0.14366, 0.38815, 0.13894, 0.59164, 0.20874, 0.23099, 0.55055, 0.25966]
Predicted label: 5
Correct prediction
Energy consumption = 200.914702 pJ
sum error= 110
Actual label: 7
Output voltages: [0.29565, 0.31711, 0.48549, 0.17713, 0.13766, 0.041694, 0.054323, 0.71635, 0.32967, 0.34488]
Predicted label: 7
Correct prediction
Energy consumption = 190.733537 pJ
sum error= 110
Actual label: 6
Output voltages: [0.39404, 0.26016, 0.31868, 0.12908, 0.25233, 0.3504, 0.72068, 0.13749, 0.40607, 0.080739]
Predicted label: 6
Correct prediction
Energy consumption = 198.936913 pJ
sum error= 110
Actual label: 9
Output voltages: [0.35748, 0.25702, 0.21587, 0.34994, 0.35684, 0.13559, 0.14337, 0.24992, 0.21842, 0.66221]
Predicted label: 9
Correct prediction
Energy consumption = 206.475834 pJ
sum error= 110
Actual label: 1
Output voltages: [0.26799, 0.75446, 0.27044, 0.42598, 0.19003, 0.10756, 0.24928, 0.14676, 0.21362, 0.32412]
Predicted label: 1
Correct prediction
Energy consumption = 215.053280 pJ
sum error= 110
Actual label: 4
Output voltages: [0.10105, 0.19501, 0.29465, 0.062406, 0.7561, 0.10205, 0.3153, 0.25618, 0.27954, 0.27946]
Predicted label: 4
Correct prediction
Energy consumption = 196.102168 pJ
sum error= 110
Actual label: 1
Output voltages: [0.19699, 0.76348, 0.12206, 0.23154, 0.31166, 0.1202, 0.3793, 0.10811, 0.32407, 0.24823]
Predicted label: 1
Correct prediction
Energy consumption = 200.688136 pJ
sum error= 110
Actual label: 6
Output voltages: [0.32317, 0.20696, 0.25059, 0.1168, 0.33422, 0.39627, 0.74189, 0.094984, 0.37596, 0.10976]
Predicted label: 6
Correct prediction
Energy consumption = 188.161384 pJ
sum error= 110
Actual label: 4
Output voltages: [0.25188, 0.20474, 0.40143, 0.1182, 0.64887, 0.038627, 0.23747, 0.22469, 0.24491, 0.45011]
Predicted label: 4
Correct prediction
Energy consumption = 209.825544 pJ
sum error= 110
Actual label: 2
Output voltages: [0.39785, 0.19127, 0.74251, 0.27731, 0.1723, 0.034301, 0.26373, 0.32823, 0.42103, 0.17281]
Predicted label: 2
Correct prediction
Energy consumption = 185.473265 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 268 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 268 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 268 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.1816, 0.1549, 0.32129, 0.15492, 0.75041, 0.096114, 0.30393, 0.29273, 0.2131, 0.32533]
Predicted label: 4
Correct prediction
Energy consumption = 198.761245 pJ
sum error= 110
Actual label: 3
Output voltages: [0.29592, 0.17297, 0.28929, 0.7483, 0.22715, 0.33457, 0.11191, 0.13008, 0.3782, 0.21932]
Predicted label: 3
Correct prediction
Energy consumption = 199.106252 pJ
sum error= 110
Actual label: 5
Output voltages: [0.22463, 0.052981, 0.072801, 0.40868, 0.27168, 0.70737, 0.28928, 0.14177, 0.52353, 0.20615]
Predicted label: 5
Correct prediction
Energy consumption = 186.833850 pJ
sum error= 110
Actual label: 4
Output voltages: [0.17567, 0.14147, 0.30398, 0.13339, 0.72571, 0.063245, 0.23691, 0.27619, 0.26447, 0.33498]
Predicted label: 4
Correct prediction
Energy consumption = 196.807970 pJ
sum error= 110
Actual label: 3
Output voltages: [0.44602, 0.25454, 0.29484, 0.698, 0.039843, 0.19912, 0.28811, 0.33605, 0.34869, 0.1223]
Predicted label: 3
Correct prediction
Energy consumption = 197.072008 pJ
sum error= 110
Actual label: 9
Output voltages: [0.36426, 0.17262, 0.1926, 0.25347, 0.28842, 0.1601, 0.072828, 0.20365, 0.36371, 0.70793]
Predicted label: 9
Correct prediction
Energy consumption = 197.164889 pJ
sum error= 110
Actual label: 5
Output voltages: [0.35214, 0.080755, 0.089104, 0.35628, 0.17666, 0.71125, 0.21858, 0.21615, 0.59965, 0.22004]
Predicted label: 5
Correct prediction
Energy consumption = 191.457793 pJ
sum error= 110
Actual label: 0
Output voltages: [0.74254, 0.25816, 0.20623, 0.21165, 0.10404, 0.23387, 0.34541, 0.18633, 0.29518, 0.25534]
Predicted label: 0
Correct prediction
Energy consumption = 196.392352 pJ
sum error= 110
Actual label: 1
Output voltages: [0.23667, 0.76719, 0.18793, 0.32235, 0.10275, 0.20052, 0.37822, 0.11512, 0.37801, 0.22777]
Predicted label: 1
Correct prediction
Energy consumption = 212.019626 pJ
sum error= 110
Actual label: 5
Output voltages: [0.26003, 0.050114, 0.16396, 0.47597, 0.12886, 0.6466, 0.30044, 0.26553, 0.43269, 0.16717]
Predicted label: 5
Correct prediction
Energy consumption = 192.852584 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 269 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 269 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 269 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26177, 0.25812, 0.29234, 0.75809, 0.12738, 0.10615, 0.10761, 0.20784, 0.44637, 0.24427]
Predicted label: 3
Correct prediction
Energy consumption = 183.118996 pJ
sum error= 110
Actual label: 8
Output voltages: [0.21098, 0.24283, 0.25996, 0.28973, 0.16981, 0.14678, 0.23634, 0.088975, 0.72539, 0.33921]
Predicted label: 8
Correct prediction
Energy consumption = 197.624058 pJ
sum error= 110
Actual label: 9
Output voltages: [0.34007, 0.13233, 0.22776, 0.27029, 0.24579, 0.13928, 0.099887, 0.29372, 0.37124, 0.68016]
Predicted label: 9
Correct prediction
Energy consumption = 198.784923 pJ
sum error= 110
Actual label: 1
Output voltages: [0.18113, 0.75287, 0.25256, 0.21884, 0.19483, 0.082607, 0.4505, 0.053364, 0.38711, 0.19672]
Predicted label: 1
Correct prediction
Energy consumption = 206.888568 pJ
sum error= 110
Actual label: 9
Output voltages: [0.38233, 0.11064, 0.23465, 0.31142, 0.34191, 0.18886, 0.093743, 0.29907, 0.3367, 0.68795]
Predicted label: 9
Correct prediction
Energy consumption = 200.434876 pJ
sum error= 110
Actual label: 7
Output voltages: [0.41154, 0.18203, 0.13824, 0.23921, 0.27413, 0.20365, 0.20174, 0.73995, 0.24831, 0.26143]
Predicted label: 7
Correct prediction
Energy consumption = 198.203768 pJ
sum error= 110
Actual label: 9
Output voltages: [0.41324, 0.12911, 0.24379, 0.23817, 0.35749, 0.1984, 0.23607, 0.20965, 0.2831, 0.71942]
Predicted label: 9
Correct prediction
Energy consumption = 191.369421 pJ
sum error= 110
Actual label: 5
Output voltages: [0.20668, 0.074027, 0.13092, 0.35889, 0.1799, 0.65137, 0.25882, 0.090125, 0.50653, 0.2801]
Predicted label: 5
Correct prediction
Energy consumption = 183.685371 pJ
sum error= 110
Actual label: 5
Output voltages: [0.1855, 0.18063, 0.071646, 0.34212, 0.21796, 0.65891, 0.24279, 0.050023, 0.4392, 0.23734]
Predicted label: 5
Correct prediction
Energy consumption = 187.896075 pJ
sum error= 110
Actual label: 2
Output voltages: [0.27143, 0.39159, 0.68427, 0.2863, 0.23501, 0.032561, 0.29413, 0.23781, 0.34642, 0.1649]
Predicted label: 2
Correct prediction
Energy consumption = 195.290863 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 270 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 270 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 270 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28883, 0.27073, 0.26861, 0.4515, 0.077778, 0.082085, 0.051744, 0.73494, 0.25183, 0.41988]
Predicted label: 7
Correct prediction
Energy consumption = 200.765145 pJ
sum error= 110
Actual label: 4
Output voltages: [0.19667, 0.15258, 0.29905, 0.18818, 0.75727, 0.076835, 0.25565, 0.32565, 0.23774, 0.20851]
Predicted label: 4
Correct prediction
Energy consumption = 201.243337 pJ
sum error= 110
Actual label: 6
Output voltages: [0.36918, 0.19445, 0.3022, 0.067506, 0.37493, 0.22905, 0.73752, 0.094146, 0.3467, 0.16577]
Predicted label: 6
Correct prediction
Energy consumption = 187.278892 pJ
sum error= 110
Actual label: 0
Output voltages: [0.7347, 0.2197, 0.18306, 0.26315, 0.12995, 0.24925, 0.35835, 0.20207, 0.34758, 0.2055]
Predicted label: 0
Correct prediction
Energy consumption = 192.543209 pJ
sum error= 110
Actual label: 1
Output voltages: [0.22826, 0.75909, 0.14954, 0.24633, 0.13187, 0.197, 0.33506, 0.10962, 0.42106, 0.23434]
Predicted label: 1
Correct prediction
Energy consumption = 214.962732 pJ
sum error= 110
Actual label: 1
Output voltages: [0.21807, 0.69233, 0.26901, 0.26157, 0.15325, 0.11532, 0.30798, 0.1351, 0.45409, 0.23944]
Predicted label: 1
Correct prediction
Energy consumption = 202.017348 pJ
sum error= 110
Actual label: 1
Output voltages: [0.22029, 0.76711, 0.1779, 0.30312, 0.22354, 0.18869, 0.35853, 0.11003, 0.32713, 0.23558]
Predicted label: 1
Correct prediction
Energy consumption = 205.199476 pJ
sum error= 110
Actual label: 0
Output voltages: [0.73587, 0.24528, 0.26792, 0.17143, 0.14359, 0.21042, 0.3969, 0.16832, 0.31228, 0.17624]
Predicted label: 0
Correct prediction
Energy consumption = 191.533975 pJ
sum error= 110
Actual label: 4
Output voltages: [0.19391, 0.17425, 0.20251, 0.28298, 0.73958, 0.19075, 0.27454, 0.26632, 0.20026, 0.32655]
Predicted label: 4
Correct prediction
Energy consumption = 205.031743 pJ
sum error= 110
Actual label: 4
Output voltages: [0.1532, 0.28549, 0.34522, 0.25208, 0.73052, 0.047056, 0.255, 0.25404, 0.15702, 0.3121]
Predicted label: 4
Correct prediction
Energy consumption = 181.868280 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 271 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 271 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 271 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33702, 0.23357, 0.28272, 0.37317, 0.10595, 0.062855, 0.054076, 0.7353, 0.30021, 0.37198]
Predicted label: 7
Correct prediction
Energy consumption = 202.118299 pJ
sum error= 110
Actual label: 6
Output voltages: [0.30629, 0.23422, 0.32535, 0.091015, 0.33962, 0.3567, 0.7499, 0.12085, 0.3719, 0.15943]
Predicted label: 6
Correct prediction
Energy consumption = 189.886283 pJ
sum error= 110
Actual label: 3
Output voltages: [0.34524, 0.16008, 0.29967, 0.75482, 0.14283, 0.20664, 0.16341, 0.16447, 0.43568, 0.23753]
Predicted label: 3
Correct prediction
Energy consumption = 188.170797 pJ
sum error= 110
Actual label: 0
Output voltages: [0.56519, 0.21676, 0.31829, 0.23741, 0.19612, 0.059304, 0.40338, 0.11841, 0.51044, 0.25034]
Predicted label: 0
Correct prediction
Energy consumption = 200.546343 pJ
sum error= 110
Actual label: 0
Output voltages: [0.71798, 0.248, 0.28288, 0.19572, 0.16052, 0.1306, 0.46688, 0.15918, 0.2901, 0.2513]
Predicted label: 0
Correct prediction
Energy consumption = 189.173280 pJ
sum error= 110
Actual label: 4
Output voltages: [0.10543, 0.13874, 0.21316, 0.2878, 0.70656, 0.065324, 0.12729, 0.32196, 0.28005, 0.26944]
Predicted label: 4
Correct prediction
Energy consumption = 199.220124 pJ
sum error= 110
Actual label: 3
Output voltages: [0.37801, 0.12961, 0.36224, 0.74694, 0.17756, 0.08549, 0.18502, 0.13604, 0.45303, 0.23145]
Predicted label: 3
Correct prediction
Energy consumption = 183.230900 pJ
sum error= 110
Actual label: 0
Output voltages: [0.72635, 0.21335, 0.30788, 0.17763, 0.11935, 0.16404, 0.36425, 0.15059, 0.31421, 0.29553]
Predicted label: 0
Correct prediction
Energy consumption = 192.163014 pJ
sum error= 110
Actual label: 6
Output voltages: [0.26562, 0.19812, 0.29098, 0.13398, 0.37096, 0.24302, 0.69168, 0.14225, 0.41426, 0.10586]
Predicted label: 6
Correct prediction
Energy consumption = 197.067101 pJ
sum error= 110
Actual label: 1
Output voltages: [0.15853, 0.74124, 0.10938, 0.14781, 0.36264, 0.32533, 0.49635, 0.12309, 0.28473, 0.18164]
Predicted label: 1
Correct prediction
Energy consumption = 203.963395 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 272 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 272 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 272 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28027, 0.13132, 0.20766, 0.24942, 0.4052, 0.07243, 0.067869, 0.18096, 0.38351, 0.57568]
Predicted label: 9
Correct prediction
Energy consumption = 202.350131 pJ
sum error= 110
Actual label: 6
Output voltages: [0.22708, 0.11817, 0.28896, 0.16669, 0.25441, 0.46282, 0.63417, 0.055313, 0.50076, 0.18151]
Predicted label: 6
Correct prediction
Energy consumption = 196.262315 pJ
sum error= 110
Actual label: 1
Output voltages: [0.21053, 0.7563, 0.22199, 0.32562, 0.19753, 0.099558, 0.24326, 0.11851, 0.33892, 0.25145]
Predicted label: 1
Correct prediction
Energy consumption = 213.581744 pJ
sum error= 110
Actual label: 3
Output voltages: [0.2979, 0.22336, 0.42034, 0.74771, 0.19364, 0.12135, 0.1347, 0.12496, 0.42859, 0.19606]
Predicted label: 3
Correct prediction
Energy consumption = 185.259338 pJ
sum error= 110
Actual label: 8
Output voltages: [0.14273, 0.18605, 0.34251, 0.25067, 0.20682, 0.24728, 0.44825, 0.042601, 0.61923, 0.2623]
Predicted label: 8
Correct prediction
Energy consumption = 194.649336 pJ
sum error= 110
Actual label: 1
Output voltages: [0.20238, 0.75209, 0.24825, 0.17158, 0.29775, 0.060122, 0.37096, 0.10563, 0.34098, 0.22646]
Predicted label: 1
Correct prediction
Energy consumption = 203.911944 pJ
sum error= 110
Actual label: 2
Output voltages: [0.34012, 0.17386, 0.72727, 0.36346, 0.11314, 0.049287, 0.22179, 0.26224, 0.43515, 0.17273]
Predicted label: 2
Correct prediction
Energy consumption = 192.371365 pJ
sum error= 110
Actual label: 5
Output voltages: [0.27699, 0.049335, 0.1402, 0.35715, 0.18745, 0.65668, 0.37357, 0.19306, 0.54077, 0.23137]
Predicted label: 5
Correct prediction
Energy consumption = 193.100547 pJ
sum error= 110
Actual label: 6
Output voltages: [0.34663, 0.28075, 0.30728, 0.084327, 0.28056, 0.27265, 0.7345, 0.071557, 0.34909, 0.16582]
Predicted label: 6
Correct prediction
Energy consumption = 198.338982 pJ
sum error= 110
Actual label: 2
Output voltages: [0.37845, 0.30977, 0.75179, 0.30096, 0.20062, 0.031881, 0.28962, 0.35975, 0.36038, 0.207]
Predicted label: 2
Correct prediction
Energy consumption = 182.034524 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 273 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 273 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 273 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.22814, 0.10853, 0.40574, 0.36337, 0.51711, 0.036554, 0.1855, 0.49002, 0.2692, 0.13365]
Predicted label: 4
Wrong prediction!
Energy consumption = 198.823693 pJ
sum error= 111
Actual label: 3
Output voltages: [0.27308, 0.17039, 0.20843, 0.75469, 0.28098, 0.30344, 0.2625, 0.22661, 0.3798, 0.24158]
Predicted label: 3
Correct prediction
Energy consumption = 187.131819 pJ
sum error= 111
Actual label: 6
Output voltages: [0.29334, 0.20801, 0.082368, 0.24708, 0.34873, 0.45336, 0.64867, 0.094072, 0.41431, 0.11477]
Predicted label: 6
Correct prediction
Energy consumption = 202.337393 pJ
sum error= 111
Actual label: 0
Output voltages: [0.67381, 0.26144, 0.3464, 0.20005, 0.19215, 0.064017, 0.30905, 0.21976, 0.34881, 0.25068]
Predicted label: 0
Correct prediction
Energy consumption = 204.193391 pJ
sum error= 111
Actual label: 1
Output voltages: [0.23047, 0.67722, 0.17554, 0.19245, 0.33705, 0.10717, 0.42659, 0.040062, 0.43371, 0.23957]
Predicted label: 1
Correct prediction
Energy consumption = 202.691974 pJ
sum error= 111
Actual label: 9
Output voltages: [0.54523, 0.18501, 0.29372, 0.35005, 0.22982, 0.16381, 0.25166, 0.36783, 0.18749, 0.57283]
Predicted label: 9
Correct prediction
Energy consumption = 202.505801 pJ
sum error= 111
Actual label: 7
Output voltages: [0.42826, 0.16359, 0.31057, 0.2078, 0.19001, 0.11181, 0.059178, 0.74027, 0.35885, 0.31049]
Predicted label: 7
Correct prediction
Energy consumption = 195.457951 pJ
sum error= 111
Actual label: 6
Output voltages: [0.34323, 0.25086, 0.30781, 0.081011, 0.30186, 0.33517, 0.7407, 0.11681, 0.39547, 0.094018]
Predicted label: 6
Correct prediction
Energy consumption = 192.654138 pJ
sum error= 111
Actual label: 6
Output voltages: [0.33097, 0.27385, 0.30122, 0.073252, 0.33239, 0.29486, 0.74323, 0.092966, 0.36982, 0.13528]
Predicted label: 6
Correct prediction
Energy consumption = 184.379752 pJ
sum error= 111
Actual label: 8
Output voltages: [0.23872, 0.22382, 0.24551, 0.32765, 0.16007, 0.12966, 0.25194, 0.10254, 0.71033, 0.32393]
Predicted label: 8
Correct prediction
Energy consumption = 201.572748 pJ
sum error= 111
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 274 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 274 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 274 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32435, 0.18178, 0.18336, 0.29943, 0.35486, 0.066124, 0.051921, 0.23305, 0.37573, 0.59031]
Predicted label: 9
Correct prediction
Energy consumption = 200.363977 pJ
sum error= 111
Actual label: 2
Output voltages: [0.32273, 0.2811, 0.75726, 0.25452, 0.17359, 0.033088, 0.2719, 0.30987, 0.3926, 0.17467]
Predicted label: 2
Correct prediction
Energy consumption = 195.910944 pJ
sum error= 111
Actual label: 9
Output voltages: [0.48631, 0.15158, 0.20229, 0.40061, 0.14909, 0.20734, 0.16325, 0.298, 0.35784, 0.53314]
Predicted label: 9
Correct prediction
Energy consumption = 216.282034 pJ
sum error= 111
Actual label: 5
Output voltages: [0.16159, 0.17598, 0.10457, 0.27246, 0.17233, 0.67887, 0.31401, 0.064717, 0.48135, 0.22848]
Predicted label: 5
Correct prediction
Energy consumption = 199.941375 pJ
sum error= 111
Actual label: 8
Output voltages: [0.16657, 0.19034, 0.27129, 0.22849, 0.2136, 0.23779, 0.20414, 0.12646, 0.73857, 0.29281]
Predicted label: 8
Correct prediction
Energy consumption = 189.085781 pJ
sum error= 111
Actual label: 3
Output voltages: [0.2923, 0.18291, 0.42756, 0.72481, 0.17637, 0.048147, 0.139, 0.14773, 0.41347, 0.17577]
Predicted label: 3
Correct prediction
Energy consumption = 181.895994 pJ
sum error= 111
Actual label: 1
Output voltages: [0.15608, 0.72234, 0.18291, 0.1431, 0.37041, 0.14418, 0.40072, 0.1538, 0.32539, 0.26482]
Predicted label: 1
Correct prediction
Energy consumption = 206.769514 pJ
sum error= 111
Actual label: 0
Output voltages: [0.73467, 0.20477, 0.20069, 0.12965, 0.24507, 0.22739, 0.42813, 0.20252, 0.27905, 0.26787]
Predicted label: 0
Correct prediction
Energy consumption = 194.509670 pJ
sum error= 111
Actual label: 0
Output voltages: [0.73049, 0.16842, 0.19617, 0.15259, 0.20195, 0.20091, 0.37489, 0.19341, 0.35318, 0.34693]
Predicted label: 0
Correct prediction
Energy consumption = 193.292106 pJ
sum error= 111
Actual label: 7
Output voltages: [0.41139, 0.17345, 0.07889, 0.30943, 0.23251, 0.34211, 0.045566, 0.70129, 0.31782, 0.43088]
Predicted label: 7
Correct prediction
Energy consumption = 197.174854 pJ
sum error= 111
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 275 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 275 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 275 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31895, 0.24732, 0.16986, 0.26057, 0.19084, 0.44466, 0.59243, 0.12987, 0.58307, 0.080228]
Predicted label: 6
Correct prediction
Energy consumption = 198.549131 pJ
sum error= 111
Actual label: 6
Output voltages: [0.46762, 0.3148, 0.15912, 0.16319, 0.24677, 0.39604, 0.70056, 0.13355, 0.34877, 0.072035]
Predicted label: 6
Correct prediction
Energy consumption = 190.289739 pJ
sum error= 111
Actual label: 2
Output voltages: [0.36048, 0.20139, 0.75946, 0.28313, 0.23565, 0.054362, 0.29507, 0.28819, 0.35949, 0.17422]
Predicted label: 2
Correct prediction
Energy consumption = 182.492565 pJ
sum error= 111
Actual label: 1
Output voltages: [0.25943, 0.6603, 0.25513, 0.18433, 0.29352, 0.16157, 0.42752, 0.055706, 0.41971, 0.22377]
Predicted label: 1
Correct prediction
Energy consumption = 197.988161 pJ
sum error= 111
Actual label: 6
Output voltages: [0.41548, 0.242, 0.31566, 0.06117, 0.36954, 0.18245, 0.72585, 0.15456, 0.25116, 0.15825]
Predicted label: 6
Correct prediction
Energy consumption = 191.289930 pJ
sum error= 111
Actual label: 9
Output voltages: [0.36128, 0.092501, 0.24355, 0.1411, 0.3019, 0.14145, 0.097488, 0.20659, 0.43289, 0.66452]
Predicted label: 9
Correct prediction
Energy consumption = 198.385655 pJ
sum error= 111
Actual label: 3
Output voltages: [0.42319, 0.25327, 0.24778, 0.71835, 0.12361, 0.33476, 0.33463, 0.22245, 0.24597, 0.054822]
Predicted label: 3
Correct prediction
Energy consumption = 195.190843 pJ
sum error= 111
Actual label: 1
Output voltages: [0.24884, 0.76445, 0.2388, 0.24735, 0.17414, 0.13121, 0.45948, 0.098192, 0.32042, 0.20414]
Predicted label: 1
Correct prediction
Energy consumption = 202.578057 pJ
sum error= 111
Actual label: 8
Output voltages: [0.38674, 0.07773, 0.23111, 0.35699, 0.17204, 0.24297, 0.33736, 0.067597, 0.65342, 0.28474]
Predicted label: 8
Correct prediction
Energy consumption = 204.683431 pJ
sum error= 111
Actual label: 6
Output voltages: [0.27188, 0.25036, 0.31245, 0.085124, 0.31134, 0.36022, 0.74895, 0.10941, 0.35267, 0.11932]
Predicted label: 6
Correct prediction
Energy consumption = 188.985995 pJ
sum error= 111
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 276 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 276 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 276 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39386, 0.22492, 0.26312, 0.19024, 0.56238, 0.044468, 0.13543, 0.10262, 0.298, 0.52362]
Predicted label: 4
Wrong prediction!
Energy consumption = 204.269450 pJ
sum error= 112
Actual label: 0
Output voltages: [0.6139, 0.18456, 0.23608, 0.10122, 0.27061, 0.15841, 0.55085, 0.15085, 0.31497, 0.15684]
Predicted label: 0
Correct prediction
Energy consumption = 198.409787 pJ
sum error= 112
Actual label: 6
Output voltages: [0.34641, 0.23052, 0.24081, 0.12753, 0.33873, 0.40511, 0.7388, 0.074504, 0.414, 0.12848]
Predicted label: 6
Correct prediction
Energy consumption = 193.244364 pJ
sum error= 112
Actual label: 0
Output voltages: [0.71635, 0.22318, 0.25466, 0.18794, 0.12008, 0.20187, 0.41947, 0.18894, 0.3258, 0.27293]
Predicted label: 0
Correct prediction
Energy consumption = 194.888972 pJ
sum error= 112
Actual label: 0
Output voltages: [0.66566, 0.23071, 0.34171, 0.24977, 0.21287, 0.085405, 0.35282, 0.1661, 0.35088, 0.23008]
Predicted label: 0
Correct prediction
Energy consumption = 205.072691 pJ
sum error= 112
Actual label: 0
Output voltages: [0.70063, 0.21993, 0.23485, 0.17468, 0.15375, 0.14068, 0.46442, 0.14448, 0.31814, 0.28085]
Predicted label: 0
Correct prediction
Energy consumption = 196.378684 pJ
sum error= 112
Actual label: 6
Output voltages: [0.34405, 0.31173, 0.2935, 0.11649, 0.23131, 0.36541, 0.74808, 0.080287, 0.34658, 0.17715]
Predicted label: 6
Correct prediction
Energy consumption = 189.388013 pJ
sum error= 112
Actual label: 3
Output voltages: [0.27786, 0.23548, 0.39307, 0.74715, 0.22222, 0.082015, 0.14648, 0.12082, 0.40959, 0.26784]
Predicted label: 3
Correct prediction
Energy consumption = 185.796542 pJ
sum error= 112
Actual label: 5
Output voltages: [0.22523, 0.075474, 0.13828, 0.37667, 0.15783, 0.63969, 0.17054, 0.1467, 0.54906, 0.2779]
Predicted label: 5
Correct prediction
Energy consumption = 179.912939 pJ
sum error= 112
Actual label: 9
Output voltages: [0.30547, 0.18315, 0.178, 0.28181, 0.26431, 0.10194, 0.077982, 0.16302, 0.4519, 0.61022]
Predicted label: 9
Correct prediction
Energy consumption = 195.691735 pJ
sum error= 112
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 277 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 277 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 277 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23127, 0.067918, 0.29448, 0.48489, 0.086759, 0.34299, 0.23583, 0.32996, 0.57117, 0.22834]
Predicted label: 8
Wrong prediction!
Energy consumption = 193.582234 pJ
sum error= 113
Actual label: 4
Output voltages: [0.25098, 0.26801, 0.21109, 0.23638, 0.60066, 0.11283, 0.21385, 0.2076, 0.2668, 0.53864]
Predicted label: 4
Correct prediction
Energy consumption = 208.360575 pJ
sum error= 113
Actual label: 5
Output voltages: [0.28059, 0.11042, 0.042254, 0.35857, 0.2512, 0.75758, 0.30774, 0.18747, 0.46045, 0.16636]
Predicted label: 5
Correct prediction
Energy consumption = 193.892346 pJ
sum error= 113
Actual label: 5
Output voltages: [0.29909, 0.04878, 0.17596, 0.32427, 0.1815, 0.58662, 0.24088, 0.10124, 0.63241, 0.27605]
Predicted label: 8
Wrong prediction!
Energy consumption = 184.080663 pJ
sum error= 114
Actual label: 8
Output voltages: [0.22571, 0.17077, 0.29884, 0.26255, 0.17122, 0.29273, 0.21547, 0.17001, 0.74784, 0.31501]
Predicted label: 8
Correct prediction
Energy consumption = 180.066478 pJ
sum error= 114
Actual label: 5
Output voltages: [0.19936, 0.056709, 0.10558, 0.28759, 0.31489, 0.68185, 0.34455, 0.1157, 0.51529, 0.27781]
Predicted label: 5
Correct prediction
Energy consumption = 180.437291 pJ
sum error= 114
Actual label: 3
Output voltages: [0.29673, 0.25809, 0.30648, 0.75657, 0.12815, 0.12741, 0.14346, 0.11304, 0.45591, 0.23565]
Predicted label: 3
Correct prediction
Energy consumption = 179.559680 pJ
sum error= 114
Actual label: 0
Output voltages: [0.65323, 0.25657, 0.22065, 0.12229, 0.23404, 0.17723, 0.52054, 0.18679, 0.29634, 0.17122]
Predicted label: 0
Correct prediction
Energy consumption = 193.949575 pJ
sum error= 114
Actual label: 4
Output voltages: [0.45015, 0.2299, 0.34293, 0.22356, 0.56965, 0.039435, 0.29875, 0.27962, 0.22097, 0.32638]
Predicted label: 4
Correct prediction
Energy consumption = 204.072269 pJ
sum error= 114
Actual label: 0
Output voltages: [0.73692, 0.24163, 0.18275, 0.24209, 0.09124, 0.29627, 0.34187, 0.15574, 0.3661, 0.23298]
Predicted label: 0
Correct prediction
Energy consumption = 194.055302 pJ
sum error= 114
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 278 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 278 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 278 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.44918, 0.066369, 0.53944, 0.57912, 0.20692, 0.089006, 0.17357, 0.14622, 0.51995, 0.27507]
Predicted label: 3
Wrong prediction!
Energy consumption = 197.375814 pJ
sum error= 115
Actual label: 9
Output voltages: [0.34764, 0.063358, 0.22811, 0.28698, 0.40779, 0.15697, 0.10713, 0.28809, 0.31849, 0.64432]
Predicted label: 9
Correct prediction
Energy consumption = 197.847548 pJ
sum error= 115
Actual label: 6
Output voltages: [0.31101, 0.13759, 0.28686, 0.17121, 0.24436, 0.42107, 0.69209, 0.048742, 0.39879, 0.17987]
Predicted label: 6
Correct prediction
Energy consumption = 188.481522 pJ
sum error= 115
Actual label: 8
Output voltages: [0.18911, 0.22236, 0.27741, 0.3606, 0.12541, 0.22018, 0.2131, 0.14306, 0.73722, 0.32422]
Predicted label: 8
Correct prediction
Energy consumption = 190.679195 pJ
sum error= 115
Actual label: 2
Output voltages: [0.32089, 0.36227, 0.73523, 0.25891, 0.17554, 0.029041, 0.22475, 0.38049, 0.35319, 0.15855]
Predicted label: 2
Correct prediction
Energy consumption = 194.334844 pJ
sum error= 115
Actual label: 3
Output voltages: [0.30387, 0.14375, 0.32109, 0.75127, 0.19403, 0.20078, 0.12251, 0.18875, 0.45447, 0.2522]
Predicted label: 3
Correct prediction
Energy consumption = 184.150361 pJ
sum error= 115
Actual label: 1
Output voltages: [0.25591, 0.77566, 0.22188, 0.26277, 0.15636, 0.16553, 0.39144, 0.14794, 0.28055, 0.26174]
Predicted label: 1
Correct prediction
Energy consumption = 209.543588 pJ
sum error= 115
Actual label: 2
Output voltages: [0.47331, 0.12583, 0.71452, 0.39399, 0.13105, 0.053982, 0.26572, 0.23856, 0.44861, 0.17201]
Predicted label: 2
Correct prediction
Energy consumption = 193.841098 pJ
sum error= 115
Actual label: 1
Output voltages: [0.20149, 0.77294, 0.16104, 0.24601, 0.16736, 0.13176, 0.45853, 0.10383, 0.34249, 0.20177]
Predicted label: 1
Correct prediction
Energy consumption = 208.873850 pJ
sum error= 115
Actual label: 1
Output voltages: [0.2533, 0.73067, 0.30959, 0.22188, 0.3352, 0.047754, 0.30702, 0.08023, 0.28973, 0.27803]
Predicted label: 1
Correct prediction
Energy consumption = 192.326587 pJ
sum error= 115
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 279 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 279 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 279 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.29569, 0.08698, 0.12221, 0.44233, 0.13466, 0.6934, 0.27381, 0.15089, 0.51537, 0.18566]
Predicted label: 5
Correct prediction
Energy consumption = 191.926676 pJ
sum error= 115
Actual label: 6
Output voltages: [0.37708, 0.30729, 0.30026, 0.15661, 0.23077, 0.25494, 0.71792, 0.076845, 0.4236, 0.15773]
Predicted label: 6
Correct prediction
Energy consumption = 196.865092 pJ
sum error= 115
Actual label: 9
Output voltages: [0.34045, 0.15378, 0.22959, 0.27855, 0.24593, 0.18972, 0.088136, 0.2696, 0.37489, 0.68931]
Predicted label: 9
Correct prediction
Energy consumption = 192.469289 pJ
sum error= 115
Actual label: 8
Output voltages: [0.2755, 0.2422, 0.37164, 0.20161, 0.22617, 0.067377, 0.27727, 0.064346, 0.72931, 0.35699]
Predicted label: 8
Correct prediction
Energy consumption = 183.285792 pJ
sum error= 115
Actual label: 0
Output voltages: [0.67963, 0.146, 0.22766, 0.20071, 0.23281, 0.12622, 0.42749, 0.12453, 0.36873, 0.40803]
Predicted label: 0
Correct prediction
Energy consumption = 201.157164 pJ
sum error= 115
Actual label: 6
Output voltages: [0.29786, 0.22005, 0.29307, 0.13377, 0.26334, 0.4064, 0.74133, 0.070257, 0.41244, 0.1608]
Predicted label: 6
Correct prediction
Energy consumption = 187.252163 pJ
sum error= 115
Actual label: 6
Output voltages: [0.29962, 0.23759, 0.23697, 0.1847, 0.29011, 0.44281, 0.72595, 0.099621, 0.45636, 0.11558]
Predicted label: 6
Correct prediction
Energy consumption = 188.834023 pJ
sum error= 115
Actual label: 5
Output voltages: [0.22295, 0.11397, 0.057714, 0.38127, 0.24548, 0.72403, 0.1996, 0.26154, 0.39007, 0.32828]
Predicted label: 5
Correct prediction
Energy consumption = 186.500537 pJ
sum error= 115
Actual label: 5
Output voltages: [0.25233, 0.053165, 0.12548, 0.33276, 0.20864, 0.69644, 0.34643, 0.15422, 0.47294, 0.25539]
Predicted label: 5
Correct prediction
Energy consumption = 179.871699 pJ
sum error= 115
Actual label: 3
Output voltages: [0.35592, 0.18634, 0.3476, 0.76065, 0.17588, 0.22266, 0.16849, 0.18494, 0.45407, 0.21144]
Predicted label: 3
Correct prediction
Energy consumption = 181.366413 pJ
sum error= 115
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 280 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 280 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 280 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.22827, 0.11839, 0.32771, 0.37286, 0.1502, 0.16881, 0.15581, 0.16947, 0.71476, 0.24742]
Predicted label: 8
Correct prediction
Energy consumption = 201.360086 pJ
sum error= 115
Actual label: 6
Output voltages: [0.29855, 0.23808, 0.23956, 0.098001, 0.30513, 0.36517, 0.70298, 0.064948, 0.34206, 0.20196]
Predicted label: 6
Correct prediction
Energy consumption = 196.945764 pJ
sum error= 115
Actual label: 2
Output voltages: [0.52609, 0.22145, 0.6957, 0.25869, 0.074245, 0.053467, 0.30446, 0.21469, 0.4055, 0.24229]
Predicted label: 2
Correct prediction
Energy consumption = 193.800376 pJ
sum error= 115
Actual label: 1
Output voltages: [0.16412, 0.72128, 0.082768, 0.29044, 0.37742, 0.18792, 0.17384, 0.11879, 0.33903, 0.3209]
Predicted label: 1
Correct prediction
Energy consumption = 212.225567 pJ
sum error= 115
Actual label: 4
Output voltages: [0.15911, 0.13209, 0.26207, 0.13201, 0.75633, 0.069866, 0.27761, 0.29495, 0.30683, 0.19006]
Predicted label: 4
Correct prediction
Energy consumption = 196.729811 pJ
sum error= 115
Actual label: 5
Output voltages: [0.29021, 0.084611, 0.068661, 0.33075, 0.2243, 0.64521, 0.29704, 0.12431, 0.47707, 0.30357]
Predicted label: 5
Correct prediction
Energy consumption = 190.655104 pJ
sum error= 115
Actual label: 4
Output voltages: [0.17039, 0.15501, 0.30182, 0.19192, 0.76079, 0.11978, 0.26442, 0.24633, 0.21936, 0.31534]
Predicted label: 4
Correct prediction
Energy consumption = 193.363513 pJ
sum error= 115
Actual label: 3
Output voltages: [0.37926, 0.18332, 0.34061, 0.7549, 0.16981, 0.11024, 0.13966, 0.16048, 0.40704, 0.23882]
Predicted label: 3
Correct prediction
Energy consumption = 188.715317 pJ
sum error= 115
Actual label: 7
Output voltages: [0.33416, 0.24775, 0.14044, 0.19817, 0.17539, 0.1417, 0.057634, 0.73592, 0.34014, 0.43261]
Predicted label: 7
Correct prediction
Energy consumption = 206.478142 pJ
sum error= 115
Actual label: 8
Output voltages: [0.25568, 0.16038, 0.27167, 0.24303, 0.22049, 0.22723, 0.30029, 0.15111, 0.7416, 0.22516]
Predicted label: 8
Correct prediction
Energy consumption = 192.742160 pJ
sum error= 115
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 281 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 281 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 281 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.41578, 0.050512, 0.19784, 0.54289, 0.22081, 0.4023, 0.17521, 0.18603, 0.37382, 0.29442]
Predicted label: 3
Wrong prediction!
Energy consumption = 200.342764 pJ
sum error= 116
Actual label: 0
Output voltages: [0.72049, 0.19455, 0.24489, 0.19238, 0.14594, 0.24802, 0.41159, 0.19364, 0.23136, 0.33804]
Predicted label: 0
Correct prediction
Energy consumption = 190.001600 pJ
sum error= 116
Actual label: 9
Output voltages: [0.32529, 0.16749, 0.22373, 0.10874, 0.52734, 0.070452, 0.23472, 0.17076, 0.26096, 0.57297]
Predicted label: 9
Correct prediction
Energy consumption = 208.649409 pJ
sum error= 116
Actual label: 3
Output voltages: [0.41167, 0.23178, 0.26161, 0.74395, 0.085617, 0.2496, 0.23566, 0.23104, 0.35352, 0.10924]
Predicted label: 3
Correct prediction
Energy consumption = 191.840654 pJ
sum error= 116
Actual label: 5
Output voltages: [0.27037, 0.056001, 0.21473, 0.37189, 0.11297, 0.64057, 0.24757, 0.13378, 0.61517, 0.27613]
Predicted label: 5
Correct prediction
Energy consumption = 184.575123 pJ
sum error= 116
Actual label: 1
Output voltages: [0.16325, 0.69779, 0.25544, 0.38817, 0.25111, 0.1712, 0.17452, 0.16209, 0.25228, 0.29647]
Predicted label: 1
Correct prediction
Energy consumption = 211.740400 pJ
sum error= 116
Actual label: 1
Output voltages: [0.15856, 0.75751, 0.14251, 0.18926, 0.32295, 0.19638, 0.43412, 0.12376, 0.26067, 0.20723]
Predicted label: 1
Correct prediction
Energy consumption = 204.126836 pJ
sum error= 116
Actual label: 0
Output voltages: [0.70158, 0.25643, 0.3092, 0.1653, 0.17133, 0.083321, 0.44517, 0.1895, 0.33898, 0.22745]
Predicted label: 0
Correct prediction
Energy consumption = 194.045287 pJ
sum error= 116
Actual label: 4
Output voltages: [0.18032, 0.1271, 0.27447, 0.21369, 0.71394, 0.11559, 0.2245, 0.16845, 0.26238, 0.28202]
Predicted label: 4
Correct prediction
Energy consumption = 194.455171 pJ
sum error= 116
Actual label: 4
Output voltages: [0.15658, 0.17798, 0.29826, 0.19505, 0.75559, 0.061541, 0.26637, 0.30283, 0.22147, 0.19289]
Predicted label: 4
Correct prediction
Energy consumption = 183.226753 pJ
sum error= 116
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 282 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 282 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 282 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.20834, 0.19983, 0.43486, 0.29617, 0.23885, 0.031193, 0.057247, 0.70136, 0.33137, 0.24226]
Predicted label: 7
Correct prediction
Energy consumption = 187.117697 pJ
sum error= 116
Actual label: 0
Output voltages: [0.67468, 0.26885, 0.20639, 0.1481, 0.19763, 0.19908, 0.52064, 0.18239, 0.23814, 0.22386]
Predicted label: 0
Correct prediction
Energy consumption = 196.209799 pJ
sum error= 116
Actual label: 1
Output voltages: [0.17844, 0.77232, 0.27194, 0.35698, 0.22225, 0.14252, 0.29158, 0.25896, 0.23465, 0.25471]
Predicted label: 1
Correct prediction
Energy consumption = 212.067166 pJ
sum error= 116
Actual label: 7
Output voltages: [0.10563, 0.23124, 0.25846, 0.41185, 0.20434, 0.32341, 0.054864, 0.48409, 0.41271, 0.22577]
Predicted label: 7
Correct prediction
Energy consumption = 196.672034 pJ
sum error= 116
Actual label: 0
Output voltages: [0.72839, 0.24273, 0.20267, 0.23109, 0.17968, 0.17111, 0.37918, 0.16143, 0.30549, 0.39221]
Predicted label: 0
Correct prediction
Energy consumption = 209.056978 pJ
sum error= 116
Actual label: 1
Output voltages: [0.20608, 0.73463, 0.29797, 0.27578, 0.12104, 0.16123, 0.38459, 0.127, 0.37733, 0.21952]
Predicted label: 1
Correct prediction
Energy consumption = 209.869678 pJ
sum error= 116
Actual label: 6
Output voltages: [0.26092, 0.23268, 0.38965, 0.10389, 0.26596, 0.32831, 0.73677, 0.054361, 0.44031, 0.21268]
Predicted label: 6
Correct prediction
Energy consumption = 183.470294 pJ
sum error= 116
Actual label: 1
Output voltages: [0.27119, 0.71168, 0.19335, 0.096765, 0.29865, 0.078898, 0.22229, 0.15799, 0.34832, 0.42209]
Predicted label: 1
Correct prediction
Energy consumption = 216.061525 pJ
sum error= 116
Actual label: 4
Output voltages: [0.13482, 0.11598, 0.28392, 0.15413, 0.7398, 0.08791, 0.21131, 0.23231, 0.32475, 0.22796]
Predicted label: 4
Correct prediction
Energy consumption = 190.568950 pJ
sum error= 116
Actual label: 5
Output voltages: [0.15116, 0.072585, 0.18698, 0.41974, 0.30269, 0.5143, 0.24938, 0.13891, 0.52057, 0.35017]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.759676 pJ
sum error= 117
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 283 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 283 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 283 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.36609, 0.14321, 0.18747, 0.11559, 0.33893, 0.53413, 0.69471, 0.078069, 0.33518, 0.20907]
Predicted label: 6
Correct prediction
Energy consumption = 189.002091 pJ
sum error= 117
Actual label: 6
Output voltages: [0.30918, 0.13658, 0.24235, 0.16306, 0.28882, 0.36849, 0.7003, 0.044384, 0.40299, 0.22882]
Predicted label: 6
Correct prediction
Energy consumption = 182.448982 pJ
sum error= 117
Actual label: 5
Output voltages: [0.2632, 0.080755, 0.070436, 0.52612, 0.22589, 0.72868, 0.28945, 0.15578, 0.41562, 0.22581]
Predicted label: 5
Correct prediction
Energy consumption = 186.170453 pJ
sum error= 117
Actual label: 7
Output voltages: [0.39273, 0.24246, 0.12377, 0.23403, 0.18294, 0.20659, 0.047914, 0.75526, 0.34631, 0.33964]
Predicted label: 7
Correct prediction
Energy consumption = 194.422144 pJ
sum error= 117
Actual label: 8
Output voltages: [0.45346, 0.1045, 0.23253, 0.38517, 0.22998, 0.19155, 0.38364, 0.072358, 0.5766, 0.18818]
Predicted label: 8
Correct prediction
Energy consumption = 205.909860 pJ
sum error= 117
Actual label: 4
Output voltages: [0.15355, 0.15204, 0.27656, 0.24453, 0.74688, 0.04044, 0.2367, 0.31082, 0.18557, 0.20881]
Predicted label: 4
Correct prediction
Energy consumption = 198.217561 pJ
sum error= 117
Actual label: 4
Output voltages: [0.21738, 0.16668, 0.50333, 0.31848, 0.61062, 0.040223, 0.10678, 0.16665, 0.21561, 0.44883]
Predicted label: 4
Correct prediction
Energy consumption = 189.570957 pJ
sum error= 117
Actual label: 7
Output voltages: [0.28923, 0.28919, 0.37571, 0.25858, 0.091155, 0.046469, 0.045851, 0.75203, 0.38935, 0.30855]
Predicted label: 7
Correct prediction
Energy consumption = 191.632574 pJ
sum error= 117
Actual label: 2
Output voltages: [0.33978, 0.35491, 0.67336, 0.31637, 0.097836, 0.028815, 0.35433, 0.15464, 0.38782, 0.21894]
Predicted label: 2
Correct prediction
Energy consumption = 190.945648 pJ
sum error= 117
Actual label: 5
Output voltages: [0.2498, 0.11241, 0.22082, 0.27127, 0.15751, 0.62193, 0.30559, 0.067985, 0.60734, 0.27354]
Predicted label: 5
Correct prediction
Energy consumption = 183.518313 pJ
sum error= 117
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 284 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 284 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 284 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34857, 0.15123, 0.34973, 0.75213, 0.23235, 0.14994, 0.1402, 0.13918, 0.4527, 0.26914]
Predicted label: 3
Correct prediction
Energy consumption = 190.361678 pJ
sum error= 117
Actual label: 7
Output voltages: [0.27906, 0.25274, 0.48803, 0.29176, 0.20561, 0.029966, 0.12293, 0.74233, 0.20325, 0.32485]
Predicted label: 7
Correct prediction
Energy consumption = 186.998024 pJ
sum error= 117
Actual label: 0
Output voltages: [0.68916, 0.18255, 0.17197, 0.21665, 0.077099, 0.38456, 0.35096, 0.17369, 0.35394, 0.24113]
Predicted label: 0
Correct prediction
Energy consumption = 197.787667 pJ
sum error= 117
Actual label: 7
Output voltages: [0.37236, 0.20185, 0.47861, 0.26551, 0.091985, 0.050033, 0.055817, 0.64515, 0.41117, 0.3256]
Predicted label: 7
Correct prediction
Energy consumption = 189.669568 pJ
sum error= 117
Actual label: 7
Output voltages: [0.27551, 0.27588, 0.26042, 0.2948, 0.13099, 0.063099, 0.044828, 0.74643, 0.39963, 0.33509]
Predicted label: 7
Correct prediction
Energy consumption = 196.773451 pJ
sum error= 117
Actual label: 9
Output voltages: [0.36963, 0.12954, 0.23191, 0.28262, 0.29435, 0.16422, 0.10708, 0.26414, 0.3704, 0.65946]
Predicted label: 9
Correct prediction
Energy consumption = 189.713767 pJ
sum error= 117
Actual label: 6
Output voltages: [0.33156, 0.17215, 0.25251, 0.13472, 0.30062, 0.43982, 0.71673, 0.10693, 0.4174, 0.10455]
Predicted label: 6
Correct prediction
Energy consumption = 188.484017 pJ
sum error= 117
Actual label: 4
Output voltages: [0.30233, 0.19609, 0.18403, 0.2005, 0.67708, 0.13247, 0.15034, 0.4118, 0.19383, 0.40538]
Predicted label: 4
Correct prediction
Energy consumption = 203.640790 pJ
sum error= 117
Actual label: 2
Output voltages: [0.22437, 0.37571, 0.64281, 0.32682, 0.063895, 0.045795, 0.33078, 0.1746, 0.48578, 0.2172]
Predicted label: 2
Correct prediction
Energy consumption = 199.647841 pJ
sum error= 117
Actual label: 8
Output voltages: [0.1885, 0.18535, 0.21091, 0.25214, 0.23735, 0.27935, 0.23208, 0.142, 0.74775, 0.17273]
Predicted label: 8
Correct prediction
Energy consumption = 187.022932 pJ
sum error= 117
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 285 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 285 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 285 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.43786, 0.16162, 0.25931, 0.42009, 0.066652, 0.55392, 0.4496, 0.11669, 0.2985, 0.13722]
Predicted label: 5
Correct prediction
Energy consumption = 197.672007 pJ
sum error= 117
Actual label: 7
Output voltages: [0.45142, 0.20928, 0.11037, 0.23897, 0.35401, 0.21509, 0.050732, 0.68941, 0.22225, 0.47939]
Predicted label: 7
Correct prediction
Energy consumption = 202.137871 pJ
sum error= 117
Actual label: 8
Output voltages: [0.21659, 0.2118, 0.26682, 0.29364, 0.24073, 0.11478, 0.26891, 0.11471, 0.71384, 0.29654]
Predicted label: 8
Correct prediction
Energy consumption = 205.921086 pJ
sum error= 117
Actual label: 3
Output voltages: [0.3162, 0.12669, 0.33625, 0.66338, 0.10182, 0.11604, 0.14425, 0.17869, 0.58482, 0.26503]
Predicted label: 3
Correct prediction
Energy consumption = 187.461736 pJ
sum error= 117
Actual label: 9
Output voltages: [0.27945, 0.15977, 0.18186, 0.21333, 0.28736, 0.14856, 0.064316, 0.24068, 0.46537, 0.58309]
Predicted label: 9
Correct prediction
Energy consumption = 196.446355 pJ
sum error= 117
Actual label: 5
Output voltages: [0.37522, 0.20516, 0.040207, 0.38754, 0.18248, 0.75194, 0.32364, 0.096488, 0.3896, 0.13089]
Predicted label: 5
Correct prediction
Energy consumption = 198.473304 pJ
sum error= 117
Actual label: 8
Output voltages: [0.22466, 0.19467, 0.26316, 0.36548, 0.14369, 0.14996, 0.19551, 0.11175, 0.71135, 0.30559]
Predicted label: 8
Correct prediction
Energy consumption = 198.251785 pJ
sum error= 117
Actual label: 9
Output voltages: [0.3813, 0.14235, 0.17192, 0.29143, 0.30948, 0.29162, 0.21734, 0.25607, 0.27378, 0.67218]
Predicted label: 9
Correct prediction
Energy consumption = 195.269497 pJ
sum error= 117
Actual label: 9
Output voltages: [0.25331, 0.15004, 0.258, 0.3301, 0.42248, 0.14633, 0.095557, 0.18643, 0.32509, 0.60284]
Predicted label: 9
Correct prediction
Energy consumption = 198.177975 pJ
sum error= 117
Actual label: 8
Output voltages: [0.27663, 0.20374, 0.28807, 0.31411, 0.094707, 0.25955, 0.31906, 0.16758, 0.72338, 0.21415]
Predicted label: 8
Correct prediction
Energy consumption = 191.827699 pJ
sum error= 117
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 286 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 286 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 286 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.28596, 0.14091, 0.27784, 0.10947, 0.26935, 0.38925, 0.71026, 0.075963, 0.46791, 0.11606]
Predicted label: 6
Correct prediction
Energy consumption = 191.910571 pJ
sum error= 117
Actual label: 2
Output voltages: [0.38051, 0.36716, 0.72184, 0.31175, 0.085397, 0.023552, 0.26698, 0.33318, 0.32649, 0.21757]
Predicted label: 2
Correct prediction
Energy consumption = 185.343024 pJ
sum error= 117
Actual label: 8
Output voltages: [0.25455, 0.27722, 0.22494, 0.28798, 0.16346, 0.20423, 0.22435, 0.075763, 0.70277, 0.32246]
Predicted label: 8
Correct prediction
Energy consumption = 209.300340 pJ
sum error= 117
Actual label: 9
Output voltages: [0.15935, 0.19243, 0.20185, 0.26939, 0.60634, 0.16318, 0.24319, 0.17709, 0.31962, 0.44952]
Predicted label: 4
Wrong prediction!
Energy consumption = 198.267567 pJ
sum error= 118
Actual label: 2
Output voltages: [0.31392, 0.20052, 0.72386, 0.35114, 0.10335, 0.035347, 0.2257, 0.36127, 0.47042, 0.1926]
Predicted label: 2
Correct prediction
Energy consumption = 188.648667 pJ
sum error= 118
Actual label: 3
Output voltages: [0.33745, 0.18475, 0.26685, 0.76386, 0.17734, 0.18757, 0.15437, 0.25021, 0.44132, 0.25074]
Predicted label: 3
Correct prediction
Energy consumption = 179.219930 pJ
sum error= 118
Actual label: 6
Output voltages: [0.23314, 0.23135, 0.2246, 0.1966, 0.3159, 0.43291, 0.7122, 0.13205, 0.36831, 0.051808]
Predicted label: 6
Correct prediction
Energy consumption = 200.409074 pJ
sum error= 118
Actual label: 1
Output voltages: [0.19871, 0.76469, 0.1997, 0.25843, 0.20324, 0.186, 0.40576, 0.10151, 0.36303, 0.22517]
Predicted label: 1
Correct prediction
Energy consumption = 212.850761 pJ
sum error= 118
Actual label: 1
Output voltages: [0.22736, 0.77016, 0.19551, 0.3266, 0.13595, 0.13647, 0.4245, 0.1316, 0.30449, 0.22996]
Predicted label: 1
Correct prediction
Energy consumption = 203.577472 pJ
sum error= 118
Actual label: 8
Output voltages: [0.23975, 0.18503, 0.36762, 0.25316, 0.17485, 0.16936, 0.27391, 0.12052, 0.74192, 0.26209]
Predicted label: 8
Correct prediction
Energy consumption = 188.117156 pJ
sum error= 118
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 287 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 287 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 287 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39672, 0.12486, 0.25482, 0.30611, 0.2296, 0.21755, 0.1604, 0.28948, 0.32209, 0.69283]
Predicted label: 9
Correct prediction
Energy consumption = 198.173640 pJ
sum error= 118
Actual label: 3
Output voltages: [0.25033, 0.17398, 0.245, 0.73285, 0.15892, 0.28363, 0.17088, 0.11659, 0.46012, 0.28156]
Predicted label: 3
Correct prediction
Energy consumption = 192.699801 pJ
sum error= 118
Actual label: 4
Output voltages: [0.1734, 0.098653, 0.34729, 0.17021, 0.72138, 0.068692, 0.17008, 0.2331, 0.28709, 0.42636]
Predicted label: 4
Correct prediction
Energy consumption = 194.745886 pJ
sum error= 118
Actual label: 0
Output voltages: [0.72385, 0.23954, 0.23573, 0.18252, 0.18649, 0.19915, 0.4829, 0.16102, 0.30314, 0.2295]
Predicted label: 0
Correct prediction
Energy consumption = 195.838995 pJ
sum error= 118
Actual label: 7
Output voltages: [0.40258, 0.18052, 0.34724, 0.3324, 0.13545, 0.046355, 0.042069, 0.74655, 0.3579, 0.24873]
Predicted label: 7
Correct prediction
Energy consumption = 200.153775 pJ
sum error= 118
Actual label: 9
Output voltages: [0.32249, 0.20937, 0.17461, 0.30882, 0.60897, 0.092676, 0.13837, 0.1891, 0.1919, 0.5762]
Predicted label: 4
Wrong prediction!
Energy consumption = 192.506927 pJ
sum error= 119
Actual label: 6
Output voltages: [0.33324, 0.12917, 0.21934, 0.18905, 0.28711, 0.46705, 0.68274, 0.055589, 0.44464, 0.21188]
Predicted label: 6
Correct prediction
Energy consumption = 185.701988 pJ
sum error= 119
Actual label: 4
Output voltages: [0.2857, 0.072946, 0.23358, 0.31354, 0.52835, 0.14424, 0.19592, 0.26845, 0.25835, 0.52055]
Predicted label: 4
Correct prediction
Energy consumption = 195.896783 pJ
sum error= 119
Actual label: 1
Output voltages: [0.25737, 0.7619, 0.20345, 0.29565, 0.10743, 0.15911, 0.42485, 0.099848, 0.35493, 0.16963]
Predicted label: 1
Correct prediction
Energy consumption = 215.440772 pJ
sum error= 119
Actual label: 4
Output voltages: [0.28334, 0.16989, 0.32425, 0.13448, 0.72153, 0.03957, 0.30792, 0.18698, 0.23262, 0.27763]
Predicted label: 4
Correct prediction
Energy consumption = 202.349934 pJ
sum error= 119
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 288 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 288 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 288 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.13471, 0.75488, 0.19011, 0.25799, 0.30212, 0.071054, 0.37394, 0.13657, 0.32386, 0.2462]
Predicted label: 1
Correct prediction
Energy consumption = 212.182478 pJ
sum error= 119
Actual label: 3
Output voltages: [0.20639, 0.10143, 0.31846, 0.73605, 0.23369, 0.27165, 0.19231, 0.14265, 0.48007, 0.13054]
Predicted label: 3
Correct prediction
Energy consumption = 184.245130 pJ
sum error= 119
Actual label: 4
Output voltages: [0.22504, 0.11243, 0.35485, 0.26763, 0.67065, 0.21668, 0.21831, 0.25714, 0.20642, 0.3931]
Predicted label: 4
Correct prediction
Energy consumption = 203.719760 pJ
sum error= 119
Actual label: 9
Output voltages: [0.30841, 0.1099, 0.1793, 0.22871, 0.24698, 0.21099, 0.11799, 0.17459, 0.52668, 0.59762]
Predicted label: 9
Correct prediction
Energy consumption = 184.645735 pJ
sum error= 119
Actual label: 3
Output voltages: [0.32466, 0.13184, 0.31292, 0.75552, 0.23713, 0.2496, 0.12759, 0.13267, 0.40199, 0.2325]
Predicted label: 3
Correct prediction
Energy consumption = 181.369880 pJ
sum error= 119
Actual label: 1
Output voltages: [0.14232, 0.73667, 0.1966, 0.21532, 0.20318, 0.17214, 0.27088, 0.14277, 0.46462, 0.26949]
Predicted label: 1
Correct prediction
Energy consumption = 208.869411 pJ
sum error= 119
Actual label: 4
Output voltages: [0.14608, 0.14732, 0.26762, 0.12899, 0.74397, 0.083729, 0.24559, 0.26118, 0.32959, 0.27687]
Predicted label: 4
Correct prediction
Energy consumption = 203.297634 pJ
sum error= 119
Actual label: 7
Output voltages: [0.25946, 0.28309, 0.23487, 0.23034, 0.11311, 0.066958, 0.036509, 0.73197, 0.42866, 0.37982]
Predicted label: 7
Correct prediction
Energy consumption = 197.873013 pJ
sum error= 119
Actual label: 7
Output voltages: [0.36918, 0.30941, 0.52559, 0.24519, 0.12379, 0.02341, 0.075699, 0.6518, 0.31818, 0.29588]
Predicted label: 7
Correct prediction
Energy consumption = 195.081585 pJ
sum error= 119
Actual label: 4
Output voltages: [0.16554, 0.15482, 0.3082, 0.13335, 0.75935, 0.092103, 0.30525, 0.22632, 0.21439, 0.30385]
Predicted label: 4
Correct prediction
Energy consumption = 195.451825 pJ
sum error= 119
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 289 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 289 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 289 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3097, 0.23411, 0.40834, 0.28322, 0.11673, 0.038886, 0.049838, 0.72103, 0.33654, 0.3539]
Predicted label: 7
Correct prediction
Energy consumption = 204.583635 pJ
sum error= 119
Actual label: 2
Output voltages: [0.3369, 0.28075, 0.62573, 0.40746, 0.13416, 0.036065, 0.27936, 0.13191, 0.54576, 0.29847]
Predicted label: 2
Correct prediction
Energy consumption = 187.579629 pJ
sum error= 119
Actual label: 9
Output voltages: [0.36446, 0.10207, 0.16908, 0.29135, 0.31669, 0.26535, 0.14738, 0.31006, 0.31549, 0.6722]
Predicted label: 9
Correct prediction
Energy consumption = 190.967603 pJ
sum error= 119
Actual label: 3
Output voltages: [0.40426, 0.2123, 0.22674, 0.74926, 0.12225, 0.30724, 0.19218, 0.23286, 0.35166, 0.14456]
Predicted label: 3
Correct prediction
Energy consumption = 191.154055 pJ
sum error= 119
Actual label: 0
Output voltages: [0.54065, 0.20311, 0.24527, 0.17913, 0.25826, 0.36175, 0.55131, 0.066324, 0.37445, 0.16314]
Predicted label: 6
Wrong prediction!
Energy consumption = 204.478737 pJ
sum error= 120
Actual label: 8
Output voltages: [0.19468, 0.1777, 0.33155, 0.32749, 0.10621, 0.24735, 0.18542, 0.14529, 0.74055, 0.26943]
Predicted label: 8
Correct prediction
Energy consumption = 194.867641 pJ
sum error= 120
Actual label: 8
Output voltages: [0.59187, 0.1359, 0.24798, 0.23506, 0.13009, 0.25558, 0.40585, 0.14406, 0.50044, 0.25339]
Predicted label: 0
Wrong prediction!
Energy consumption = 202.949879 pJ
sum error= 121
Actual label: 8
Output voltages: [0.23455, 0.19964, 0.34367, 0.21587, 0.21556, 0.17501, 0.18904, 0.19762, 0.74597, 0.23583]
Predicted label: 8
Correct prediction
Energy consumption = 193.653793 pJ
sum error= 121
Actual label: 4
Output voltages: [0.13213, 0.17975, 0.24224, 0.10471, 0.65765, 0.14726, 0.21952, 0.24101, 0.37908, 0.35738]
Predicted label: 4
Correct prediction
Energy consumption = 199.171746 pJ
sum error= 121
Actual label: 0
Output voltages: [0.69119, 0.18792, 0.25437, 0.075344, 0.21916, 0.17994, 0.42636, 0.18789, 0.30196, 0.28396]
Predicted label: 0
Correct prediction
Energy consumption = 192.701189 pJ
sum error= 121
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 290 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 290 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 290 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.20997, 0.14331, 0.34066, 0.17486, 0.74023, 0.066682, 0.31409, 0.11559, 0.24749, 0.31289]
Predicted label: 4
Correct prediction
Energy consumption = 195.452563 pJ
sum error= 121
Actual label: 4
Output voltages: [0.19507, 0.30569, 0.24061, 0.12747, 0.65398, 0.055974, 0.39309, 0.055458, 0.37025, 0.2397]
Predicted label: 4
Correct prediction
Energy consumption = 202.620822 pJ
sum error= 121
Actual label: 1
Output voltages: [0.22581, 0.73834, 0.27034, 0.32802, 0.20282, 0.13962, 0.33937, 0.095447, 0.36762, 0.196]
Predicted label: 1
Correct prediction
Energy consumption = 211.034110 pJ
sum error= 121
Actual label: 5
Output voltages: [0.20655, 0.044039, 0.13949, 0.38413, 0.21211, 0.64057, 0.29048, 0.13584, 0.57523, 0.24066]
Predicted label: 5
Correct prediction
Energy consumption = 186.549247 pJ
sum error= 121
Actual label: 2
Output voltages: [0.35536, 0.29037, 0.75464, 0.29176, 0.16228, 0.035571, 0.2972, 0.27166, 0.36643, 0.21842]
Predicted label: 2
Correct prediction
Energy consumption = 187.672353 pJ
sum error= 121
Actual label: 8
Output voltages: [0.14855, 0.32456, 0.29098, 0.21243, 0.20788, 0.18721, 0.23535, 0.19072, 0.72488, 0.34133]
Predicted label: 8
Correct prediction
Energy consumption = 201.906367 pJ
sum error= 121
Actual label: 3
Output voltages: [0.26523, 0.12764, 0.21087, 0.66373, 0.25657, 0.28996, 0.16829, 0.21136, 0.46997, 0.23052]
Predicted label: 3
Correct prediction
Energy consumption = 198.984984 pJ
sum error= 121
Actual label: 4
Output voltages: [0.17277, 0.16781, 0.44584, 0.21573, 0.73974, 0.04715, 0.29618, 0.21471, 0.16917, 0.33304]
Predicted label: 4
Correct prediction
Energy consumption = 190.734532 pJ
sum error= 121
Actual label: 9
Output voltages: [0.34385, 0.16978, 0.25708, 0.322, 0.33861, 0.14841, 0.1549, 0.16774, 0.27979, 0.67763]
Predicted label: 9
Correct prediction
Energy consumption = 199.133963 pJ
sum error= 121
Actual label: 5
Output voltages: [0.25846, 0.089374, 0.068981, 0.44391, 0.21189, 0.74802, 0.30906, 0.20171, 0.45715, 0.2374]
Predicted label: 5
Correct prediction
Energy consumption = 190.306107 pJ
sum error= 121
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 291 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 291 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 291 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31837, 0.29078, 0.68431, 0.40479, 0.11832, 0.033371, 0.22093, 0.34852, 0.40844, 0.23068]
Predicted label: 2
Correct prediction
Energy consumption = 196.045243 pJ
sum error= 121
Actual label: 8
Output voltages: [0.29714, 0.28981, 0.40357, 0.35004, 0.18507, 0.084899, 0.28972, 0.048427, 0.62708, 0.32847]
Predicted label: 8
Correct prediction
Energy consumption = 195.379441 pJ
sum error= 121
Actual label: 1
Output voltages: [0.1807, 0.75811, 0.23093, 0.30168, 0.19014, 0.1068, 0.21841, 0.15077, 0.43127, 0.27598]
Predicted label: 1
Correct prediction
Energy consumption = 215.297907 pJ
sum error= 121
Actual label: 5
Output voltages: [0.19395, 0.049716, 0.079203, 0.35634, 0.26957, 0.70063, 0.2541, 0.19549, 0.48112, 0.30792]
Predicted label: 5
Correct prediction
Energy consumption = 194.486099 pJ
sum error= 121
Actual label: 3
Output voltages: [0.29237, 0.25102, 0.26709, 0.75896, 0.099631, 0.13456, 0.11404, 0.31194, 0.38958, 0.27966]
Predicted label: 3
Correct prediction
Energy consumption = 186.847472 pJ
sum error= 121
Actual label: 7
Output voltages: [0.23791, 0.42656, 0.41677, 0.39803, 0.12151, 0.030199, 0.08021, 0.58916, 0.39759, 0.21395]
Predicted label: 7
Correct prediction
Energy consumption = 197.079390 pJ
sum error= 121
Actual label: 9
Output voltages: [0.30628, 0.12415, 0.19262, 0.22432, 0.30558, 0.15382, 0.062897, 0.22092, 0.38906, 0.68384]
Predicted label: 9
Correct prediction
Energy consumption = 193.499878 pJ
sum error= 121
Actual label: 4
Output voltages: [0.18089, 0.26974, 0.29037, 0.23854, 0.74391, 0.12175, 0.32938, 0.19121, 0.16315, 0.33792]
Predicted label: 4
Correct prediction
Energy consumption = 202.249937 pJ
sum error= 121
Actual label: 2
Output voltages: [0.37643, 0.14557, 0.74595, 0.34717, 0.19843, 0.046047, 0.26686, 0.29629, 0.41244, 0.14937]
Predicted label: 2
Correct prediction
Energy consumption = 189.429869 pJ
sum error= 121
Actual label: 5
Output voltages: [0.21615, 0.055855, 0.070542, 0.37573, 0.32073, 0.66628, 0.35138, 0.19843, 0.40252, 0.33231]
Predicted label: 5
Correct prediction
Energy consumption = 188.139644 pJ
sum error= 121
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 292 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 292 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 292 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.24864, 0.17826, 0.26027, 0.093919, 0.36371, 0.35856, 0.73039, 0.16281, 0.30359, 0.14815]
Predicted label: 6
Correct prediction
Energy consumption = 192.859464 pJ
sum error= 121
Actual label: 3
Output voltages: [0.4715, 0.14732, 0.55005, 0.49737, 0.055253, 0.096267, 0.21373, 0.30479, 0.59603, 0.13323]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.705565 pJ
sum error= 122
Actual label: 5
Output voltages: [0.23195, 0.093056, 0.11725, 0.35135, 0.20232, 0.69569, 0.27206, 0.13426, 0.57942, 0.23111]
Predicted label: 5
Correct prediction
Energy consumption = 186.832955 pJ
sum error= 122
Actual label: 9
Output voltages: [0.31382, 0.15215, 0.21086, 0.22472, 0.25602, 0.12735, 0.073622, 0.20351, 0.39179, 0.70395]
Predicted label: 9
Correct prediction
Energy consumption = 188.043454 pJ
sum error= 122
Actual label: 3
Output voltages: [0.28638, 0.1937, 0.27287, 0.76227, 0.17172, 0.21051, 0.2262, 0.19267, 0.40419, 0.20055]
Predicted label: 3
Correct prediction
Energy consumption = 184.465559 pJ
sum error= 122
Actual label: 5
Output voltages: [0.2908, 0.11043, 0.035232, 0.32776, 0.34071, 0.5083, 0.43236, 0.10074, 0.42777, 0.29836]
Predicted label: 5
Correct prediction
Energy consumption = 194.189894 pJ
sum error= 122
Actual label: 9
Output voltages: [0.34913, 0.18296, 0.1859, 0.31844, 0.44989, 0.20803, 0.16325, 0.21773, 0.25544, 0.66984]
Predicted label: 9
Correct prediction
Energy consumption = 198.082063 pJ
sum error= 122
Actual label: 3
Output voltages: [0.28717, 0.18344, 0.63409, 0.5328, 0.19332, 0.06127, 0.15018, 0.36104, 0.41702, 0.15152]
Predicted label: 2
Wrong prediction!
Energy consumption = 195.447310 pJ
sum error= 123
Actual label: 1
Output voltages: [0.19788, 0.74441, 0.31888, 0.19904, 0.3249, 0.086796, 0.4233, 0.12713, 0.25321, 0.177]
Predicted label: 1
Correct prediction
Energy consumption = 212.057695 pJ
sum error= 123
Actual label: 9
Output voltages: [0.34027, 0.059981, 0.18895, 0.19454, 0.28534, 0.23947, 0.04768, 0.40462, 0.43808, 0.60657]
Predicted label: 9
Correct prediction
Energy consumption = 195.831242 pJ
sum error= 123
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 293 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 293 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 293 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.44076, 0.20379, 0.03416, 0.42192, 0.32876, 0.67228, 0.25946, 0.17088, 0.28386, 0.23908]
Predicted label: 5
Correct prediction
Energy consumption = 203.725570 pJ
sum error= 123
Actual label: 3
Output voltages: [0.24485, 0.24554, 0.26589, 0.75214, 0.18185, 0.14342, 0.11881, 0.20057, 0.39391, 0.30716]
Predicted label: 3
Correct prediction
Energy consumption = 188.548966 pJ
sum error= 123
Actual label: 0
Output voltages: [0.67644, 0.20255, 0.3783, 0.10616, 0.12229, 0.16806, 0.41565, 0.091992, 0.30712, 0.29844]
Predicted label: 0
Correct prediction
Energy consumption = 192.926869 pJ
sum error= 123
Actual label: 6
Output voltages: [0.32182, 0.20788, 0.27381, 0.14146, 0.29299, 0.42096, 0.72741, 0.069534, 0.41228, 0.14097]
Predicted label: 6
Correct prediction
Energy consumption = 184.409084 pJ
sum error= 123
Actual label: 9
Output voltages: [0.32232, 0.13923, 0.16263, 0.2681, 0.1956, 0.22387, 0.05687, 0.41374, 0.38329, 0.59286]
Predicted label: 9
Correct prediction
Energy consumption = 199.854088 pJ
sum error= 123
Actual label: 8
Output voltages: [0.20778, 0.19584, 0.30212, 0.2677, 0.13186, 0.24524, 0.17921, 0.20961, 0.74804, 0.2632]
Predicted label: 8
Correct prediction
Energy consumption = 189.982824 pJ
sum error= 123
Actual label: 4
Output voltages: [0.17284, 0.17985, 0.27741, 0.10819, 0.76266, 0.18742, 0.24204, 0.23774, 0.21693, 0.37927]
Predicted label: 4
Correct prediction
Energy consumption = 197.080148 pJ
sum error= 123
Actual label: 0
Output voltages: [0.73237, 0.24237, 0.19205, 0.1974, 0.13698, 0.1931, 0.24955, 0.3038, 0.41541, 0.24615]
Predicted label: 0
Correct prediction
Energy consumption = 203.845202 pJ
sum error= 123
Actual label: 4
Output voltages: [0.35943, 0.13577, 0.13169, 0.17701, 0.5739, 0.11943, 0.38105, 0.097101, 0.25071, 0.36287]
Predicted label: 4
Correct prediction
Energy consumption = 200.691443 pJ
sum error= 123
Actual label: 9
Output voltages: [0.5153, 0.20113, 0.05448, 0.33579, 0.42532, 0.35856, 0.080275, 0.32664, 0.23382, 0.55032]
Predicted label: 9
Correct prediction
Energy consumption = 193.811498 pJ
sum error= 123
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 294 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 294 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 294 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35033, 0.39196, 0.67594, 0.31943, 0.18651, 0.034951, 0.37008, 0.19208, 0.40029, 0.16733]
Predicted label: 2
Correct prediction
Energy consumption = 191.188282 pJ
sum error= 123
Actual label: 9
Output voltages: [0.33666, 0.089199, 0.15562, 0.16986, 0.31022, 0.34482, 0.13371, 0.24667, 0.45159, 0.62702]
Predicted label: 9
Correct prediction
Energy consumption = 193.669051 pJ
sum error= 123
Actual label: 0
Output voltages: [0.72961, 0.22309, 0.24873, 0.18263, 0.17003, 0.18941, 0.42583, 0.1718, 0.26661, 0.32796]
Predicted label: 0
Correct prediction
Energy consumption = 199.201399 pJ
sum error= 123
Actual label: 1
Output voltages: [0.29676, 0.75665, 0.21985, 0.35126, 0.11195, 0.13222, 0.39462, 0.080095, 0.39056, 0.21962]
Predicted label: 1
Correct prediction
Energy consumption = 202.619491 pJ
sum error= 123
Actual label: 0
Output voltages: [0.68474, 0.17532, 0.39261, 0.21597, 0.12473, 0.1141, 0.23324, 0.15456, 0.49272, 0.30754]
Predicted label: 0
Correct prediction
Energy consumption = 201.805545 pJ
sum error= 123
Actual label: 3
Output voltages: [0.32113, 0.26167, 0.28413, 0.73577, 0.13081, 0.10332, 0.057516, 0.43527, 0.23792, 0.40171]
Predicted label: 3
Correct prediction
Energy consumption = 199.580371 pJ
sum error= 123
Actual label: 1
Output voltages: [0.25844, 0.56027, 0.24082, 0.13143, 0.30735, 0.26912, 0.40375, 0.049955, 0.5196, 0.27567]
Predicted label: 1
Correct prediction
Energy consumption = 199.420239 pJ
sum error= 123
Actual label: 6
Output voltages: [0.32484, 0.22699, 0.26763, 0.13456, 0.37815, 0.35794, 0.74291, 0.082199, 0.39097, 0.12205]
Predicted label: 6
Correct prediction
Energy consumption = 192.364980 pJ
sum error= 123
Actual label: 5
Output voltages: [0.27909, 0.09839, 0.20757, 0.41739, 0.083316, 0.63566, 0.21316, 0.096891, 0.5855, 0.234]
Predicted label: 5
Correct prediction
Energy consumption = 186.447608 pJ
sum error= 123
Actual label: 8
Output voltages: [0.16499, 0.25134, 0.22902, 0.26884, 0.13418, 0.26566, 0.24428, 0.090751, 0.7366, 0.3107]
Predicted label: 8
Correct prediction
Energy consumption = 196.377021 pJ
sum error= 123
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 295 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 295 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 295 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17985, 0.7683, 0.20043, 0.22582, 0.23022, 0.12996, 0.43781, 0.065461, 0.30907, 0.23568]
Predicted label: 1
Correct prediction
Energy consumption = 213.207335 pJ
sum error= 123
Actual label: 5
Output voltages: [0.20545, 0.047763, 0.087219, 0.33598, 0.22535, 0.59942, 0.38235, 0.083552, 0.54505, 0.23276]
Predicted label: 5
Correct prediction
Energy consumption = 198.521823 pJ
sum error= 123
Actual label: 3
Output voltages: [0.23554, 0.044905, 0.18181, 0.61201, 0.2901, 0.51711, 0.2378, 0.15406, 0.442, 0.24748]
Predicted label: 3
Correct prediction
Energy consumption = 185.858986 pJ
sum error= 123
Actual label: 3
Output voltages: [0.24976, 0.065365, 0.22268, 0.5722, 0.15804, 0.44482, 0.12101, 0.23541, 0.59496, 0.17916]
Predicted label: 8
Wrong prediction!
Energy consumption = 188.209932 pJ
sum error= 124
Actual label: 0
Output voltages: [0.60666, 0.20703, 0.34692, 0.12536, 0.22831, 0.095773, 0.50127, 0.21676, 0.39646, 0.13319]
Predicted label: 0
Correct prediction
Energy consumption = 195.595998 pJ
sum error= 124
Actual label: 3
Output voltages: [0.28856, 0.15221, 0.30865, 0.74636, 0.23023, 0.22274, 0.14332, 0.085866, 0.42966, 0.27031]
Predicted label: 3
Correct prediction
Energy consumption = 189.327361 pJ
sum error= 124
Actual label: 5
Output voltages: [0.12198, 0.10911, 0.26744, 0.43188, 0.28894, 0.51757, 0.17128, 0.067735, 0.55902, 0.26772]
Predicted label: 8
Wrong prediction!
Energy consumption = 190.584255 pJ
sum error= 125
Actual label: 5
Output voltages: [0.33656, 0.064898, 0.055855, 0.37772, 0.18392, 0.73688, 0.36591, 0.15806, 0.47903, 0.14442]
Predicted label: 5
Correct prediction
Energy consumption = 188.569507 pJ
sum error= 125
Actual label: 9
Output voltages: [0.34571, 0.17846, 0.17045, 0.28704, 0.34657, 0.12635, 0.17257, 0.15539, 0.35468, 0.68674]
Predicted label: 9
Correct prediction
Energy consumption = 196.749116 pJ
sum error= 125
Actual label: 2
Output voltages: [0.26967, 0.15223, 0.62995, 0.45264, 0.19554, 0.037404, 0.12563, 0.41429, 0.39653, 0.18573]
Predicted label: 2
Correct prediction
Energy consumption = 190.578081 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 296 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 296 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 296 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20911, 0.25324, 0.28954, 0.21389, 0.18275, 0.17008, 0.18512, 0.16486, 0.74542, 0.37358]
Predicted label: 8
Correct prediction
Energy consumption = 203.089702 pJ
sum error= 125
Actual label: 7
Output voltages: [0.33604, 0.18775, 0.45139, 0.55417, 0.14571, 0.061302, 0.076928, 0.56247, 0.22474, 0.39494]
Predicted label: 7
Correct prediction
Energy consumption = 196.185619 pJ
sum error= 125
Actual label: 0
Output voltages: [0.70765, 0.21106, 0.2638, 0.20384, 0.18971, 0.097651, 0.45861, 0.1453, 0.34303, 0.25188]
Predicted label: 0
Correct prediction
Energy consumption = 200.978156 pJ
sum error= 125
Actual label: 4
Output voltages: [0.16513, 0.16397, 0.28206, 0.14764, 0.75798, 0.07526, 0.29346, 0.27861, 0.21464, 0.24567]
Predicted label: 4
Correct prediction
Energy consumption = 190.802561 pJ
sum error= 125
Actual label: 9
Output voltages: [0.36117, 0.17915, 0.2352, 0.20522, 0.59238, 0.083604, 0.17767, 0.15918, 0.22184, 0.61037]
Predicted label: 9
Correct prediction
Energy consumption = 194.271085 pJ
sum error= 125
Actual label: 1
Output voltages: [0.20372, 0.76445, 0.29569, 0.2769, 0.21888, 0.070125, 0.33527, 0.13793, 0.29626, 0.20726]
Predicted label: 1
Correct prediction
Energy consumption = 215.324416 pJ
sum error= 125
Actual label: 9
Output voltages: [0.36491, 0.18315, 0.13486, 0.27647, 0.44013, 0.23072, 0.2539, 0.17948, 0.2754, 0.68763]
Predicted label: 9
Correct prediction
Energy consumption = 207.898071 pJ
sum error= 125
Actual label: 7
Output voltages: [0.26364, 0.24582, 0.32737, 0.29243, 0.15319, 0.051731, 0.046458, 0.75843, 0.37769, 0.30696]
Predicted label: 7
Correct prediction
Energy consumption = 199.924496 pJ
sum error= 125
Actual label: 7
Output voltages: [0.35255, 0.23538, 0.29246, 0.35776, 0.16019, 0.063509, 0.043464, 0.71623, 0.30726, 0.38346]
Predicted label: 7
Correct prediction
Energy consumption = 192.106733 pJ
sum error= 125
Actual label: 5
Output voltages: [0.32774, 0.066208, 0.091239, 0.33922, 0.24505, 0.74385, 0.37587, 0.19828, 0.47034, 0.14485]
Predicted label: 5
Correct prediction
Energy consumption = 188.070113 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 297 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 297 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 297 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.33536, 0.088493, 0.13822, 0.4956, 0.068574, 0.53435, 0.18619, 0.26314, 0.44972, 0.23418]
Predicted label: 5
Correct prediction
Energy consumption = 197.174842 pJ
sum error= 125
Actual label: 2
Output voltages: [0.36055, 0.26048, 0.73878, 0.28628, 0.16393, 0.028482, 0.30599, 0.31552, 0.42051, 0.21314]
Predicted label: 2
Correct prediction
Energy consumption = 190.354147 pJ
sum error= 125
Actual label: 0
Output voltages: [0.62444, 0.21216, 0.29589, 0.096944, 0.29128, 0.090385, 0.5182, 0.24616, 0.25998, 0.24768]
Predicted label: 0
Correct prediction
Energy consumption = 196.987531 pJ
sum error= 125
Actual label: 9
Output voltages: [0.3555, 0.10274, 0.22963, 0.24724, 0.33337, 0.20993, 0.17844, 0.21839, 0.34389, 0.69616]
Predicted label: 9
Correct prediction
Energy consumption = 190.820493 pJ
sum error= 125
Actual label: 1
Output voltages: [0.2167, 0.76863, 0.30834, 0.26366, 0.22721, 0.079059, 0.43134, 0.1169, 0.25762, 0.20988]
Predicted label: 1
Correct prediction
Energy consumption = 209.793552 pJ
sum error= 125
Actual label: 8
Output voltages: [0.37495, 0.17931, 0.45782, 0.12335, 0.24012, 0.05081, 0.25878, 0.11121, 0.67622, 0.325]
Predicted label: 8
Correct prediction
Energy consumption = 187.240102 pJ
sum error= 125
Actual label: 6
Output voltages: [0.37329, 0.15577, 0.17856, 0.21388, 0.28887, 0.47685, 0.69102, 0.078575, 0.42325, 0.17932]
Predicted label: 6
Correct prediction
Energy consumption = 187.368075 pJ
sum error= 125
Actual label: 2
Output voltages: [0.38942, 0.20397, 0.70075, 0.38333, 0.14365, 0.035868, 0.26358, 0.21523, 0.50822, 0.17306]
Predicted label: 2
Correct prediction
Energy consumption = 183.589408 pJ
sum error= 125
Actual label: 3
Output voltages: [0.35637, 0.26048, 0.25778, 0.76288, 0.13072, 0.23791, 0.11362, 0.25556, 0.41219, 0.27852]
Predicted label: 3
Correct prediction
Energy consumption = 186.436031 pJ
sum error= 125
Actual label: 9
Output voltages: [0.52567, 0.18993, 0.18382, 0.20115, 0.29144, 0.064154, 0.20411, 0.35098, 0.28544, 0.5351]
Predicted label: 9
Correct prediction
Energy consumption = 202.812714 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 298 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 298 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 298 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.34222, 0.16915, 0.21996, 0.21706, 0.26868, 0.48043, 0.73664, 0.069075, 0.36281, 0.23644]
Predicted label: 6
Correct prediction
Energy consumption = 191.933550 pJ
sum error= 125
Actual label: 2
Output voltages: [0.36043, 0.16048, 0.67318, 0.39619, 0.077414, 0.062348, 0.25803, 0.20334, 0.49144, 0.24611]
Predicted label: 2
Correct prediction
Energy consumption = 195.176998 pJ
sum error= 125
Actual label: 1
Output voltages: [0.15353, 0.76383, 0.17853, 0.33253, 0.28804, 0.13381, 0.33844, 0.19822, 0.27126, 0.22041]
Predicted label: 1
Correct prediction
Energy consumption = 212.499698 pJ
sum error= 125
Actual label: 9
Output voltages: [0.35338, 0.14667, 0.21558, 0.25894, 0.41956, 0.14512, 0.09266, 0.23183, 0.30597, 0.69293]
Predicted label: 9
Correct prediction
Energy consumption = 198.509607 pJ
sum error= 125
Actual label: 1
Output voltages: [0.25832, 0.76103, 0.3224, 0.32756, 0.14316, 0.057125, 0.3141, 0.15151, 0.2584, 0.28006]
Predicted label: 1
Correct prediction
Energy consumption = 214.559488 pJ
sum error= 125
Actual label: 3
Output voltages: [0.2974, 0.20939, 0.2802, 0.76025, 0.21809, 0.19886, 0.156, 0.22471, 0.35135, 0.27365]
Predicted label: 3
Correct prediction
Energy consumption = 192.347541 pJ
sum error= 125
Actual label: 5
Output voltages: [0.19892, 0.042456, 0.11821, 0.30895, 0.36022, 0.56664, 0.41584, 0.052515, 0.46302, 0.24251]
Predicted label: 5
Correct prediction
Energy consumption = 193.776781 pJ
sum error= 125
Actual label: 5
Output voltages: [0.22916, 0.056658, 0.096215, 0.42748, 0.18395, 0.64957, 0.23568, 0.14805, 0.50591, 0.26787]
Predicted label: 5
Correct prediction
Energy consumption = 189.975531 pJ
sum error= 125
Actual label: 0
Output voltages: [0.73658, 0.24379, 0.25089, 0.19153, 0.17839, 0.17697, 0.35519, 0.22169, 0.37164, 0.25507]
Predicted label: 0
Correct prediction
Energy consumption = 200.090880 pJ
sum error= 125
Actual label: 3
Output voltages: [0.31291, 0.18785, 0.40563, 0.71861, 0.19135, 0.1556, 0.13626, 0.14673, 0.44859, 0.13248]
Predicted label: 3
Correct prediction
Energy consumption = 195.715112 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 299 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 299 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 299 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.24635, 0.11709, 0.27429, 0.24741, 0.13648, 0.27475, 0.1035, 0.15398, 0.65498, 0.40178]
Predicted label: 8
Correct prediction
Energy consumption = 199.874311 pJ
sum error= 125
Actual label: 3
Output voltages: [0.22988, 0.16563, 0.21525, 0.72421, 0.2283, 0.28251, 0.13817, 0.23204, 0.38127, 0.31319]
Predicted label: 3
Correct prediction
Energy consumption = 195.928918 pJ
sum error= 125
Actual label: 3
Output voltages: [0.35343, 0.15526, 0.22821, 0.75658, 0.18694, 0.33949, 0.17331, 0.17736, 0.42386, 0.22622]
Predicted label: 3
Correct prediction
Energy consumption = 186.373553 pJ
sum error= 125
Actual label: 7
Output voltages: [0.40821, 0.23548, 0.48813, 0.2223, 0.13393, 0.043534, 0.069006, 0.68525, 0.32364, 0.27716]
Predicted label: 7
Correct prediction
Energy consumption = 199.084098 pJ
sum error= 125
Actual label: 6
Output voltages: [0.22704, 0.33332, 0.35857, 0.11157, 0.35329, 0.27506, 0.73167, 0.11692, 0.38328, 0.062837]
Predicted label: 6
Correct prediction
Energy consumption = 207.386406 pJ
sum error= 125
Actual label: 6
Output voltages: [0.34422, 0.29831, 0.18262, 0.31634, 0.11136, 0.39409, 0.55552, 0.085828, 0.54237, 0.15462]
Predicted label: 6
Correct prediction
Energy consumption = 205.066343 pJ
sum error= 125
Actual label: 0
Output voltages: [0.739, 0.26533, 0.21822, 0.20004, 0.10553, 0.28213, 0.33401, 0.14643, 0.32625, 0.25384]
Predicted label: 0
Correct prediction
Energy consumption = 191.341449 pJ
sum error= 125
Actual label: 1
Output voltages: [0.30415, 0.76155, 0.32577, 0.28644, 0.22923, 0.052117, 0.32359, 0.12016, 0.2588, 0.29225]
Predicted label: 1
Correct prediction
Energy consumption = 209.176270 pJ
sum error= 125
Actual label: 4
Output voltages: [0.22784, 0.16852, 0.28518, 0.14702, 0.74096, 0.15394, 0.24541, 0.21123, 0.20765, 0.41598]
Predicted label: 4
Correct prediction
Energy consumption = 195.595515 pJ
sum error= 125
Actual label: 0
Output voltages: [0.70238, 0.26721, 0.21029, 0.15894, 0.15952, 0.25449, 0.47378, 0.1654, 0.32005, 0.18443]
Predicted label: 0
Correct prediction
Energy consumption = 192.690554 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 300 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 300 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 300 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30308, 0.18181, 0.20588, 0.21859, 0.26113, 0.4778, 0.67671, 0.09558, 0.4759, 0.091593]
Predicted label: 6
Correct prediction
Energy consumption = 195.048225 pJ
sum error= 125
Actual label: 9
Output voltages: [0.37591, 0.21494, 0.29218, 0.22336, 0.26278, 0.094611, 0.21299, 0.13079, 0.42946, 0.62985]
Predicted label: 9
Correct prediction
Energy consumption = 200.520813 pJ
sum error= 125
Actual label: 8
Output voltages: [0.18617, 0.27533, 0.27898, 0.29942, 0.12801, 0.11915, 0.23492, 0.11811, 0.72906, 0.34013]
Predicted label: 8
Correct prediction
Energy consumption = 198.768333 pJ
sum error= 125
Actual label: 1
Output voltages: [0.24231, 0.7618, 0.18685, 0.28368, 0.24318, 0.16329, 0.23659, 0.19295, 0.32178, 0.35475]
Predicted label: 1
Correct prediction
Energy consumption = 213.888088 pJ
sum error= 125
Actual label: 2
Output voltages: [0.26524, 0.24189, 0.69079, 0.28494, 0.24157, 0.034747, 0.23199, 0.24955, 0.48755, 0.13982]
Predicted label: 2
Correct prediction
Energy consumption = 196.420407 pJ
sum error= 125
Actual label: 9
Output voltages: [0.18809, 0.4189, 0.18238, 0.30031, 0.17358, 0.33825, 0.28504, 0.042495, 0.58336, 0.44037]
Predicted label: 8
Wrong prediction!
Energy consumption = 213.871768 pJ
sum error= 126
Actual label: 9
Output voltages: [0.37793, 0.11352, 0.21836, 0.30678, 0.34806, 0.18047, 0.1316, 0.2871, 0.32882, 0.66574]
Predicted label: 9
Correct prediction
Energy consumption = 199.085188 pJ
sum error= 126
Actual label: 5
Output voltages: [0.20873, 0.052171, 0.13224, 0.24673, 0.17121, 0.64431, 0.279, 0.084561, 0.59456, 0.17444]
Predicted label: 5
Correct prediction
Energy consumption = 187.433598 pJ
sum error= 126
Actual label: 9
Output voltages: [0.34703, 0.11345, 0.20243, 0.25955, 0.2807, 0.20433, 0.086187, 0.24446, 0.4203, 0.66545]
Predicted label: 9
Correct prediction
Energy consumption = 188.390999 pJ
sum error= 126
Actual label: 7
Output voltages: [0.29344, 0.36213, 0.36243, 0.23871, 0.10794, 0.05385, 0.042464, 0.73, 0.33201, 0.36448]
Predicted label: 7
Correct prediction
Energy consumption = 189.770512 pJ
sum error= 126
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 301 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 301 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 301 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.24091, 0.17689, 0.30477, 0.75092, 0.16026, 0.24112, 0.09756, 0.22975, 0.47123, 0.23457]
Predicted label: 3
Correct prediction
Energy consumption = 183.503853 pJ
sum error= 126
Actual label: 7
Output voltages: [0.42701, 0.24224, 0.058322, 0.29533, 0.2442, 0.42151, 0.064802, 0.72648, 0.24003, 0.37989]
Predicted label: 7
Correct prediction
Energy consumption = 194.614275 pJ
sum error= 126
Actual label: 8
Output voltages: [0.19254, 0.24075, 0.22769, 0.23942, 0.27366, 0.10358, 0.14101, 0.11096, 0.60172, 0.46362]
Predicted label: 8
Correct prediction
Energy consumption = 198.021866 pJ
sum error= 126
Actual label: 0
Output voltages: [0.69831, 0.21388, 0.19458, 0.26493, 0.09387, 0.30251, 0.36923, 0.092707, 0.34808, 0.3071]
Predicted label: 0
Correct prediction
Energy consumption = 191.745538 pJ
sum error= 126
Actual label: 1
Output voltages: [0.17754, 0.75127, 0.11683, 0.23031, 0.20957, 0.30058, 0.47537, 0.16064, 0.29776, 0.14505]
Predicted label: 1
Correct prediction
Energy consumption = 208.077559 pJ
sum error= 126
Actual label: 3
Output voltages: [0.23044, 0.20516, 0.33225, 0.72747, 0.13858, 0.19251, 0.1131, 0.14901, 0.52371, 0.28771]
Predicted label: 3
Correct prediction
Energy consumption = 186.819137 pJ
sum error= 126
Actual label: 0
Output voltages: [0.74206, 0.19525, 0.18861, 0.1769, 0.19096, 0.2516, 0.40034, 0.21718, 0.3057, 0.2494]
Predicted label: 0
Correct prediction
Energy consumption = 189.734939 pJ
sum error= 126
Actual label: 4
Output voltages: [0.14414, 0.16237, 0.29114, 0.21754, 0.74023, 0.054222, 0.16999, 0.27256, 0.26918, 0.25653]
Predicted label: 4
Correct prediction
Energy consumption = 194.451230 pJ
sum error= 126
Actual label: 6
Output voltages: [0.33115, 0.2297, 0.25381, 0.14559, 0.32745, 0.31936, 0.74361, 0.10642, 0.43719, 0.11751]
Predicted label: 6
Correct prediction
Energy consumption = 189.099155 pJ
sum error= 126
Actual label: 1
Output voltages: [0.11013, 0.75668, 0.21574, 0.16657, 0.27918, 0.14189, 0.39191, 0.13757, 0.38051, 0.23125]
Predicted label: 1
Correct prediction
Energy consumption = 207.196940 pJ
sum error= 126
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 302 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 302 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 302 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.68029, 0.25143, 0.26679, 0.15243, 0.10937, 0.28986, 0.38216, 0.11206, 0.30029, 0.27141]
Predicted label: 0
Correct prediction
Energy consumption = 202.615556 pJ
sum error= 126
Actual label: 2
Output voltages: [0.42558, 0.23074, 0.68467, 0.33933, 0.11881, 0.026489, 0.23465, 0.40503, 0.39179, 0.14665]
Predicted label: 2
Correct prediction
Energy consumption = 193.011938 pJ
sum error= 126
Actual label: 5
Output voltages: [0.25517, 0.056021, 0.054841, 0.35773, 0.31957, 0.69833, 0.27482, 0.15254, 0.51764, 0.24725]
Predicted label: 5
Correct prediction
Energy consumption = 190.724727 pJ
sum error= 126
Actual label: 8
Output voltages: [0.25741, 0.069289, 0.32639, 0.21038, 0.1494, 0.478, 0.38329, 0.085561, 0.61889, 0.18164]
Predicted label: 8
Correct prediction
Energy consumption = 194.458932 pJ
sum error= 126
Actual label: 4
Output voltages: [0.19487, 0.14316, 0.28427, 0.062349, 0.72896, 0.14007, 0.27759, 0.21035, 0.32957, 0.31814]
Predicted label: 4
Correct prediction
Energy consumption = 191.833792 pJ
sum error= 126
Actual label: 4
Output voltages: [0.17939, 0.15924, 0.34083, 0.14876, 0.75771, 0.12972, 0.2627, 0.23323, 0.23329, 0.32598]
Predicted label: 4
Correct prediction
Energy consumption = 190.006600 pJ
sum error= 126
Actual label: 1
Output voltages: [0.20748, 0.70401, 0.2591, 0.20484, 0.40471, 0.054705, 0.25788, 0.12456, 0.28708, 0.28958]
Predicted label: 1
Correct prediction
Energy consumption = 203.281970 pJ
sum error= 126
Actual label: 1
Output voltages: [0.15524, 0.7653, 0.31793, 0.18686, 0.17077, 0.07317, 0.35662, 0.13439, 0.36979, 0.18082]
Predicted label: 1
Correct prediction
Energy consumption = 196.151858 pJ
sum error= 126
Actual label: 5
Output voltages: [0.32122, 0.043861, 0.082199, 0.33476, 0.19958, 0.66954, 0.33086, 0.21706, 0.53665, 0.17192]
Predicted label: 5
Correct prediction
Energy consumption = 190.340712 pJ
sum error= 126
Actual label: 4
Output voltages: [0.13124, 0.18917, 0.26918, 0.14705, 0.73707, 0.068228, 0.16848, 0.26341, 0.3234, 0.2698]
Predicted label: 4
Correct prediction
Energy consumption = 196.595353 pJ
sum error= 126
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 303 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 303 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 303 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.55156, 0.19424, 0.23871, 0.15266, 0.25674, 0.076848, 0.45332, 0.17359, 0.43545, 0.25188]
Predicted label: 0
Wrong prediction!
Energy consumption = 210.014205 pJ
sum error= 127
Actual label: 6
Output voltages: [0.24105, 0.24011, 0.40593, 0.055369, 0.30537, 0.29023, 0.7492, 0.085556, 0.34804, 0.14968]
Predicted label: 6
Correct prediction
Energy consumption = 187.277930 pJ
sum error= 127
Actual label: 0
Output voltages: [0.73321, 0.20681, 0.31672, 0.23657, 0.17179, 0.15475, 0.28572, 0.17513, 0.42608, 0.26716]
Predicted label: 0
Correct prediction
Energy consumption = 197.857990 pJ
sum error= 127
Actual label: 6
Output voltages: [0.35797, 0.25643, 0.29794, 0.11681, 0.3057, 0.25131, 0.70135, 0.080836, 0.39871, 0.19642]
Predicted label: 6
Correct prediction
Energy consumption = 198.169909 pJ
sum error= 127
Actual label: 9
Output voltages: [0.35652, 0.15226, 0.22879, 0.29109, 0.28347, 0.23587, 0.16979, 0.25759, 0.32047, 0.71462]
Predicted label: 9
Correct prediction
Energy consumption = 197.797284 pJ
sum error= 127
Actual label: 2
Output voltages: [0.23954, 0.16028, 0.74571, 0.29823, 0.29944, 0.042114, 0.18227, 0.25855, 0.37344, 0.20904]
Predicted label: 2
Correct prediction
Energy consumption = 188.071611 pJ
sum error= 127
Actual label: 6
Output voltages: [0.29333, 0.26335, 0.32359, 0.071359, 0.34945, 0.30156, 0.74517, 0.06172, 0.37969, 0.11796]
Predicted label: 6
Correct prediction
Energy consumption = 190.443716 pJ
sum error= 127
Actual label: 2
Output voltages: [0.46215, 0.1712, 0.72259, 0.38739, 0.1538, 0.046679, 0.29361, 0.30678, 0.32831, 0.15826]
Predicted label: 2
Correct prediction
Energy consumption = 185.794378 pJ
sum error= 127
Actual label: 7
Output voltages: [0.39538, 0.24536, 0.065259, 0.17844, 0.26957, 0.18034, 0.064353, 0.73302, 0.34711, 0.35797]
Predicted label: 7
Correct prediction
Energy consumption = 205.794506 pJ
sum error= 127
Actual label: 1
Output voltages: [0.09229, 0.73859, 0.28312, 0.50837, 0.18161, 0.19978, 0.21826, 0.1926, 0.21892, 0.35527]
Predicted label: 1
Correct prediction
Energy consumption = 211.571440 pJ
sum error= 127
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 304 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 304 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 304 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35199, 0.2639, 0.38216, 0.23128, 0.14085, 0.036152, 0.047227, 0.68094, 0.31785, 0.33689]
Predicted label: 7
Correct prediction
Energy consumption = 203.280844 pJ
sum error= 127
Actual label: 9
Output voltages: [0.34064, 0.12834, 0.2356, 0.30971, 0.28562, 0.19635, 0.085809, 0.30962, 0.37365, 0.67382]
Predicted label: 9
Correct prediction
Energy consumption = 191.288297 pJ
sum error= 127
Actual label: 4
Output voltages: [0.13134, 0.17624, 0.25664, 0.11591, 0.74401, 0.10853, 0.41096, 0.27881, 0.22484, 0.15837]
Predicted label: 4
Correct prediction
Energy consumption = 193.574892 pJ
sum error= 127
Actual label: 0
Output voltages: [0.71567, 0.23041, 0.31395, 0.161, 0.12926, 0.21483, 0.37724, 0.14359, 0.31013, 0.30111]
Predicted label: 0
Correct prediction
Energy consumption = 194.768073 pJ
sum error= 127
Actual label: 0
Output voltages: [0.74189, 0.22767, 0.19937, 0.2183, 0.17805, 0.18439, 0.34693, 0.1891, 0.28664, 0.37987]
Predicted label: 0
Correct prediction
Energy consumption = 193.942827 pJ
sum error= 127
Actual label: 3
Output voltages: [0.33941, 0.20105, 0.28103, 0.75581, 0.18273, 0.15923, 0.21186, 0.15262, 0.42255, 0.20697]
Predicted label: 3
Correct prediction
Energy consumption = 192.393233 pJ
sum error= 127
Actual label: 8
Output voltages: [0.23605, 0.19253, 0.2725, 0.28065, 0.16101, 0.22074, 0.21331, 0.1369, 0.73514, 0.33507]
Predicted label: 8
Correct prediction
Energy consumption = 188.360146 pJ
sum error= 127
Actual label: 2
Output voltages: [0.36815, 0.34835, 0.64684, 0.48672, 0.13457, 0.028352, 0.28034, 0.14842, 0.35866, 0.18991]
Predicted label: 2
Correct prediction
Energy consumption = 188.221275 pJ
sum error= 127
Actual label: 2
Output voltages: [0.40629, 0.13839, 0.71902, 0.36297, 0.17523, 0.038822, 0.2205, 0.26269, 0.45452, 0.20463]
Predicted label: 2
Correct prediction
Energy consumption = 180.431694 pJ
sum error= 127
Actual label: 3
Output voltages: [0.38595, 0.14176, 0.23817, 0.75212, 0.1866, 0.33273, 0.16082, 0.16464, 0.44278, 0.22203]
Predicted label: 3
Correct prediction
Energy consumption = 185.052630 pJ
sum error= 127
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 305 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 305 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 305 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23407, 0.75866, 0.26321, 0.25491, 0.29254, 0.079544, 0.36348, 0.12527, 0.31834, 0.21555]
Predicted label: 1
Correct prediction
Energy consumption = 210.145735 pJ
sum error= 127
Actual label: 6
Output voltages: [0.32323, 0.19709, 0.24667, 0.18859, 0.29729, 0.35592, 0.72002, 0.11275, 0.48888, 0.10739]
Predicted label: 6
Correct prediction
Energy consumption = 189.999210 pJ
sum error= 127
Actual label: 0
Output voltages: [0.71926, 0.25165, 0.21354, 0.18749, 0.17848, 0.15101, 0.46084, 0.15615, 0.26734, 0.28322]
Predicted label: 0
Correct prediction
Energy consumption = 193.932724 pJ
sum error= 127
Actual label: 5
Output voltages: [0.16524, 0.048244, 0.12482, 0.32285, 0.27229, 0.69505, 0.28796, 0.17336, 0.54393, 0.28616]
Predicted label: 5
Correct prediction
Energy consumption = 182.646612 pJ
sum error= 127
Actual label: 7
Output voltages: [0.37666, 0.2909, 0.35817, 0.1748, 0.22832, 0.050286, 0.055995, 0.7404, 0.22815, 0.30878]
Predicted label: 7
Correct prediction
Energy consumption = 202.576703 pJ
sum error= 127
Actual label: 7
Output voltages: [0.27915, 0.3655, 0.25789, 0.34122, 0.05304, 0.22304, 0.052357, 0.5882, 0.61432, 0.27286]
Predicted label: 8
Wrong prediction!
Energy consumption = 190.990229 pJ
sum error= 128
Actual label: 9
Output voltages: [0.32692, 0.10993, 0.21321, 0.28891, 0.25933, 0.19799, 0.096879, 0.34093, 0.39355, 0.66108]
Predicted label: 9
Correct prediction
Energy consumption = 190.880868 pJ
sum error= 128
Actual label: 2
Output voltages: [0.42181, 0.089967, 0.73964, 0.37619, 0.178, 0.059195, 0.26085, 0.26602, 0.44351, 0.16205]
Predicted label: 2
Correct prediction
Energy consumption = 180.248952 pJ
sum error= 128
Actual label: 6
Output voltages: [0.4416, 0.23025, 0.23418, 0.10276, 0.31997, 0.38945, 0.73278, 0.17232, 0.30433, 0.18736]
Predicted label: 6
Correct prediction
Energy consumption = 189.698309 pJ
sum error= 128
Actual label: 7
Output voltages: [0.26227, 0.33764, 0.22188, 0.13049, 0.18673, 0.068259, 0.062822, 0.58167, 0.31833, 0.38458]
Predicted label: 7
Correct prediction
Energy consumption = 206.370503 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 306 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 306 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 306 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39482, 0.4064, 0.27073, 0.28909, 0.18765, 0.057856, 0.045213, 0.39082, 0.23846, 0.51374]
Predicted label: 9
Correct prediction
Energy consumption = 204.367974 pJ
sum error= 128
Actual label: 7
Output voltages: [0.29983, 0.19439, 0.34733, 0.40009, 0.15205, 0.041524, 0.05258, 0.73133, 0.27381, 0.3397]
Predicted label: 7
Correct prediction
Energy consumption = 184.405340 pJ
sum error= 128
Actual label: 8
Output voltages: [0.42864, 0.18136, 0.35633, 0.56423, 0.039595, 0.25634, 0.2988, 0.14964, 0.57337, 0.060258]
Predicted label: 8
Correct prediction
Energy consumption = 193.464720 pJ
sum error= 128
Actual label: 6
Output voltages: [0.33597, 0.21766, 0.17947, 0.21516, 0.277, 0.41619, 0.71397, 0.12412, 0.48165, 0.14391]
Predicted label: 6
Correct prediction
Energy consumption = 190.668800 pJ
sum error= 128
Actual label: 8
Output voltages: [0.18941, 0.17942, 0.24881, 0.30532, 0.13205, 0.28831, 0.30055, 0.12336, 0.73717, 0.22336]
Predicted label: 8
Correct prediction
Energy consumption = 195.740351 pJ
sum error= 128
Actual label: 8
Output voltages: [0.21635, 0.25711, 0.22139, 0.34429, 0.17879, 0.22258, 0.24754, 0.049889, 0.67172, 0.35029]
Predicted label: 8
Correct prediction
Energy consumption = 199.492742 pJ
sum error= 128
Actual label: 4
Output voltages: [0.17035, 0.18829, 0.2259, 0.1532, 0.731, 0.10002, 0.24761, 0.23438, 0.2371, 0.25617]
Predicted label: 4
Correct prediction
Energy consumption = 200.157166 pJ
sum error= 128
Actual label: 6
Output voltages: [0.27905, 0.20374, 0.28677, 0.12079, 0.3221, 0.42066, 0.72995, 0.073095, 0.44859, 0.17008]
Predicted label: 6
Correct prediction
Energy consumption = 185.007084 pJ
sum error= 128
Actual label: 8
Output voltages: [0.2519, 0.19165, 0.33941, 0.44917, 0.068175, 0.18349, 0.054106, 0.33215, 0.70908, 0.25836]
Predicted label: 8
Correct prediction
Energy consumption = 197.595490 pJ
sum error= 128
Actual label: 4
Output voltages: [0.36392, 0.057199, 0.38498, 0.058948, 0.58917, 0.15095, 0.37178, 0.091134, 0.29702, 0.38098]
Predicted label: 4
Correct prediction
Energy consumption = 203.519430 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 307 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 307 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 307 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16097, 0.75752, 0.36348, 0.32873, 0.22651, 0.060403, 0.34212, 0.19259, 0.26556, 0.21236]
Predicted label: 1
Correct prediction
Energy consumption = 214.388918 pJ
sum error= 128
Actual label: 2
Output voltages: [0.38985, 0.14145, 0.74936, 0.32123, 0.21476, 0.047779, 0.25601, 0.31168, 0.41552, 0.15672]
Predicted label: 2
Correct prediction
Energy consumption = 185.210729 pJ
sum error= 128
Actual label: 8
Output voltages: [0.25338, 0.28165, 0.32567, 0.34415, 0.10991, 0.19757, 0.1841, 0.2271, 0.7507, 0.25911]
Predicted label: 8
Correct prediction
Energy consumption = 190.801674 pJ
sum error= 128
Actual label: 1
Output voltages: [0.22536, 0.54991, 0.51122, 0.47948, 0.17341, 0.049986, 0.2524, 0.25848, 0.29596, 0.097031]
Predicted label: 1
Correct prediction
Energy consumption = 192.262580 pJ
sum error= 128
Actual label: 3
Output voltages: [0.29657, 0.16342, 0.34239, 0.7548, 0.1937, 0.17045, 0.11964, 0.20282, 0.44791, 0.25776]
Predicted label: 3
Correct prediction
Energy consumption = 173.064136 pJ
sum error= 128
Actual label: 9
Output voltages: [0.40018, 0.071744, 0.17747, 0.22345, 0.3072, 0.25675, 0.086491, 0.27284, 0.39321, 0.67025]
Predicted label: 9
Correct prediction
Energy consumption = 191.321825 pJ
sum error= 128
Actual label: 4
Output voltages: [0.14912, 0.15699, 0.26681, 0.14418, 0.75627, 0.10422, 0.27416, 0.26256, 0.29835, 0.20885]
Predicted label: 4
Correct prediction
Energy consumption = 185.498505 pJ
sum error= 128
Actual label: 0
Output voltages: [0.68631, 0.24821, 0.26114, 0.20877, 0.13854, 0.14729, 0.4325, 0.15214, 0.31266, 0.32938]
Predicted label: 0
Correct prediction
Energy consumption = 194.379810 pJ
sum error= 128
Actual label: 3
Output voltages: [0.2565, 0.23534, 0.32959, 0.75606, 0.16649, 0.17716, 0.20047, 0.24376, 0.39494, 0.21002]
Predicted label: 3
Correct prediction
Energy consumption = 199.093522 pJ
sum error= 128
Actual label: 7
Output voltages: [0.29703, 0.21445, 0.25651, 0.26127, 0.11976, 0.095127, 0.044265, 0.75628, 0.40691, 0.34638]
Predicted label: 7
Correct prediction
Energy consumption = 193.726001 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 308 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 308 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 308 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32116, 0.18752, 0.32696, 0.75222, 0.19147, 0.13687, 0.13526, 0.16481, 0.51033, 0.26818]
Predicted label: 3
Correct prediction
Energy consumption = 180.743353 pJ
sum error= 128
Actual label: 2
Output voltages: [0.30339, 0.34612, 0.73442, 0.35835, 0.12241, 0.031799, 0.28777, 0.21854, 0.37508, 0.18286]
Predicted label: 2
Correct prediction
Energy consumption = 178.082049 pJ
sum error= 128
Actual label: 3
Output voltages: [0.41309, 0.12718, 0.34528, 0.75249, 0.21593, 0.20725, 0.10005, 0.18697, 0.41146, 0.24963]
Predicted label: 3
Correct prediction
Energy consumption = 186.671720 pJ
sum error= 128
Actual label: 3
Output voltages: [0.29292, 0.22226, 0.22827, 0.74968, 0.23083, 0.28183, 0.26529, 0.21811, 0.37884, 0.15375]
Predicted label: 3
Correct prediction
Energy consumption = 182.518587 pJ
sum error= 128
Actual label: 7
Output voltages: [0.34104, 0.24801, 0.17987, 0.22143, 0.20545, 0.15371, 0.053097, 0.7131, 0.2988, 0.45099]
Predicted label: 7
Correct prediction
Energy consumption = 200.870401 pJ
sum error= 128
Actual label: 3
Output voltages: [0.2554, 0.17959, 0.37679, 0.74213, 0.1665, 0.17656, 0.14319, 0.13449, 0.46402, 0.25946]
Predicted label: 3
Correct prediction
Energy consumption = 192.460777 pJ
sum error= 128
Actual label: 4
Output voltages: [0.084287, 0.16304, 0.24833, 0.12995, 0.6663, 0.098824, 0.15905, 0.22026, 0.41774, 0.27496]
Predicted label: 4
Correct prediction
Energy consumption = 200.057183 pJ
sum error= 128
Actual label: 0
Output voltages: [0.71707, 0.20713, 0.20874, 0.22032, 0.18069, 0.16299, 0.43202, 0.20877, 0.31487, 0.3316]
Predicted label: 0
Correct prediction
Energy consumption = 201.793483 pJ
sum error= 128
Actual label: 6
Output voltages: [0.2845, 0.20806, 0.28001, 0.15252, 0.24225, 0.39698, 0.73689, 0.090459, 0.41452, 0.15084]
Predicted label: 6
Correct prediction
Energy consumption = 191.288306 pJ
sum error= 128
Actual label: 2
Output voltages: [0.38886, 0.33634, 0.70493, 0.33243, 0.086174, 0.028535, 0.30463, 0.21262, 0.39371, 0.20649]
Predicted label: 2
Correct prediction
Energy consumption = 188.322004 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 309 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 309 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 309 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73113, 0.2039, 0.27951, 0.17233, 0.23265, 0.15102, 0.42554, 0.17843, 0.31467, 0.34661]
Predicted label: 0
Correct prediction
Energy consumption = 203.863957 pJ
sum error= 128
Actual label: 8
Output voltages: [0.38222, 0.13917, 0.31397, 0.34427, 0.15831, 0.18594, 0.2218, 0.05851, 0.67562, 0.33057]
Predicted label: 8
Correct prediction
Energy consumption = 197.621846 pJ
sum error= 128
Actual label: 1
Output voltages: [0.26152, 0.73016, 0.3099, 0.20143, 0.38318, 0.055878, 0.27986, 0.17195, 0.2778, 0.28319]
Predicted label: 1
Correct prediction
Energy consumption = 215.086312 pJ
sum error= 128
Actual label: 5
Output voltages: [0.24448, 0.050736, 0.14542, 0.3751, 0.18442, 0.65187, 0.36646, 0.16432, 0.4984, 0.26148]
Predicted label: 5
Correct prediction
Energy consumption = 193.108324 pJ
sum error= 128
Actual label: 3
Output voltages: [0.34987, 0.22589, 0.26945, 0.76369, 0.12333, 0.21593, 0.15294, 0.22384, 0.38249, 0.248]
Predicted label: 3
Correct prediction
Energy consumption = 185.711686 pJ
sum error= 128
Actual label: 5
Output voltages: [0.29751, 0.10923, 0.12726, 0.34539, 0.21181, 0.73271, 0.41554, 0.1274, 0.44408, 0.1875]
Predicted label: 5
Correct prediction
Energy consumption = 189.067291 pJ
sum error= 128
Actual label: 4
Output voltages: [0.21272, 0.13957, 0.29008, 0.10946, 0.73197, 0.063474, 0.33111, 0.27665, 0.32823, 0.13123]
Predicted label: 4
Correct prediction
Energy consumption = 193.075212 pJ
sum error= 128
Actual label: 1
Output voltages: [0.24093, 0.72705, 0.14344, 0.1694, 0.42498, 0.087427, 0.27016, 0.1858, 0.27523, 0.29832]
Predicted label: 1
Correct prediction
Energy consumption = 201.830422 pJ
sum error= 128
Actual label: 7
Output voltages: [0.3397, 0.26871, 0.14784, 0.19787, 0.17216, 0.10367, 0.064379, 0.74813, 0.34924, 0.36616]
Predicted label: 7
Correct prediction
Energy consumption = 199.654714 pJ
sum error= 128
Actual label: 1
Output voltages: [0.20378, 0.72971, 0.31571, 0.13961, 0.27031, 0.098639, 0.38635, 0.16882, 0.39028, 0.18544]
Predicted label: 1
Correct prediction
Energy consumption = 197.284708 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 310 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 310 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 310 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.21606, 0.083569, 0.19722, 0.58278, 0.092051, 0.53193, 0.24488, 0.22669, 0.51647, 0.2074]
Predicted label: 3
Wrong prediction!
Energy consumption = 194.414057 pJ
sum error= 129
Actual label: 7
Output voltages: [0.36305, 0.15513, 0.176, 0.28598, 0.23501, 0.22762, 0.037184, 0.75857, 0.34339, 0.37215]
Predicted label: 7
Correct prediction
Energy consumption = 195.605528 pJ
sum error= 129
Actual label: 5
Output voltages: [0.20767, 0.14346, 0.087732, 0.47838, 0.20012, 0.69364, 0.23743, 0.25462, 0.35767, 0.29285]
Predicted label: 5
Correct prediction
Energy consumption = 196.842873 pJ
sum error= 129
Actual label: 7
Output voltages: [0.28772, 0.33954, 0.3062, 0.21226, 0.17673, 0.049258, 0.048902, 0.71717, 0.25514, 0.39252]
Predicted label: 7
Correct prediction
Energy consumption = 199.321149 pJ
sum error= 129
Actual label: 3
Output voltages: [0.33101, 0.22916, 0.3026, 0.75936, 0.20172, 0.14339, 0.17406, 0.18334, 0.43654, 0.21146]
Predicted label: 3
Correct prediction
Energy consumption = 193.832748 pJ
sum error= 129
Actual label: 2
Output voltages: [0.43509, 0.15084, 0.70899, 0.43162, 0.17863, 0.050378, 0.26009, 0.22937, 0.44605, 0.17097]
Predicted label: 2
Correct prediction
Energy consumption = 185.299193 pJ
sum error= 129
Actual label: 2
Output voltages: [0.46711, 0.21787, 0.55168, 0.35579, 0.15543, 0.053029, 0.3843, 0.10904, 0.47203, 0.13323]
Predicted label: 2
Correct prediction
Energy consumption = 193.501255 pJ
sum error= 129
Actual label: 7
Output voltages: [0.36138, 0.12526, 0.091097, 0.21295, 0.21968, 0.28879, 0.055926, 0.73343, 0.40643, 0.35748]
Predicted label: 7
Correct prediction
Energy consumption = 201.285982 pJ
sum error= 129
Actual label: 3
Output voltages: [0.30283, 0.18619, 0.25791, 0.71107, 0.11954, 0.34972, 0.14807, 0.14082, 0.4732, 0.24815]
Predicted label: 3
Correct prediction
Energy consumption = 189.976270 pJ
sum error= 129
Actual label: 7
Output voltages: [0.29048, 0.50742, 0.35794, 0.47518, 0.086083, 0.037409, 0.11287, 0.53641, 0.22909, 0.36373]
Predicted label: 7
Correct prediction
Energy consumption = 201.531643 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 311 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 311 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 311 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.41685, 0.15012, 0.28051, 0.73763, 0.11105, 0.31457, 0.24605, 0.27695, 0.35928, 0.081207]
Predicted label: 3
Correct prediction
Energy consumption = 193.136882 pJ
sum error= 129
Actual label: 7
Output voltages: [0.34277, 0.30342, 0.28533, 0.21925, 0.2526, 0.089028, 0.057048, 0.73719, 0.15559, 0.39145]
Predicted label: 7
Correct prediction
Energy consumption = 195.237548 pJ
sum error= 129
Actual label: 8
Output voltages: [0.35109, 0.063383, 0.40495, 0.35597, 0.17575, 0.23213, 0.21465, 0.11657, 0.71303, 0.28768]
Predicted label: 8
Correct prediction
Energy consumption = 203.531410 pJ
sum error= 129
Actual label: 5
Output voltages: [0.22403, 0.053972, 0.090959, 0.34553, 0.25953, 0.71082, 0.27603, 0.19496, 0.52603, 0.25279]
Predicted label: 5
Correct prediction
Energy consumption = 183.425328 pJ
sum error= 129
Actual label: 4
Output voltages: [0.21557, 0.1946, 0.36875, 0.19912, 0.71249, 0.087335, 0.4479, 0.26835, 0.094099, 0.19906]
Predicted label: 4
Correct prediction
Energy consumption = 206.943747 pJ
sum error= 129
Actual label: 5
Output voltages: [0.26307, 0.050994, 0.070586, 0.25787, 0.25965, 0.72414, 0.14669, 0.34423, 0.42412, 0.27144]
Predicted label: 5
Correct prediction
Energy consumption = 197.897023 pJ
sum error= 129
Actual label: 2
Output voltages: [0.36957, 0.28872, 0.74933, 0.33491, 0.18337, 0.03428, 0.31383, 0.23749, 0.39256, 0.20987]
Predicted label: 2
Correct prediction
Energy consumption = 185.591409 pJ
sum error= 129
Actual label: 5
Output voltages: [0.24745, 0.068003, 0.041324, 0.36803, 0.42215, 0.47912, 0.25411, 0.089544, 0.3207, 0.37344]
Predicted label: 5
Correct prediction
Energy consumption = 195.949454 pJ
sum error= 129
Actual label: 6
Output voltages: [0.36304, 0.22159, 0.21876, 0.18082, 0.29801, 0.46548, 0.73755, 0.098524, 0.38701, 0.1399]
Predicted label: 6
Correct prediction
Energy consumption = 189.583112 pJ
sum error= 129
Actual label: 5
Output voltages: [0.22331, 0.068567, 0.1484, 0.35292, 0.21178, 0.65162, 0.19656, 0.1562, 0.562, 0.3138]
Predicted label: 5
Correct prediction
Energy consumption = 179.694113 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 312 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 312 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 312 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.40216, 0.20912, 0.39189, 0.74847, 0.11241, 0.16439, 0.17773, 0.12107, 0.41, 0.13825]
Predicted label: 3
Correct prediction
Energy consumption = 188.097951 pJ
sum error= 129
Actual label: 6
Output voltages: [0.3784, 0.20806, 0.3523, 0.066626, 0.39464, 0.18885, 0.70746, 0.21361, 0.2857, 0.089658]
Predicted label: 6
Correct prediction
Energy consumption = 197.062076 pJ
sum error= 129
Actual label: 7
Output voltages: [0.29769, 0.12814, 0.45236, 0.30277, 0.19995, 0.039836, 0.11821, 0.74038, 0.2843, 0.24032]
Predicted label: 7
Correct prediction
Energy consumption = 187.896294 pJ
sum error= 129
Actual label: 4
Output voltages: [0.15242, 0.21304, 0.25182, 0.11676, 0.74678, 0.072435, 0.26572, 0.24216, 0.24763, 0.31937]
Predicted label: 4
Correct prediction
Energy consumption = 204.906563 pJ
sum error= 129
Actual label: 1
Output voltages: [0.20792, 0.71725, 0.2249, 0.21784, 0.30267, 0.091038, 0.32903, 0.15724, 0.28298, 0.25959]
Predicted label: 1
Correct prediction
Energy consumption = 211.839725 pJ
sum error= 129
Actual label: 7
Output voltages: [0.3001, 0.27722, 0.36716, 0.30328, 0.13876, 0.092509, 0.0382, 0.75231, 0.33418, 0.36091]
Predicted label: 7
Correct prediction
Energy consumption = 194.226634 pJ
sum error= 129
Actual label: 1
Output voltages: [0.25961, 0.76124, 0.26642, 0.26939, 0.28562, 0.097071, 0.34612, 0.14729, 0.31989, 0.22567]
Predicted label: 1
Correct prediction
Energy consumption = 212.142391 pJ
sum error= 129
Actual label: 5
Output voltages: [0.26223, 0.045627, 0.084944, 0.35644, 0.25497, 0.73231, 0.22345, 0.24096, 0.45762, 0.31531]
Predicted label: 5
Correct prediction
Energy consumption = 193.655424 pJ
sum error= 129
Actual label: 2
Output voltages: [0.37165, 0.33949, 0.72472, 0.41079, 0.13436, 0.034392, 0.2995, 0.1319, 0.38429, 0.21197]
Predicted label: 2
Correct prediction
Energy consumption = 191.423942 pJ
sum error= 129
Actual label: 3
Output voltages: [0.346, 0.15581, 0.46017, 0.68467, 0.098987, 0.050258, 0.22741, 0.1311, 0.47714, 0.20311]
Predicted label: 3
Correct prediction
Energy consumption = 183.163633 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 313 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 313 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 313 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.53648, 0.26332, 0.13343, 0.20506, 0.13825, 0.43912, 0.60398, 0.19062, 0.35129, 0.11523]
Predicted label: 6
Correct prediction
Energy consumption = 197.212351 pJ
sum error= 129
Actual label: 3
Output voltages: [0.26982, 0.10427, 0.25547, 0.74467, 0.28544, 0.3227, 0.25339, 0.11763, 0.41925, 0.20951]
Predicted label: 3
Correct prediction
Energy consumption = 191.517897 pJ
sum error= 129
Actual label: 1
Output voltages: [0.28099, 0.53214, 0.53261, 0.39424, 0.077901, 0.056143, 0.32395, 0.19007, 0.35325, 0.095505]
Predicted label: 2
Wrong prediction!
Energy consumption = 189.943279 pJ
sum error= 130
Actual label: 4
Output voltages: [0.095193, 0.17111, 0.16852, 0.13864, 0.65989, 0.18829, 0.28695, 0.27418, 0.39542, 0.28891]
Predicted label: 4
Correct prediction
Energy consumption = 192.674874 pJ
sum error= 130
Actual label: 2
Output voltages: [0.4282, 0.11108, 0.70899, 0.34374, 0.14668, 0.037723, 0.24957, 0.31301, 0.42881, 0.16199]
Predicted label: 2
Correct prediction
Energy consumption = 191.153377 pJ
sum error= 130
Actual label: 6
Output voltages: [0.30321, 0.2286, 0.2219, 0.17245, 0.33239, 0.45904, 0.73422, 0.057583, 0.34583, 0.13126]
Predicted label: 6
Correct prediction
Energy consumption = 190.997549 pJ
sum error= 130
Actual label: 7
Output voltages: [0.13831, 0.088238, 0.23163, 0.36165, 0.39225, 0.17912, 0.055205, 0.48295, 0.51202, 0.2298]
Predicted label: 8
Wrong prediction!
Energy consumption = 198.375089 pJ
sum error= 131
Actual label: 4
Output voltages: [0.1056, 0.20379, 0.25334, 0.054914, 0.74346, 0.070122, 0.32116, 0.30243, 0.30713, 0.23173]
Predicted label: 4
Correct prediction
Energy consumption = 188.588208 pJ
sum error= 131
Actual label: 3
Output voltages: [0.49859, 0.31214, 0.19657, 0.69523, 0.11771, 0.44293, 0.21784, 0.28747, 0.27227, 0.064069]
Predicted label: 3
Correct prediction
Energy consumption = 199.910449 pJ
sum error= 131
Actual label: 8
Output voltages: [0.25797, 0.17621, 0.32492, 0.3748, 0.12387, 0.22276, 0.28643, 0.075459, 0.73353, 0.18621]
Predicted label: 8
Correct prediction
Energy consumption = 195.435728 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 314 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 314 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 314 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.67044, 0.2577, 0.31873, 0.20447, 0.16427, 0.065217, 0.37771, 0.17764, 0.37843, 0.2488]
Predicted label: 0
Correct prediction
Energy consumption = 203.946556 pJ
sum error= 131
Actual label: 6
Output voltages: [0.34147, 0.22874, 0.24028, 0.17845, 0.27396, 0.40899, 0.73217, 0.075469, 0.42601, 0.22031]
Predicted label: 6
Correct prediction
Energy consumption = 188.852770 pJ
sum error= 131
Actual label: 2
Output voltages: [0.36243, 0.28361, 0.72153, 0.35694, 0.1492, 0.034342, 0.29196, 0.26651, 0.47677, 0.22529]
Predicted label: 2
Correct prediction
Energy consumption = 187.801844 pJ
sum error= 131
Actual label: 1
Output voltages: [0.19001, 0.75928, 0.19049, 0.41007, 0.12963, 0.12946, 0.18875, 0.23729, 0.29293, 0.32776]
Predicted label: 1
Correct prediction
Energy consumption = 211.032098 pJ
sum error= 131
Actual label: 6
Output voltages: [0.28865, 0.16597, 0.32357, 0.076633, 0.30998, 0.30631, 0.72827, 0.057186, 0.41458, 0.15189]
Predicted label: 6
Correct prediction
Energy consumption = 188.231538 pJ
sum error= 131
Actual label: 5
Output voltages: [0.16595, 0.044547, 0.18948, 0.31148, 0.26465, 0.60771, 0.22485, 0.22703, 0.52242, 0.3982]
Predicted label: 5
Correct prediction
Energy consumption = 193.681546 pJ
sum error= 131
Actual label: 3
Output voltages: [0.22388, 0.205, 0.2571, 0.73532, 0.1649, 0.24281, 0.12213, 0.26412, 0.50706, 0.25095]
Predicted label: 3
Correct prediction
Energy consumption = 188.968514 pJ
sum error= 131
Actual label: 9
Output voltages: [0.35271, 0.13002, 0.20884, 0.27989, 0.32839, 0.22653, 0.22501, 0.12276, 0.32278, 0.65675]
Predicted label: 9
Correct prediction
Energy consumption = 192.041119 pJ
sum error= 131
Actual label: 1
Output voltages: [0.20533, 0.77075, 0.24671, 0.18339, 0.27011, 0.11659, 0.39365, 0.11515, 0.28263, 0.26313]
Predicted label: 1
Correct prediction
Energy consumption = 214.872499 pJ
sum error= 131
Actual label: 9
Output voltages: [0.34591, 0.12833, 0.16932, 0.26899, 0.34547, 0.18146, 0.081257, 0.23071, 0.35732, 0.70526]
Predicted label: 9
Correct prediction
Energy consumption = 190.781864 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 315 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 315 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 315 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.20146, 0.20309, 0.25699, 0.74318, 0.16732, 0.25866, 0.11524, 0.19838, 0.48403, 0.22136]
Predicted label: 3
Correct prediction
Energy consumption = 184.824405 pJ
sum error= 131
Actual label: 2
Output voltages: [0.30405, 0.388, 0.66111, 0.3309, 0.14181, 0.024049, 0.29227, 0.17591, 0.40147, 0.22663]
Predicted label: 2
Correct prediction
Energy consumption = 190.668939 pJ
sum error= 131
Actual label: 1
Output voltages: [0.077939, 0.76087, 0.29394, 0.28628, 0.18504, 0.093254, 0.31701, 0.17801, 0.37372, 0.22702]
Predicted label: 1
Correct prediction
Energy consumption = 208.625773 pJ
sum error= 131
Actual label: 8
Output voltages: [0.32547, 0.11054, 0.32617, 0.43329, 0.14831, 0.15049, 0.16854, 0.13538, 0.6562, 0.31612]
Predicted label: 8
Correct prediction
Energy consumption = 206.290247 pJ
sum error= 131
Actual label: 4
Output voltages: [0.32357, 0.18799, 0.24599, 0.086057, 0.72921, 0.08788, 0.39438, 0.25309, 0.16353, 0.31749]
Predicted label: 4
Correct prediction
Energy consumption = 201.343342 pJ
sum error= 131
Actual label: 4
Output voltages: [0.15622, 0.20904, 0.27551, 0.22329, 0.74478, 0.05408, 0.23134, 0.24294, 0.19769, 0.2636]
Predicted label: 4
Correct prediction
Energy consumption = 203.090724 pJ
sum error= 131
Actual label: 6
Output voltages: [0.30887, 0.16998, 0.27735, 0.076767, 0.34865, 0.34083, 0.72915, 0.074847, 0.4208, 0.15465]
Predicted label: 6
Correct prediction
Energy consumption = 185.326820 pJ
sum error= 131
Actual label: 5
Output voltages: [0.40623, 0.19903, 0.048347, 0.45715, 0.17956, 0.69135, 0.16525, 0.34605, 0.36799, 0.12896]
Predicted label: 5
Correct prediction
Energy consumption = 194.525479 pJ
sum error= 131
Actual label: 8
Output voltages: [0.32725, 0.148, 0.37858, 0.34451, 0.1516, 0.11596, 0.23303, 0.087716, 0.70726, 0.32448]
Predicted label: 8
Correct prediction
Energy consumption = 193.618911 pJ
sum error= 131
Actual label: 6
Output voltages: [0.32076, 0.21454, 0.19026, 0.23421, 0.29181, 0.36734, 0.72197, 0.093635, 0.45799, 0.12827]
Predicted label: 6
Correct prediction
Energy consumption = 191.228049 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 316 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 316 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 316 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.22749, 0.15253, 0.081439, 0.28112, 0.44016, 0.35902, 0.33535, 0.15097, 0.28784, 0.52604]
Predicted label: 9
Correct prediction
Energy consumption = 203.082305 pJ
sum error= 131
Actual label: 7
Output voltages: [0.39038, 0.30864, 0.3922, 0.13656, 0.17022, 0.041803, 0.060993, 0.73978, 0.30967, 0.26838]
Predicted label: 7
Correct prediction
Energy consumption = 200.117858 pJ
sum error= 131
Actual label: 7
Output voltages: [0.30601, 0.25849, 0.31177, 0.19561, 0.061445, 0.052407, 0.050462, 0.73331, 0.44795, 0.36767]
Predicted label: 7
Correct prediction
Energy consumption = 196.114908 pJ
sum error= 131
Actual label: 8
Output voltages: [0.18198, 0.1591, 0.24423, 0.30824, 0.18738, 0.21825, 0.23747, 0.11848, 0.73983, 0.27436]
Predicted label: 8
Correct prediction
Energy consumption = 194.101759 pJ
sum error= 131
Actual label: 6
Output voltages: [0.31185, 0.17103, 0.35456, 0.13964, 0.31493, 0.27524, 0.72094, 0.084916, 0.41584, 0.12998]
Predicted label: 6
Correct prediction
Energy consumption = 189.645722 pJ
sum error= 131
Actual label: 9
Output voltages: [0.38012, 0.14812, 0.19895, 0.26262, 0.2626, 0.23411, 0.096103, 0.20367, 0.40905, 0.67481]
Predicted label: 9
Correct prediction
Energy consumption = 193.535146 pJ
sum error= 131
Actual label: 7
Output voltages: [0.27903, 0.26466, 0.54954, 0.3937, 0.18955, 0.035385, 0.15081, 0.46274, 0.50324, 0.27821]
Predicted label: 2
Wrong prediction!
Energy consumption = 193.067734 pJ
sum error= 132
Actual label: 3
Output voltages: [0.28352, 0.40737, 0.33053, 0.7435, 0.17024, 0.20269, 0.17418, 0.30444, 0.32984, 0.13659]
Predicted label: 3
Correct prediction
Energy consumption = 204.420359 pJ
sum error= 132
Actual label: 9
Output voltages: [0.35072, 0.14285, 0.21822, 0.27929, 0.28141, 0.19535, 0.13761, 0.24964, 0.36119, 0.69645]
Predicted label: 9
Correct prediction
Energy consumption = 198.902051 pJ
sum error= 132
Actual label: 4
Output voltages: [0.15321, 0.18568, 0.33916, 0.13755, 0.75242, 0.052191, 0.31942, 0.28216, 0.19547, 0.27554]
Predicted label: 4
Correct prediction
Energy consumption = 189.137273 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 317 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 317 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 317 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74076, 0.22825, 0.24727, 0.14928, 0.09883, 0.29832, 0.32035, 0.13383, 0.33177, 0.30809]
Predicted label: 0
Correct prediction
Energy consumption = 198.974049 pJ
sum error= 132
Actual label: 5
Output voltages: [0.27152, 0.05104, 0.21029, 0.43883, 0.11767, 0.45948, 0.23779, 0.12472, 0.57483, 0.25431]
Predicted label: 8
Wrong prediction!
Energy consumption = 196.924779 pJ
sum error= 133
Actual label: 4
Output voltages: [0.20692, 0.1154, 0.30275, 0.22371, 0.70896, 0.17594, 0.15502, 0.16181, 0.28376, 0.43341]
Predicted label: 4
Correct prediction
Energy consumption = 196.159116 pJ
sum error= 133
Actual label: 6
Output voltages: [0.2949, 0.32368, 0.30096, 0.16386, 0.38278, 0.40785, 0.73478, 0.051369, 0.28864, 0.067824]
Predicted label: 6
Correct prediction
Energy consumption = 191.976644 pJ
sum error= 133
Actual label: 4
Output voltages: [0.13198, 0.11865, 0.32862, 0.1446, 0.76522, 0.096082, 0.3085, 0.29361, 0.22485, 0.24375]
Predicted label: 4
Correct prediction
Energy consumption = 192.895192 pJ
sum error= 133
Actual label: 1
Output voltages: [0.18799, 0.75754, 0.1848, 0.33285, 0.17187, 0.14144, 0.26479, 0.21795, 0.33378, 0.26136]
Predicted label: 1
Correct prediction
Energy consumption = 220.342635 pJ
sum error= 133
Actual label: 2
Output voltages: [0.39745, 0.26653, 0.68376, 0.30945, 0.12841, 0.028352, 0.24177, 0.42976, 0.36419, 0.20849]
Predicted label: 2
Correct prediction
Energy consumption = 193.242452 pJ
sum error= 133
Actual label: 3
Output voltages: [0.35556, 0.25475, 0.30984, 0.76299, 0.20269, 0.1338, 0.14899, 0.26321, 0.40447, 0.21972]
Predicted label: 3
Correct prediction
Energy consumption = 178.852042 pJ
sum error= 133
Actual label: 0
Output voltages: [0.61318, 0.09474, 0.30365, 0.20635, 0.16866, 0.30684, 0.40876, 0.074011, 0.41597, 0.26395]
Predicted label: 0
Correct prediction
Energy consumption = 205.361100 pJ
sum error= 133
Actual label: 0
Output voltages: [0.72949, 0.19696, 0.24737, 0.14272, 0.15831, 0.22879, 0.43017, 0.1599, 0.28387, 0.25343]
Predicted label: 0
Correct prediction
Energy consumption = 188.537148 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 318 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 318 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 318 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.37371, 0.29897, 0.73002, 0.36424, 0.15772, 0.025963, 0.297, 0.17792, 0.38999, 0.21205]
Predicted label: 2
Correct prediction
Energy consumption = 189.332658 pJ
sum error= 133
Actual label: 6
Output voltages: [0.42697, 0.21353, 0.23284, 0.13908, 0.27974, 0.40653, 0.72438, 0.13016, 0.33927, 0.18169]
Predicted label: 6
Correct prediction
Energy consumption = 192.126502 pJ
sum error= 133
Actual label: 6
Output voltages: [0.27096, 0.18665, 0.39523, 0.046182, 0.38836, 0.24772, 0.73476, 0.10831, 0.31535, 0.16568]
Predicted label: 6
Correct prediction
Energy consumption = 184.045030 pJ
sum error= 133
Actual label: 5
Output voltages: [0.28151, 0.070687, 0.048199, 0.40212, 0.19376, 0.70592, 0.41607, 0.16302, 0.51404, 0.20499]
Predicted label: 5
Correct prediction
Energy consumption = 191.087222 pJ
sum error= 133
Actual label: 7
Output voltages: [0.26572, 0.16743, 0.28822, 0.27041, 0.17824, 0.052069, 0.050803, 0.75855, 0.32469, 0.29403]
Predicted label: 7
Correct prediction
Energy consumption = 195.820597 pJ
sum error= 133
Actual label: 0
Output voltages: [0.67724, 0.22134, 0.24012, 0.1786, 0.26671, 0.13231, 0.52882, 0.17199, 0.32402, 0.24493]
Predicted label: 0
Correct prediction
Energy consumption = 204.492792 pJ
sum error= 133
Actual label: 8
Output voltages: [0.27753, 0.20718, 0.35467, 0.31397, 0.20658, 0.04962, 0.2061, 0.11922, 0.66682, 0.36231]
Predicted label: 8
Correct prediction
Energy consumption = 207.305781 pJ
sum error= 133
Actual label: 6
Output voltages: [0.29195, 0.19583, 0.21215, 0.17053, 0.2987, 0.46047, 0.72993, 0.086589, 0.4229, 0.15018]
Predicted label: 6
Correct prediction
Energy consumption = 192.151726 pJ
sum error= 133
Actual label: 4
Output voltages: [0.1461, 0.16009, 0.32273, 0.15227, 0.75903, 0.054026, 0.30536, 0.30376, 0.19617, 0.22526]
Predicted label: 4
Correct prediction
Energy consumption = 186.363599 pJ
sum error= 133
Actual label: 7
Output voltages: [0.24909, 0.184, 0.25608, 0.21528, 0.25743, 0.18002, 0.18971, 0.72214, 0.31389, 0.21105]
Predicted label: 7
Correct prediction
Energy consumption = 191.900953 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 319 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 319 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 319 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39034, 0.17552, 0.23591, 0.37981, 0.36002, 0.21421, 0.15471, 0.22939, 0.25966, 0.72881]
Predicted label: 9
Correct prediction
Energy consumption = 201.079699 pJ
sum error= 133
Actual label: 0
Output voltages: [0.70857, 0.27436, 0.25258, 0.21413, 0.28729, 0.14006, 0.40649, 0.16614, 0.31311, 0.19294]
Predicted label: 0
Correct prediction
Energy consumption = 206.947870 pJ
sum error= 133
Actual label: 7
Output voltages: [0.33649, 0.28395, 0.41205, 0.33181, 0.071579, 0.038745, 0.056429, 0.70678, 0.34903, 0.35693]
Predicted label: 7
Correct prediction
Energy consumption = 204.079061 pJ
sum error= 133
Actual label: 3
Output voltages: [0.32829, 0.19376, 0.38386, 0.73089, 0.1083, 0.15623, 0.099542, 0.12663, 0.5323, 0.19347]
Predicted label: 3
Correct prediction
Energy consumption = 188.544659 pJ
sum error= 133
Actual label: 4
Output voltages: [0.1465, 0.20035, 0.2289, 0.15643, 0.7334, 0.070251, 0.21905, 0.36659, 0.26607, 0.19956]
Predicted label: 4
Correct prediction
Energy consumption = 195.315607 pJ
sum error= 133
Actual label: 2
Output voltages: [0.40782, 0.24063, 0.72453, 0.34584, 0.19945, 0.034698, 0.31564, 0.20525, 0.47564, 0.21224]
Predicted label: 2
Correct prediction
Energy consumption = 188.960457 pJ
sum error= 133
Actual label: 1
Output voltages: [0.14191, 0.74325, 0.17, 0.18082, 0.29172, 0.10343, 0.34629, 0.12681, 0.40835, 0.26906]
Predicted label: 1
Correct prediction
Energy consumption = 203.102206 pJ
sum error= 133
Actual label: 8
Output voltages: [0.22487, 0.27304, 0.33125, 0.18014, 0.25844, 0.17902, 0.21145, 0.15821, 0.74378, 0.26276]
Predicted label: 8
Correct prediction
Energy consumption = 193.518409 pJ
sum error= 133
Actual label: 8
Output voltages: [0.25406, 0.12418, 0.32551, 0.31848, 0.15083, 0.29803, 0.28162, 0.13272, 0.74702, 0.2593]
Predicted label: 8
Correct prediction
Energy consumption = 190.304337 pJ
sum error= 133
Actual label: 5
Output voltages: [0.20161, 0.041299, 0.1049, 0.2464, 0.30969, 0.68206, 0.33955, 0.16615, 0.56135, 0.25254]
Predicted label: 5
Correct prediction
Energy consumption = 179.022160 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 320 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 320 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 320 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33362, 0.13102, 0.19694, 0.32509, 0.30329, 0.26384, 0.19723, 0.28431, 0.29116, 0.67156]
Predicted label: 9
Correct prediction
Energy consumption = 202.503021 pJ
sum error= 133
Actual label: 2
Output voltages: [0.28556, 0.28191, 0.7315, 0.3276, 0.1566, 0.043671, 0.32684, 0.19829, 0.40499, 0.15161]
Predicted label: 2
Correct prediction
Energy consumption = 193.030925 pJ
sum error= 133
Actual label: 7
Output voltages: [0.20181, 0.12917, 0.33174, 0.36213, 0.18658, 0.14088, 0.04635, 0.72614, 0.5879, 0.16634]
Predicted label: 7
Correct prediction
Energy consumption = 187.217255 pJ
sum error= 133
Actual label: 1
Output voltages: [0.19722, 0.76909, 0.24965, 0.24699, 0.23247, 0.092962, 0.31185, 0.15587, 0.31646, 0.2372]
Predicted label: 1
Correct prediction
Energy consumption = 209.128940 pJ
sum error= 133
Actual label: 8
Output voltages: [0.23954, 0.1764, 0.27372, 0.29003, 0.16012, 0.20983, 0.179, 0.11835, 0.70795, 0.40324]
Predicted label: 8
Correct prediction
Energy consumption = 200.233099 pJ
sum error= 133
Actual label: 8
Output voltages: [0.40287, 0.1409, 0.20535, 0.37241, 0.065579, 0.41655, 0.27442, 0.11625, 0.69691, 0.18696]
Predicted label: 8
Correct prediction
Energy consumption = 199.387628 pJ
sum error= 133
Actual label: 8
Output voltages: [0.35801, 0.19481, 0.33166, 0.66874, 0.17632, 0.15638, 0.14163, 0.10682, 0.60562, 0.16534]
Predicted label: 3
Wrong prediction!
Energy consumption = 194.180684 pJ
sum error= 134
Actual label: 2
Output voltages: [0.3637, 0.23542, 0.62709, 0.37285, 0.15784, 0.041363, 0.26702, 0.19278, 0.489, 0.1928]
Predicted label: 2
Correct prediction
Energy consumption = 185.271121 pJ
sum error= 134
Actual label: 7
Output voltages: [0.28649, 0.16125, 0.20689, 0.50755, 0.19348, 0.12311, 0.037891, 0.6709, 0.33382, 0.39074]
Predicted label: 7
Correct prediction
Energy consumption = 189.282086 pJ
sum error= 134
Actual label: 6
Output voltages: [0.34614, 0.19947, 0.20334, 0.22043, 0.28519, 0.42411, 0.7025, 0.079936, 0.45011, 0.20281]
Predicted label: 6
Correct prediction
Energy consumption = 189.875010 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 321 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 321 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 321 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.64272, 0.24564, 0.33411, 0.1847, 0.20324, 0.061745, 0.39713, 0.2118, 0.30853, 0.22143]
Predicted label: 0
Correct prediction
Energy consumption = 205.762786 pJ
sum error= 134
Actual label: 1
Output voltages: [0.21577, 0.687, 0.26366, 0.20886, 0.43649, 0.073291, 0.39881, 0.052089, 0.29616, 0.26577]
Predicted label: 1
Correct prediction
Energy consumption = 203.236879 pJ
sum error= 134
Actual label: 2
Output voltages: [0.2765, 0.15768, 0.75003, 0.27942, 0.17361, 0.036182, 0.24366, 0.34511, 0.444, 0.14559]
Predicted label: 2
Correct prediction
Energy consumption = 187.500895 pJ
sum error= 134
Actual label: 7
Output voltages: [0.30202, 0.37033, 0.39416, 0.2216, 0.23234, 0.023325, 0.047611, 0.61625, 0.26735, 0.33422]
Predicted label: 7
Correct prediction
Energy consumption = 196.040064 pJ
sum error= 134
Actual label: 1
Output voltages: [0.26276, 0.68305, 0.31202, 0.1274, 0.37557, 0.057848, 0.31544, 0.12036, 0.35962, 0.22508]
Predicted label: 1
Correct prediction
Energy consumption = 198.274429 pJ
sum error= 134
Actual label: 0
Output voltages: [0.72294, 0.22298, 0.22363, 0.16153, 0.16349, 0.17728, 0.41234, 0.13551, 0.30352, 0.25351]
Predicted label: 0
Correct prediction
Energy consumption = 195.587905 pJ
sum error= 134
Actual label: 8
Output voltages: [0.2061, 0.25043, 0.24582, 0.46341, 0.097508, 0.24667, 0.13282, 0.18661, 0.72253, 0.26702]
Predicted label: 8
Correct prediction
Energy consumption = 194.566310 pJ
sum error= 134
Actual label: 3
Output voltages: [0.35229, 0.20812, 0.37783, 0.7509, 0.2154, 0.15242, 0.19592, 0.14271, 0.40861, 0.19024]
Predicted label: 3
Correct prediction
Energy consumption = 181.232007 pJ
sum error= 134
Actual label: 6
Output voltages: [0.29896, 0.047022, 0.12353, 0.20004, 0.2906, 0.52979, 0.56328, 0.06688, 0.53404, 0.16922]
Predicted label: 6
Correct prediction
Energy consumption = 186.205644 pJ
sum error= 134
Actual label: 0
Output voltages: [0.67024, 0.23119, 0.22891, 0.13714, 0.28134, 0.14746, 0.51519, 0.16707, 0.27443, 0.19372]
Predicted label: 0
Correct prediction
Energy consumption = 198.097202 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 322 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 322 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 322 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22497, 0.09772, 0.11458, 0.44486, 0.18213, 0.67448, 0.20237, 0.10473, 0.55676, 0.21066]
Predicted label: 5
Correct prediction
Energy consumption = 190.604599 pJ
sum error= 134
Actual label: 3
Output voltages: [0.2858, 0.19829, 0.29611, 0.75106, 0.21452, 0.12659, 0.14728, 0.18291, 0.44567, 0.23668]
Predicted label: 3
Correct prediction
Energy consumption = 184.052704 pJ
sum error= 134
Actual label: 6
Output voltages: [0.21942, 0.10013, 0.31121, 0.26877, 0.23664, 0.3054, 0.6364, 0.067339, 0.49089, 0.28908]
Predicted label: 6
Correct prediction
Energy consumption = 181.850238 pJ
sum error= 134
Actual label: 2
Output voltages: [0.33533, 0.26597, 0.74241, 0.32782, 0.17716, 0.031148, 0.25075, 0.31883, 0.39995, 0.15404]
Predicted label: 2
Correct prediction
Energy consumption = 187.184886 pJ
sum error= 134
Actual label: 8
Output voltages: [0.23232, 0.2526, 0.20259, 0.37576, 0.098023, 0.28649, 0.23434, 0.0879, 0.72504, 0.22513]
Predicted label: 8
Correct prediction
Energy consumption = 203.684489 pJ
sum error= 134
Actual label: 7
Output voltages: [0.24073, 0.38343, 0.29281, 0.45972, 0.13236, 0.056473, 0.041644, 0.57713, 0.36016, 0.47809]
Predicted label: 7
Correct prediction
Energy consumption = 206.000651 pJ
sum error= 134
Actual label: 0
Output voltages: [0.71452, 0.21115, 0.18572, 0.17058, 0.18174, 0.26964, 0.47482, 0.13086, 0.23496, 0.30755]
Predicted label: 0
Correct prediction
Energy consumption = 202.208363 pJ
sum error= 134
Actual label: 1
Output voltages: [0.12715, 0.75467, 0.063528, 0.24284, 0.24916, 0.32027, 0.42571, 0.2608, 0.31853, 0.1514]
Predicted label: 1
Correct prediction
Energy consumption = 214.010485 pJ
sum error= 134
Actual label: 4
Output voltages: [0.18764, 0.23271, 0.27715, 0.11828, 0.75232, 0.08807, 0.36424, 0.18019, 0.22982, 0.35996]
Predicted label: 4
Correct prediction
Energy consumption = 205.078373 pJ
sum error= 134
Actual label: 2
Output voltages: [0.36221, 0.27253, 0.6518, 0.40954, 0.14135, 0.034844, 0.31483, 0.20831, 0.43535, 0.1473]
Predicted label: 2
Correct prediction
Energy consumption = 196.276908 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 323 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 323 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 323 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.19259, 0.768, 0.3019, 0.32516, 0.18166, 0.057194, 0.33218, 0.15428, 0.24987, 0.24825]
Predicted label: 1
Correct prediction
Energy consumption = 209.437549 pJ
sum error= 134
Actual label: 1
Output voltages: [0.24117, 0.7526, 0.28483, 0.28679, 0.18974, 0.090838, 0.39144, 0.094676, 0.33597, 0.20809]
Predicted label: 1
Correct prediction
Energy consumption = 204.286303 pJ
sum error= 134
Actual label: 4
Output voltages: [0.21156, 0.16882, 0.37023, 0.20416, 0.72339, 0.062831, 0.26725, 0.19959, 0.20593, 0.45634]
Predicted label: 4
Correct prediction
Energy consumption = 204.461464 pJ
sum error= 134
Actual label: 4
Output voltages: [0.13789, 0.19867, 0.2475, 0.13324, 0.7025, 0.11253, 0.19128, 0.21184, 0.32834, 0.38136]
Predicted label: 4
Correct prediction
Energy consumption = 199.067173 pJ
sum error= 134
Actual label: 4
Output voltages: [0.14134, 0.13439, 0.34421, 0.078815, 0.76308, 0.11589, 0.31241, 0.25623, 0.25368, 0.28663]
Predicted label: 4
Correct prediction
Energy consumption = 186.244129 pJ
sum error= 134
Actual label: 4
Output voltages: [0.17344, 0.20448, 0.25162, 0.15429, 0.71444, 0.16392, 0.26626, 0.27188, 0.23351, 0.43327]
Predicted label: 4
Correct prediction
Energy consumption = 198.786541 pJ
sum error= 134
Actual label: 7
Output voltages: [0.39923, 0.38531, 0.35773, 0.44581, 0.11862, 0.046521, 0.060505, 0.50005, 0.21771, 0.30486]
Predicted label: 7
Correct prediction
Energy consumption = 211.105447 pJ
sum error= 134
Actual label: 1
Output voltages: [0.19514, 0.76683, 0.21112, 0.30382, 0.25088, 0.11394, 0.28646, 0.21264, 0.24608, 0.34151]
Predicted label: 1
Correct prediction
Energy consumption = 206.324395 pJ
sum error= 134
Actual label: 6
Output voltages: [0.34188, 0.14403, 0.17197, 0.18933, 0.31443, 0.45926, 0.67983, 0.080005, 0.43465, 0.17048]
Predicted label: 6
Correct prediction
Energy consumption = 190.813725 pJ
sum error= 134
Actual label: 2
Output voltages: [0.39142, 0.33357, 0.65014, 0.35398, 0.30742, 0.04119, 0.3224, 0.2866, 0.39573, 0.14389]
Predicted label: 2
Correct prediction
Energy consumption = 194.947185 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 324 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 324 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 324 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39156, 0.057486, 0.18433, 0.38476, 0.27219, 0.24758, 0.15222, 0.070969, 0.45648, 0.50922]
Predicted label: 9
Correct prediction
Energy consumption = 207.846963 pJ
sum error= 134
Actual label: 9
Output voltages: [0.33229, 0.11688, 0.20694, 0.29851, 0.41236, 0.22196, 0.15801, 0.28453, 0.28442, 0.68439]
Predicted label: 9
Correct prediction
Energy consumption = 197.357402 pJ
sum error= 134
Actual label: 0
Output voltages: [0.70173, 0.15677, 0.38355, 0.17273, 0.062389, 0.20493, 0.35445, 0.20203, 0.3452, 0.20752]
Predicted label: 0
Correct prediction
Energy consumption = 194.757953 pJ
sum error= 134
Actual label: 0
Output voltages: [0.7177, 0.25808, 0.20769, 0.22018, 0.21212, 0.14222, 0.43791, 0.17125, 0.36749, 0.19089]
Predicted label: 0
Correct prediction
Energy consumption = 201.364960 pJ
sum error= 134
Actual label: 1
Output voltages: [0.1671, 0.7606, 0.15339, 0.20021, 0.21743, 0.12844, 0.41905, 0.13026, 0.36685, 0.24914]
Predicted label: 1
Correct prediction
Energy consumption = 203.832130 pJ
sum error= 134
Actual label: 8
Output voltages: [0.22505, 0.36961, 0.25944, 0.31243, 0.21182, 0.20375, 0.28088, 0.064864, 0.71549, 0.30527]
Predicted label: 8
Correct prediction
Energy consumption = 195.601779 pJ
sum error= 134
Actual label: 8
Output voltages: [0.31607, 0.15825, 0.26224, 0.45484, 0.10214, 0.25801, 0.208, 0.066833, 0.70983, 0.30426]
Predicted label: 8
Correct prediction
Energy consumption = 194.334859 pJ
sum error= 134
Actual label: 4
Output voltages: [0.22888, 0.12494, 0.3309, 0.19223, 0.7315, 0.065616, 0.19887, 0.28727, 0.20621, 0.37663]
Predicted label: 4
Correct prediction
Energy consumption = 201.889316 pJ
sum error= 134
Actual label: 3
Output voltages: [0.26539, 0.18778, 0.30217, 0.75561, 0.20423, 0.23739, 0.15443, 0.17262, 0.43732, 0.25289]
Predicted label: 3
Correct prediction
Energy consumption = 186.064479 pJ
sum error= 134
Actual label: 4
Output voltages: [0.12313, 0.12394, 0.25842, 0.13153, 0.74722, 0.12186, 0.25579, 0.24271, 0.34986, 0.15938]
Predicted label: 4
Correct prediction
Energy consumption = 191.460996 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 325 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 325 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 325 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24469, 0.38508, 0.49419, 0.22244, 0.37625, 0.13539, 0.52512, 0.14567, 0.286, 0.053319]
Predicted label: 6
Wrong prediction!
Energy consumption = 195.718091 pJ
sum error= 135
Actual label: 0
Output voltages: [0.62648, 0.070253, 0.28194, 0.20667, 0.2477, 0.24134, 0.40209, 0.11925, 0.22845, 0.46747]
Predicted label: 0
Correct prediction
Energy consumption = 195.543825 pJ
sum error= 135
Actual label: 6
Output voltages: [0.32294, 0.30497, 0.24837, 0.26077, 0.22421, 0.33346, 0.70487, 0.0711, 0.5021, 0.11276]
Predicted label: 6
Correct prediction
Energy consumption = 193.842952 pJ
sum error= 135
Actual label: 1
Output voltages: [0.21005, 0.76507, 0.23006, 0.17938, 0.29774, 0.13653, 0.44863, 0.11993, 0.27542, 0.23239]
Predicted label: 1
Correct prediction
Energy consumption = 202.286780 pJ
sum error= 135
Actual label: 6
Output voltages: [0.37169, 0.21908, 0.23421, 0.19033, 0.20122, 0.3933, 0.65108, 0.15809, 0.5156, 0.1144]
Predicted label: 6
Correct prediction
Energy consumption = 191.813927 pJ
sum error= 135
Actual label: 1
Output voltages: [0.16182, 0.75562, 0.26669, 0.2612, 0.29877, 0.17763, 0.41184, 0.11478, 0.30533, 0.21481]
Predicted label: 1
Correct prediction
Energy consumption = 212.904960 pJ
sum error= 135
Actual label: 2
Output voltages: [0.34198, 0.26808, 0.72497, 0.34498, 0.1429, 0.032459, 0.23546, 0.29367, 0.42662, 0.1983]
Predicted label: 2
Correct prediction
Energy consumption = 186.960772 pJ
sum error= 135
Actual label: 2
Output voltages: [0.35116, 0.2658, 0.73343, 0.30734, 0.17876, 0.024236, 0.27311, 0.29328, 0.35404, 0.22868]
Predicted label: 2
Correct prediction
Energy consumption = 179.511658 pJ
sum error= 135
Actual label: 2
Output voltages: [0.39106, 0.32188, 0.72886, 0.34704, 0.17024, 0.027857, 0.32274, 0.18732, 0.41016, 0.20667]
Predicted label: 2
Correct prediction
Energy consumption = 182.932743 pJ
sum error= 135
Actual label: 1
Output voltages: [0.19021, 0.72214, 0.20999, 0.41523, 0.25068, 0.12157, 0.15626, 0.24567, 0.33404, 0.26385]
Predicted label: 1
Correct prediction
Energy consumption = 208.027086 pJ
sum error= 135
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 326 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 326 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 326 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40626, 0.2187, 0.66703, 0.35819, 0.11715, 0.032776, 0.2718, 0.25383, 0.47188, 0.28892]
Predicted label: 2
Correct prediction
Energy consumption = 199.257823 pJ
sum error= 135
Actual label: 3
Output voltages: [0.34475, 0.18154, 0.26332, 0.74711, 0.18756, 0.16523, 0.078522, 0.31516, 0.3864, 0.2508]
Predicted label: 3
Correct prediction
Energy consumption = 189.760091 pJ
sum error= 135
Actual label: 7
Output voltages: [0.21571, 0.26229, 0.41076, 0.37311, 0.2192, 0.050689, 0.052981, 0.72419, 0.32944, 0.23167]
Predicted label: 7
Correct prediction
Energy consumption = 186.763506 pJ
sum error= 135
Actual label: 8
Output voltages: [0.30262, 0.08874, 0.30757, 0.16351, 0.21882, 0.14545, 0.11812, 0.26137, 0.71503, 0.32103]
Predicted label: 8
Correct prediction
Energy consumption = 199.459506 pJ
sum error= 135
Actual label: 1
Output voltages: [0.21421, 0.76185, 0.25352, 0.26196, 0.19614, 0.061429, 0.39532, 0.12436, 0.3366, 0.21889]
Predicted label: 1
Correct prediction
Energy consumption = 208.812404 pJ
sum error= 135
Actual label: 0
Output voltages: [0.73181, 0.25387, 0.21173, 0.16453, 0.17562, 0.18208, 0.38431, 0.16627, 0.2696, 0.30798]
Predicted label: 0
Correct prediction
Energy consumption = 193.907596 pJ
sum error= 135
Actual label: 0
Output voltages: [0.71945, 0.20326, 0.13711, 0.20083, 0.19493, 0.2448, 0.47102, 0.19829, 0.30805, 0.21706]
Predicted label: 0
Correct prediction
Energy consumption = 193.830109 pJ
sum error= 135
Actual label: 2
Output voltages: [0.30513, 0.3785, 0.73339, 0.32333, 0.16351, 0.024076, 0.22839, 0.33267, 0.30992, 0.23076]
Predicted label: 2
Correct prediction
Energy consumption = 186.847797 pJ
sum error= 135
Actual label: 1
Output voltages: [0.25453, 0.77074, 0.2643, 0.28147, 0.1205, 0.13579, 0.38598, 0.10876, 0.31999, 0.2193]
Predicted label: 1
Correct prediction
Energy consumption = 204.865453 pJ
sum error= 135
Actual label: 6
Output voltages: [0.46176, 0.34443, 0.17645, 0.20575, 0.24805, 0.37931, 0.59728, 0.073996, 0.26012, 0.1676]
Predicted label: 6
Correct prediction
Energy consumption = 198.466042 pJ
sum error= 135
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 327 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 327 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 327 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.34475, 0.24886, 0.3208, 0.08674, 0.30458, 0.27686, 0.74114, 0.077341, 0.39606, 0.14576]
Predicted label: 6
Correct prediction
Energy consumption = 196.465734 pJ
sum error= 135
Actual label: 0
Output voltages: [0.72086, 0.22574, 0.22816, 0.13576, 0.17981, 0.22233, 0.41755, 0.16203, 0.25517, 0.29471]
Predicted label: 0
Correct prediction
Energy consumption = 189.818997 pJ
sum error= 135
Actual label: 1
Output voltages: [0.17195, 0.75953, 0.14258, 0.22513, 0.21738, 0.12941, 0.38926, 0.084993, 0.35886, 0.28252]
Predicted label: 1
Correct prediction
Energy consumption = 207.767390 pJ
sum error= 135
Actual label: 6
Output voltages: [0.33327, 0.14808, 0.2426, 0.16729, 0.26809, 0.44781, 0.6974, 0.054189, 0.42341, 0.19375]
Predicted label: 6
Correct prediction
Energy consumption = 182.468915 pJ
sum error= 135
Actual label: 2
Output voltages: [0.39232, 0.34788, 0.68947, 0.31633, 0.20064, 0.029284, 0.33248, 0.32766, 0.34014, 0.16648]
Predicted label: 2
Correct prediction
Energy consumption = 191.473824 pJ
sum error= 135
Actual label: 5
Output voltages: [0.32398, 0.078195, 0.056151, 0.50716, 0.22017, 0.69736, 0.24239, 0.27956, 0.45636, 0.21139]
Predicted label: 5
Correct prediction
Energy consumption = 197.383198 pJ
sum error= 135
Actual label: 1
Output voltages: [0.26604, 0.76975, 0.19202, 0.23926, 0.17894, 0.2052, 0.3666, 0.13122, 0.28119, 0.29401]
Predicted label: 1
Correct prediction
Energy consumption = 217.279268 pJ
sum error= 135
Actual label: 7
Output voltages: [0.2197, 0.33361, 0.34691, 0.19094, 0.18793, 0.10976, 0.046176, 0.74546, 0.39967, 0.21827]
Predicted label: 7
Correct prediction
Energy consumption = 191.940079 pJ
sum error= 135
Actual label: 4
Output voltages: [0.19171, 0.13936, 0.25099, 0.11468, 0.75569, 0.12646, 0.30976, 0.23396, 0.23389, 0.34521]
Predicted label: 4
Correct prediction
Energy consumption = 201.615497 pJ
sum error= 135
Actual label: 8
Output voltages: [0.21393, 0.17193, 0.30481, 0.34993, 0.10484, 0.18674, 0.16068, 0.14085, 0.74136, 0.26227]
Predicted label: 8
Correct prediction
Energy consumption = 191.867055 pJ
sum error= 135
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 328 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 328 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 328 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.30819, 0.45212, 0.68632, 0.29062, 0.13139, 0.021316, 0.20442, 0.38062, 0.29195, 0.17926]
Predicted label: 2
Correct prediction
Energy consumption = 192.426452 pJ
sum error= 135
Actual label: 1
Output voltages: [0.18468, 0.76373, 0.21314, 0.28153, 0.23938, 0.15013, 0.41084, 0.19455, 0.3078, 0.17189]
Predicted label: 1
Correct prediction
Energy consumption = 210.840612 pJ
sum error= 135
Actual label: 4
Output voltages: [0.23405, 0.17779, 0.29095, 0.1683, 0.74801, 0.072901, 0.25173, 0.29691, 0.14701, 0.38937]
Predicted label: 4
Correct prediction
Energy consumption = 200.624432 pJ
sum error= 135
Actual label: 3
Output voltages: [0.33399, 0.16788, 0.2987, 0.75632, 0.19279, 0.20779, 0.13703, 0.16726, 0.4558, 0.20649]
Predicted label: 3
Correct prediction
Energy consumption = 192.852570 pJ
sum error= 135
Actual label: 8
Output voltages: [0.328, 0.16878, 0.33978, 0.15477, 0.1598, 0.11444, 0.17695, 0.17225, 0.71189, 0.39224]
Predicted label: 8
Correct prediction
Energy consumption = 195.272435 pJ
sum error= 135
Actual label: 3
Output voltages: [0.39379, 0.2051, 0.32737, 0.75589, 0.1092, 0.12075, 0.12732, 0.23125, 0.45079, 0.18463]
Predicted label: 3
Correct prediction
Energy consumption = 193.140718 pJ
sum error= 135
Actual label: 9
Output voltages: [0.35589, 0.15112, 0.21121, 0.31267, 0.3527, 0.23455, 0.12738, 0.31904, 0.28373, 0.68879]
Predicted label: 9
Correct prediction
Energy consumption = 195.437860 pJ
sum error= 135
Actual label: 9
Output voltages: [0.48395, 0.06586, 0.25519, 0.1648, 0.35422, 0.15988, 0.22382, 0.1507, 0.28862, 0.66652]
Predicted label: 9
Correct prediction
Energy consumption = 187.525677 pJ
sum error= 135
Actual label: 4
Output voltages: [0.39427, 0.16553, 0.28569, 0.13072, 0.67644, 0.063657, 0.32644, 0.14051, 0.2094, 0.43459]
Predicted label: 4
Correct prediction
Energy consumption = 190.778972 pJ
sum error= 135
Actual label: 8
Output voltages: [0.30594, 0.09558, 0.22966, 0.28082, 0.15098, 0.26192, 0.084255, 0.23423, 0.66473, 0.38408]
Predicted label: 8
Correct prediction
Energy consumption = 196.108140 pJ
sum error= 135
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 329 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 329 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 329 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26867, 0.11482, 0.24697, 0.56701, 0.15079, 0.24818, 0.088682, 0.22203, 0.62611, 0.38162]
Predicted label: 8
Wrong prediction!
Energy consumption = 188.106582 pJ
sum error= 136
Actual label: 4
Output voltages: [0.19735, 0.25904, 0.29908, 0.12833, 0.74766, 0.11005, 0.29969, 0.20339, 0.22105, 0.35947]
Predicted label: 4
Correct prediction
Energy consumption = 205.344054 pJ
sum error= 136
Actual label: 7
Output voltages: [0.45729, 0.22417, 0.12973, 0.19687, 0.15238, 0.21219, 0.080885, 0.69349, 0.39317, 0.36188]
Predicted label: 7
Correct prediction
Energy consumption = 202.667904 pJ
sum error= 136
Actual label: 2
Output voltages: [0.33716, 0.2935, 0.7426, 0.3411, 0.19135, 0.031345, 0.32686, 0.20625, 0.37904, 0.23189]
Predicted label: 2
Correct prediction
Energy consumption = 186.860144 pJ
sum error= 136
Actual label: 7
Output voltages: [0.29502, 0.16637, 0.48929, 0.24784, 0.21226, 0.025779, 0.079922, 0.71474, 0.32738, 0.23537]
Predicted label: 7
Correct prediction
Energy consumption = 189.212697 pJ
sum error= 136
Actual label: 5
Output voltages: [0.30303, 0.045331, 0.12352, 0.33836, 0.22615, 0.69728, 0.27206, 0.21462, 0.53142, 0.28864]
Predicted label: 5
Correct prediction
Energy consumption = 189.749533 pJ
sum error= 136
Actual label: 7
Output voltages: [0.44679, 0.17323, 0.45607, 0.27512, 0.064352, 0.044852, 0.14874, 0.65582, 0.35578, 0.29335]
Predicted label: 7
Correct prediction
Energy consumption = 196.615328 pJ
sum error= 136
Actual label: 0
Output voltages: [0.71483, 0.22974, 0.24104, 0.19232, 0.15855, 0.16744, 0.47161, 0.16021, 0.30326, 0.27874]
Predicted label: 0
Correct prediction
Energy consumption = 190.890126 pJ
sum error= 136
Actual label: 4
Output voltages: [0.18722, 0.17807, 0.22361, 0.17142, 0.75877, 0.10286, 0.30679, 0.23568, 0.24158, 0.22283]
Predicted label: 4
Correct prediction
Energy consumption = 198.823549 pJ
sum error= 136
Actual label: 3
Output voltages: [0.27782, 0.15193, 0.26582, 0.75539, 0.20514, 0.2345, 0.16173, 0.24289, 0.38974, 0.25767]
Predicted label: 3
Correct prediction
Energy consumption = 185.031605 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 330 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 330 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 330 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.37179, 0.20739, 0.36346, 0.74247, 0.20305, 0.23065, 0.27198, 0.16937, 0.3682, 0.12155]
Predicted label: 3
Correct prediction
Energy consumption = 192.256214 pJ
sum error= 136
Actual label: 2
Output voltages: [0.37576, 0.463, 0.64839, 0.3485, 0.15603, 0.029599, 0.306, 0.23641, 0.33572, 0.1699]
Predicted label: 2
Correct prediction
Energy consumption = 187.632786 pJ
sum error= 136
Actual label: 6
Output voltages: [0.26861, 0.20979, 0.32785, 0.080241, 0.33446, 0.27759, 0.7228, 0.12329, 0.34155, 0.14282]
Predicted label: 6
Correct prediction
Energy consumption = 196.042445 pJ
sum error= 136
Actual label: 7
Output voltages: [0.39859, 0.11455, 0.17544, 0.18995, 0.23373, 0.1875, 0.046416, 0.6285, 0.40237, 0.44702]
Predicted label: 7
Correct prediction
Energy consumption = 204.274766 pJ
sum error= 136
Actual label: 6
Output voltages: [0.32115, 0.29435, 0.27803, 0.21926, 0.30184, 0.33844, 0.73033, 0.12252, 0.3452, 0.085801]
Predicted label: 6
Correct prediction
Energy consumption = 202.743167 pJ
sum error= 136
Actual label: 0
Output voltages: [0.70432, 0.18442, 0.20041, 0.2968, 0.21238, 0.17812, 0.42283, 0.18914, 0.40256, 0.27514]
Predicted label: 0
Correct prediction
Energy consumption = 203.693208 pJ
sum error= 136
Actual label: 0
Output voltages: [0.72282, 0.21069, 0.2936, 0.17259, 0.15922, 0.14278, 0.41545, 0.12453, 0.31341, 0.321]
Predicted label: 0
Correct prediction
Energy consumption = 189.855675 pJ
sum error= 136
Actual label: 6
Output voltages: [0.28279, 0.20372, 0.28098, 0.09867, 0.29007, 0.25533, 0.73633, 0.11553, 0.33824, 0.2173]
Predicted label: 6
Correct prediction
Energy consumption = 186.872997 pJ
sum error= 136
Actual label: 7
Output voltages: [0.41132, 0.2133, 0.36951, 0.24624, 0.17775, 0.051734, 0.066697, 0.75398, 0.27669, 0.28932]
Predicted label: 7
Correct prediction
Energy consumption = 192.291746 pJ
sum error= 136
Actual label: 7
Output voltages: [0.27636, 0.32113, 0.41694, 0.21543, 0.11342, 0.043941, 0.043903, 0.74128, 0.37206, 0.29087]
Predicted label: 7
Correct prediction
Energy consumption = 190.879325 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 331 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 331 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 331 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.734, 0.24463, 0.2406, 0.21111, 0.1464, 0.19965, 0.43497, 0.15746, 0.26648, 0.31679]
Predicted label: 0
Correct prediction
Energy consumption = 197.909173 pJ
sum error= 136
Actual label: 5
Output voltages: [0.21314, 0.11065, 0.046994, 0.37282, 0.30602, 0.70946, 0.28162, 0.15295, 0.37812, 0.28589]
Predicted label: 5
Correct prediction
Energy consumption = 190.007967 pJ
sum error= 136
Actual label: 5
Output voltages: [0.15786, 0.051101, 0.14643, 0.43883, 0.24547, 0.67648, 0.26397, 0.27104, 0.47845, 0.31067]
Predicted label: 5
Correct prediction
Energy consumption = 185.965261 pJ
sum error= 136
Actual label: 8
Output voltages: [0.24065, 0.20142, 0.29989, 0.28198, 0.12838, 0.25765, 0.19655, 0.16976, 0.75048, 0.32563]
Predicted label: 8
Correct prediction
Energy consumption = 186.494149 pJ
sum error= 136
Actual label: 1
Output voltages: [0.20936, 0.76096, 0.2588, 0.22157, 0.28014, 0.10488, 0.39431, 0.13034, 0.32027, 0.19372]
Predicted label: 1
Correct prediction
Energy consumption = 209.842677 pJ
sum error= 136
Actual label: 0
Output voltages: [0.6749, 0.19482, 0.17139, 0.14523, 0.17113, 0.31735, 0.40626, 0.14381, 0.43816, 0.17454]
Predicted label: 0
Correct prediction
Energy consumption = 196.631829 pJ
sum error= 136
Actual label: 7
Output voltages: [0.14199, 0.15853, 0.28866, 0.091611, 0.44759, 0.051514, 0.16909, 0.71686, 0.36616, 0.19543]
Predicted label: 7
Correct prediction
Energy consumption = 202.971863 pJ
sum error= 136
Actual label: 0
Output voltages: [0.70522, 0.16989, 0.19207, 0.12266, 0.28205, 0.19539, 0.49146, 0.20557, 0.27346, 0.26332]
Predicted label: 0
Correct prediction
Energy consumption = 200.892185 pJ
sum error= 136
Actual label: 2
Output voltages: [0.29965, 0.30998, 0.67777, 0.4043, 0.12749, 0.038068, 0.25418, 0.21188, 0.44888, 0.172]
Predicted label: 2
Correct prediction
Energy consumption = 190.782277 pJ
sum error= 136
Actual label: 8
Output voltages: [0.2593, 0.14127, 0.27551, 0.29795, 0.11838, 0.1487, 0.13072, 0.17822, 0.7029, 0.38362]
Predicted label: 8
Correct prediction
Energy consumption = 196.982492 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 332 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 332 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 332 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.15318, 0.75225, 0.16933, 0.17752, 0.37296, 0.16913, 0.38891, 0.088613, 0.3386, 0.24584]
Predicted label: 1
Correct prediction
Energy consumption = 209.450759 pJ
sum error= 136
Actual label: 5
Output voltages: [0.22475, 0.12981, 0.23239, 0.36555, 0.092186, 0.50065, 0.19756, 0.08184, 0.67567, 0.23521]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.051494 pJ
sum error= 137
Actual label: 0
Output voltages: [0.73848, 0.20716, 0.21368, 0.22767, 0.18052, 0.20265, 0.36216, 0.19278, 0.29837, 0.36591]
Predicted label: 0
Correct prediction
Energy consumption = 200.033178 pJ
sum error= 137
Actual label: 8
Output voltages: [0.33103, 0.12961, 0.30637, 0.39447, 0.1653, 0.24657, 0.25195, 0.080912, 0.73177, 0.21374]
Predicted label: 8
Correct prediction
Energy consumption = 194.066984 pJ
sum error= 137
Actual label: 8
Output voltages: [0.24006, 0.18065, 0.26766, 0.33005, 0.07209, 0.33447, 0.15117, 0.27264, 0.74593, 0.19858]
Predicted label: 8
Correct prediction
Energy consumption = 193.841364 pJ
sum error= 137
Actual label: 0
Output voltages: [0.73079, 0.21409, 0.23956, 0.14011, 0.17475, 0.2037, 0.42762, 0.17386, 0.29381, 0.27615]
Predicted label: 0
Correct prediction
Energy consumption = 194.581613 pJ
sum error= 137
Actual label: 3
Output voltages: [0.45881, 0.17703, 0.22274, 0.74558, 0.075802, 0.3377, 0.19252, 0.24018, 0.38874, 0.10522]
Predicted label: 3
Correct prediction
Energy consumption = 189.026795 pJ
sum error= 137
Actual label: 2
Output voltages: [0.35653, 0.30687, 0.70793, 0.37504, 0.1263, 0.031384, 0.31566, 0.21539, 0.42405, 0.18752]
Predicted label: 2
Correct prediction
Energy consumption = 182.496029 pJ
sum error= 137
Actual label: 7
Output voltages: [0.39944, 0.32589, 0.4487, 0.13441, 0.10315, 0.046345, 0.091209, 0.72972, 0.44953, 0.15058]
Predicted label: 7
Correct prediction
Energy consumption = 194.290209 pJ
sum error= 137
Actual label: 7
Output voltages: [0.32616, 0.19839, 0.43683, 0.41504, 0.26301, 0.025027, 0.10936, 0.57354, 0.30795, 0.2542]
Predicted label: 7
Correct prediction
Energy consumption = 190.785673 pJ
sum error= 137
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 333 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 333 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 333 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.42784, 0.16963, 0.52267, 0.58509, 0.060729, 0.12405, 0.1777, 0.12264, 0.53401, 0.21256]
Predicted label: 3
Wrong prediction!
Energy consumption = 193.527736 pJ
sum error= 138
Actual label: 6
Output voltages: [0.3137, 0.163, 0.24438, 0.15715, 0.28119, 0.38392, 0.71214, 0.056796, 0.42671, 0.19622]
Predicted label: 6
Correct prediction
Energy consumption = 185.623837 pJ
sum error= 138
Actual label: 4
Output voltages: [0.12896, 0.10144, 0.32539, 0.20877, 0.74134, 0.060897, 0.24847, 0.2581, 0.25423, 0.28997]
Predicted label: 4
Correct prediction
Energy consumption = 199.053588 pJ
sum error= 138
Actual label: 7
Output voltages: [0.34377, 0.13395, 0.31165, 0.43338, 0.37877, 0.050609, 0.054573, 0.49982, 0.15821, 0.43775]
Predicted label: 7
Correct prediction
Energy consumption = 191.471374 pJ
sum error= 138
Actual label: 5
Output voltages: [0.23719, 0.061258, 0.070371, 0.39802, 0.18853, 0.66758, 0.19483, 0.25161, 0.44534, 0.35165]
Predicted label: 5
Correct prediction
Energy consumption = 186.433865 pJ
sum error= 138
Actual label: 5
Output voltages: [0.31173, 0.075365, 0.069675, 0.39168, 0.26483, 0.72819, 0.40891, 0.11309, 0.40818, 0.21042]
Predicted label: 5
Correct prediction
Energy consumption = 183.598316 pJ
sum error= 138
Actual label: 5
Output voltages: [0.18641, 0.087888, 0.051226, 0.25469, 0.38389, 0.60969, 0.09263, 0.41522, 0.38528, 0.38568]
Predicted label: 5
Correct prediction
Energy consumption = 193.945313 pJ
sum error= 138
Actual label: 2
Output voltages: [0.33501, 0.23208, 0.71038, 0.3272, 0.14144, 0.032218, 0.25931, 0.36572, 0.45996, 0.23165]
Predicted label: 2
Correct prediction
Energy consumption = 191.863738 pJ
sum error= 138
Actual label: 9
Output voltages: [0.34964, 0.12321, 0.19224, 0.28432, 0.31747, 0.28316, 0.19958, 0.20314, 0.3571, 0.67747]
Predicted label: 9
Correct prediction
Energy consumption = 200.991573 pJ
sum error= 138
Actual label: 2
Output voltages: [0.30136, 0.42263, 0.69151, 0.30121, 0.15836, 0.0226, 0.2437, 0.29038, 0.34333, 0.18897]
Predicted label: 2
Correct prediction
Energy consumption = 189.773438 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 334 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 334 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 334 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26052, 0.17337, 0.2549, 0.35221, 0.085523, 0.31105, 0.16862, 0.096534, 0.74136, 0.30568]
Predicted label: 8
Correct prediction
Energy consumption = 197.461866 pJ
sum error= 138
Actual label: 4
Output voltages: [0.23843, 0.20849, 0.32875, 0.16361, 0.73111, 0.060299, 0.21646, 0.17551, 0.27763, 0.22244]
Predicted label: 4
Correct prediction
Energy consumption = 190.843189 pJ
sum error= 138
Actual label: 6
Output voltages: [0.32381, 0.1259, 0.25037, 0.20938, 0.24859, 0.35775, 0.67276, 0.044961, 0.40178, 0.23482]
Predicted label: 6
Correct prediction
Energy consumption = 191.367577 pJ
sum error= 138
Actual label: 8
Output voltages: [0.29379, 0.23117, 0.4328, 0.23956, 0.17081, 0.089929, 0.30156, 0.096427, 0.69529, 0.33517]
Predicted label: 8
Correct prediction
Energy consumption = 193.658425 pJ
sum error= 138
Actual label: 6
Output voltages: [0.42725, 0.21821, 0.14325, 0.13856, 0.31209, 0.38812, 0.63357, 0.15584, 0.44904, 0.15463]
Predicted label: 6
Correct prediction
Energy consumption = 198.666248 pJ
sum error= 138
Actual label: 5
Output voltages: [0.27779, 0.058106, 0.12847, 0.29527, 0.14742, 0.74195, 0.33949, 0.26692, 0.49159, 0.16709]
Predicted label: 5
Correct prediction
Energy consumption = 184.405948 pJ
sum error= 138
Actual label: 0
Output voltages: [0.68879, 0.26231, 0.31497, 0.18214, 0.080126, 0.13776, 0.34305, 0.18289, 0.41217, 0.23203]
Predicted label: 0
Correct prediction
Energy consumption = 188.859445 pJ
sum error= 138
Actual label: 0
Output voltages: [0.57195, 0.1605, 0.31197, 0.094135, 0.21025, 0.24058, 0.49189, 0.15807, 0.47445, 0.15556]
Predicted label: 0
Correct prediction
Energy consumption = 200.006297 pJ
sum error= 138
Actual label: 8
Output voltages: [0.28402, 0.14392, 0.38712, 0.32071, 0.14373, 0.16132, 0.17448, 0.13061, 0.72443, 0.33261]
Predicted label: 8
Correct prediction
Energy consumption = 189.955798 pJ
sum error= 138
Actual label: 7
Output voltages: [0.25593, 0.20571, 0.33023, 0.42035, 0.12864, 0.059741, 0.046606, 0.7234, 0.2931, 0.38429]
Predicted label: 7
Correct prediction
Energy consumption = 184.772240 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 335 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 335 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 335 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30115, 0.23778, 0.31294, 0.067883, 0.35789, 0.35484, 0.74596, 0.083402, 0.34342, 0.10525]
Predicted label: 6
Correct prediction
Energy consumption = 191.285912 pJ
sum error= 138
Actual label: 1
Output voltages: [0.28271, 0.70483, 0.27733, 0.15784, 0.40295, 0.057452, 0.30951, 0.19356, 0.26767, 0.19958]
Predicted label: 1
Correct prediction
Energy consumption = 199.513491 pJ
sum error= 138
Actual label: 7
Output voltages: [0.267, 0.14719, 0.32755, 0.44878, 0.23238, 0.045509, 0.048001, 0.61679, 0.49255, 0.28464]
Predicted label: 7
Correct prediction
Energy consumption = 190.174027 pJ
sum error= 138
Actual label: 1
Output voltages: [0.13106, 0.76126, 0.25509, 0.36475, 0.25765, 0.20145, 0.21718, 0.19693, 0.21482, 0.29408]
Predicted label: 1
Correct prediction
Energy consumption = 207.312007 pJ
sum error= 138
Actual label: 1
Output voltages: [0.2298, 0.76302, 0.30201, 0.27267, 0.28013, 0.063794, 0.35436, 0.15132, 0.26586, 0.17917]
Predicted label: 1
Correct prediction
Energy consumption = 202.630710 pJ
sum error= 138
Actual label: 2
Output voltages: [0.34332, 0.22836, 0.75459, 0.30982, 0.22702, 0.040965, 0.23586, 0.32817, 0.4244, 0.1816]
Predicted label: 2
Correct prediction
Energy consumption = 178.200303 pJ
sum error= 138
Actual label: 7
Output voltages: [0.33273, 0.2311, 0.17638, 0.31158, 0.14973, 0.11319, 0.041762, 0.75437, 0.29816, 0.38599]
Predicted label: 7
Correct prediction
Energy consumption = 200.413742 pJ
sum error= 138
Actual label: 4
Output voltages: [0.23557, 0.11134, 0.28071, 0.094808, 0.75568, 0.13084, 0.31482, 0.18204, 0.24322, 0.32788]
Predicted label: 4
Correct prediction
Energy consumption = 194.138433 pJ
sum error= 138
Actual label: 0
Output voltages: [0.61728, 0.19512, 0.27877, 0.15385, 0.10925, 0.12621, 0.26667, 0.29642, 0.50941, 0.16458]
Predicted label: 0
Correct prediction
Energy consumption = 205.679288 pJ
sum error= 138
Actual label: 0
Output voltages: [0.71541, 0.17679, 0.22756, 0.12423, 0.1925, 0.28039, 0.45105, 0.16665, 0.24744, 0.2723]
Predicted label: 0
Correct prediction
Energy consumption = 185.201512 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 336 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 336 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 336 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26519, 0.26822, 0.2382, 0.23132, 0.20576, 0.11241, 0.043771, 0.75841, 0.25401, 0.35406]
Predicted label: 7
Correct prediction
Energy consumption = 197.171655 pJ
sum error= 138
Actual label: 7
Output voltages: [0.49343, 0.20527, 0.40676, 0.22388, 0.13704, 0.045569, 0.072231, 0.6703, 0.32249, 0.25836]
Predicted label: 7
Correct prediction
Energy consumption = 189.484300 pJ
sum error= 138
Actual label: 6
Output voltages: [0.2901, 0.14986, 0.23003, 0.16387, 0.36462, 0.40496, 0.71337, 0.055845, 0.42065, 0.16522]
Predicted label: 6
Correct prediction
Energy consumption = 188.294925 pJ
sum error= 138
Actual label: 3
Output voltages: [0.33834, 0.19425, 0.25441, 0.75493, 0.15521, 0.24825, 0.21679, 0.1706, 0.37711, 0.19584]
Predicted label: 3
Correct prediction
Energy consumption = 192.996955 pJ
sum error= 138
Actual label: 8
Output voltages: [0.28303, 0.16888, 0.35916, 0.32874, 0.11729, 0.2428, 0.16467, 0.15484, 0.74956, 0.26163]
Predicted label: 8
Correct prediction
Energy consumption = 185.379890 pJ
sum error= 138
Actual label: 6
Output voltages: [0.34877, 0.41623, 0.16953, 0.22123, 0.21425, 0.44699, 0.70444, 0.12093, 0.41252, 0.12613]
Predicted label: 6
Correct prediction
Energy consumption = 194.064280 pJ
sum error= 138
Actual label: 4
Output voltages: [0.21101, 0.17754, 0.27731, 0.20299, 0.74713, 0.063522, 0.28228, 0.23274, 0.21161, 0.22736]
Predicted label: 4
Correct prediction
Energy consumption = 197.364780 pJ
sum error= 138
Actual label: 2
Output voltages: [0.39963, 0.18934, 0.67169, 0.41661, 0.16687, 0.032618, 0.24567, 0.20134, 0.48142, 0.1528]
Predicted label: 2
Correct prediction
Energy consumption = 183.589827 pJ
sum error= 138
Actual label: 0
Output voltages: [0.72545, 0.1356, 0.21503, 0.18731, 0.18628, 0.27938, 0.41808, 0.19861, 0.35606, 0.27211]
Predicted label: 0
Correct prediction
Energy consumption = 200.774415 pJ
sum error= 138
Actual label: 9
Output voltages: [0.24308, 0.39123, 0.11852, 0.22467, 0.22256, 0.074002, 0.066804, 0.331, 0.47025, 0.51558]
Predicted label: 9
Correct prediction
Energy consumption = 204.536739 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 337 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 337 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 337 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.095022, 0.18226, 0.33275, 0.10857, 0.75814, 0.10171, 0.27987, 0.28714, 0.21811, 0.29347]
Predicted label: 4
Correct prediction
Energy consumption = 195.706535 pJ
sum error= 138
Actual label: 0
Output voltages: [0.73654, 0.20101, 0.24126, 0.15019, 0.20763, 0.16993, 0.46603, 0.18638, 0.28642, 0.27305]
Predicted label: 0
Correct prediction
Energy consumption = 192.130665 pJ
sum error= 138
Actual label: 5
Output voltages: [0.25589, 0.046685, 0.066794, 0.38815, 0.2675, 0.74147, 0.29956, 0.22739, 0.50913, 0.25831]
Predicted label: 5
Correct prediction
Energy consumption = 192.470150 pJ
sum error= 138
Actual label: 7
Output voltages: [0.35302, 0.15214, 0.17561, 0.38295, 0.24417, 0.12899, 0.052503, 0.70986, 0.27874, 0.451]
Predicted label: 7
Correct prediction
Energy consumption = 196.359766 pJ
sum error= 138
Actual label: 8
Output voltages: [0.22366, 0.20938, 0.31027, 0.31867, 0.14319, 0.18441, 0.23198, 0.12648, 0.74338, 0.30976]
Predicted label: 8
Correct prediction
Energy consumption = 190.701603 pJ
sum error= 138
Actual label: 2
Output voltages: [0.21481, 0.31618, 0.68058, 0.33257, 0.20455, 0.042138, 0.32797, 0.12209, 0.38841, 0.22526]
Predicted label: 2
Correct prediction
Energy consumption = 192.292729 pJ
sum error= 138
Actual label: 7
Output voltages: [0.33069, 0.37942, 0.23644, 0.059693, 0.19723, 0.052486, 0.080515, 0.67514, 0.35852, 0.39661]
Predicted label: 7
Correct prediction
Energy consumption = 213.558199 pJ
sum error= 138
Actual label: 4
Output voltages: [0.20831, 0.13233, 0.099963, 0.21839, 0.6332, 0.29648, 0.41781, 0.17868, 0.28395, 0.18289]
Predicted label: 4
Correct prediction
Energy consumption = 201.233317 pJ
sum error= 138
Actual label: 7
Output voltages: [0.348, 0.19697, 0.15941, 0.24237, 0.24865, 0.19676, 0.045203, 0.7657, 0.33088, 0.33896]
Predicted label: 7
Correct prediction
Energy consumption = 192.616861 pJ
sum error= 138
Actual label: 1
Output voltages: [0.19175, 0.76852, 0.19464, 0.33192, 0.18184, 0.17624, 0.3525, 0.16175, 0.29218, 0.27566]
Predicted label: 1
Correct prediction
Energy consumption = 205.730962 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 338 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 338 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 338 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16618, 0.76233, 0.27965, 0.23897, 0.23082, 0.10195, 0.42321, 0.15376, 0.33446, 0.19751]
Predicted label: 1
Correct prediction
Energy consumption = 210.619517 pJ
sum error= 138
Actual label: 3
Output voltages: [0.25973, 0.21939, 0.46676, 0.66772, 0.20188, 0.069325, 0.1226, 0.16775, 0.42067, 0.31203]
Predicted label: 3
Correct prediction
Energy consumption = 194.610522 pJ
sum error= 138
Actual label: 6
Output voltages: [0.28251, 0.18605, 0.2381, 0.17942, 0.29055, 0.36151, 0.70666, 0.099017, 0.52074, 0.15752]
Predicted label: 6
Correct prediction
Energy consumption = 188.844931 pJ
sum error= 138
Actual label: 6
Output voltages: [0.34879, 0.18553, 0.17195, 0.2279, 0.2591, 0.42852, 0.65854, 0.1027, 0.48745, 0.13784]
Predicted label: 6
Correct prediction
Energy consumption = 187.842209 pJ
sum error= 138
Actual label: 2
Output voltages: [0.49264, 0.24515, 0.47086, 0.28536, 0.15563, 0.071756, 0.53099, 0.29776, 0.37116, 0.055283]
Predicted label: 6
Wrong prediction!
Energy consumption = 191.641024 pJ
sum error= 139
Actual label: 9
Output voltages: [0.33291, 0.073786, 0.28674, 0.36431, 0.28122, 0.1389, 0.10042, 0.31797, 0.25394, 0.64158]
Predicted label: 9
Correct prediction
Energy consumption = 197.604847 pJ
sum error= 139
Actual label: 1
Output voltages: [0.18136, 0.76218, 0.2958, 0.22015, 0.24688, 0.083889, 0.414, 0.1315, 0.29166, 0.19848]
Predicted label: 1
Correct prediction
Energy consumption = 203.063166 pJ
sum error= 139
Actual label: 9
Output voltages: [0.35239, 0.19382, 0.25095, 0.33591, 0.30992, 0.17916, 0.12273, 0.31717, 0.28225, 0.72186]
Predicted label: 9
Correct prediction
Energy consumption = 199.227299 pJ
sum error= 139
Actual label: 4
Output voltages: [0.19395, 0.21732, 0.20458, 0.22645, 0.68664, 0.077386, 0.20761, 0.17968, 0.28264, 0.36825]
Predicted label: 4
Correct prediction
Energy consumption = 197.001169 pJ
sum error= 139
Actual label: 8
Output voltages: [0.31122, 0.16893, 0.31993, 0.34798, 0.12417, 0.23317, 0.13177, 0.14209, 0.73715, 0.29709]
Predicted label: 8
Correct prediction
Energy consumption = 188.288989 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 339 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 339 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 339 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30018, 0.18578, 0.25946, 0.75557, 0.24195, 0.25532, 0.23508, 0.1358, 0.3701, 0.23315]
Predicted label: 3
Correct prediction
Energy consumption = 195.038061 pJ
sum error= 139
Actual label: 6
Output voltages: [0.26685, 0.1678, 0.22906, 0.098112, 0.33901, 0.3361, 0.72134, 0.1118, 0.47493, 0.13904]
Predicted label: 6
Correct prediction
Energy consumption = 192.673166 pJ
sum error= 139
Actual label: 9
Output voltages: [0.33319, 0.13744, 0.15013, 0.23003, 0.35439, 0.31546, 0.19805, 0.21672, 0.34116, 0.64995]
Predicted label: 9
Correct prediction
Energy consumption = 188.610821 pJ
sum error= 139
Actual label: 5
Output voltages: [0.2728, 0.076981, 0.11264, 0.34716, 0.18126, 0.71397, 0.31853, 0.15439, 0.53122, 0.23691]
Predicted label: 5
Correct prediction
Energy consumption = 187.886949 pJ
sum error= 139
Actual label: 9
Output voltages: [0.43411, 0.047635, 0.40175, 0.27644, 0.28566, 0.14822, 0.13592, 0.23951, 0.27843, 0.63773]
Predicted label: 9
Correct prediction
Energy consumption = 205.766289 pJ
sum error= 139
Actual label: 6
Output voltages: [0.31099, 0.1918, 0.28281, 0.12129, 0.31915, 0.42746, 0.74017, 0.063356, 0.33853, 0.14357]
Predicted label: 6
Correct prediction
Energy consumption = 191.310161 pJ
sum error= 139
Actual label: 2
Output voltages: [0.32247, 0.27113, 0.74559, 0.29668, 0.20048, 0.027595, 0.23512, 0.24092, 0.39293, 0.20254]
Predicted label: 2
Correct prediction
Energy consumption = 185.844722 pJ
sum error= 139
Actual label: 4
Output voltages: [0.13083, 0.18208, 0.24477, 0.097299, 0.75898, 0.12078, 0.31514, 0.30931, 0.21615, 0.2424]
Predicted label: 4
Correct prediction
Energy consumption = 192.224132 pJ
sum error= 139
Actual label: 6
Output voltages: [0.35457, 0.30699, 0.25283, 0.20014, 0.24904, 0.289, 0.73459, 0.11205, 0.43087, 0.12525]
Predicted label: 6
Correct prediction
Energy consumption = 201.509432 pJ
sum error= 139
Actual label: 7
Output voltages: [0.49931, 0.18318, 0.12628, 0.23442, 0.21181, 0.26213, 0.13814, 0.72725, 0.28775, 0.35756]
Predicted label: 7
Correct prediction
Energy consumption = 195.969851 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 340 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 340 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 340 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.31673, 0.20774, 0.22998, 0.31467, 0.099953, 0.15078, 0.038991, 0.75678, 0.41476, 0.42202]
Predicted label: 7
Correct prediction
Energy consumption = 201.836544 pJ
sum error= 139
Actual label: 0
Output voltages: [0.69039, 0.26502, 0.34085, 0.14494, 0.07353, 0.1255, 0.39092, 0.18909, 0.32348, 0.28759]
Predicted label: 0
Correct prediction
Energy consumption = 187.954428 pJ
sum error= 139
Actual label: 6
Output voltages: [0.26815, 0.24036, 0.28318, 0.1547, 0.25063, 0.41227, 0.74003, 0.065781, 0.42588, 0.12692]
Predicted label: 6
Correct prediction
Energy consumption = 188.858993 pJ
sum error= 139
Actual label: 6
Output voltages: [0.26614, 0.276, 0.34718, 0.16405, 0.38149, 0.33003, 0.74267, 0.095378, 0.31434, 0.083081]
Predicted label: 6
Correct prediction
Energy consumption = 184.906270 pJ
sum error= 139
Actual label: 9
Output voltages: [0.38882, 0.11387, 0.21173, 0.2755, 0.33362, 0.18431, 0.28248, 0.2239, 0.28301, 0.6732]
Predicted label: 9
Correct prediction
Energy consumption = 198.995153 pJ
sum error= 139
Actual label: 4
Output voltages: [0.28554, 0.14382, 0.26936, 0.16408, 0.69571, 0.038845, 0.16384, 0.29482, 0.30914, 0.32715]
Predicted label: 4
Correct prediction
Energy consumption = 197.547420 pJ
sum error= 139
Actual label: 8
Output voltages: [0.21312, 0.24661, 0.29433, 0.31672, 0.10765, 0.15277, 0.12699, 0.27631, 0.73302, 0.29478]
Predicted label: 8
Correct prediction
Energy consumption = 190.601617 pJ
sum error= 139
Actual label: 3
Output voltages: [0.30331, 0.17384, 0.2697, 0.75551, 0.26056, 0.2129, 0.17459, 0.19106, 0.3795, 0.28537]
Predicted label: 3
Correct prediction
Energy consumption = 191.194493 pJ
sum error= 139
Actual label: 5
Output voltages: [0.26244, 0.058217, 0.081743, 0.35692, 0.29934, 0.74196, 0.36953, 0.19866, 0.49212, 0.24342]
Predicted label: 5
Correct prediction
Energy consumption = 185.578014 pJ
sum error= 139
Actual label: 3
Output voltages: [0.36617, 0.17237, 0.34873, 0.75008, 0.16861, 0.12268, 0.14876, 0.14537, 0.48168, 0.20753]
Predicted label: 3
Correct prediction
Energy consumption = 181.550345 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 341 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 341 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 341 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.27301, 0.13299, 0.29273, 0.1038, 0.74621, 0.13421, 0.27677, 0.26593, 0.22611, 0.44824]
Predicted label: 4
Correct prediction
Energy consumption = 205.384909 pJ
sum error= 139
Actual label: 9
Output voltages: [0.31159, 0.10524, 0.18664, 0.24225, 0.25218, 0.2038, 0.071284, 0.35896, 0.43761, 0.65851]
Predicted label: 9
Correct prediction
Energy consumption = 188.620331 pJ
sum error= 139
Actual label: 0
Output voltages: [0.66672, 0.24721, 0.20988, 0.21536, 0.12038, 0.19175, 0.29716, 0.29498, 0.31862, 0.39995]
Predicted label: 0
Correct prediction
Energy consumption = 202.105509 pJ
sum error= 139
Actual label: 0
Output voltages: [0.73083, 0.2237, 0.21408, 0.18634, 0.20099, 0.16053, 0.33809, 0.17077, 0.3516, 0.21889]
Predicted label: 0
Correct prediction
Energy consumption = 196.269015 pJ
sum error= 139
Actual label: 5
Output voltages: [0.25453, 0.07289, 0.21092, 0.36617, 0.10684, 0.61555, 0.29104, 0.13816, 0.54174, 0.25728]
Predicted label: 5
Correct prediction
Energy consumption = 191.160899 pJ
sum error= 139
Actual label: 2
Output voltages: [0.32012, 0.18636, 0.69153, 0.41964, 0.11603, 0.037266, 0.18282, 0.38302, 0.46574, 0.15683]
Predicted label: 2
Correct prediction
Energy consumption = 194.996537 pJ
sum error= 139
Actual label: 5
Output voltages: [0.21801, 0.1383, 0.11232, 0.36514, 0.26667, 0.6581, 0.27848, 0.096594, 0.47226, 0.30574]
Predicted label: 5
Correct prediction
Energy consumption = 185.852148 pJ
sum error= 139
Actual label: 0
Output voltages: [0.72292, 0.19888, 0.24462, 0.16924, 0.21358, 0.1444, 0.39683, 0.16236, 0.30686, 0.35665]
Predicted label: 0
Correct prediction
Energy consumption = 195.126447 pJ
sum error= 139
Actual label: 7
Output voltages: [0.25794, 0.42835, 0.25822, 0.40569, 0.090419, 0.073222, 0.041559, 0.66805, 0.29512, 0.45334]
Predicted label: 7
Correct prediction
Energy consumption = 208.646816 pJ
sum error= 139
Actual label: 1
Output voltages: [0.2257, 0.76134, 0.258, 0.27094, 0.23199, 0.12362, 0.37931, 0.11157, 0.31054, 0.18859]
Predicted label: 1
Correct prediction
Energy consumption = 201.943252 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 342 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 342 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 342 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23084, 0.7644, 0.20636, 0.20304, 0.31519, 0.080641, 0.38235, 0.15226, 0.24596, 0.24755]
Predicted label: 1
Correct prediction
Energy consumption = 206.675437 pJ
sum error= 139
Actual label: 1
Output voltages: [0.18074, 0.75876, 0.24276, 0.25152, 0.29519, 0.085085, 0.37186, 0.12475, 0.31056, 0.20848]
Predicted label: 1
Correct prediction
Energy consumption = 204.502594 pJ
sum error= 139
Actual label: 6
Output voltages: [0.51461, 0.24285, 0.30176, 0.095317, 0.25838, 0.21428, 0.59904, 0.12324, 0.33966, 0.096065]
Predicted label: 6
Correct prediction
Energy consumption = 196.478976 pJ
sum error= 139
Actual label: 7
Output voltages: [0.35659, 0.27473, 0.25718, 0.24957, 0.19938, 0.17056, 0.05509, 0.70708, 0.22304, 0.46435]
Predicted label: 7
Correct prediction
Energy consumption = 192.955530 pJ
sum error= 139
Actual label: 6
Output voltages: [0.33985, 0.17255, 0.17224, 0.23528, 0.27968, 0.47374, 0.70764, 0.06621, 0.44891, 0.19696]
Predicted label: 6
Correct prediction
Energy consumption = 195.955570 pJ
sum error= 139
Actual label: 7
Output voltages: [0.44173, 0.17081, 0.48283, 0.41767, 0.069433, 0.0427, 0.064051, 0.64456, 0.34115, 0.24947]
Predicted label: 7
Correct prediction
Energy consumption = 203.053967 pJ
sum error= 139
Actual label: 9
Output voltages: [0.32475, 0.10433, 0.14952, 0.20981, 0.37489, 0.2879, 0.12848, 0.1795, 0.38791, 0.62576]
Predicted label: 9
Correct prediction
Energy consumption = 187.243768 pJ
sum error= 139
Actual label: 6
Output voltages: [0.43772, 0.24488, 0.26292, 0.13825, 0.27498, 0.27671, 0.71246, 0.1428, 0.41353, 0.13438]
Predicted label: 6
Correct prediction
Energy consumption = 193.443257 pJ
sum error= 139
Actual label: 6
Output voltages: [0.36253, 0.21881, 0.23845, 0.14761, 0.33484, 0.37196, 0.73212, 0.13049, 0.44805, 0.092882]
Predicted label: 6
Correct prediction
Energy consumption = 188.195173 pJ
sum error= 139
Actual label: 4
Output voltages: [0.12834, 0.10549, 0.18483, 0.17921, 0.68496, 0.1064, 0.18402, 0.19974, 0.38751, 0.25944]
Predicted label: 4
Correct prediction
Energy consumption = 194.030301 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 343 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 343 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 343 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.19993, 0.66379, 0.18314, 0.20036, 0.16458, 0.071951, 0.18744, 0.23761, 0.39131, 0.4357]
Predicted label: 1
Correct prediction
Energy consumption = 218.227539 pJ
sum error= 139
Actual label: 4
Output voltages: [0.16366, 0.15162, 0.23698, 0.057554, 0.74727, 0.15319, 0.27802, 0.36536, 0.31858, 0.23947]
Predicted label: 4
Correct prediction
Energy consumption = 193.822175 pJ
sum error= 139
Actual label: 3
Output voltages: [0.29751, 0.25873, 0.25593, 0.74741, 0.11539, 0.36366, 0.16034, 0.26871, 0.39962, 0.15392]
Predicted label: 3
Correct prediction
Energy consumption = 204.595657 pJ
sum error= 139
Actual label: 1
Output voltages: [0.18189, 0.75854, 0.26463, 0.2565, 0.22944, 0.12503, 0.46865, 0.082963, 0.33191, 0.19861]
Predicted label: 1
Correct prediction
Energy consumption = 201.775015 pJ
sum error= 139
Actual label: 1
Output voltages: [0.21202, 0.76501, 0.13567, 0.23505, 0.21081, 0.15366, 0.43372, 0.14109, 0.32423, 0.21001]
Predicted label: 1
Correct prediction
Energy consumption = 205.808417 pJ
sum error= 139
Actual label: 2
Output voltages: [0.38413, 0.17054, 0.74927, 0.3121, 0.18919, 0.044754, 0.23509, 0.2404, 0.39767, 0.15589]
Predicted label: 2
Correct prediction
Energy consumption = 187.963003 pJ
sum error= 139
Actual label: 2
Output voltages: [0.38372, 0.3961, 0.68988, 0.26106, 0.088903, 0.026507, 0.26571, 0.46548, 0.32653, 0.23285]
Predicted label: 2
Correct prediction
Energy consumption = 180.631832 pJ
sum error= 139
Actual label: 4
Output voltages: [0.14316, 0.21895, 0.27572, 0.19735, 0.73108, 0.058364, 0.16129, 0.22107, 0.32821, 0.33586]
Predicted label: 4
Correct prediction
Energy consumption = 203.058427 pJ
sum error= 139
Actual label: 1
Output voltages: [0.22143, 0.76026, 0.31437, 0.20363, 0.18006, 0.072714, 0.31123, 0.13882, 0.37421, 0.20273]
Predicted label: 1
Correct prediction
Energy consumption = 209.516798 pJ
sum error= 139
Actual label: 0
Output voltages: [0.71255, 0.22328, 0.28537, 0.18112, 0.213, 0.1299, 0.4647, 0.18552, 0.32251, 0.2883]
Predicted label: 0
Correct prediction
Energy consumption = 200.707095 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 344 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 344 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 344 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.27145, 0.19239, 0.34212, 0.44598, 0.13841, 0.16548, 0.19779, 0.11337, 0.72689, 0.30989]
Predicted label: 8
Correct prediction
Energy consumption = 194.255565 pJ
sum error= 139
Actual label: 7
Output voltages: [0.35569, 0.13672, 0.49214, 0.19296, 0.052402, 0.10559, 0.11023, 0.56754, 0.57449, 0.22534]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.654457 pJ
sum error= 140
Actual label: 6
Output voltages: [0.34344, 0.17453, 0.16107, 0.22401, 0.26291, 0.42754, 0.68519, 0.076255, 0.45344, 0.20254]
Predicted label: 6
Correct prediction
Energy consumption = 191.657499 pJ
sum error= 140
Actual label: 3
Output voltages: [0.32108, 0.13363, 0.31267, 0.74475, 0.26495, 0.25005, 0.25492, 0.24036, 0.3788, 0.15054]
Predicted label: 3
Correct prediction
Energy consumption = 188.720255 pJ
sum error= 140
Actual label: 4
Output voltages: [0.14472, 0.17266, 0.24898, 0.10101, 0.73678, 0.071171, 0.38023, 0.2638, 0.25556, 0.20939]
Predicted label: 4
Correct prediction
Energy consumption = 187.866608 pJ
sum error= 140
Actual label: 0
Output voltages: [0.74432, 0.26769, 0.27568, 0.17797, 0.14096, 0.23725, 0.3862, 0.16508, 0.26983, 0.2906]
Predicted label: 0
Correct prediction
Energy consumption = 196.997675 pJ
sum error= 140
Actual label: 0
Output voltages: [0.70082, 0.21949, 0.33977, 0.23453, 0.1524, 0.11582, 0.31311, 0.12718, 0.42303, 0.37627]
Predicted label: 0
Correct prediction
Energy consumption = 191.023618 pJ
sum error= 140
Actual label: 6
Output voltages: [0.30083, 0.20546, 0.38261, 0.049717, 0.48544, 0.19243, 0.67017, 0.1007, 0.30596, 0.10987]
Predicted label: 6
Correct prediction
Energy consumption = 191.722929 pJ
sum error= 140
Actual label: 3
Output voltages: [0.50328, 0.16322, 0.39346, 0.71628, 0.12544, 0.1711, 0.22147, 0.15873, 0.40016, 0.15654]
Predicted label: 3
Correct prediction
Energy consumption = 191.366972 pJ
sum error= 140
Actual label: 3
Output voltages: [0.32272, 0.2025, 0.28953, 0.75612, 0.15104, 0.23327, 0.14398, 0.25594, 0.43107, 0.20619]
Predicted label: 3
Correct prediction
Energy consumption = 173.011513 pJ
sum error= 140
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 345 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 345 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 345 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.63055, 0.27868, 0.20834, 0.23763, 0.1189, 0.12409, 0.37809, 0.23432, 0.43835, 0.25155]
Predicted label: 0
Correct prediction
Energy consumption = 203.593465 pJ
sum error= 140
Actual label: 7
Output voltages: [0.36206, 0.12286, 0.17313, 0.44811, 0.17569, 0.26604, 0.039041, 0.4107, 0.37416, 0.55349]
Predicted label: 9
Wrong prediction!
Energy consumption = 207.996689 pJ
sum error= 141
Actual label: 1
Output voltages: [0.26583, 0.73165, 0.34377, 0.26757, 0.33782, 0.041514, 0.31049, 0.18318, 0.22689, 0.2754]
Predicted label: 1
Correct prediction
Energy consumption = 213.382129 pJ
sum error= 141
Actual label: 7
Output voltages: [0.32905, 0.4295, 0.36663, 0.43985, 0.052479, 0.049194, 0.060153, 0.59292, 0.43938, 0.29607]
Predicted label: 7
Correct prediction
Energy consumption = 202.761425 pJ
sum error= 141
Actual label: 1
Output voltages: [0.21664, 0.76602, 0.25782, 0.28425, 0.20144, 0.11773, 0.36504, 0.13848, 0.33243, 0.22893]
Predicted label: 1
Correct prediction
Energy consumption = 207.829005 pJ
sum error= 141
Actual label: 1
Output voltages: [0.23499, 0.7692, 0.30885, 0.33898, 0.1731, 0.061479, 0.29174, 0.18875, 0.26274, 0.23868]
Predicted label: 1
Correct prediction
Energy consumption = 202.419134 pJ
sum error= 141
Actual label: 3
Output voltages: [0.2299, 0.13705, 0.22058, 0.65449, 0.16594, 0.38958, 0.13186, 0.25169, 0.59289, 0.28641]
Predicted label: 3
Correct prediction
Energy consumption = 182.094439 pJ
sum error= 141
Actual label: 1
Output voltages: [0.19081, 0.72564, 0.20424, 0.30944, 0.21027, 0.15828, 0.4959, 0.094366, 0.37942, 0.090664]
Predicted label: 1
Correct prediction
Energy consumption = 209.732214 pJ
sum error= 141
Actual label: 0
Output voltages: [0.73184, 0.24821, 0.23062, 0.21801, 0.13153, 0.15879, 0.4026, 0.17759, 0.27492, 0.31181]
Predicted label: 0
Correct prediction
Energy consumption = 194.922006 pJ
sum error= 141
Actual label: 9
Output voltages: [0.397, 0.061786, 0.21485, 0.22067, 0.40744, 0.20586, 0.097804, 0.23636, 0.2577, 0.66164]
Predicted label: 9
Correct prediction
Energy consumption = 193.523207 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 346 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 346 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 346 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29501, 0.1313, 0.26069, 0.29519, 0.40865, 0.11124, 0.35614, 0.10675, 0.29249, 0.54844]
Predicted label: 9
Correct prediction
Energy consumption = 199.543837 pJ
sum error= 141
Actual label: 7
Output voltages: [0.32245, 0.2106, 0.39872, 0.28086, 0.071993, 0.076884, 0.037607, 0.72285, 0.51811, 0.32638]
Predicted label: 7
Correct prediction
Energy consumption = 192.507854 pJ
sum error= 141
Actual label: 5
Output voltages: [0.22292, 0.097027, 0.11882, 0.34596, 0.20742, 0.679, 0.27927, 0.10277, 0.51773, 0.22982]
Predicted label: 5
Correct prediction
Energy consumption = 181.665957 pJ
sum error= 141
Actual label: 4
Output voltages: [0.10579, 0.15863, 0.2459, 0.16286, 0.75556, 0.077143, 0.21989, 0.26393, 0.26522, 0.20564]
Predicted label: 4
Correct prediction
Energy consumption = 191.539833 pJ
sum error= 141
Actual label: 1
Output voltages: [0.30816, 0.72132, 0.3461, 0.36274, 0.26512, 0.052763, 0.2427, 0.054447, 0.29256, 0.29931]
Predicted label: 1
Correct prediction
Energy consumption = 209.584013 pJ
sum error= 141
Actual label: 4
Output voltages: [0.19083, 0.21851, 0.25593, 0.19488, 0.74758, 0.16478, 0.21333, 0.21967, 0.21765, 0.39642]
Predicted label: 4
Correct prediction
Energy consumption = 198.280471 pJ
sum error= 141
Actual label: 8
Output voltages: [0.15008, 0.1618, 0.24344, 0.33855, 0.1556, 0.23977, 0.27556, 0.11466, 0.73089, 0.26978]
Predicted label: 8
Correct prediction
Energy consumption = 200.040225 pJ
sum error= 141
Actual label: 9
Output voltages: [0.31453, 0.15255, 0.21555, 0.19321, 0.24286, 0.11721, 0.052613, 0.17864, 0.47273, 0.65266]
Predicted label: 9
Correct prediction
Energy consumption = 187.597204 pJ
sum error= 141
Actual label: 5
Output voltages: [0.21138, 0.043713, 0.087161, 0.32344, 0.29816, 0.67018, 0.34234, 0.1924, 0.50473, 0.29886]
Predicted label: 5
Correct prediction
Energy consumption = 191.763619 pJ
sum error= 141
Actual label: 3
Output voltages: [0.2958, 0.17855, 0.3235, 0.75073, 0.17095, 0.11312, 0.13055, 0.22347, 0.45192, 0.25119]
Predicted label: 3
Correct prediction
Energy consumption = 184.124596 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 347 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 347 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 347 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25432, 0.049892, 0.13268, 0.33879, 0.18213, 0.71528, 0.32298, 0.13529, 0.5334, 0.19767]
Predicted label: 5
Correct prediction
Energy consumption = 200.131425 pJ
sum error= 141
Actual label: 1
Output voltages: [0.23814, 0.74052, 0.21456, 0.27892, 0.37466, 0.057994, 0.28036, 0.0821, 0.31727, 0.29901]
Predicted label: 1
Correct prediction
Energy consumption = 215.753420 pJ
sum error= 141
Actual label: 9
Output voltages: [0.38512, 0.10213, 0.21691, 0.209, 0.33778, 0.20736, 0.1788, 0.25335, 0.32936, 0.71072]
Predicted label: 9
Correct prediction
Energy consumption = 194.999223 pJ
sum error= 141
Actual label: 8
Output voltages: [0.35762, 0.15357, 0.32037, 0.37997, 0.10328, 0.17983, 0.13404, 0.076006, 0.72199, 0.3747]
Predicted label: 8
Correct prediction
Energy consumption = 190.945156 pJ
sum error= 141
Actual label: 2
Output voltages: [0.29346, 0.48919, 0.67681, 0.33245, 0.26439, 0.020219, 0.20052, 0.26321, 0.21525, 0.19337]
Predicted label: 2
Correct prediction
Energy consumption = 195.725128 pJ
sum error= 141
Actual label: 3
Output voltages: [0.33156, 0.24732, 0.28538, 0.71973, 0.077644, 0.098336, 0.04372, 0.51267, 0.39673, 0.33178]
Predicted label: 3
Correct prediction
Energy consumption = 183.842906 pJ
sum error= 141
Actual label: 3
Output voltages: [0.276, 0.27889, 0.31264, 0.74931, 0.10924, 0.16069, 0.119, 0.19222, 0.45048, 0.25201]
Predicted label: 3
Correct prediction
Energy consumption = 183.164183 pJ
sum error= 141
Actual label: 9
Output voltages: [0.36448, 0.1103, 0.21, 0.15689, 0.33964, 0.1775, 0.086008, 0.16099, 0.44642, 0.65513]
Predicted label: 9
Correct prediction
Energy consumption = 182.818166 pJ
sum error= 141
Actual label: 9
Output voltages: [0.39167, 0.081059, 0.25626, 0.23599, 0.28188, 0.18809, 0.18895, 0.20806, 0.37363, 0.66907]
Predicted label: 9
Correct prediction
Energy consumption = 190.275211 pJ
sum error= 141
Actual label: 0
Output voltages: [0.71359, 0.33038, 0.31935, 0.21333, 0.055298, 0.16787, 0.36118, 0.13092, 0.3265, 0.29879]
Predicted label: 0
Correct prediction
Energy consumption = 191.589061 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 348 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 348 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 348 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17211, 0.74653, 0.21149, 0.28338, 0.26566, 0.075157, 0.39295, 0.088515, 0.38762, 0.22246]
Predicted label: 1
Correct prediction
Energy consumption = 213.806373 pJ
sum error= 141
Actual label: 0
Output voltages: [0.71501, 0.24051, 0.21816, 0.15827, 0.25137, 0.11734, 0.4981, 0.17438, 0.29355, 0.26296]
Predicted label: 0
Correct prediction
Energy consumption = 201.801912 pJ
sum error= 141
Actual label: 2
Output voltages: [0.33286, 0.36897, 0.74395, 0.27702, 0.13734, 0.031182, 0.28992, 0.22604, 0.3321, 0.19183]
Predicted label: 2
Correct prediction
Energy consumption = 188.563273 pJ
sum error= 141
Actual label: 9
Output voltages: [0.42218, 0.10969, 0.20596, 0.28774, 0.39021, 0.18892, 0.18213, 0.29774, 0.23173, 0.64696]
Predicted label: 9
Correct prediction
Energy consumption = 198.334147 pJ
sum error= 141
Actual label: 3
Output voltages: [0.29201, 0.16613, 0.34553, 0.74991, 0.16232, 0.20281, 0.10589, 0.15232, 0.5187, 0.18539]
Predicted label: 3
Correct prediction
Energy consumption = 180.066194 pJ
sum error= 141
Actual label: 9
Output voltages: [0.34072, 0.071817, 0.22528, 0.26216, 0.30682, 0.23388, 0.12599, 0.25645, 0.41803, 0.64686]
Predicted label: 9
Correct prediction
Energy consumption = 190.032213 pJ
sum error= 141
Actual label: 3
Output voltages: [0.41075, 0.13594, 0.2365, 0.75964, 0.15265, 0.26631, 0.15219, 0.20051, 0.4174, 0.22086]
Predicted label: 3
Correct prediction
Energy consumption = 185.612001 pJ
sum error= 141
Actual label: 3
Output voltages: [0.42216, 0.20611, 0.33367, 0.75898, 0.14947, 0.1525, 0.15328, 0.18954, 0.38678, 0.23319]
Predicted label: 3
Correct prediction
Energy consumption = 182.048531 pJ
sum error= 141
Actual label: 6
Output voltages: [0.24665, 0.10936, 0.28833, 0.076564, 0.39299, 0.27588, 0.68631, 0.046495, 0.45353, 0.16528]
Predicted label: 6
Correct prediction
Energy consumption = 188.160008 pJ
sum error= 141
Actual label: 2
Output voltages: [0.27186, 0.3468, 0.70223, 0.33154, 0.19667, 0.039175, 0.30244, 0.14435, 0.43812, 0.18033]
Predicted label: 2
Correct prediction
Energy consumption = 182.379633 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 349 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 349 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 349 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.14737, 0.27407, 0.24385, 0.15041, 0.70499, 0.15967, 0.20319, 0.20967, 0.31216, 0.39077]
Predicted label: 4
Correct prediction
Energy consumption = 207.562173 pJ
sum error= 141
Actual label: 9
Output voltages: [0.41788, 0.12205, 0.17729, 0.22441, 0.40413, 0.22316, 0.12484, 0.29639, 0.25375, 0.68741]
Predicted label: 9
Correct prediction
Energy consumption = 192.504531 pJ
sum error= 141
Actual label: 8
Output voltages: [0.46199, 0.15082, 0.22997, 0.41672, 0.15539, 0.16876, 0.27151, 0.058935, 0.6095, 0.36862]
Predicted label: 8
Correct prediction
Energy consumption = 207.734011 pJ
sum error= 141
Actual label: 3
Output voltages: [0.30307, 0.17675, 0.33511, 0.75405, 0.20428, 0.18506, 0.21228, 0.127, 0.40886, 0.2277]
Predicted label: 3
Correct prediction
Energy consumption = 180.241899 pJ
sum error= 141
Actual label: 7
Output voltages: [0.30462, 0.35859, 0.47699, 0.33724, 0.083261, 0.049405, 0.053284, 0.69761, 0.3396, 0.33276]
Predicted label: 7
Correct prediction
Energy consumption = 196.171037 pJ
sum error= 141
Actual label: 4
Output voltages: [0.17559, 0.1866, 0.28168, 0.16744, 0.75411, 0.079241, 0.27415, 0.23293, 0.22418, 0.2822]
Predicted label: 4
Correct prediction
Energy consumption = 199.557201 pJ
sum error= 141
Actual label: 0
Output voltages: [0.73349, 0.19677, 0.21098, 0.20096, 0.19491, 0.16386, 0.44425, 0.12361, 0.32567, 0.32911]
Predicted label: 0
Correct prediction
Energy consumption = 201.490744 pJ
sum error= 141
Actual label: 4
Output voltages: [0.20302, 0.11882, 0.29459, 0.12444, 0.75574, 0.084673, 0.34431, 0.21643, 0.22085, 0.32802]
Predicted label: 4
Correct prediction
Energy consumption = 198.281470 pJ
sum error= 141
Actual label: 7
Output voltages: [0.45996, 0.17188, 0.23551, 0.21842, 0.14736, 0.18823, 0.09262, 0.73146, 0.3066, 0.42541]
Predicted label: 7
Correct prediction
Energy consumption = 205.803840 pJ
sum error= 141
Actual label: 8
Output voltages: [0.24319, 0.25846, 0.28986, 0.23407, 0.18855, 0.1121, 0.19945, 0.10883, 0.73434, 0.36316]
Predicted label: 8
Correct prediction
Energy consumption = 194.608927 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 350 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 350 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 350 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19575, 0.13243, 0.3231, 0.12932, 0.74951, 0.12046, 0.2678, 0.20442, 0.26038, 0.33114]
Predicted label: 4
Correct prediction
Energy consumption = 195.441709 pJ
sum error= 141
Actual label: 9
Output voltages: [0.37751, 0.13152, 0.17922, 0.26293, 0.33033, 0.21709, 0.076525, 0.3, 0.33745, 0.69311]
Predicted label: 9
Correct prediction
Energy consumption = 192.984466 pJ
sum error= 141
Actual label: 8
Output voltages: [0.18312, 0.15374, 0.26837, 0.30287, 0.17288, 0.27653, 0.22986, 0.095107, 0.74298, 0.33094]
Predicted label: 8
Correct prediction
Energy consumption = 195.281869 pJ
sum error= 141
Actual label: 9
Output voltages: [0.078674, 0.47413, 0.23349, 0.12411, 0.35951, 0.15519, 0.21895, 0.19742, 0.3941, 0.34587]
Predicted label: 1
Wrong prediction!
Energy consumption = 213.522989 pJ
sum error= 142
Actual label: 9
Output voltages: [0.29743, 0.20688, 0.19046, 0.38619, 0.3685, 0.060397, 0.070857, 0.13834, 0.33169, 0.641]
Predicted label: 9
Correct prediction
Energy consumption = 194.512940 pJ
sum error= 142
Actual label: 7
Output voltages: [0.27749, 0.30727, 0.31319, 0.35038, 0.068091, 0.056233, 0.044421, 0.68921, 0.39097, 0.42468]
Predicted label: 7
Correct prediction
Energy consumption = 200.242560 pJ
sum error= 142
Actual label: 5
Output voltages: [0.21142, 0.056524, 0.059162, 0.36964, 0.29949, 0.72173, 0.40724, 0.15355, 0.4677, 0.18493]
Predicted label: 5
Correct prediction
Energy consumption = 189.799589 pJ
sum error= 142
Actual label: 9
Output voltages: [0.35905, 0.12992, 0.22791, 0.21165, 0.2429, 0.19494, 0.15821, 0.23575, 0.37947, 0.6788]
Predicted label: 9
Correct prediction
Energy consumption = 190.995710 pJ
sum error= 142
Actual label: 2
Output voltages: [0.35405, 0.31482, 0.73554, 0.34863, 0.15473, 0.030289, 0.26882, 0.25227, 0.37661, 0.232]
Predicted label: 2
Correct prediction
Energy consumption = 194.284961 pJ
sum error= 142
Actual label: 8
Output voltages: [0.29644, 0.14763, 0.32549, 0.24729, 0.10815, 0.21925, 0.24042, 0.13423, 0.72022, 0.32724]
Predicted label: 8
Correct prediction
Energy consumption = 186.897442 pJ
sum error= 142
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 351 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 351 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 351 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36251, 0.37886, 0.70814, 0.35056, 0.13749, 0.02341, 0.31631, 0.19171, 0.34768, 0.20344]
Predicted label: 2
Correct prediction
Energy consumption = 192.037788 pJ
sum error= 142
Actual label: 2
Output voltages: [0.41238, 0.15711, 0.62903, 0.43738, 0.076629, 0.042397, 0.13123, 0.38379, 0.44096, 0.18156]
Predicted label: 2
Correct prediction
Energy consumption = 192.705673 pJ
sum error= 142
Actual label: 0
Output voltages: [0.72587, 0.2543, 0.22957, 0.18616, 0.15196, 0.16144, 0.36447, 0.18818, 0.34355, 0.34304]
Predicted label: 0
Correct prediction
Energy consumption = 195.630588 pJ
sum error= 142
Actual label: 2
Output voltages: [0.31382, 0.24057, 0.74716, 0.31137, 0.125, 0.036108, 0.22987, 0.33455, 0.41904, 0.18468]
Predicted label: 2
Correct prediction
Energy consumption = 183.268410 pJ
sum error= 142
Actual label: 2
Output voltages: [0.35075, 0.28215, 0.73401, 0.35403, 0.1331, 0.035514, 0.32108, 0.20049, 0.46716, 0.19311]
Predicted label: 2
Correct prediction
Energy consumption = 182.646212 pJ
sum error= 142
Actual label: 3
Output voltages: [0.33971, 0.1671, 0.32708, 0.75745, 0.17719, 0.16545, 0.1801, 0.15229, 0.39169, 0.2302]
Predicted label: 3
Correct prediction
Energy consumption = 187.092885 pJ
sum error= 142
Actual label: 8
Output voltages: [0.20259, 0.13737, 0.24105, 0.39306, 0.13762, 0.20541, 0.22976, 0.081599, 0.69577, 0.30136]
Predicted label: 8
Correct prediction
Energy consumption = 194.666773 pJ
sum error= 142
Actual label: 4
Output voltages: [0.14385, 0.20106, 0.24588, 0.091179, 0.75271, 0.29553, 0.31711, 0.19051, 0.27034, 0.32791]
Predicted label: 4
Correct prediction
Energy consumption = 191.879918 pJ
sum error= 142
Actual label: 6
Output voltages: [0.31215, 0.17671, 0.23706, 0.15189, 0.32023, 0.41231, 0.72997, 0.067553, 0.40945, 0.18879]
Predicted label: 6
Correct prediction
Energy consumption = 185.961935 pJ
sum error= 142
Actual label: 8
Output voltages: [0.23767, 0.17763, 0.24106, 0.39638, 0.1129, 0.2523, 0.34509, 0.11388, 0.71811, 0.25388]
Predicted label: 8
Correct prediction
Energy consumption = 194.716663 pJ
sum error= 142
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 352 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 352 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 352 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.13486, 0.10505, 0.26417, 0.11154, 0.61725, 0.26197, 0.4438, 0.2166, 0.37246, 0.29242]
Predicted label: 4
Wrong prediction!
Energy consumption = 184.305293 pJ
sum error= 143
Actual label: 8
Output voltages: [0.29872, 0.10035, 0.3141, 0.30504, 0.13344, 0.31853, 0.20574, 0.072682, 0.72684, 0.28814]
Predicted label: 8
Correct prediction
Energy consumption = 197.188608 pJ
sum error= 143
Actual label: 2
Output voltages: [0.32659, 0.43804, 0.70815, 0.32008, 0.14045, 0.031697, 0.29124, 0.20422, 0.36693, 0.2239]
Predicted label: 2
Correct prediction
Energy consumption = 191.995022 pJ
sum error= 143
Actual label: 4
Output voltages: [0.22181, 0.21853, 0.28367, 0.14014, 0.7417, 0.048876, 0.29024, 0.31978, 0.16975, 0.27897]
Predicted label: 4
Correct prediction
Energy consumption = 205.566402 pJ
sum error= 143
Actual label: 6
Output voltages: [0.24978, 0.14534, 0.24225, 0.095065, 0.36999, 0.32061, 0.70313, 0.078495, 0.40763, 0.18921]
Predicted label: 6
Correct prediction
Energy consumption = 186.806008 pJ
sum error= 143
Actual label: 7
Output voltages: [0.29833, 0.1664, 0.55015, 0.23074, 0.056405, 0.052477, 0.086239, 0.63942, 0.53727, 0.23906]
Predicted label: 7
Correct prediction
Energy consumption = 190.865601 pJ
sum error= 143
Actual label: 9
Output voltages: [0.36071, 0.14928, 0.22012, 0.27988, 0.33775, 0.16836, 0.20969, 0.15526, 0.34853, 0.71816]
Predicted label: 9
Correct prediction
Energy consumption = 195.386365 pJ
sum error= 143
Actual label: 3
Output voltages: [0.33435, 0.17931, 0.30003, 0.75281, 0.16917, 0.21778, 0.22118, 0.17765, 0.34251, 0.17621]
Predicted label: 3
Correct prediction
Energy consumption = 188.919022 pJ
sum error= 143
Actual label: 3
Output voltages: [0.42283, 0.10554, 0.31661, 0.75018, 0.15547, 0.18381, 0.15936, 0.2029, 0.40014, 0.23254]
Predicted label: 3
Correct prediction
Energy consumption = 184.897214 pJ
sum error= 143
Actual label: 9
Output voltages: [0.32174, 0.098899, 0.18137, 0.22571, 0.39718, 0.17127, 0.1023, 0.38692, 0.33779, 0.56851]
Predicted label: 9
Correct prediction
Energy consumption = 199.875709 pJ
sum error= 143
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 353 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 353 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 353 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.18811, 0.28241, 0.21205, 0.13914, 0.72912, 0.1128, 0.36375, 0.1746, 0.20348, 0.34214]
Predicted label: 4
Correct prediction
Energy consumption = 215.027411 pJ
sum error= 143
Actual label: 3
Output voltages: [0.29841, 0.18282, 0.23962, 0.73982, 0.14513, 0.31642, 0.14908, 0.11808, 0.48364, 0.21343]
Predicted label: 3
Correct prediction
Energy consumption = 187.653910 pJ
sum error= 143
Actual label: 1
Output voltages: [0.20888, 0.756, 0.20466, 0.4961, 0.082406, 0.24542, 0.26781, 0.18996, 0.25373, 0.2564]
Predicted label: 1
Correct prediction
Energy consumption = 211.554690 pJ
sum error= 143
Actual label: 4
Output voltages: [0.31746, 0.17757, 0.25569, 0.3162, 0.61952, 0.17485, 0.15154, 0.20565, 0.14801, 0.44168]
Predicted label: 4
Correct prediction
Energy consumption = 200.686840 pJ
sum error= 143
Actual label: 4
Output voltages: [0.20699, 0.19203, 0.25361, 0.046345, 0.6451, 0.11095, 0.43037, 0.19513, 0.41584, 0.16037]
Predicted label: 4
Correct prediction
Energy consumption = 190.484642 pJ
sum error= 143
Actual label: 7
Output voltages: [0.37373, 0.225, 0.087491, 0.21177, 0.23916, 0.28428, 0.053502, 0.75602, 0.3341, 0.40523]
Predicted label: 7
Correct prediction
Energy consumption = 198.796653 pJ
sum error= 143
Actual label: 0
Output voltages: [0.73121, 0.29492, 0.15625, 0.33179, 0.17607, 0.18409, 0.43954, 0.086701, 0.2972, 0.28608]
Predicted label: 0
Correct prediction
Energy consumption = 201.393825 pJ
sum error= 143
Actual label: 5
Output voltages: [0.23419, 0.13452, 0.13316, 0.40127, 0.12008, 0.63632, 0.20904, 0.068008, 0.59473, 0.18906]
Predicted label: 5
Correct prediction
Energy consumption = 191.004929 pJ
sum error= 143
Actual label: 9
Output voltages: [0.38425, 0.12693, 0.25259, 0.25294, 0.27469, 0.13206, 0.093391, 0.24166, 0.37726, 0.68072]
Predicted label: 9
Correct prediction
Energy consumption = 196.598280 pJ
sum error= 143
Actual label: 6
Output voltages: [0.29999, 0.20525, 0.29624, 0.17964, 0.26841, 0.31665, 0.72873, 0.04743, 0.44324, 0.24519]
Predicted label: 6
Correct prediction
Energy consumption = 188.266874 pJ
sum error= 143
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 354 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 354 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 354 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.67201, 0.090516, 0.31095, 0.14329, 0.21555, 0.1291, 0.41686, 0.15185, 0.24113, 0.39328]
Predicted label: 0
Correct prediction
Energy consumption = 189.822020 pJ
sum error= 143
Actual label: 4
Output voltages: [0.19968, 0.086946, 0.31191, 0.15376, 0.73959, 0.087722, 0.29138, 0.27723, 0.26512, 0.23491]
Predicted label: 4
Correct prediction
Energy consumption = 199.973233 pJ
sum error= 143
Actual label: 4
Output voltages: [0.22245, 0.16559, 0.44083, 0.060462, 0.71607, 0.12111, 0.3608, 0.1488, 0.34432, 0.27454]
Predicted label: 4
Correct prediction
Energy consumption = 190.925444 pJ
sum error= 143
Actual label: 4
Output voltages: [0.15657, 0.1932, 0.20661, 0.20644, 0.73806, 0.26579, 0.41441, 0.1866, 0.17673, 0.21087]
Predicted label: 4
Correct prediction
Energy consumption = 187.881720 pJ
sum error= 143
Actual label: 4
Output voltages: [0.14822, 0.16425, 0.2636, 0.14138, 0.73851, 0.092422, 0.28555, 0.25319, 0.23721, 0.25217]
Predicted label: 4
Correct prediction
Energy consumption = 185.732515 pJ
sum error= 143
Actual label: 6
Output voltages: [0.27628, 0.27872, 0.29809, 0.11922, 0.28392, 0.37922, 0.74757, 0.1007, 0.35289, 0.18249]
Predicted label: 6
Correct prediction
Energy consumption = 191.689869 pJ
sum error= 143
Actual label: 1
Output voltages: [0.24618, 0.76996, 0.19826, 0.27777, 0.16991, 0.13122, 0.39469, 0.070983, 0.33479, 0.26505]
Predicted label: 1
Correct prediction
Energy consumption = 208.210897 pJ
sum error= 143
Actual label: 2
Output voltages: [0.44315, 0.06911, 0.65524, 0.50016, 0.11458, 0.053619, 0.20453, 0.24379, 0.44722, 0.18705]
Predicted label: 2
Correct prediction
Energy consumption = 188.905422 pJ
sum error= 143
Actual label: 3
Output voltages: [0.3589, 0.24475, 0.32434, 0.76258, 0.10895, 0.21092, 0.12022, 0.2446, 0.4045, 0.18167]
Predicted label: 3
Correct prediction
Energy consumption = 188.401074 pJ
sum error= 143
Actual label: 3
Output voltages: [0.34667, 0.067929, 0.50245, 0.50073, 0.14952, 0.054881, 0.19155, 0.17132, 0.58446, 0.16302]
Predicted label: 8
Wrong prediction!
Energy consumption = 182.954235 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 355 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 355 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 355 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.36988, 0.089138, 0.065984, 0.26421, 0.20761, 0.57794, 0.5784, 0.13855, 0.43909, 0.18934]
Predicted label: 6
Correct prediction
Energy consumption = 196.439528 pJ
sum error= 144
Actual label: 4
Output voltages: [0.11613, 0.18452, 0.26036, 0.23326, 0.74665, 0.045844, 0.15711, 0.26805, 0.24772, 0.23806]
Predicted label: 4
Correct prediction
Energy consumption = 198.820812 pJ
sum error= 144
Actual label: 5
Output voltages: [0.34496, 0.085341, 0.038933, 0.41923, 0.18027, 0.73133, 0.27539, 0.21207, 0.47089, 0.20958]
Predicted label: 5
Correct prediction
Energy consumption = 197.885577 pJ
sum error= 144
Actual label: 9
Output voltages: [0.32407, 0.14488, 0.18526, 0.33946, 0.29795, 0.12238, 0.086974, 0.23578, 0.33697, 0.68208]
Predicted label: 9
Correct prediction
Energy consumption = 187.937151 pJ
sum error= 144
Actual label: 6
Output voltages: [0.295, 0.2201, 0.23166, 0.16523, 0.33351, 0.36037, 0.742, 0.099171, 0.38755, 0.13044]
Predicted label: 6
Correct prediction
Energy consumption = 195.869600 pJ
sum error= 144
Actual label: 8
Output voltages: [0.33787, 0.17899, 0.3017, 0.38621, 0.13287, 0.2411, 0.26573, 0.063134, 0.7226, 0.26035]
Predicted label: 8
Correct prediction
Energy consumption = 196.174205 pJ
sum error= 144
Actual label: 5
Output voltages: [0.34093, 0.056701, 0.055153, 0.23152, 0.21609, 0.68342, 0.35869, 0.23435, 0.57209, 0.15433]
Predicted label: 5
Correct prediction
Energy consumption = 186.332411 pJ
sum error= 144
Actual label: 6
Output voltages: [0.36987, 0.30721, 0.26727, 0.17706, 0.2213, 0.23361, 0.66882, 0.079332, 0.48272, 0.093437]
Predicted label: 6
Correct prediction
Energy consumption = 194.715109 pJ
sum error= 144
Actual label: 5
Output voltages: [0.65673, 0.070042, 0.21862, 0.32193, 0.18932, 0.27848, 0.37383, 0.26139, 0.19971, 0.1873]
Predicted label: 0
Wrong prediction!
Energy consumption = 206.557642 pJ
sum error= 145
Actual label: 8
Output voltages: [0.49408, 0.2992, 0.14035, 0.34779, 0.045146, 0.42083, 0.39584, 0.17715, 0.53659, 0.057926]
Predicted label: 8
Correct prediction
Energy consumption = 190.800522 pJ
sum error= 145
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 356 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 356 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 356 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.25955, 0.18593, 0.25175, 0.14741, 0.33993, 0.37885, 0.73111, 0.10899, 0.38102, 0.14349]
Predicted label: 6
Correct prediction
Energy consumption = 196.255546 pJ
sum error= 145
Actual label: 4
Output voltages: [0.17217, 0.18273, 0.27456, 0.20722, 0.73768, 0.046894, 0.20301, 0.22442, 0.25339, 0.34152]
Predicted label: 4
Correct prediction
Energy consumption = 207.972338 pJ
sum error= 145
Actual label: 1
Output voltages: [0.10709, 0.75474, 0.26522, 0.13657, 0.25563, 0.13933, 0.43412, 0.16491, 0.41289, 0.17138]
Predicted label: 1
Correct prediction
Energy consumption = 202.415731 pJ
sum error= 145
Actual label: 8
Output voltages: [0.23808, 0.10384, 0.24855, 0.41001, 0.18383, 0.24973, 0.15689, 0.14593, 0.72032, 0.25489]
Predicted label: 8
Correct prediction
Energy consumption = 193.804709 pJ
sum error= 145
Actual label: 6
Output voltages: [0.38746, 0.26004, 0.1674, 0.21936, 0.31392, 0.344, 0.69194, 0.078169, 0.45776, 0.092961]
Predicted label: 6
Correct prediction
Energy consumption = 192.434634 pJ
sum error= 145
Actual label: 5
Output voltages: [0.27236, 0.049696, 0.163, 0.44377, 0.18334, 0.64131, 0.32316, 0.17497, 0.55354, 0.21507]
Predicted label: 5
Correct prediction
Energy consumption = 197.535103 pJ
sum error= 145
Actual label: 2
Output voltages: [0.36851, 0.38604, 0.74049, 0.28324, 0.17403, 0.023027, 0.33845, 0.22896, 0.34341, 0.26306]
Predicted label: 2
Correct prediction
Energy consumption = 187.986025 pJ
sum error= 145
Actual label: 8
Output voltages: [0.27792, 0.18282, 0.1695, 0.17576, 0.20081, 0.37184, 0.27012, 0.23885, 0.66864, 0.1365]
Predicted label: 8
Correct prediction
Energy consumption = 198.363986 pJ
sum error= 145
Actual label: 4
Output voltages: [0.23964, 0.16859, 0.33749, 0.15186, 0.74142, 0.060838, 0.35377, 0.26956, 0.15944, 0.25999]
Predicted label: 4
Correct prediction
Energy consumption = 202.645122 pJ
sum error= 145
Actual label: 5
Output voltages: [0.2527, 0.057285, 0.12299, 0.34622, 0.21747, 0.74883, 0.24392, 0.28669, 0.53585, 0.24722]
Predicted label: 5
Correct prediction
Energy consumption = 186.706173 pJ
sum error= 145
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 357 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 357 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 357 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.29201, 0.061295, 0.14604, 0.36893, 0.13641, 0.65869, 0.24241, 0.10248, 0.58293, 0.23783]
Predicted label: 5
Correct prediction
Energy consumption = 188.489824 pJ
sum error= 145
Actual label: 4
Output voltages: [0.16148, 0.25847, 0.1778, 0.2073, 0.67186, 0.20743, 0.37261, 0.21663, 0.21603, 0.34183]
Predicted label: 4
Correct prediction
Energy consumption = 198.290046 pJ
sum error= 145
Actual label: 7
Output voltages: [0.26274, 0.24129, 0.36499, 0.27, 0.10331, 0.039539, 0.038562, 0.74499, 0.42224, 0.29832]
Predicted label: 7
Correct prediction
Energy consumption = 194.527515 pJ
sum error= 145
Actual label: 7
Output voltages: [0.27217, 0.11876, 0.44744, 0.41945, 0.26323, 0.031875, 0.048985, 0.54075, 0.39875, 0.21165]
Predicted label: 7
Correct prediction
Energy consumption = 185.573169 pJ
sum error= 145
Actual label: 0
Output voltages: [0.72784, 0.23631, 0.20469, 0.21383, 0.11363, 0.22604, 0.27504, 0.18405, 0.32064, 0.40261]
Predicted label: 0
Correct prediction
Energy consumption = 199.698038 pJ
sum error= 145
Actual label: 7
Output voltages: [0.22538, 0.16257, 0.29979, 0.21708, 0.11967, 0.15287, 0.06045, 0.73315, 0.50531, 0.27164]
Predicted label: 7
Correct prediction
Energy consumption = 183.668994 pJ
sum error= 145
Actual label: 8
Output voltages: [0.14431, 0.18036, 0.22103, 0.2469, 0.19304, 0.18521, 0.13918, 0.18388, 0.73204, 0.38115]
Predicted label: 8
Correct prediction
Energy consumption = 196.188256 pJ
sum error= 145
Actual label: 2
Output voltages: [0.37391, 0.3362, 0.71939, 0.33195, 0.12674, 0.034869, 0.34945, 0.15966, 0.41598, 0.21326]
Predicted label: 2
Correct prediction
Energy consumption = 189.331237 pJ
sum error= 145
Actual label: 2
Output voltages: [0.46302, 0.33419, 0.65428, 0.27228, 0.069428, 0.026537, 0.31553, 0.38575, 0.36757, 0.21669]
Predicted label: 2
Correct prediction
Energy consumption = 182.081043 pJ
sum error= 145
Actual label: 3
Output voltages: [0.43952, 0.11885, 0.36108, 0.74532, 0.19318, 0.14526, 0.13685, 0.16752, 0.43859, 0.19458]
Predicted label: 3
Correct prediction
Energy consumption = 181.607470 pJ
sum error= 145
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 358 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 358 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 358 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30158, 0.31656, 0.434, 0.36974, 0.05065, 0.056171, 0.047841, 0.63334, 0.48467, 0.27905]
Predicted label: 7
Correct prediction
Energy consumption = 196.764492 pJ
sum error= 145
Actual label: 0
Output voltages: [0.72747, 0.24498, 0.24613, 0.23287, 0.15527, 0.12765, 0.40074, 0.20645, 0.30016, 0.33463]
Predicted label: 0
Correct prediction
Energy consumption = 204.050379 pJ
sum error= 145
Actual label: 1
Output voltages: [0.1924, 0.75255, 0.2261, 0.28957, 0.26535, 0.13988, 0.27946, 0.12264, 0.27436, 0.30968]
Predicted label: 1
Correct prediction
Energy consumption = 212.887984 pJ
sum error= 145
Actual label: 8
Output voltages: [0.16102, 0.27148, 0.22324, 0.33861, 0.11127, 0.28094, 0.10398, 0.2569, 0.7439, 0.26965]
Predicted label: 8
Correct prediction
Energy consumption = 195.100245 pJ
sum error= 145
Actual label: 0
Output voltages: [0.74425, 0.29763, 0.24457, 0.18415, 0.15316, 0.21513, 0.38957, 0.18378, 0.25513, 0.27051]
Predicted label: 0
Correct prediction
Energy consumption = 194.495408 pJ
sum error= 145
Actual label: 7
Output voltages: [0.39022, 0.24805, 0.21037, 0.35637, 0.071894, 0.089128, 0.048526, 0.69974, 0.31967, 0.41188]
Predicted label: 7
Correct prediction
Energy consumption = 206.454081 pJ
sum error= 145
Actual label: 1
Output voltages: [0.18829, 0.74461, 0.30953, 0.28914, 0.14788, 0.097032, 0.38351, 0.08932, 0.40734, 0.21691]
Predicted label: 1
Correct prediction
Energy consumption = 198.249600 pJ
sum error= 145
Actual label: 9
Output voltages: [0.34676, 0.089865, 0.18844, 0.2496, 0.26994, 0.20777, 0.061213, 0.34751, 0.44081, 0.63561]
Predicted label: 9
Correct prediction
Energy consumption = 190.406449 pJ
sum error= 145
Actual label: 8
Output voltages: [0.2169, 0.20906, 0.26983, 0.4035, 0.083578, 0.25661, 0.24355, 0.10055, 0.74652, 0.29044]
Predicted label: 8
Correct prediction
Energy consumption = 193.740009 pJ
sum error= 145
Actual label: 7
Output voltages: [0.29585, 0.27563, 0.23457, 0.31792, 0.15998, 0.094109, 0.053975, 0.75458, 0.19744, 0.39346]
Predicted label: 7
Correct prediction
Energy consumption = 199.821331 pJ
sum error= 145
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 359 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 359 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 359 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24519, 0.099446, 0.08023, 0.42834, 0.20067, 0.74967, 0.25734, 0.18063, 0.50839, 0.24299]
Predicted label: 5
Correct prediction
Energy consumption = 194.126150 pJ
sum error= 145
Actual label: 5
Output voltages: [0.283, 0.05283, 0.19354, 0.32348, 0.18647, 0.52891, 0.16432, 0.1886, 0.61452, 0.34034]
Predicted label: 8
Wrong prediction!
Energy consumption = 186.348149 pJ
sum error= 146
Actual label: 9
Output voltages: [0.34341, 0.12208, 0.24338, 0.26592, 0.23985, 0.22254, 0.090402, 0.31589, 0.35321, 0.64625]
Predicted label: 9
Correct prediction
Energy consumption = 198.836654 pJ
sum error= 146
Actual label: 1
Output voltages: [0.28331, 0.71528, 0.24795, 0.15856, 0.35417, 0.07926, 0.32231, 0.1028, 0.31337, 0.30415]
Predicted label: 1
Correct prediction
Energy consumption = 202.174838 pJ
sum error= 146
Actual label: 7
Output voltages: [0.33586, 0.25147, 0.14228, 0.28911, 0.14609, 0.1378, 0.035125, 0.74495, 0.33235, 0.39233]
Predicted label: 7
Correct prediction
Energy consumption = 202.652050 pJ
sum error= 146
Actual label: 5
Output voltages: [0.30731, 0.065578, 0.041654, 0.33423, 0.24852, 0.73884, 0.23042, 0.14494, 0.51951, 0.19131]
Predicted label: 5
Correct prediction
Energy consumption = 185.147110 pJ
sum error= 146
Actual label: 4
Output voltages: [0.11678, 0.16725, 0.29146, 0.11331, 0.75166, 0.13652, 0.26404, 0.23187, 0.27717, 0.34944]
Predicted label: 4
Correct prediction
Energy consumption = 194.957616 pJ
sum error= 146
Actual label: 9
Output voltages: [0.31656, 0.20089, 0.34157, 0.50539, 0.19032, 0.33514, 0.14031, 0.16871, 0.46914, 0.25385]
Predicted label: 3
Wrong prediction!
Energy consumption = 209.460797 pJ
sum error= 147
Actual label: 1
Output voltages: [0.19138, 0.6098, 0.24575, 0.31144, 0.37633, 0.15975, 0.31292, 0.112, 0.25882, 0.24598]
Predicted label: 1
Correct prediction
Energy consumption = 212.741170 pJ
sum error= 147
Actual label: 2
Output voltages: [0.42447, 0.40619, 0.64278, 0.29611, 0.088935, 0.025893, 0.19603, 0.37716, 0.29589, 0.17605]
Predicted label: 2
Correct prediction
Energy consumption = 197.694438 pJ
sum error= 147
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 360 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 360 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 360 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36753, 0.36097, 0.69393, 0.29418, 0.12348, 0.024891, 0.31886, 0.18653, 0.37576, 0.22196]
Predicted label: 2
Correct prediction
Energy consumption = 189.651739 pJ
sum error= 147
Actual label: 1
Output voltages: [0.24601, 0.45061, 0.2037, 0.21322, 0.36884, 0.35923, 0.63947, 0.04662, 0.3051, 0.12512]
Predicted label: 6
Wrong prediction!
Energy consumption = 210.790088 pJ
sum error= 148
Actual label: 6
Output voltages: [0.29106, 0.20827, 0.33867, 0.06098, 0.37134, 0.31178, 0.74573, 0.06016, 0.35458, 0.1402]
Predicted label: 6
Correct prediction
Energy consumption = 185.708807 pJ
sum error= 148
Actual label: 6
Output voltages: [0.28325, 0.22359, 0.36193, 0.071804, 0.2811, 0.3229, 0.74242, 0.071081, 0.44528, 0.143]
Predicted label: 6
Correct prediction
Energy consumption = 178.773001 pJ
sum error= 148
Actual label: 7
Output voltages: [0.57462, 0.10225, 0.34519, 0.15338, 0.18999, 0.1664, 0.26594, 0.68434, 0.37934, 0.08457]
Predicted label: 7
Correct prediction
Energy consumption = 189.226916 pJ
sum error= 148
Actual label: 1
Output voltages: [0.20864, 0.73867, 0.23152, 0.24897, 0.21127, 0.089298, 0.4084, 0.052914, 0.39753, 0.19298]
Predicted label: 1
Correct prediction
Energy consumption = 210.145968 pJ
sum error= 148
Actual label: 1
Output voltages: [0.13136, 0.75891, 0.17772, 0.18119, 0.12807, 0.15535, 0.40373, 0.14557, 0.45896, 0.24331]
Predicted label: 1
Correct prediction
Energy consumption = 204.693446 pJ
sum error= 148
Actual label: 4
Output voltages: [0.18699, 0.12322, 0.26201, 0.21102, 0.607, 0.11127, 0.14723, 0.1508, 0.31084, 0.46706]
Predicted label: 4
Correct prediction
Energy consumption = 204.524781 pJ
sum error= 148
Actual label: 0
Output voltages: [0.73338, 0.25215, 0.27557, 0.17367, 0.097481, 0.18392, 0.38582, 0.16416, 0.26378, 0.29114]
Predicted label: 0
Correct prediction
Energy consumption = 195.355674 pJ
sum error= 148
Actual label: 7
Output voltages: [0.36885, 0.1968, 0.33951, 0.34704, 0.080769, 0.04859, 0.044834, 0.71384, 0.35637, 0.3733]
Predicted label: 7
Correct prediction
Energy consumption = 190.768295 pJ
sum error= 148
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 361 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 361 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 361 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.11846, 0.17549, 0.30481, 0.13493, 0.7625, 0.076406, 0.2585, 0.28117, 0.25084, 0.26668]
Predicted label: 4
Correct prediction
Energy consumption = 190.108584 pJ
sum error= 148
Actual label: 2
Output voltages: [0.36349, 0.28391, 0.73539, 0.28367, 0.11391, 0.029169, 0.26399, 0.29349, 0.42728, 0.18283]
Predicted label: 2
Correct prediction
Energy consumption = 194.042103 pJ
sum error= 148
Actual label: 4
Output voltages: [0.1534, 0.21069, 0.19613, 0.092887, 0.74466, 0.1941, 0.29212, 0.31951, 0.28288, 0.30616]
Predicted label: 4
Correct prediction
Energy consumption = 196.528606 pJ
sum error= 148
Actual label: 0
Output voltages: [0.73437, 0.22127, 0.26931, 0.2399, 0.14229, 0.15244, 0.27273, 0.23342, 0.39277, 0.25867]
Predicted label: 0
Correct prediction
Energy consumption = 199.266489 pJ
sum error= 148
Actual label: 6
Output voltages: [0.36786, 0.16902, 0.29094, 0.087961, 0.27466, 0.23478, 0.68261, 0.14807, 0.32324, 0.27047]
Predicted label: 6
Correct prediction
Energy consumption = 187.455280 pJ
sum error= 148
Actual label: 4
Output voltages: [0.22462, 0.22512, 0.26195, 0.10308, 0.72843, 0.060645, 0.38174, 0.2101, 0.24224, 0.27113]
Predicted label: 4
Correct prediction
Energy consumption = 196.091110 pJ
sum error= 148
Actual label: 7
Output voltages: [0.29995, 0.30266, 0.26111, 0.27863, 0.11497, 0.068299, 0.044268, 0.75128, 0.32194, 0.29693]
Predicted label: 7
Correct prediction
Energy consumption = 199.995824 pJ
sum error= 148
Actual label: 6
Output voltages: [0.34617, 0.29573, 0.26292, 0.19689, 0.26027, 0.32423, 0.72646, 0.14634, 0.42351, 0.0831]
Predicted label: 6
Correct prediction
Energy consumption = 195.585351 pJ
sum error= 148
Actual label: 9
Output voltages: [0.2728, 0.094524, 0.20255, 0.2184, 0.23069, 0.15774, 0.058233, 0.39739, 0.53079, 0.56913]
Predicted label: 9
Correct prediction
Energy consumption = 195.406260 pJ
sum error= 148
Actual label: 5
Output voltages: [0.29065, 0.1253, 0.070813, 0.47001, 0.17639, 0.68018, 0.21992, 0.12016, 0.49584, 0.23395]
Predicted label: 5
Correct prediction
Energy consumption = 188.424318 pJ
sum error= 148
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 362 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 362 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 362 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33241, 0.13353, 0.21018, 0.75115, 0.20531, 0.33533, 0.13165, 0.22544, 0.39054, 0.17517]
Predicted label: 3
Correct prediction
Energy consumption = 192.737889 pJ
sum error= 148
Actual label: 4
Output voltages: [0.15526, 0.14899, 0.30833, 0.14388, 0.75803, 0.11194, 0.27347, 0.27421, 0.23931, 0.29738]
Predicted label: 4
Correct prediction
Energy consumption = 191.251183 pJ
sum error= 148
Actual label: 6
Output voltages: [0.28613, 0.2283, 0.35739, 0.056766, 0.34627, 0.27508, 0.74693, 0.0687, 0.34921, 0.14597]
Predicted label: 6
Correct prediction
Energy consumption = 189.929801 pJ
sum error= 148
Actual label: 5
Output voltages: [0.32431, 0.16282, 0.040445, 0.37529, 0.24248, 0.74098, 0.32465, 0.15647, 0.37431, 0.2418]
Predicted label: 5
Correct prediction
Energy consumption = 190.902533 pJ
sum error= 148
Actual label: 0
Output voltages: [0.72014, 0.21345, 0.22819, 0.19195, 0.13967, 0.13768, 0.41257, 0.21375, 0.35804, 0.24305]
Predicted label: 0
Correct prediction
Energy consumption = 189.157278 pJ
sum error= 148
Actual label: 1
Output voltages: [0.2348, 0.76178, 0.16042, 0.27157, 0.14282, 0.15991, 0.44864, 0.081603, 0.35764, 0.18353]
Predicted label: 1
Correct prediction
Energy consumption = 211.400405 pJ
sum error= 148
Actual label: 8
Output voltages: [0.22591, 0.27558, 0.33049, 0.62615, 0.068237, 0.080547, 0.26039, 0.14497, 0.58497, 0.2554]
Predicted label: 3
Wrong prediction!
Energy consumption = 196.700815 pJ
sum error= 149
Actual label: 8
Output voltages: [0.30551, 0.18123, 0.35773, 0.218, 0.2609, 0.099582, 0.25152, 0.15253, 0.71872, 0.29633]
Predicted label: 8
Correct prediction
Energy consumption = 196.724615 pJ
sum error= 149
Actual label: 2
Output voltages: [0.34617, 0.13879, 0.73902, 0.30588, 0.14779, 0.036202, 0.24218, 0.34164, 0.45387, 0.17721]
Predicted label: 2
Correct prediction
Energy consumption = 183.608481 pJ
sum error= 149
Actual label: 8
Output voltages: [0.42079, 0.10305, 0.26138, 0.41656, 0.14688, 0.2261, 0.26625, 0.053739, 0.66572, 0.25198]
Predicted label: 8
Correct prediction
Energy consumption = 193.149574 pJ
sum error= 149
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 363 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 363 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 363 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33566, 0.15179, 0.36126, 0.74713, 0.22326, 0.19133, 0.13299, 0.19051, 0.4827, 0.26397]
Predicted label: 3
Correct prediction
Energy consumption = 185.723433 pJ
sum error= 149
Actual label: 5
Output voltages: [0.21353, 0.057943, 0.1251, 0.37473, 0.21653, 0.70799, 0.25987, 0.19341, 0.53784, 0.29012]
Predicted label: 5
Correct prediction
Energy consumption = 183.128863 pJ
sum error= 149
Actual label: 7
Output voltages: [0.27699, 0.27942, 0.2049, 0.24118, 0.075485, 0.087453, 0.040903, 0.72144, 0.40846, 0.40497]
Predicted label: 7
Correct prediction
Energy consumption = 201.021280 pJ
sum error= 149
Actual label: 8
Output voltages: [0.22641, 0.17588, 0.32311, 0.33223, 0.11844, 0.21113, 0.18528, 0.13933, 0.74676, 0.23004]
Predicted label: 8
Correct prediction
Energy consumption = 193.953536 pJ
sum error= 149
Actual label: 0
Output voltages: [0.63289, 0.21888, 0.28846, 0.19532, 0.18992, 0.050445, 0.36499, 0.26772, 0.34054, 0.33557]
Predicted label: 0
Correct prediction
Energy consumption = 205.981428 pJ
sum error= 149
Actual label: 8
Output voltages: [0.3782, 0.14014, 0.34596, 0.33524, 0.20885, 0.16018, 0.33107, 0.047324, 0.65243, 0.30668]
Predicted label: 8
Correct prediction
Energy consumption = 199.553286 pJ
sum error= 149
Actual label: 5
Output voltages: [0.1756, 0.061615, 0.10488, 0.30372, 0.27761, 0.69229, 0.29179, 0.26128, 0.45386, 0.3401]
Predicted label: 5
Correct prediction
Energy consumption = 184.459629 pJ
sum error= 149
Actual label: 7
Output voltages: [0.25795, 0.3395, 0.24868, 0.28099, 0.14549, 0.073408, 0.032812, 0.70317, 0.28677, 0.328]
Predicted label: 7
Correct prediction
Energy consumption = 201.462128 pJ
sum error= 149
Actual label: 1
Output voltages: [0.13561, 0.72164, 0.37253, 0.25448, 0.31983, 0.065934, 0.43477, 0.12785, 0.2905, 0.17799]
Predicted label: 1
Correct prediction
Energy consumption = 207.369606 pJ
sum error= 149
Actual label: 1
Output voltages: [0.1836, 0.75717, 0.27326, 0.41766, 0.1915, 0.078551, 0.36905, 0.24813, 0.25759, 0.18942]
Predicted label: 1
Correct prediction
Energy consumption = 206.289387 pJ
sum error= 149
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 364 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 364 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 364 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7275, 0.23958, 0.28349, 0.18246, 0.15722, 0.17364, 0.34672, 0.19882, 0.34564, 0.36407]
Predicted label: 0
Correct prediction
Energy consumption = 197.700025 pJ
sum error= 149
Actual label: 1
Output voltages: [0.20005, 0.76477, 0.32173, 0.40379, 0.24529, 0.092155, 0.25723, 0.17851, 0.19004, 0.33397]
Predicted label: 1
Correct prediction
Energy consumption = 214.025278 pJ
sum error= 149
Actual label: 3
Output voltages: [0.29282, 0.20153, 0.27558, 0.76088, 0.16272, 0.12032, 0.14127, 0.19853, 0.43987, 0.23939]
Predicted label: 3
Correct prediction
Energy consumption = 180.986346 pJ
sum error= 149
Actual label: 7
Output voltages: [0.34911, 0.3283, 0.3491, 0.32203, 0.10585, 0.044145, 0.053127, 0.73109, 0.4013, 0.21206]
Predicted label: 7
Correct prediction
Energy consumption = 191.536622 pJ
sum error= 149
Actual label: 8
Output voltages: [0.22734, 0.27864, 0.31128, 0.3094, 0.19805, 0.21038, 0.23418, 0.069148, 0.73502, 0.27757]
Predicted label: 8
Correct prediction
Energy consumption = 192.505633 pJ
sum error= 149
Actual label: 5
Output voltages: [0.22498, 0.10324, 0.091637, 0.31713, 0.22146, 0.69009, 0.35804, 0.14177, 0.42599, 0.27735]
Predicted label: 5
Correct prediction
Energy consumption = 193.681986 pJ
sum error= 149
Actual label: 0
Output voltages: [0.69463, 0.27384, 0.17657, 0.25542, 0.24717, 0.085795, 0.47537, 0.12608, 0.33541, 0.22052]
Predicted label: 0
Correct prediction
Energy consumption = 202.834674 pJ
sum error= 149
Actual label: 7
Output voltages: [0.23046, 0.18223, 0.28495, 0.5674, 0.14981, 0.1443, 0.044368, 0.61279, 0.36996, 0.3633]
Predicted label: 7
Correct prediction
Energy consumption = 199.571906 pJ
sum error= 149
Actual label: 1
Output voltages: [0.21033, 0.76851, 0.2443, 0.20017, 0.21907, 0.12123, 0.3667, 0.085393, 0.34349, 0.23954]
Predicted label: 1
Correct prediction
Energy consumption = 211.620443 pJ
sum error= 149
Actual label: 1
Output voltages: [0.28193, 0.76323, 0.26936, 0.23919, 0.13145, 0.082852, 0.41192, 0.11524, 0.33818, 0.22898]
Predicted label: 1
Correct prediction
Energy consumption = 198.836244 pJ
sum error= 149
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 365 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 365 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 365 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.71801, 0.24903, 0.33643, 0.20452, 0.16382, 0.079459, 0.39336, 0.17813, 0.30361, 0.2862]
Predicted label: 0
Correct prediction
Energy consumption = 202.075274 pJ
sum error= 149
Actual label: 1
Output voltages: [0.20593, 0.76614, 0.29537, 0.3923, 0.21633, 0.11532, 0.2991, 0.13997, 0.19275, 0.32277]
Predicted label: 1
Correct prediction
Energy consumption = 212.350123 pJ
sum error= 149
Actual label: 1
Output voltages: [0.1836, 0.77027, 0.23671, 0.26171, 0.18442, 0.11537, 0.41519, 0.14583, 0.33139, 0.20299]
Predicted label: 1
Correct prediction
Energy consumption = 209.509419 pJ
sum error= 149
Actual label: 4
Output voltages: [0.26206, 0.21773, 0.28479, 0.16795, 0.73398, 0.05736, 0.29319, 0.27243, 0.15441, 0.41455]
Predicted label: 4
Correct prediction
Energy consumption = 201.360587 pJ
sum error= 149
Actual label: 5
Output voltages: [0.30153, 0.18815, 0.089186, 0.36053, 0.14734, 0.63235, 0.45072, 0.073057, 0.53841, 0.17965]
Predicted label: 5
Correct prediction
Energy consumption = 205.096452 pJ
sum error= 149
Actual label: 2
Output voltages: [0.33998, 0.49077, 0.715, 0.3246, 0.1571, 0.023841, 0.30621, 0.20196, 0.29671, 0.24724]
Predicted label: 2
Correct prediction
Energy consumption = 193.508822 pJ
sum error= 149
Actual label: 7
Output voltages: [0.28484, 0.14149, 0.24738, 0.44754, 0.21126, 0.12694, 0.035355, 0.70167, 0.33169, 0.37176]
Predicted label: 7
Correct prediction
Energy consumption = 185.322235 pJ
sum error= 149
Actual label: 6
Output voltages: [0.34339, 0.221, 0.30703, 0.061112, 0.3474, 0.28642, 0.73732, 0.12915, 0.23929, 0.20997]
Predicted label: 6
Correct prediction
Energy consumption = 192.744673 pJ
sum error= 149
Actual label: 2
Output voltages: [0.30186, 0.42735, 0.71634, 0.28142, 0.13858, 0.026456, 0.28879, 0.27756, 0.34127, 0.18535]
Predicted label: 2
Correct prediction
Energy consumption = 198.214546 pJ
sum error= 149
Actual label: 3
Output voltages: [0.28738, 0.21312, 0.28013, 0.75615, 0.15941, 0.14873, 0.11346, 0.30321, 0.37307, 0.30419]
Predicted label: 3
Correct prediction
Energy consumption = 175.625049 pJ
sum error= 149
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 366 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 366 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 366 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.71518, 0.23821, 0.25168, 0.17912, 0.12924, 0.1317, 0.44262, 0.16251, 0.33384, 0.23325]
Predicted label: 0
Correct prediction
Energy consumption = 199.048961 pJ
sum error= 149
Actual label: 2
Output voltages: [0.34337, 0.27853, 0.71019, 0.40339, 0.17373, 0.036475, 0.30289, 0.21922, 0.3906, 0.18546]
Predicted label: 2
Correct prediction
Energy consumption = 191.529730 pJ
sum error= 149
Actual label: 8
Output voltages: [0.40019, 0.13872, 0.29068, 0.26249, 0.28089, 0.14867, 0.40085, 0.05485, 0.62572, 0.14071]
Predicted label: 8
Correct prediction
Energy consumption = 196.862479 pJ
sum error= 149
Actual label: 5
Output voltages: [0.23881, 0.061405, 0.10616, 0.31664, 0.18801, 0.65465, 0.18573, 0.23693, 0.47952, 0.36735]
Predicted label: 5
Correct prediction
Energy consumption = 196.892874 pJ
sum error= 149
Actual label: 9
Output voltages: [0.30768, 0.17797, 0.19755, 0.33109, 0.34898, 0.17419, 0.18246, 0.14468, 0.35892, 0.56104]
Predicted label: 9
Correct prediction
Energy consumption = 199.190510 pJ
sum error= 149
Actual label: 6
Output voltages: [0.32231, 0.16372, 0.30787, 0.071961, 0.33312, 0.26334, 0.73153, 0.12247, 0.30456, 0.21974]
Predicted label: 6
Correct prediction
Energy consumption = 196.243009 pJ
sum error= 149
Actual label: 9
Output voltages: [0.30858, 0.12332, 0.20996, 0.22156, 0.29806, 0.15145, 0.078092, 0.26175, 0.39971, 0.63879]
Predicted label: 9
Correct prediction
Energy consumption = 193.095265 pJ
sum error= 149
Actual label: 7
Output voltages: [0.4146, 0.24197, 0.25981, 0.25164, 0.15393, 0.059964, 0.046319, 0.65957, 0.3653, 0.34619]
Predicted label: 7
Correct prediction
Energy consumption = 196.919197 pJ
sum error= 149
Actual label: 2
Output voltages: [0.39488, 0.15902, 0.74537, 0.33706, 0.1983, 0.038061, 0.24675, 0.3435, 0.38743, 0.16779]
Predicted label: 2
Correct prediction
Energy consumption = 185.020757 pJ
sum error= 149
Actual label: 1
Output voltages: [0.22631, 0.76395, 0.16616, 0.29199, 0.181, 0.20057, 0.32948, 0.15585, 0.30365, 0.25313]
Predicted label: 1
Correct prediction
Energy consumption = 209.794081 pJ
sum error= 149
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 367 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 367 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 367 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35675, 0.13786, 0.37085, 0.75412, 0.17787, 0.16454, 0.13093, 0.18873, 0.45757, 0.24741]
Predicted label: 3
Correct prediction
Energy consumption = 178.363333 pJ
sum error= 149
Actual label: 6
Output voltages: [0.31111, 0.17214, 0.23733, 0.1819, 0.30132, 0.51319, 0.72578, 0.068995, 0.38845, 0.16679]
Predicted label: 6
Correct prediction
Energy consumption = 190.549711 pJ
sum error= 149
Actual label: 4
Output voltages: [0.15299, 0.19975, 0.22493, 0.10626, 0.74196, 0.10623, 0.37872, 0.26276, 0.2599, 0.21578]
Predicted label: 4
Correct prediction
Energy consumption = 198.133409 pJ
sum error= 149
Actual label: 1
Output voltages: [0.16917, 0.76223, 0.26594, 0.32737, 0.31072, 0.064572, 0.27271, 0.12939, 0.27613, 0.31281]
Predicted label: 1
Correct prediction
Energy consumption = 216.408140 pJ
sum error= 149
Actual label: 8
Output voltages: [0.20081, 0.13745, 0.21422, 0.32052, 0.068882, 0.47453, 0.15775, 0.14897, 0.70666, 0.22959]
Predicted label: 8
Correct prediction
Energy consumption = 193.754988 pJ
sum error= 149
Actual label: 2
Output voltages: [0.42926, 0.16527, 0.74153, 0.33559, 0.18895, 0.040577, 0.2597, 0.32217, 0.4157, 0.17258]
Predicted label: 2
Correct prediction
Energy consumption = 184.820659 pJ
sum error= 149
Actual label: 4
Output voltages: [0.1209, 0.12579, 0.31393, 0.16879, 0.74993, 0.078584, 0.25206, 0.28187, 0.29096, 0.26405]
Predicted label: 4
Correct prediction
Energy consumption = 195.202477 pJ
sum error= 149
Actual label: 0
Output voltages: [0.73061, 0.2392, 0.19176, 0.23097, 0.14772, 0.23053, 0.42994, 0.16137, 0.34653, 0.2316]
Predicted label: 0
Correct prediction
Energy consumption = 196.698389 pJ
sum error= 149
Actual label: 5
Output voltages: [0.25452, 0.053501, 0.17993, 0.33006, 0.1601, 0.67606, 0.33669, 0.17613, 0.54207, 0.23333]
Predicted label: 5
Correct prediction
Energy consumption = 185.330767 pJ
sum error= 149
Actual label: 1
Output voltages: [0.17597, 0.76094, 0.12955, 0.23187, 0.31646, 0.11775, 0.37618, 0.12841, 0.32928, 0.25469]
Predicted label: 1
Correct prediction
Energy consumption = 206.937827 pJ
sum error= 149
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 368 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 368 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 368 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.75004, 0.2234, 0.22612, 0.25748, 0.13772, 0.32278, 0.31275, 0.18281, 0.31444, 0.22244]
Predicted label: 0
Correct prediction
Energy consumption = 198.625221 pJ
sum error= 149
Actual label: 2
Output voltages: [0.33784, 0.12303, 0.52145, 0.58982, 0.093035, 0.16775, 0.16052, 0.12549, 0.57218, 0.1091]
Predicted label: 3
Wrong prediction!
Energy consumption = 188.869506 pJ
sum error= 150
Actual label: 2
Output voltages: [0.46265, 0.14134, 0.73311, 0.34553, 0.15976, 0.042762, 0.28938, 0.29834, 0.37677, 0.17993]
Predicted label: 2
Correct prediction
Energy consumption = 186.461008 pJ
sum error= 150
Actual label: 6
Output voltages: [0.36315, 0.33806, 0.33093, 0.10056, 0.28091, 0.26691, 0.73915, 0.1413, 0.34743, 0.11685]
Predicted label: 6
Correct prediction
Energy consumption = 198.732697 pJ
sum error= 150
Actual label: 4
Output voltages: [0.24742, 0.17374, 0.2896, 0.17187, 0.7485, 0.13313, 0.29686, 0.24242, 0.16353, 0.32919]
Predicted label: 4
Correct prediction
Energy consumption = 196.700151 pJ
sum error= 150
Actual label: 4
Output voltages: [0.27099, 0.17158, 0.34475, 0.14262, 0.72071, 0.048683, 0.38312, 0.22051, 0.20537, 0.29002]
Predicted label: 4
Correct prediction
Energy consumption = 196.400715 pJ
sum error= 150
Actual label: 3
Output voltages: [0.29174, 0.25523, 0.28156, 0.74743, 0.099013, 0.14373, 0.12874, 0.21099, 0.52023, 0.2315]
Predicted label: 3
Correct prediction
Energy consumption = 194.823169 pJ
sum error= 150
Actual label: 9
Output voltages: [0.25035, 0.19527, 0.14952, 0.27196, 0.35394, 0.25416, 0.28817, 0.15074, 0.36011, 0.63395]
Predicted label: 9
Correct prediction
Energy consumption = 192.834564 pJ
sum error= 150
Actual label: 6
Output voltages: [0.30395, 0.37599, 0.18734, 0.22079, 0.18156, 0.3991, 0.71972, 0.11065, 0.43113, 0.081042]
Predicted label: 6
Correct prediction
Energy consumption = 202.549480 pJ
sum error= 150
Actual label: 1
Output voltages: [0.16798, 0.7681, 0.22045, 0.22913, 0.29058, 0.13106, 0.37825, 0.14579, 0.27378, 0.24735]
Predicted label: 1
Correct prediction
Energy consumption = 211.486529 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 369 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 369 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 369 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.35378, 0.22193, 0.1976, 0.15366, 0.30974, 0.44786, 0.72545, 0.084356, 0.36733, 0.13174]
Predicted label: 6
Correct prediction
Energy consumption = 194.829828 pJ
sum error= 150
Actual label: 5
Output voltages: [0.16259, 0.044096, 0.1398, 0.31831, 0.23288, 0.65291, 0.30386, 0.15349, 0.6019, 0.22254]
Predicted label: 5
Correct prediction
Energy consumption = 184.195624 pJ
sum error= 150
Actual label: 7
Output voltages: [0.35141, 0.18874, 0.21412, 0.27114, 0.22523, 0.15951, 0.048963, 0.76597, 0.30269, 0.32539]
Predicted label: 7
Correct prediction
Energy consumption = 195.858580 pJ
sum error= 150
Actual label: 9
Output voltages: [0.32377, 0.14756, 0.20845, 0.22772, 0.4322, 0.073685, 0.086917, 0.27222, 0.30549, 0.63492]
Predicted label: 9
Correct prediction
Energy consumption = 199.197693 pJ
sum error= 150
Actual label: 2
Output voltages: [0.29003, 0.39514, 0.69219, 0.28834, 0.18875, 0.032163, 0.2905, 0.1663, 0.3784, 0.23823]
Predicted label: 2
Correct prediction
Energy consumption = 193.887950 pJ
sum error= 150
Actual label: 0
Output voltages: [0.72724, 0.27477, 0.26246, 0.12491, 0.16066, 0.10701, 0.37272, 0.30746, 0.31546, 0.26871]
Predicted label: 0
Correct prediction
Energy consumption = 192.493074 pJ
sum error= 150
Actual label: 2
Output voltages: [0.35297, 0.3542, 0.73171, 0.33214, 0.12282, 0.026319, 0.30285, 0.17006, 0.39238, 0.22091]
Predicted label: 2
Correct prediction
Energy consumption = 183.324501 pJ
sum error= 150
Actual label: 6
Output voltages: [0.33708, 0.19032, 0.26046, 0.18132, 0.27961, 0.42126, 0.71355, 0.045087, 0.44757, 0.19573]
Predicted label: 6
Correct prediction
Energy consumption = 189.267244 pJ
sum error= 150
Actual label: 0
Output voltages: [0.73069, 0.27268, 0.21689, 0.21842, 0.15131, 0.21785, 0.3681, 0.16398, 0.28658, 0.33671]
Predicted label: 0
Correct prediction
Energy consumption = 202.943184 pJ
sum error= 150
Actual label: 1
Output voltages: [0.22522, 0.76064, 0.30687, 0.26951, 0.21713, 0.059068, 0.36839, 0.11548, 0.30126, 0.23319]
Predicted label: 1
Correct prediction
Energy consumption = 211.135692 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 370 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 370 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 370 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16639, 0.14405, 0.30277, 0.23955, 0.74587, 0.0526, 0.2057, 0.25414, 0.23864, 0.23578]
Predicted label: 4
Correct prediction
Energy consumption = 200.385436 pJ
sum error= 150
Actual label: 3
Output voltages: [0.36407, 0.19223, 0.34139, 0.75493, 0.16868, 0.14123, 0.14069, 0.16274, 0.41247, 0.269]
Predicted label: 3
Correct prediction
Energy consumption = 190.051463 pJ
sum error= 150
Actual label: 5
Output voltages: [0.14907, 0.095914, 0.062404, 0.47277, 0.35321, 0.55683, 0.28929, 0.24965, 0.38304, 0.2626]
Predicted label: 5
Correct prediction
Energy consumption = 201.282975 pJ
sum error= 150
Actual label: 2
Output voltages: [0.31588, 0.46371, 0.67324, 0.37463, 0.17834, 0.029623, 0.25091, 0.24288, 0.33202, 0.21164]
Predicted label: 2
Correct prediction
Energy consumption = 190.662844 pJ
sum error= 150
Actual label: 8
Output voltages: [0.18059, 0.25244, 0.25521, 0.30765, 0.10876, 0.2806, 0.17642, 0.22516, 0.75325, 0.25895]
Predicted label: 8
Correct prediction
Energy consumption = 191.960772 pJ
sum error= 150
Actual label: 8
Output voltages: [0.19505, 0.24586, 0.4042, 0.22533, 0.10345, 0.22393, 0.28525, 0.21927, 0.70895, 0.17031]
Predicted label: 8
Correct prediction
Energy consumption = 190.982813 pJ
sum error= 150
Actual label: 0
Output voltages: [0.70051, 0.20759, 0.32548, 0.15646, 0.123, 0.13184, 0.38709, 0.18023, 0.38955, 0.25909]
Predicted label: 0
Correct prediction
Energy consumption = 192.265230 pJ
sum error= 150
Actual label: 8
Output voltages: [0.2109, 0.23594, 0.2977, 0.22591, 0.1696, 0.14006, 0.19926, 0.14189, 0.742, 0.35036]
Predicted label: 8
Correct prediction
Energy consumption = 194.626469 pJ
sum error= 150
Actual label: 8
Output voltages: [0.28577, 0.12205, 0.34136, 0.2791, 0.18179, 0.20423, 0.21812, 0.11238, 0.7393, 0.32475]
Predicted label: 8
Correct prediction
Energy consumption = 186.133786 pJ
sum error= 150
Actual label: 9
Output voltages: [0.38971, 0.14326, 0.12806, 0.25712, 0.30918, 0.22803, 0.05636, 0.43926, 0.34152, 0.6179]
Predicted label: 9
Correct prediction
Energy consumption = 197.704490 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 371 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 371 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 371 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.61306, 0.22991, 0.35403, 0.18833, 0.0704, 0.07293, 0.35295, 0.12483, 0.43228, 0.35865]
Predicted label: 0
Correct prediction
Energy consumption = 201.489225 pJ
sum error= 150
Actual label: 9
Output voltages: [0.34165, 0.14283, 0.19723, 0.28751, 0.33066, 0.1483, 0.09378, 0.20239, 0.36129, 0.6676]
Predicted label: 9
Correct prediction
Energy consumption = 191.192216 pJ
sum error= 150
Actual label: 6
Output voltages: [0.30155, 0.23641, 0.31819, 0.11508, 0.27992, 0.35549, 0.74766, 0.089821, 0.36818, 0.15466]
Predicted label: 6
Correct prediction
Energy consumption = 187.979434 pJ
sum error= 150
Actual label: 7
Output voltages: [0.28977, 0.20413, 0.46087, 0.37063, 0.09969, 0.03448, 0.1039, 0.70246, 0.35748, 0.26095]
Predicted label: 7
Correct prediction
Energy consumption = 194.738028 pJ
sum error= 150
Actual label: 6
Output voltages: [0.31916, 0.17921, 0.17028, 0.23416, 0.26843, 0.58776, 0.71253, 0.10183, 0.38184, 0.15263]
Predicted label: 6
Correct prediction
Energy consumption = 190.381172 pJ
sum error= 150
Actual label: 3
Output voltages: [0.31588, 0.14923, 0.39882, 0.72863, 0.16418, 0.065889, 0.11956, 0.15297, 0.4375, 0.29027]
Predicted label: 3
Correct prediction
Energy consumption = 187.236157 pJ
sum error= 150
Actual label: 9
Output voltages: [0.26611, 0.13524, 0.19848, 0.42209, 0.23042, 0.24236, 0.12287, 0.054997, 0.47439, 0.49416]
Predicted label: 9
Correct prediction
Energy consumption = 193.523212 pJ
sum error= 150
Actual label: 3
Output voltages: [0.29544, 0.20383, 0.27125, 0.7608, 0.16484, 0.21031, 0.18465, 0.15113, 0.45108, 0.26314]
Predicted label: 3
Correct prediction
Energy consumption = 183.823924 pJ
sum error= 150
Actual label: 4
Output voltages: [0.16799, 0.11971, 0.22801, 0.13783, 0.52455, 0.13413, 0.063811, 0.12423, 0.41803, 0.4491]
Predicted label: 4
Correct prediction
Energy consumption = 193.052210 pJ
sum error= 150
Actual label: 7
Output voltages: [0.33647, 0.27633, 0.31013, 0.31374, 0.11191, 0.048818, 0.055739, 0.7372, 0.26759, 0.40184]
Predicted label: 7
Correct prediction
Energy consumption = 202.579827 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 372 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 372 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 372 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.2701, 0.14472, 0.23208, 0.56448, 0.11036, 0.19203, 0.046465, 0.60926, 0.34682, 0.43203]
Predicted label: 7
Correct prediction
Energy consumption = 198.717682 pJ
sum error= 150
Actual label: 7
Output voltages: [0.34314, 0.459, 0.31221, 0.42521, 0.10093, 0.040578, 0.070198, 0.59158, 0.23266, 0.35818]
Predicted label: 7
Correct prediction
Energy consumption = 205.003937 pJ
sum error= 150
Actual label: 4
Output voltages: [0.25757, 0.092824, 0.25856, 0.1577, 0.73847, 0.13961, 0.19503, 0.34193, 0.22664, 0.38387]
Predicted label: 4
Correct prediction
Energy consumption = 202.300883 pJ
sum error= 150
Actual label: 9
Output voltages: [0.52533, 0.15035, 0.16018, 0.25512, 0.20262, 0.17952, 0.38786, 0.14475, 0.34959, 0.45023]
Predicted label: 0
Wrong prediction!
Energy consumption = 197.099714 pJ
sum error= 151
Actual label: 0
Output voltages: [0.72843, 0.20926, 0.19192, 0.18608, 0.1443, 0.22818, 0.40155, 0.26591, 0.34491, 0.20022]
Predicted label: 0
Correct prediction
Energy consumption = 194.241441 pJ
sum error= 151
Actual label: 6
Output voltages: [0.25991, 0.20139, 0.32639, 0.18697, 0.34741, 0.33815, 0.74653, 0.11404, 0.34845, 0.16155]
Predicted label: 6
Correct prediction
Energy consumption = 197.311753 pJ
sum error= 151
Actual label: 4
Output voltages: [0.26646, 0.21465, 0.25731, 0.24185, 0.67418, 0.049689, 0.077434, 0.21914, 0.20037, 0.4818]
Predicted label: 4
Correct prediction
Energy consumption = 194.153172 pJ
sum error= 151
Actual label: 8
Output voltages: [0.33358, 0.041397, 0.26851, 0.38441, 0.27301, 0.2422, 0.1958, 0.07125, 0.56691, 0.39625]
Predicted label: 8
Correct prediction
Energy consumption = 192.458895 pJ
sum error= 151
Actual label: 4
Output voltages: [0.17342, 0.17962, 0.26642, 0.18651, 0.71252, 0.083505, 0.14364, 0.17995, 0.21543, 0.47496]
Predicted label: 4
Correct prediction
Energy consumption = 201.002493 pJ
sum error= 151
Actual label: 2
Output voltages: [0.37127, 0.19891, 0.68429, 0.43627, 0.13316, 0.038049, 0.24481, 0.26734, 0.46865, 0.17293]
Predicted label: 2
Correct prediction
Energy consumption = 190.325709 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 373 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 373 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 373 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.4315, 0.12107, 0.17418, 0.23572, 0.1963, 0.26746, 0.055293, 0.61191, 0.38364, 0.52735]
Predicted label: 7
Correct prediction
Energy consumption = 199.954312 pJ
sum error= 151
Actual label: 2
Output voltages: [0.41823, 0.16665, 0.71052, 0.40889, 0.13701, 0.037235, 0.2103, 0.25351, 0.37966, 0.14659]
Predicted label: 2
Correct prediction
Energy consumption = 186.210737 pJ
sum error= 151
Actual label: 8
Output voltages: [0.19484, 0.41353, 0.22637, 0.42929, 0.085449, 0.19765, 0.24379, 0.09835, 0.69864, 0.27361]
Predicted label: 8
Correct prediction
Energy consumption = 200.814150 pJ
sum error= 151
Actual label: 1
Output voltages: [0.27443, 0.73566, 0.25234, 0.16481, 0.45628, 0.11965, 0.38144, 0.14682, 0.21289, 0.21258]
Predicted label: 1
Correct prediction
Energy consumption = 199.294890 pJ
sum error= 151
Actual label: 0
Output voltages: [0.68885, 0.18605, 0.19909, 0.19901, 0.080101, 0.35974, 0.36067, 0.097768, 0.3447, 0.28822]
Predicted label: 0
Correct prediction
Energy consumption = 203.571500 pJ
sum error= 151
Actual label: 0
Output voltages: [0.6957, 0.19178, 0.1942, 0.20376, 0.074403, 0.3241, 0.36975, 0.1274, 0.37125, 0.25122]
Predicted label: 0
Correct prediction
Energy consumption = 194.948194 pJ
sum error= 151
Actual label: 7
Output voltages: [0.21828, 0.57795, 0.35004, 0.42866, 0.046203, 0.047183, 0.13139, 0.49311, 0.34099, 0.19272]
Predicted label: 1
Wrong prediction!
Energy consumption = 206.426551 pJ
sum error= 152
Actual label: 8
Output voltages: [0.2292, 0.11137, 0.22387, 0.29887, 0.18762, 0.26399, 0.24006, 0.1604, 0.73495, 0.15608]
Predicted label: 8
Correct prediction
Energy consumption = 191.383785 pJ
sum error= 152
Actual label: 3
Output voltages: [0.44355, 0.31653, 0.20717, 0.72605, 0.06725, 0.35011, 0.30957, 0.26236, 0.2568, 0.073523]
Predicted label: 3
Correct prediction
Energy consumption = 191.304068 pJ
sum error= 152
Actual label: 3
Output voltages: [0.34111, 0.19031, 0.25226, 0.76638, 0.17684, 0.26735, 0.20195, 0.21424, 0.39988, 0.22976]
Predicted label: 3
Correct prediction
Energy consumption = 184.515324 pJ
sum error= 152
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 374 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 374 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 374 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4596, 0.22185, 0.18126, 0.74771, 0.13579, 0.33961, 0.13855, 0.27574, 0.36265, 0.10281]
Predicted label: 3
Correct prediction
Energy consumption = 193.335196 pJ
sum error= 152
Actual label: 1
Output voltages: [0.19946, 0.76017, 0.30085, 0.31786, 0.27019, 0.075189, 0.35148, 0.1197, 0.2853, 0.25158]
Predicted label: 1
Correct prediction
Energy consumption = 210.231757 pJ
sum error= 152
Actual label: 3
Output voltages: [0.15639, 0.24991, 0.26323, 0.56335, 0.13129, 0.10835, 0.10524, 0.1436, 0.51246, 0.40077]
Predicted label: 3
Correct prediction
Energy consumption = 208.729802 pJ
sum error= 152
Actual label: 7
Output voltages: [0.28509, 0.24957, 0.3245, 0.27275, 0.078573, 0.083684, 0.044648, 0.71599, 0.51957, 0.31389]
Predicted label: 7
Correct prediction
Energy consumption = 194.063465 pJ
sum error= 152
Actual label: 6
Output voltages: [0.39459, 0.20498, 0.17984, 0.17204, 0.27905, 0.39872, 0.6642, 0.099773, 0.4708, 0.11499]
Predicted label: 6
Correct prediction
Energy consumption = 194.351118 pJ
sum error= 152
Actual label: 1
Output voltages: [0.27887, 0.75725, 0.26142, 0.36456, 0.17944, 0.12296, 0.27365, 0.052816, 0.32459, 0.31339]
Predicted label: 1
Correct prediction
Energy consumption = 211.914947 pJ
sum error= 152
Actual label: 3
Output voltages: [0.27704, 0.24136, 0.25003, 0.76582, 0.17098, 0.15292, 0.17285, 0.34589, 0.40939, 0.29907]
Predicted label: 3
Correct prediction
Energy consumption = 184.528564 pJ
sum error= 152
Actual label: 1
Output voltages: [0.19471, 0.75915, 0.23512, 0.33563, 0.15327, 0.18707, 0.30398, 0.14785, 0.34288, 0.24296]
Predicted label: 1
Correct prediction
Energy consumption = 207.188698 pJ
sum error= 152
Actual label: 6
Output voltages: [0.37332, 0.28292, 0.2135, 0.27353, 0.20255, 0.36452, 0.65362, 0.089131, 0.44533, 0.07501]
Predicted label: 6
Correct prediction
Energy consumption = 198.578926 pJ
sum error= 152
Actual label: 6
Output voltages: [0.56004, 0.16606, 0.28148, 0.11422, 0.20724, 0.14168, 0.55939, 0.13541, 0.30534, 0.32224]
Predicted label: 0
Wrong prediction!
Energy consumption = 200.417509 pJ
sum error= 153
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 375 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 375 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 375 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.23934, 0.04701, 0.12064, 0.32629, 0.20999, 0.66808, 0.25863, 0.15849, 0.58286, 0.23628]
Predicted label: 5
Correct prediction
Energy consumption = 184.301647 pJ
sum error= 153
Actual label: 7
Output voltages: [0.14345, 0.31511, 0.46704, 0.38975, 0.12553, 0.051813, 0.14174, 0.60992, 0.43081, 0.15576]
Predicted label: 7
Correct prediction
Energy consumption = 196.342857 pJ
sum error= 153
Actual label: 4
Output voltages: [0.17284, 0.10925, 0.35641, 0.13338, 0.75423, 0.049688, 0.38706, 0.26362, 0.18639, 0.23464]
Predicted label: 4
Correct prediction
Energy consumption = 196.077194 pJ
sum error= 153
Actual label: 7
Output voltages: [0.27498, 0.33002, 0.41971, 0.29101, 0.10169, 0.041703, 0.045861, 0.73141, 0.35415, 0.31141]
Predicted label: 7
Correct prediction
Energy consumption = 194.757029 pJ
sum error= 153
Actual label: 5
Output voltages: [0.19003, 0.041808, 0.11564, 0.35011, 0.2877, 0.66847, 0.36257, 0.13451, 0.49609, 0.28694]
Predicted label: 5
Correct prediction
Energy consumption = 187.123608 pJ
sum error= 153
Actual label: 9
Output voltages: [0.32544, 0.23952, 0.37266, 0.13153, 0.43952, 0.046261, 0.25285, 0.13012, 0.35584, 0.52144]
Predicted label: 9
Correct prediction
Energy consumption = 204.604635 pJ
sum error= 153
Actual label: 5
Output voltages: [0.31452, 0.06679, 0.080447, 0.38991, 0.14872, 0.72186, 0.20171, 0.25956, 0.52445, 0.28778]
Predicted label: 5
Correct prediction
Energy consumption = 187.735368 pJ
sum error= 153
Actual label: 8
Output voltages: [0.34181, 0.20131, 0.28549, 0.46662, 0.21255, 0.2379, 0.31889, 0.060949, 0.59166, 0.15309]
Predicted label: 8
Correct prediction
Energy consumption = 192.360729 pJ
sum error= 153
Actual label: 4
Output voltages: [0.13167, 0.1374, 0.23657, 0.22161, 0.72732, 0.082697, 0.22591, 0.22507, 0.33111, 0.24686]
Predicted label: 4
Correct prediction
Energy consumption = 201.211178 pJ
sum error= 153
Actual label: 9
Output voltages: [0.34934, 0.12246, 0.20419, 0.32074, 0.39111, 0.21317, 0.17268, 0.27826, 0.28105, 0.68135]
Predicted label: 9
Correct prediction
Energy consumption = 192.259809 pJ
sum error= 153
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 376 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 376 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 376 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34223, 0.1348, 0.20526, 0.20886, 0.41924, 0.10909, 0.065574, 0.11172, 0.35372, 0.6426]
Predicted label: 9
Correct prediction
Energy consumption = 192.460812 pJ
sum error= 153
Actual label: 1
Output voltages: [0.22672, 0.76164, 0.18705, 0.34011, 0.11747, 0.14404, 0.32968, 0.19106, 0.36137, 0.20962]
Predicted label: 1
Correct prediction
Energy consumption = 212.700876 pJ
sum error= 153
Actual label: 6
Output voltages: [0.27989, 0.2889, 0.18075, 0.32942, 0.1946, 0.3247, 0.59853, 0.11685, 0.65633, 0.076759]
Predicted label: 8
Wrong prediction!
Energy consumption = 196.743841 pJ
sum error= 154
Actual label: 5
Output voltages: [0.17629, 0.075754, 0.13704, 0.33436, 0.21609, 0.70767, 0.21187, 0.14475, 0.51464, 0.23102]
Predicted label: 5
Correct prediction
Energy consumption = 186.622894 pJ
sum error= 154
Actual label: 0
Output voltages: [0.7259, 0.27444, 0.22621, 0.18134, 0.063459, 0.24436, 0.36657, 0.16522, 0.33118, 0.25505]
Predicted label: 0
Correct prediction
Energy consumption = 195.274055 pJ
sum error= 154
Actual label: 1
Output voltages: [0.2264, 0.76682, 0.20684, 0.29517, 0.23672, 0.14942, 0.31863, 0.098014, 0.278, 0.28896]
Predicted label: 1
Correct prediction
Energy consumption = 209.725372 pJ
sum error= 154
Actual label: 3
Output voltages: [0.37364, 0.16188, 0.28799, 0.74253, 0.14953, 0.29968, 0.1364, 0.14539, 0.44993, 0.20027]
Predicted label: 3
Correct prediction
Energy consumption = 189.012996 pJ
sum error= 154
Actual label: 7
Output voltages: [0.29516, 0.22407, 0.67347, 0.34221, 0.10322, 0.030425, 0.12857, 0.4281, 0.49827, 0.20613]
Predicted label: 2
Wrong prediction!
Energy consumption = 188.534936 pJ
sum error= 155
Actual label: 0
Output voltages: [0.67833, 0.11902, 0.2401, 0.19302, 0.20049, 0.20584, 0.35298, 0.13272, 0.44655, 0.30259]
Predicted label: 0
Correct prediction
Energy consumption = 190.153621 pJ
sum error= 155
Actual label: 3
Output voltages: [0.23944, 0.25855, 0.21256, 0.74147, 0.10656, 0.15024, 0.071447, 0.25583, 0.4127, 0.3341]
Predicted label: 3
Correct prediction
Energy consumption = 185.673779 pJ
sum error= 155
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 377 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 377 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 377 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16259, 0.17913, 0.28284, 0.15137, 0.74426, 0.069918, 0.35838, 0.30078, 0.18862, 0.2391]
Predicted label: 4
Correct prediction
Energy consumption = 198.062002 pJ
sum error= 155
Actual label: 8
Output voltages: [0.21756, 0.089041, 0.29524, 0.23023, 0.18973, 0.31891, 0.21618, 0.11327, 0.68992, 0.35796]
Predicted label: 8
Correct prediction
Energy consumption = 199.308869 pJ
sum error= 155
Actual label: 2
Output voltages: [0.34027, 0.24142, 0.69226, 0.35258, 0.083617, 0.029614, 0.2058, 0.40814, 0.47327, 0.18494]
Predicted label: 2
Correct prediction
Energy consumption = 189.526973 pJ
sum error= 155
Actual label: 2
Output voltages: [0.33079, 0.33553, 0.73302, 0.35781, 0.14294, 0.033851, 0.26709, 0.14762, 0.35683, 0.19915]
Predicted label: 2
Correct prediction
Energy consumption = 175.547690 pJ
sum error= 155
Actual label: 0
Output voltages: [0.73006, 0.24572, 0.15726, 0.17978, 0.1437, 0.26405, 0.41631, 0.17996, 0.32749, 0.26705]
Predicted label: 0
Correct prediction
Energy consumption = 195.223699 pJ
sum error= 155
Actual label: 2
Output voltages: [0.40139, 0.20224, 0.74848, 0.3309, 0.2058, 0.038568, 0.30678, 0.28426, 0.42411, 0.19907]
Predicted label: 2
Correct prediction
Energy consumption = 179.804315 pJ
sum error= 155
Actual label: 5
Output voltages: [0.16712, 0.18932, 0.16777, 0.27807, 0.11842, 0.66296, 0.27942, 0.1215, 0.5365, 0.22013]
Predicted label: 5
Correct prediction
Energy consumption = 198.337308 pJ
sum error= 155
Actual label: 1
Output voltages: [0.22586, 0.74737, 0.076159, 0.33275, 0.15814, 0.31195, 0.24601, 0.12032, 0.33652, 0.30752]
Predicted label: 1
Correct prediction
Energy consumption = 213.799904 pJ
sum error= 155
Actual label: 5
Output voltages: [0.55258, 0.10989, 0.38843, 0.3301, 0.043496, 0.38535, 0.26713, 0.27063, 0.45115, 0.17937]
Predicted label: 0
Wrong prediction!
Energy consumption = 201.795711 pJ
sum error= 156
Actual label: 1
Output voltages: [0.14337, 0.7637, 0.25932, 0.39917, 0.26905, 0.14784, 0.28394, 0.21111, 0.14618, 0.33825]
Predicted label: 1
Correct prediction
Energy consumption = 213.648428 pJ
sum error= 156
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 378 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 378 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 378 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25996, 0.18316, 0.32705, 0.074674, 0.50226, 0.25506, 0.60105, 0.066503, 0.34861, 0.077692]
Predicted label: 6
Wrong prediction!
Energy consumption = 203.573798 pJ
sum error= 157
Actual label: 8
Output voltages: [0.25464, 0.27051, 0.32611, 0.40827, 0.18278, 0.088904, 0.23469, 0.095047, 0.66685, 0.29762]
Predicted label: 8
Correct prediction
Energy consumption = 211.692834 pJ
sum error= 157
Actual label: 8
Output voltages: [0.38289, 0.056588, 0.52824, 0.38745, 0.1197, 0.12897, 0.1527, 0.22232, 0.67185, 0.16658]
Predicted label: 8
Correct prediction
Energy consumption = 193.440235 pJ
sum error= 157
Actual label: 9
Output voltages: [0.37033, 0.096762, 0.16942, 0.25213, 0.38532, 0.24374, 0.12251, 0.26174, 0.27338, 0.6822]
Predicted label: 9
Correct prediction
Energy consumption = 192.905142 pJ
sum error= 157
Actual label: 1
Output voltages: [0.21314, 0.77314, 0.27553, 0.31032, 0.21225, 0.07867, 0.3505, 0.15663, 0.26532, 0.2852]
Predicted label: 1
Correct prediction
Energy consumption = 208.562840 pJ
sum error= 157
Actual label: 2
Output voltages: [0.36268, 0.42578, 0.68792, 0.28004, 0.093194, 0.028839, 0.20747, 0.34685, 0.34053, 0.20145]
Predicted label: 2
Correct prediction
Energy consumption = 196.599048 pJ
sum error= 157
Actual label: 1
Output voltages: [0.23401, 0.76328, 0.2628, 0.32419, 0.17446, 0.14791, 0.31606, 0.11082, 0.27969, 0.23169]
Predicted label: 1
Correct prediction
Energy consumption = 199.145115 pJ
sum error= 157
Actual label: 3
Output voltages: [0.37687, 0.13661, 0.42093, 0.6684, 0.14492, 0.10211, 0.1492, 0.14647, 0.54369, 0.2247]
Predicted label: 3
Correct prediction
Energy consumption = 196.400287 pJ
sum error= 157
Actual label: 5
Output voltages: [0.27297, 0.052867, 0.095429, 0.39359, 0.23322, 0.71454, 0.2593, 0.21868, 0.50812, 0.30187]
Predicted label: 5
Correct prediction
Energy consumption = 185.840735 pJ
sum error= 157
Actual label: 1
Output voltages: [0.18122, 0.75971, 0.20928, 0.27783, 0.21552, 0.088334, 0.35155, 0.12955, 0.3711, 0.23345]
Predicted label: 1
Correct prediction
Energy consumption = 207.007690 pJ
sum error= 157
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 379 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 379 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 379 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.68113, 0.20018, 0.2457, 0.17695, 0.12337, 0.2852, 0.43638, 0.13902, 0.34061, 0.2959]
Predicted label: 0
Correct prediction
Energy consumption = 196.447494 pJ
sum error= 157
Actual label: 9
Output voltages: [0.43806, 0.080927, 0.22338, 0.18821, 0.31521, 0.19733, 0.1837, 0.25435, 0.26277, 0.64628]
Predicted label: 9
Correct prediction
Energy consumption = 197.865167 pJ
sum error= 157
Actual label: 4
Output voltages: [0.21316, 0.11073, 0.27631, 0.13303, 0.75148, 0.15755, 0.27235, 0.25585, 0.25178, 0.33237]
Predicted label: 4
Correct prediction
Energy consumption = 195.055220 pJ
sum error= 157
Actual label: 4
Output voltages: [0.17579, 0.18389, 0.30229, 0.19373, 0.74604, 0.079439, 0.31758, 0.35003, 0.14645, 0.28988]
Predicted label: 4
Correct prediction
Energy consumption = 193.991492 pJ
sum error= 157
Actual label: 8
Output voltages: [0.16551, 0.29836, 0.26683, 0.3844, 0.15306, 0.16195, 0.16065, 0.23156, 0.72205, 0.28149]
Predicted label: 8
Correct prediction
Energy consumption = 200.913572 pJ
sum error= 157
Actual label: 3
Output voltages: [0.18254, 0.23307, 0.32586, 0.7332, 0.22286, 0.14873, 0.071951, 0.33128, 0.41076, 0.30929]
Predicted label: 3
Correct prediction
Energy consumption = 188.268735 pJ
sum error= 157
Actual label: 2
Output voltages: [0.21465, 0.50219, 0.48194, 0.38643, 0.087322, 0.03626, 0.32746, 0.13486, 0.45918, 0.2507]
Predicted label: 1
Wrong prediction!
Energy consumption = 194.836958 pJ
sum error= 158
Actual label: 5
Output voltages: [0.23208, 0.054268, 0.083025, 0.36368, 0.21139, 0.71062, 0.25419, 0.18466, 0.51204, 0.28328]
Predicted label: 5
Correct prediction
Energy consumption = 187.906618 pJ
sum error= 158
Actual label: 9
Output voltages: [0.37191, 0.12256, 0.18566, 0.22709, 0.27964, 0.14952, 0.07423, 0.19649, 0.4382, 0.6723]
Predicted label: 9
Correct prediction
Energy consumption = 190.522259 pJ
sum error= 158
Actual label: 7
Output voltages: [0.49717, 0.21445, 0.48952, 0.36915, 0.047087, 0.069737, 0.10289, 0.62239, 0.3681, 0.2486]
Predicted label: 7
Correct prediction
Energy consumption = 190.269603 pJ
sum error= 158
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 380 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 380 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 380 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39458, 0.24025, 0.17418, 0.30665, 0.22693, 0.35523, 0.62241, 0.089684, 0.4901, 0.090852]
Predicted label: 6
Correct prediction
Energy consumption = 195.241598 pJ
sum error= 158
Actual label: 6
Output voltages: [0.40148, 0.30586, 0.30228, 0.10713, 0.38677, 0.2699, 0.71357, 0.10995, 0.2355, 0.12762]
Predicted label: 6
Correct prediction
Energy consumption = 196.995583 pJ
sum error= 158
Actual label: 2
Output voltages: [0.36314, 0.23563, 0.7496, 0.28572, 0.19022, 0.037623, 0.23694, 0.26812, 0.42453, 0.2136]
Predicted label: 2
Correct prediction
Energy consumption = 182.847501 pJ
sum error= 158
Actual label: 0
Output voltages: [0.67312, 0.24096, 0.3085, 0.2453, 0.17858, 0.059435, 0.37029, 0.16794, 0.29307, 0.4131]
Predicted label: 0
Correct prediction
Energy consumption = 199.253623 pJ
sum error= 158
Actual label: 0
Output voltages: [0.70963, 0.23568, 0.22696, 0.19915, 0.15432, 0.10116, 0.36205, 0.20317, 0.35267, 0.33865]
Predicted label: 0
Correct prediction
Energy consumption = 193.433377 pJ
sum error= 158
Actual label: 0
Output voltages: [0.73615, 0.18645, 0.20116, 0.17785, 0.22885, 0.17766, 0.43524, 0.17997, 0.26635, 0.3219]
Predicted label: 0
Correct prediction
Energy consumption = 196.002104 pJ
sum error= 158
Actual label: 5
Output voltages: [0.25722, 0.1695, 0.040453, 0.29033, 0.29, 0.51941, 0.2641, 0.28765, 0.50127, 0.19952]
Predicted label: 5
Correct prediction
Energy consumption = 199.634268 pJ
sum error= 158
Actual label: 8
Output voltages: [0.27383, 0.14451, 0.32249, 0.3085, 0.11405, 0.3047, 0.14279, 0.16909, 0.75119, 0.20125]
Predicted label: 8
Correct prediction
Energy consumption = 182.595885 pJ
sum error= 158
Actual label: 7
Output voltages: [0.27583, 0.32738, 0.45407, 0.44745, 0.051896, 0.12113, 0.1125, 0.25245, 0.5577, 0.29955]
Predicted label: 8
Wrong prediction!
Energy consumption = 188.653929 pJ
sum error= 159
Actual label: 1
Output voltages: [0.15197, 0.7613, 0.1423, 0.20341, 0.34086, 0.1804, 0.4462, 0.15978, 0.27719, 0.21516]
Predicted label: 1
Correct prediction
Energy consumption = 199.865088 pJ
sum error= 159
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 381 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 381 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 381 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.17278, 0.050944, 0.17122, 0.41614, 0.22094, 0.65551, 0.31925, 0.17187, 0.50084, 0.29154]
Predicted label: 5
Correct prediction
Energy consumption = 191.829722 pJ
sum error= 159
Actual label: 2
Output voltages: [0.51323, 0.17227, 0.48362, 0.50294, 0.23673, 0.038759, 0.14722, 0.31304, 0.34376, 0.16096]
Predicted label: 0
Wrong prediction!
Energy consumption = 201.920481 pJ
sum error= 160
Actual label: 3
Output voltages: [0.41506, 0.13506, 0.36733, 0.7379, 0.22937, 0.16259, 0.11691, 0.20706, 0.39107, 0.14781]
Predicted label: 3
Correct prediction
Energy consumption = 192.039227 pJ
sum error= 160
Actual label: 8
Output voltages: [0.26619, 0.15633, 0.29689, 0.26396, 0.14966, 0.37554, 0.25508, 0.1324, 0.7406, 0.23087]
Predicted label: 8
Correct prediction
Energy consumption = 184.359376 pJ
sum error= 160
Actual label: 5
Output voltages: [0.27167, 0.048504, 0.071901, 0.30397, 0.17768, 0.67667, 0.29809, 0.085729, 0.56226, 0.2242]
Predicted label: 5
Correct prediction
Energy consumption = 185.870387 pJ
sum error= 160
Actual label: 1
Output voltages: [0.12052, 0.75491, 0.2227, 0.26088, 0.19897, 0.11468, 0.34504, 0.11938, 0.43794, 0.2422]
Predicted label: 1
Correct prediction
Energy consumption = 214.647488 pJ
sum error= 160
Actual label: 8
Output voltages: [0.28486, 0.12604, 0.21052, 0.33825, 0.14042, 0.35083, 0.21675, 0.14892, 0.74108, 0.23327]
Predicted label: 8
Correct prediction
Energy consumption = 194.033456 pJ
sum error= 160
Actual label: 2
Output voltages: [0.37828, 0.20751, 0.69971, 0.20215, 0.35489, 0.035942, 0.31005, 0.26886, 0.35859, 0.15615]
Predicted label: 2
Correct prediction
Energy consumption = 182.603384 pJ
sum error= 160
Actual label: 0
Output voltages: [0.52851, 0.16683, 0.37802, 0.081152, 0.21984, 0.13416, 0.58042, 0.058224, 0.41837, 0.28934]
Predicted label: 6
Wrong prediction!
Energy consumption = 195.280862 pJ
sum error= 161
Actual label: 4
Output voltages: [0.19377, 0.12519, 0.25969, 0.11834, 0.75213, 0.16973, 0.33884, 0.20515, 0.24412, 0.28481]
Predicted label: 4
Correct prediction
Energy consumption = 191.817836 pJ
sum error= 161
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 382 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 382 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 382 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.55381, 0.10449, 0.28686, 0.26509, 0.18858, 0.21062, 0.25023, 0.15717, 0.33575, 0.62878]
Predicted label: 9
Correct prediction
Energy consumption = 196.475303 pJ
sum error= 161
Actual label: 9
Output voltages: [0.22932, 0.11963, 0.23226, 0.2529, 0.57625, 0.29912, 0.29507, 0.13982, 0.27623, 0.58057]
Predicted label: 9
Correct prediction
Energy consumption = 193.115151 pJ
sum error= 161
Actual label: 6
Output voltages: [0.26889, 0.23074, 0.29347, 0.087067, 0.34082, 0.31909, 0.74906, 0.080188, 0.35028, 0.18687]
Predicted label: 6
Correct prediction
Energy consumption = 188.016904 pJ
sum error= 161
Actual label: 2
Output voltages: [0.38161, 0.2759, 0.73905, 0.30088, 0.19793, 0.033308, 0.32439, 0.23413, 0.36211, 0.16314]
Predicted label: 2
Correct prediction
Energy consumption = 192.883262 pJ
sum error= 161
Actual label: 3
Output voltages: [0.28672, 0.24968, 0.29649, 0.7578, 0.094259, 0.15403, 0.12449, 0.26609, 0.4412, 0.2496]
Predicted label: 3
Correct prediction
Energy consumption = 176.331143 pJ
sum error= 161
Actual label: 3
Output voltages: [0.28993, 0.13431, 0.29535, 0.7462, 0.27861, 0.30346, 0.26257, 0.12295, 0.37482, 0.20476]
Predicted label: 3
Correct prediction
Energy consumption = 186.399860 pJ
sum error= 161
Actual label: 5
Output voltages: [0.22117, 0.091372, 0.076117, 0.20535, 0.27229, 0.73622, 0.35101, 0.12772, 0.49253, 0.24829]
Predicted label: 5
Correct prediction
Energy consumption = 193.095417 pJ
sum error= 161
Actual label: 6
Output voltages: [0.34395, 0.26414, 0.29039, 0.12609, 0.21927, 0.30661, 0.72634, 0.093457, 0.34188, 0.23874]
Predicted label: 6
Correct prediction
Energy consumption = 189.736933 pJ
sum error= 161
Actual label: 4
Output voltages: [0.11949, 0.1303, 0.33823, 0.17954, 0.76037, 0.16065, 0.2605, 0.22736, 0.25615, 0.3122]
Predicted label: 4
Correct prediction
Energy consumption = 196.309839 pJ
sum error= 161
Actual label: 8
Output voltages: [0.27932, 0.1156, 0.30216, 0.34111, 0.10918, 0.28518, 0.20893, 0.085027, 0.72592, 0.29478]
Predicted label: 8
Correct prediction
Energy consumption = 188.288206 pJ
sum error= 161
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 383 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 383 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 383 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.70586, 0.20004, 0.20621, 0.15408, 0.17021, 0.25975, 0.42054, 0.17875, 0.35844, 0.27255]
Predicted label: 0
Correct prediction
Energy consumption = 200.360837 pJ
sum error= 161
Actual label: 9
Output voltages: [0.23123, 0.16835, 0.23549, 0.28568, 0.29424, 0.060299, 0.10029, 0.1503, 0.52378, 0.50225]
Predicted label: 8
Wrong prediction!
Energy consumption = 201.923753 pJ
sum error= 162
Actual label: 2
Output voltages: [0.43002, 0.27237, 0.70835, 0.29471, 0.088527, 0.02905, 0.26146, 0.38334, 0.42914, 0.23507]
Predicted label: 2
Correct prediction
Energy consumption = 190.582190 pJ
sum error= 162
Actual label: 8
Output voltages: [0.245, 0.29218, 0.31504, 0.48333, 0.093027, 0.086134, 0.12035, 0.29008, 0.6624, 0.19796]
Predicted label: 8
Correct prediction
Energy consumption = 199.874407 pJ
sum error= 162
Actual label: 3
Output voltages: [0.32256, 0.16979, 0.44732, 0.71067, 0.17245, 0.048688, 0.11783, 0.14202, 0.49392, 0.19445]
Predicted label: 3
Correct prediction
Energy consumption = 184.344090 pJ
sum error= 162
Actual label: 6
Output voltages: [0.38225, 0.25856, 0.29943, 0.10568, 0.30087, 0.31394, 0.73176, 0.10404, 0.33251, 0.17508]
Predicted label: 6
Correct prediction
Energy consumption = 195.889067 pJ
sum error= 162
Actual label: 7
Output voltages: [0.30751, 0.11238, 0.033886, 0.31405, 0.43575, 0.47671, 0.088271, 0.58135, 0.3121, 0.40733]
Predicted label: 7
Correct prediction
Energy consumption = 202.490802 pJ
sum error= 162
Actual label: 5
Output voltages: [0.30275, 0.094533, 0.077642, 0.42494, 0.14098, 0.7372, 0.22165, 0.18401, 0.53023, 0.21274]
Predicted label: 5
Correct prediction
Energy consumption = 189.881205 pJ
sum error= 162
Actual label: 7
Output voltages: [0.088753, 0.1064, 0.25896, 0.41061, 0.34645, 0.23592, 0.13234, 0.31595, 0.45195, 0.30846]
Predicted label: 8
Wrong prediction!
Energy consumption = 204.698232 pJ
sum error= 163
Actual label: 2
Output voltages: [0.28333, 0.21481, 0.63291, 0.33546, 0.12919, 0.036864, 0.26066, 0.15283, 0.56462, 0.28222]
Predicted label: 2
Correct prediction
Energy consumption = 189.778430 pJ
sum error= 163
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 384 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 384 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 384 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.44306, 0.080149, 0.24208, 0.18474, 0.4084, 0.1933, 0.2347, 0.17427, 0.22236, 0.66655]
Predicted label: 9
Correct prediction
Energy consumption = 199.015528 pJ
sum error= 163
Actual label: 4
Output voltages: [0.15595, 0.16387, 0.2883, 0.057765, 0.75486, 0.20693, 0.34147, 0.24075, 0.28012, 0.25423]
Predicted label: 4
Correct prediction
Energy consumption = 197.363046 pJ
sum error= 163
Actual label: 9
Output voltages: [0.32995, 0.14657, 0.19799, 0.20862, 0.34495, 0.20176, 0.1602, 0.20309, 0.34008, 0.69785]
Predicted label: 9
Correct prediction
Energy consumption = 189.820000 pJ
sum error= 163
Actual label: 1
Output voltages: [0.25109, 0.7656, 0.32715, 0.2668, 0.17114, 0.055836, 0.30535, 0.21646, 0.29277, 0.23925]
Predicted label: 1
Correct prediction
Energy consumption = 210.694481 pJ
sum error= 163
Actual label: 2
Output voltages: [0.36513, 0.24101, 0.72161, 0.40801, 0.17874, 0.034303, 0.22674, 0.37446, 0.39123, 0.17545]
Predicted label: 2
Correct prediction
Energy consumption = 184.256651 pJ
sum error= 163
Actual label: 8
Output voltages: [0.25228, 0.20343, 0.37286, 0.28147, 0.13711, 0.19366, 0.21301, 0.15284, 0.74724, 0.25879]
Predicted label: 8
Correct prediction
Energy consumption = 187.153241 pJ
sum error= 163
Actual label: 6
Output voltages: [0.41956, 0.3755, 0.32383, 0.064794, 0.3241, 0.26252, 0.63478, 0.078295, 0.24882, 0.22007]
Predicted label: 6
Correct prediction
Energy consumption = 203.592271 pJ
sum error= 163
Actual label: 0
Output voltages: [0.7316, 0.30828, 0.25681, 0.26678, 0.084372, 0.17476, 0.33072, 0.21276, 0.3029, 0.23918]
Predicted label: 0
Correct prediction
Energy consumption = 197.136286 pJ
sum error= 163
Actual label: 7
Output voltages: [0.30184, 0.1329, 0.43317, 0.44584, 0.27623, 0.034321, 0.081088, 0.48967, 0.43583, 0.23687]
Predicted label: 7
Correct prediction
Energy consumption = 191.257517 pJ
sum error= 163
Actual label: 0
Output voltages: [0.71688, 0.25682, 0.24539, 0.16673, 0.096145, 0.30451, 0.34728, 0.1058, 0.32048, 0.30878]
Predicted label: 0
Correct prediction
Energy consumption = 190.381090 pJ
sum error= 163
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 385 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 385 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 385 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.16328, 0.20037, 0.2931, 0.14303, 0.64387, 0.13089, 0.19773, 0.16905, 0.29435, 0.50582]
Predicted label: 4
Wrong prediction!
Energy consumption = 204.288615 pJ
sum error= 164
Actual label: 1
Output voltages: [0.27852, 0.77113, 0.14161, 0.24037, 0.16787, 0.22392, 0.41762, 0.12429, 0.28642, 0.20702]
Predicted label: 1
Correct prediction
Energy consumption = 216.434871 pJ
sum error= 164
Actual label: 1
Output voltages: [0.25176, 0.74052, 0.18881, 0.19627, 0.38157, 0.13742, 0.32775, 0.16101, 0.23797, 0.24254]
Predicted label: 1
Correct prediction
Energy consumption = 203.944885 pJ
sum error= 164
Actual label: 6
Output voltages: [0.39871, 0.25413, 0.25639, 0.20762, 0.17814, 0.36633, 0.51036, 0.050662, 0.51036, 0.13822]
Predicted label: 6
Wrong prediction!
Energy consumption = 193.420803 pJ
sum error= 165
Actual label: 7
Output voltages: [0.31682, 0.22931, 0.18425, 0.4047, 0.096508, 0.16338, 0.03274, 0.71911, 0.32416, 0.44228]
Predicted label: 7
Correct prediction
Energy consumption = 196.421773 pJ
sum error= 165
Actual label: 5
Output voltages: [0.35202, 0.20207, 0.061117, 0.3131, 0.14731, 0.73019, 0.28641, 0.12002, 0.58827, 0.088348]
Predicted label: 5
Correct prediction
Energy consumption = 201.451373 pJ
sum error= 165
Actual label: 9
Output voltages: [0.25497, 0.075375, 0.1423, 0.43193, 0.30858, 0.22069, 0.045968, 0.39963, 0.32555, 0.53887]
Predicted label: 9
Correct prediction
Energy consumption = 202.088782 pJ
sum error= 165
Actual label: 9
Output voltages: [0.31769, 0.13106, 0.21048, 0.27469, 0.25687, 0.1036, 0.084906, 0.23484, 0.42436, 0.66516]
Predicted label: 9
Correct prediction
Energy consumption = 195.570059 pJ
sum error= 165
Actual label: 1
Output voltages: [0.19839, 0.75978, 0.17967, 0.15053, 0.36873, 0.16391, 0.39619, 0.15568, 0.31775, 0.26449]
Predicted label: 1
Correct prediction
Energy consumption = 207.098469 pJ
sum error= 165
Actual label: 9
Output voltages: [0.28213, 0.071349, 0.39729, 0.37115, 0.42639, 0.13149, 0.16535, 0.20188, 0.22593, 0.54449]
Predicted label: 9
Correct prediction
Energy consumption = 197.851338 pJ
sum error= 165
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 386 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 386 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 386 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.19892, 0.054606, 0.13732, 0.27327, 0.26048, 0.67996, 0.39589, 0.1453, 0.55425, 0.23205]
Predicted label: 5
Correct prediction
Energy consumption = 184.500584 pJ
sum error= 165
Actual label: 9
Output voltages: [0.32335, 0.14668, 0.23488, 0.29547, 0.30064, 0.16012, 0.072199, 0.29041, 0.30916, 0.71156]
Predicted label: 9
Correct prediction
Energy consumption = 201.435480 pJ
sum error= 165
Actual label: 2
Output voltages: [0.39602, 0.45166, 0.6378, 0.38408, 0.10309, 0.025801, 0.20189, 0.31202, 0.24484, 0.20225]
Predicted label: 2
Correct prediction
Energy consumption = 191.523217 pJ
sum error= 165
Actual label: 5
Output voltages: [0.21283, 0.048061, 0.12637, 0.30091, 0.19412, 0.66258, 0.39939, 0.1013, 0.53565, 0.25501]
Predicted label: 5
Correct prediction
Energy consumption = 190.680348 pJ
sum error= 165
Actual label: 0
Output voltages: [0.68974, 0.2467, 0.2293, 0.19656, 0.18182, 0.13584, 0.45361, 0.19755, 0.40646, 0.24978]
Predicted label: 0
Correct prediction
Energy consumption = 190.383902 pJ
sum error= 165
Actual label: 4
Output voltages: [0.14486, 0.11173, 0.31036, 0.19869, 0.75548, 0.11044, 0.26607, 0.24583, 0.22071, 0.28713]
Predicted label: 4
Correct prediction
Energy consumption = 197.578328 pJ
sum error= 165
Actual label: 1
Output voltages: [0.23558, 0.76033, 0.10753, 0.30871, 0.2229, 0.19667, 0.30604, 0.15521, 0.25812, 0.28811]
Predicted label: 1
Correct prediction
Energy consumption = 212.086183 pJ
sum error= 165
Actual label: 0
Output voltages: [0.68676, 0.25803, 0.31827, 0.21255, 0.11383, 0.1687, 0.47316, 0.15744, 0.28347, 0.24337]
Predicted label: 0
Correct prediction
Energy consumption = 197.942266 pJ
sum error= 165
Actual label: 8
Output voltages: [0.18762, 0.23179, 0.26275, 0.3186, 0.14039, 0.17191, 0.19664, 0.12321, 0.74024, 0.28288]
Predicted label: 8
Correct prediction
Energy consumption = 203.628690 pJ
sum error= 165
Actual label: 9
Output voltages: [0.24587, 0.17041, 0.23044, 0.28291, 0.65092, 0.087497, 0.15774, 0.14455, 0.23981, 0.44925]
Predicted label: 4
Wrong prediction!
Energy consumption = 189.687086 pJ
sum error= 166
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 387 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 387 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 387 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69363, 0.26549, 0.24619, 0.19023, 0.16054, 0.10064, 0.42674, 0.17007, 0.28426, 0.32999]
Predicted label: 0
Correct prediction
Energy consumption = 192.602312 pJ
sum error= 166
Actual label: 8
Output voltages: [0.29764, 0.16024, 0.31837, 0.31024, 0.068666, 0.17428, 0.098192, 0.25947, 0.70209, 0.21944]
Predicted label: 8
Correct prediction
Energy consumption = 199.926931 pJ
sum error= 166
Actual label: 9
Output voltages: [0.32423, 0.14009, 0.23174, 0.34621, 0.35053, 0.15967, 0.12611, 0.21684, 0.32737, 0.66497]
Predicted label: 9
Correct prediction
Energy consumption = 190.302678 pJ
sum error= 166
Actual label: 8
Output voltages: [0.29876, 0.2414, 0.37427, 0.24254, 0.15371, 0.17829, 0.30344, 0.10656, 0.71874, 0.28632]
Predicted label: 8
Correct prediction
Energy consumption = 191.821745 pJ
sum error= 166
Actual label: 9
Output voltages: [0.37348, 0.18698, 0.23105, 0.31111, 0.31248, 0.099448, 0.072435, 0.18538, 0.32749, 0.68464]
Predicted label: 9
Correct prediction
Energy consumption = 189.245370 pJ
sum error= 166
Actual label: 4
Output voltages: [0.11867, 0.16793, 0.28708, 0.1382, 0.75173, 0.15371, 0.2731, 0.1355, 0.2805, 0.3412]
Predicted label: 4
Correct prediction
Energy consumption = 190.911680 pJ
sum error= 166
Actual label: 2
Output voltages: [0.39826, 0.36039, 0.58503, 0.35728, 0.087568, 0.0488, 0.38036, 0.18659, 0.44996, 0.12921]
Predicted label: 2
Correct prediction
Energy consumption = 202.558597 pJ
sum error= 166
Actual label: 5
Output voltages: [0.31593, 0.059108, 0.047484, 0.38983, 0.19704, 0.73048, 0.29989, 0.20502, 0.48806, 0.17259]
Predicted label: 5
Correct prediction
Energy consumption = 188.666265 pJ
sum error= 166
Actual label: 7
Output voltages: [0.25766, 0.39672, 0.20037, 0.22391, 0.091862, 0.060491, 0.048475, 0.69771, 0.3536, 0.45528]
Predicted label: 7
Correct prediction
Energy consumption = 208.082718 pJ
sum error= 166
Actual label: 9
Output voltages: [0.49203, 0.060216, 0.23132, 0.26843, 0.36623, 0.21229, 0.15484, 0.18019, 0.29139, 0.61603]
Predicted label: 9
Correct prediction
Energy consumption = 193.302567 pJ
sum error= 166
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 388 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 388 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 388 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.22113, 0.20444, 0.30361, 0.23961, 0.14624, 0.23683, 0.20797, 0.071627, 0.71796, 0.39602]
Predicted label: 8
Correct prediction
Energy consumption = 204.599974 pJ
sum error= 166
Actual label: 9
Output voltages: [0.38343, 0.070574, 0.20831, 0.23937, 0.26676, 0.25896, 0.13821, 0.29244, 0.36716, 0.63895]
Predicted label: 9
Correct prediction
Energy consumption = 201.212713 pJ
sum error= 166
Actual label: 8
Output voltages: [0.21413, 0.18465, 0.2605, 0.25468, 0.17461, 0.26073, 0.1892, 0.12253, 0.75, 0.33508]
Predicted label: 8
Correct prediction
Energy consumption = 193.962649 pJ
sum error= 166
Actual label: 0
Output voltages: [0.73728, 0.25525, 0.28382, 0.22564, 0.13136, 0.23786, 0.39602, 0.19191, 0.23446, 0.23577]
Predicted label: 0
Correct prediction
Energy consumption = 191.618132 pJ
sum error= 166
Actual label: 9
Output voltages: [0.4211, 0.082758, 0.30726, 0.19283, 0.25204, 0.18513, 0.24663, 0.14265, 0.33652, 0.68476]
Predicted label: 9
Correct prediction
Energy consumption = 196.236247 pJ
sum error= 166
Actual label: 9
Output voltages: [0.42892, 0.064389, 0.30461, 0.22828, 0.41747, 0.15633, 0.18228, 0.18894, 0.2404, 0.6704]
Predicted label: 9
Correct prediction
Energy consumption = 195.868455 pJ
sum error= 166
Actual label: 6
Output voltages: [0.30246, 0.25371, 0.24215, 0.17482, 0.28778, 0.39212, 0.74222, 0.077196, 0.3323, 0.25369]
Predicted label: 6
Correct prediction
Energy consumption = 191.110602 pJ
sum error= 166
Actual label: 8
Output voltages: [0.22988, 0.19568, 0.29808, 0.35154, 0.11683, 0.21635, 0.24477, 0.11697, 0.74365, 0.27778]
Predicted label: 8
Correct prediction
Energy consumption = 194.126121 pJ
sum error= 166
Actual label: 9
Output voltages: [0.38898, 0.13755, 0.21695, 0.22341, 0.37583, 0.20404, 0.22555, 0.20222, 0.26254, 0.69349]
Predicted label: 9
Correct prediction
Energy consumption = 201.867511 pJ
sum error= 166
Actual label: 9
Output voltages: [0.32611, 0.13743, 0.21591, 0.22856, 0.34682, 0.19601, 0.11499, 0.22446, 0.37952, 0.71455]
Predicted label: 9
Correct prediction
Energy consumption = 176.456792 pJ
sum error= 166
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 389 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 389 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 389 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.34512, 0.0511, 0.067903, 0.4348, 0.16725, 0.64789, 0.26711, 0.16203, 0.55017, 0.15326]
Predicted label: 5
Correct prediction
Energy consumption = 192.985469 pJ
sum error= 166
Actual label: 9
Output voltages: [0.31884, 0.13897, 0.18138, 0.2357, 0.28776, 0.11775, 0.05617, 0.18617, 0.40904, 0.67201]
Predicted label: 9
Correct prediction
Energy consumption = 191.125962 pJ
sum error= 166
Actual label: 8
Output voltages: [0.15978, 0.15401, 0.28505, 0.32077, 0.13436, 0.29932, 0.28358, 0.10071, 0.72326, 0.24819]
Predicted label: 8
Correct prediction
Energy consumption = 191.122076 pJ
sum error= 166
Actual label: 5
Output voltages: [0.36302, 0.076002, 0.13207, 0.35798, 0.24265, 0.50806, 0.5473, 0.1363, 0.3558, 0.15744]
Predicted label: 6
Wrong prediction!
Energy consumption = 197.513503 pJ
sum error= 167
Actual label: 1
Output voltages: [0.11266, 0.74672, 0.17383, 0.36398, 0.20862, 0.06593, 0.23735, 0.20983, 0.44116, 0.2964]
Predicted label: 1
Correct prediction
Energy consumption = 213.349957 pJ
sum error= 167
Actual label: 0
Output voltages: [0.6881, 0.20405, 0.22235, 0.23741, 0.22576, 0.12473, 0.41467, 0.14692, 0.39706, 0.28733]
Predicted label: 0
Correct prediction
Energy consumption = 202.946025 pJ
sum error= 167
Actual label: 3
Output voltages: [0.28498, 0.24925, 0.28688, 0.76465, 0.14153, 0.17045, 0.12323, 0.25256, 0.42963, 0.2503]
Predicted label: 3
Correct prediction
Energy consumption = 177.808378 pJ
sum error= 167
Actual label: 3
Output voltages: [0.21008, 0.3491, 0.36544, 0.73664, 0.12447, 0.091644, 0.133, 0.26089, 0.38187, 0.207]
Predicted label: 3
Correct prediction
Energy consumption = 193.555112 pJ
sum error= 167
Actual label: 5
Output voltages: [0.20544, 0.070279, 0.15145, 0.43153, 0.18769, 0.58856, 0.17251, 0.19525, 0.51284, 0.32132]
Predicted label: 5
Correct prediction
Energy consumption = 187.252991 pJ
sum error= 167
Actual label: 2
Output voltages: [0.3448, 0.15064, 0.61844, 0.52864, 0.14197, 0.032792, 0.22368, 0.23542, 0.43804, 0.20283]
Predicted label: 2
Correct prediction
Energy consumption = 192.170421 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 390 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 390 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 390 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1769, 0.75899, 0.2895, 0.30936, 0.28194, 0.053162, 0.34094, 0.17057, 0.28913, 0.23465]
Predicted label: 1
Correct prediction
Energy consumption = 213.878657 pJ
sum error= 167
Actual label: 6
Output voltages: [0.39506, 0.23803, 0.27809, 0.1031, 0.2775, 0.3276, 0.7143, 0.13655, 0.41977, 0.11932]
Predicted label: 6
Correct prediction
Energy consumption = 191.945814 pJ
sum error= 167
Actual label: 5
Output voltages: [0.24901, 0.050026, 0.15219, 0.36946, 0.17591, 0.64378, 0.28367, 0.22671, 0.53636, 0.22626]
Predicted label: 5
Correct prediction
Energy consumption = 198.838606 pJ
sum error= 167
Actual label: 0
Output voltages: [0.72747, 0.24289, 0.23926, 0.18641, 0.22068, 0.11808, 0.46084, 0.17538, 0.27013, 0.26435]
Predicted label: 0
Correct prediction
Energy consumption = 198.690040 pJ
sum error= 167
Actual label: 2
Output voltages: [0.31205, 0.28467, 0.72362, 0.3353, 0.14061, 0.023952, 0.22632, 0.27511, 0.39699, 0.251]
Predicted label: 2
Correct prediction
Energy consumption = 190.392309 pJ
sum error= 167
Actual label: 8
Output voltages: [0.11953, 0.26138, 0.26873, 0.42686, 0.18424, 0.13019, 0.19438, 0.12811, 0.63393, 0.26613]
Predicted label: 8
Correct prediction
Energy consumption = 200.177588 pJ
sum error= 167
Actual label: 1
Output voltages: [0.25361, 0.48996, 0.41376, 0.66968, 0.11635, 0.099405, 0.15595, 0.21077, 0.26591, 0.19369]
Predicted label: 3
Wrong prediction!
Energy consumption = 184.955334 pJ
sum error= 168
Actual label: 5
Output voltages: [0.25542, 0.068052, 0.064194, 0.37431, 0.16685, 0.73264, 0.30304, 0.1869, 0.50528, 0.16608]
Predicted label: 5
Correct prediction
Energy consumption = 184.218380 pJ
sum error= 168
Actual label: 6
Output voltages: [0.31553, 0.19245, 0.2537, 0.1225, 0.32435, 0.34542, 0.7347, 0.095307, 0.44756, 0.12812]
Predicted label: 6
Correct prediction
Energy consumption = 186.553929 pJ
sum error= 168
Actual label: 2
Output voltages: [0.35357, 0.3835, 0.69495, 0.25015, 0.10775, 0.028536, 0.2096, 0.49349, 0.33342, 0.20204]
Predicted label: 2
Correct prediction
Energy consumption = 188.727331 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 391 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 391 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 391 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.47189, 0.14919, 0.307, 0.75863, 0.19342, 0.22323, 0.14944, 0.18791, 0.38847, 0.20478]
Predicted label: 3
Correct prediction
Energy consumption = 192.359783 pJ
sum error= 168
Actual label: 0
Output voltages: [0.72386, 0.20507, 0.3567, 0.18004, 0.15734, 0.10955, 0.42348, 0.28141, 0.22445, 0.31144]
Predicted label: 0
Correct prediction
Energy consumption = 188.732205 pJ
sum error= 168
Actual label: 2
Output voltages: [0.35471, 0.1761, 0.74511, 0.30157, 0.28148, 0.045254, 0.21485, 0.24737, 0.37309, 0.17873]
Predicted label: 2
Correct prediction
Energy consumption = 184.498659 pJ
sum error= 168
Actual label: 2
Output voltages: [0.45411, 0.14746, 0.7395, 0.28933, 0.16585, 0.041043, 0.23009, 0.25878, 0.41116, 0.18021]
Predicted label: 2
Correct prediction
Energy consumption = 182.989955 pJ
sum error= 168
Actual label: 6
Output voltages: [0.27532, 0.20367, 0.31073, 0.10684, 0.31722, 0.28879, 0.72113, 0.090222, 0.30843, 0.20706]
Predicted label: 6
Correct prediction
Energy consumption = 191.630483 pJ
sum error= 168
Actual label: 4
Output voltages: [0.20399, 0.16237, 0.30068, 0.19908, 0.75036, 0.064264, 0.28794, 0.24331, 0.15735, 0.23228]
Predicted label: 4
Correct prediction
Energy consumption = 193.534912 pJ
sum error= 168
Actual label: 3
Output voltages: [0.27274, 0.18072, 0.34, 0.71857, 0.18442, 0.05391, 0.12756, 0.12625, 0.49043, 0.27919]
Predicted label: 3
Correct prediction
Energy consumption = 187.046237 pJ
sum error= 168
Actual label: 5
Output voltages: [0.26792, 0.044725, 0.1548, 0.42363, 0.16552, 0.58787, 0.28585, 0.14916, 0.56051, 0.23733]
Predicted label: 5
Correct prediction
Energy consumption = 186.421735 pJ
sum error= 168
Actual label: 5
Output voltages: [0.36963, 0.094739, 0.11878, 0.36847, 0.19959, 0.62222, 0.21712, 0.094134, 0.46481, 0.34513]
Predicted label: 5
Correct prediction
Energy consumption = 185.323881 pJ
sum error= 168
Actual label: 1
Output voltages: [0.16323, 0.75857, 0.28653, 0.31632, 0.21988, 0.11749, 0.37672, 0.15544, 0.31049, 0.1927]
Predicted label: 1
Correct prediction
Energy consumption = 213.708978 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 392 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 392 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 392 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32192, 0.23848, 0.25666, 0.20254, 0.16675, 0.10528, 0.046016, 0.7601, 0.33922, 0.32349]
Predicted label: 7
Correct prediction
Energy consumption = 202.674533 pJ
sum error= 168
Actual label: 2
Output voltages: [0.25484, 0.20314, 0.62808, 0.49699, 0.20085, 0.044725, 0.19326, 0.19739, 0.47699, 0.1694]
Predicted label: 2
Correct prediction
Energy consumption = 192.661028 pJ
sum error= 168
Actual label: 1
Output voltages: [0.15909, 0.72568, 0.2477, 0.18197, 0.24261, 0.15296, 0.55221, 0.065514, 0.3512, 0.16918]
Predicted label: 1
Correct prediction
Energy consumption = 208.501842 pJ
sum error= 168
Actual label: 6
Output voltages: [0.28184, 0.19299, 0.25197, 0.11077, 0.31511, 0.36331, 0.73246, 0.10727, 0.378, 0.09734]
Predicted label: 6
Correct prediction
Energy consumption = 192.835011 pJ
sum error= 168
Actual label: 9
Output voltages: [0.39937, 0.10949, 0.25326, 0.26816, 0.32883, 0.19978, 0.13869, 0.28563, 0.34088, 0.644]
Predicted label: 9
Correct prediction
Energy consumption = 197.479632 pJ
sum error= 168
Actual label: 1
Output voltages: [0.2321, 0.73502, 0.3352, 0.23723, 0.32366, 0.056809, 0.31068, 0.17697, 0.31367, 0.213]
Predicted label: 1
Correct prediction
Energy consumption = 192.037048 pJ
sum error= 168
Actual label: 9
Output voltages: [0.2066, 0.16957, 0.22034, 0.50838, 0.23103, 0.28719, 0.11402, 0.050391, 0.49538, 0.45976]
Predicted label: 3
Wrong prediction!
Energy consumption = 200.753364 pJ
sum error= 169
Actual label: 9
Output voltages: [0.38772, 0.089126, 0.18403, 0.25484, 0.3823, 0.18104, 0.11409, 0.2778, 0.36392, 0.63785]
Predicted label: 9
Correct prediction
Energy consumption = 190.428731 pJ
sum error= 169
Actual label: 5
Output voltages: [0.34529, 0.068669, 0.10965, 0.42398, 0.13586, 0.6185, 0.31964, 0.1068, 0.52744, 0.27018]
Predicted label: 5
Correct prediction
Energy consumption = 199.009264 pJ
sum error= 169
Actual label: 5
Output voltages: [0.30118, 0.060953, 0.17084, 0.42367, 0.10074, 0.70689, 0.3213, 0.18286, 0.5334, 0.26323]
Predicted label: 5
Correct prediction
Energy consumption = 182.559701 pJ
sum error= 169
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 393 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 393 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 393 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.18839, 0.75557, 0.22293, 0.30558, 0.26225, 0.064464, 0.34559, 0.1579, 0.31735, 0.26001]
Predicted label: 1
Correct prediction
Energy consumption = 215.267901 pJ
sum error= 169
Actual label: 6
Output voltages: [0.26712, 0.25093, 0.23718, 0.14249, 0.25737, 0.42868, 0.72481, 0.13717, 0.40668, 0.12913]
Predicted label: 6
Correct prediction
Energy consumption = 199.061548 pJ
sum error= 169
Actual label: 2
Output voltages: [0.3842, 0.16991, 0.72647, 0.38342, 0.14298, 0.046122, 0.25017, 0.17928, 0.43283, 0.1656]
Predicted label: 2
Correct prediction
Energy consumption = 192.338397 pJ
sum error= 169
Actual label: 2
Output voltages: [0.37576, 0.2967, 0.73349, 0.34271, 0.21878, 0.034704, 0.27064, 0.28266, 0.34062, 0.20639]
Predicted label: 2
Correct prediction
Energy consumption = 178.378100 pJ
sum error= 169
Actual label: 8
Output voltages: [0.20322, 0.1659, 0.247, 0.30247, 0.13577, 0.31272, 0.18139, 0.13142, 0.74842, 0.3158]
Predicted label: 8
Correct prediction
Energy consumption = 191.412682 pJ
sum error= 169
Actual label: 6
Output voltages: [0.29976, 0.17349, 0.25526, 0.1417, 0.31766, 0.40438, 0.7283, 0.060944, 0.36269, 0.1174]
Predicted label: 6
Correct prediction
Energy consumption = 192.642123 pJ
sum error= 169
Actual label: 7
Output voltages: [0.23346, 0.1959, 0.50617, 0.37841, 0.13642, 0.047317, 0.086183, 0.7353, 0.36266, 0.23588]
Predicted label: 7
Correct prediction
Energy consumption = 191.415444 pJ
sum error= 169
Actual label: 1
Output voltages: [0.17307, 0.75495, 0.15272, 0.28376, 0.21512, 0.32053, 0.34868, 0.18887, 0.30421, 0.21524]
Predicted label: 1
Correct prediction
Energy consumption = 217.035496 pJ
sum error= 169
Actual label: 4
Output voltages: [0.21201, 0.18641, 0.28428, 0.25249, 0.74523, 0.086799, 0.22547, 0.16558, 0.18552, 0.38999]
Predicted label: 4
Correct prediction
Energy consumption = 207.273705 pJ
sum error= 169
Actual label: 6
Output voltages: [0.36984, 0.14178, 0.32024, 0.088528, 0.38299, 0.23476, 0.72366, 0.081482, 0.28673, 0.31342]
Predicted label: 6
Correct prediction
Energy consumption = 186.730837 pJ
sum error= 169
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 394 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 394 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 394 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.70936, 0.15527, 0.27001, 0.25926, 0.087117, 0.30936, 0.44065, 0.1501, 0.31549, 0.24797]
Predicted label: 0
Correct prediction
Energy consumption = 192.108835 pJ
sum error= 169
Actual label: 4
Output voltages: [0.31625, 0.29563, 0.34933, 0.1224, 0.47224, 0.10043, 0.56219, 0.084063, 0.32989, 0.057314]
Predicted label: 6
Wrong prediction!
Energy consumption = 192.750832 pJ
sum error= 170
Actual label: 0
Output voltages: [0.6126, 0.20925, 0.20741, 0.067042, 0.2081, 0.19734, 0.49764, 0.17977, 0.33216, 0.26459]
Predicted label: 0
Correct prediction
Energy consumption = 196.121901 pJ
sum error= 170
Actual label: 3
Output voltages: [0.14509, 0.10188, 0.1755, 0.64254, 0.32411, 0.42937, 0.30036, 0.12188, 0.45676, 0.089987]
Predicted label: 3
Correct prediction
Energy consumption = 196.428171 pJ
sum error= 170
Actual label: 3
Output voltages: [0.31068, 0.14975, 0.29146, 0.74762, 0.17618, 0.1784, 0.14851, 0.13894, 0.4473, 0.24582]
Predicted label: 3
Correct prediction
Energy consumption = 184.381234 pJ
sum error= 170
Actual label: 2
Output voltages: [0.34164, 0.21911, 0.75235, 0.28029, 0.17043, 0.037846, 0.27932, 0.26141, 0.37174, 0.15688]
Predicted label: 2
Correct prediction
Energy consumption = 192.248420 pJ
sum error= 170
Actual label: 2
Output voltages: [0.34918, 0.42103, 0.58964, 0.34156, 0.10835, 0.03968, 0.2964, 0.18685, 0.4489, 0.19866]
Predicted label: 2
Correct prediction
Energy consumption = 193.061989 pJ
sum error= 170
Actual label: 3
Output voltages: [0.34744, 0.20837, 0.31357, 0.75782, 0.13823, 0.19321, 0.1408, 0.21124, 0.4555, 0.19153]
Predicted label: 3
Correct prediction
Energy consumption = 179.671545 pJ
sum error= 170
Actual label: 6
Output voltages: [0.30036, 0.22722, 0.37731, 0.059451, 0.25998, 0.33758, 0.73996, 0.068451, 0.35698, 0.19752]
Predicted label: 6
Correct prediction
Energy consumption = 192.359938 pJ
sum error= 170
Actual label: 8
Output voltages: [0.30059, 0.25165, 0.33262, 0.32943, 0.17885, 0.1461, 0.33788, 0.1053, 0.71154, 0.22134]
Predicted label: 8
Correct prediction
Energy consumption = 195.206640 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 395 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 395 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 395 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29544, 0.095554, 0.20744, 0.31568, 0.33126, 0.06099, 0.063785, 0.39451, 0.38156, 0.61018]
Predicted label: 9
Correct prediction
Energy consumption = 204.562501 pJ
sum error= 170
Actual label: 8
Output voltages: [0.40774, 0.11716, 0.3218, 0.32502, 0.10879, 0.1668, 0.10754, 0.20018, 0.64652, 0.38899]
Predicted label: 8
Correct prediction
Energy consumption = 198.770781 pJ
sum error= 170
Actual label: 5
Output voltages: [0.29502, 0.051815, 0.045531, 0.37036, 0.29539, 0.72455, 0.35385, 0.11625, 0.42027, 0.26571]
Predicted label: 5
Correct prediction
Energy consumption = 199.688512 pJ
sum error= 170
Actual label: 3
Output voltages: [0.35377, 0.13136, 0.40268, 0.75677, 0.20909, 0.15765, 0.15042, 0.22082, 0.37806, 0.23013]
Predicted label: 3
Correct prediction
Energy consumption = 180.529070 pJ
sum error= 170
Actual label: 8
Output voltages: [0.27345, 0.12559, 0.31647, 0.15926, 0.16083, 0.1938, 0.12336, 0.17284, 0.6721, 0.43797]
Predicted label: 8
Correct prediction
Energy consumption = 193.551892 pJ
sum error= 170
Actual label: 5
Output voltages: [0.29132, 0.082008, 0.062756, 0.30031, 0.17012, 0.73102, 0.34879, 0.17379, 0.49441, 0.20401]
Predicted label: 5
Correct prediction
Energy consumption = 188.235104 pJ
sum error= 170
Actual label: 4
Output voltages: [0.12047, 0.14303, 0.32945, 0.14475, 0.75252, 0.077813, 0.2464, 0.24029, 0.25263, 0.24859]
Predicted label: 4
Correct prediction
Energy consumption = 188.010958 pJ
sum error= 170
Actual label: 5
Output voltages: [0.26278, 0.05888, 0.098555, 0.40334, 0.17608, 0.73676, 0.30541, 0.25127, 0.45658, 0.26212]
Predicted label: 5
Correct prediction
Energy consumption = 189.614912 pJ
sum error= 170
Actual label: 2
Output voltages: [0.43169, 0.20959, 0.68973, 0.3901, 0.15353, 0.035842, 0.29419, 0.19647, 0.44662, 0.23471]
Predicted label: 2
Correct prediction
Energy consumption = 192.012140 pJ
sum error= 170
Actual label: 0
Output voltages: [0.73194, 0.24957, 0.22781, 0.21848, 0.17765, 0.16, 0.42097, 0.15256, 0.26673, 0.32849]
Predicted label: 0
Correct prediction
Energy consumption = 192.702448 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 396 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 396 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 396 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27374, 0.075734, 0.071168, 0.35163, 0.18009, 0.66372, 0.34993, 0.074102, 0.53369, 0.18433]
Predicted label: 5
Correct prediction
Energy consumption = 192.925758 pJ
sum error= 170
Actual label: 6
Output voltages: [0.30237, 0.090155, 0.19182, 0.18179, 0.29627, 0.40169, 0.63067, 0.06144, 0.52719, 0.15774]
Predicted label: 6
Correct prediction
Energy consumption = 184.570666 pJ
sum error= 170
Actual label: 3
Output voltages: [0.3008, 0.14815, 0.37332, 0.74112, 0.24538, 0.14767, 0.22858, 0.20826, 0.44511, 0.14297]
Predicted label: 3
Correct prediction
Energy consumption = 187.942771 pJ
sum error= 170
Actual label: 2
Output voltages: [0.40072, 0.22114, 0.74245, 0.33465, 0.20275, 0.038175, 0.28834, 0.22298, 0.38478, 0.1586]
Predicted label: 2
Correct prediction
Energy consumption = 181.901708 pJ
sum error= 170
Actual label: 8
Output voltages: [0.12989, 0.20731, 0.29201, 0.18958, 0.2125, 0.14832, 0.21534, 0.15134, 0.73317, 0.34015]
Predicted label: 8
Correct prediction
Energy consumption = 194.562574 pJ
sum error= 170
Actual label: 3
Output voltages: [0.30499, 0.20437, 0.3136, 0.74456, 0.23864, 0.20805, 0.18316, 0.19978, 0.42328, 0.14709]
Predicted label: 3
Correct prediction
Energy consumption = 189.964117 pJ
sum error= 170
Actual label: 9
Output voltages: [0.34198, 0.056363, 0.22377, 0.22906, 0.38152, 0.27779, 0.10079, 0.26762, 0.27997, 0.64793]
Predicted label: 9
Correct prediction
Energy consumption = 193.902146 pJ
sum error= 170
Actual label: 9
Output voltages: [0.43322, 0.19242, 0.16577, 0.23073, 0.35076, 0.20733, 0.23469, 0.19273, 0.32644, 0.68581]
Predicted label: 9
Correct prediction
Energy consumption = 198.290955 pJ
sum error= 170
Actual label: 5
Output voltages: [0.13206, 0.059995, 0.28838, 0.47127, 0.28039, 0.47672, 0.21042, 0.10968, 0.53974, 0.19734]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.411217 pJ
sum error= 171
Actual label: 7
Output voltages: [0.33805, 0.4721, 0.31055, 0.37294, 0.082346, 0.037508, 0.061676, 0.56814, 0.2765, 0.3751]
Predicted label: 7
Correct prediction
Energy consumption = 205.304389 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 397 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 397 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 397 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31987, 0.17772, 0.17446, 0.28262, 0.31316, 0.068981, 0.062306, 0.18418, 0.36754, 0.65925]
Predicted label: 9
Correct prediction
Energy consumption = 200.248096 pJ
sum error= 171
Actual label: 4
Output voltages: [0.18356, 0.12755, 0.35962, 0.08775, 0.7105, 0.085949, 0.40499, 0.19793, 0.28, 0.19982]
Predicted label: 4
Correct prediction
Energy consumption = 193.433027 pJ
sum error= 171
Actual label: 6
Output voltages: [0.33864, 0.16323, 0.2303, 0.15453, 0.32613, 0.39145, 0.72451, 0.067228, 0.42279, 0.17109]
Predicted label: 6
Correct prediction
Energy consumption = 190.467573 pJ
sum error= 171
Actual label: 7
Output voltages: [0.27872, 0.32506, 0.33264, 0.31002, 0.10493, 0.045747, 0.053932, 0.75357, 0.27723, 0.37559]
Predicted label: 7
Correct prediction
Energy consumption = 202.605170 pJ
sum error= 171
Actual label: 1
Output voltages: [0.30164, 0.76269, 0.26678, 0.31236, 0.24252, 0.055217, 0.21822, 0.22719, 0.28019, 0.28514]
Predicted label: 1
Correct prediction
Energy consumption = 211.107605 pJ
sum error= 171
Actual label: 3
Output voltages: [0.48298, 0.12973, 0.44645, 0.6781, 0.18919, 0.062636, 0.17163, 0.20098, 0.35257, 0.11433]
Predicted label: 3
Correct prediction
Energy consumption = 192.989165 pJ
sum error= 171
Actual label: 7
Output voltages: [0.26538, 0.56697, 0.23355, 0.37914, 0.11174, 0.066165, 0.079333, 0.60876, 0.30533, 0.30138]
Predicted label: 7
Correct prediction
Energy consumption = 206.494448 pJ
sum error= 171
Actual label: 3
Output voltages: [0.36393, 0.22178, 0.32268, 0.76045, 0.16323, 0.18306, 0.15781, 0.30895, 0.36153, 0.16824]
Predicted label: 3
Correct prediction
Energy consumption = 188.639747 pJ
sum error= 171
Actual label: 6
Output voltages: [0.37339, 0.20125, 0.16558, 0.19614, 0.29536, 0.44066, 0.71797, 0.095954, 0.40649, 0.17821]
Predicted label: 6
Correct prediction
Energy consumption = 194.059539 pJ
sum error= 171
Actual label: 6
Output voltages: [0.32436, 0.23299, 0.24694, 0.19998, 0.28189, 0.41492, 0.72203, 0.094113, 0.46641, 0.10342]
Predicted label: 6
Correct prediction
Energy consumption = 180.061645 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 398 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 398 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 398 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72344, 0.29012, 0.27524, 0.19536, 0.095239, 0.12366, 0.37137, 0.23387, 0.32659, 0.26874]
Predicted label: 0
Correct prediction
Energy consumption = 193.202860 pJ
sum error= 171
Actual label: 9
Output voltages: [0.32817, 0.15834, 0.23945, 0.3172, 0.30365, 0.17093, 0.20645, 0.24797, 0.27334, 0.69654]
Predicted label: 9
Correct prediction
Energy consumption = 197.745993 pJ
sum error= 171
Actual label: 0
Output voltages: [0.72435, 0.19547, 0.17814, 0.1646, 0.15502, 0.34669, 0.37039, 0.12686, 0.32054, 0.35707]
Predicted label: 0
Correct prediction
Energy consumption = 198.990407 pJ
sum error= 171
Actual label: 1
Output voltages: [0.27989, 0.72061, 0.20604, 0.23452, 0.38869, 0.080156, 0.32923, 0.1252, 0.29023, 0.23056]
Predicted label: 1
Correct prediction
Energy consumption = 207.428138 pJ
sum error= 171
Actual label: 9
Output voltages: [0.21007, 0.18619, 0.18921, 0.20189, 0.25766, 0.085781, 0.07965, 0.14176, 0.52886, 0.61555]
Predicted label: 9
Correct prediction
Energy consumption = 200.501556 pJ
sum error= 171
Actual label: 9
Output voltages: [0.25442, 0.11762, 0.28223, 0.28252, 0.51817, 0.067587, 0.097402, 0.23765, 0.26508, 0.55625]
Predicted label: 9
Correct prediction
Energy consumption = 197.490990 pJ
sum error= 171
Actual label: 2
Output voltages: [0.39938, 0.41819, 0.67166, 0.33566, 0.16898, 0.036466, 0.34247, 0.16343, 0.42901, 0.18379]
Predicted label: 2
Correct prediction
Energy consumption = 192.731151 pJ
sum error= 171
Actual label: 8
Output voltages: [0.33483, 0.27348, 0.32209, 0.39139, 0.10299, 0.12087, 0.29575, 0.068811, 0.66797, 0.3402]
Predicted label: 8
Correct prediction
Energy consumption = 201.164389 pJ
sum error= 171
Actual label: 8
Output voltages: [0.30654, 0.16012, 0.14063, 0.48109, 0.18159, 0.30344, 0.22945, 0.057495, 0.67133, 0.31318]
Predicted label: 8
Correct prediction
Energy consumption = 200.636597 pJ
sum error= 171
Actual label: 0
Output voltages: [0.68801, 0.21462, 0.24963, 0.19496, 0.24098, 0.075197, 0.3986, 0.20795, 0.34897, 0.26291]
Predicted label: 0
Correct prediction
Energy consumption = 199.330473 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 399 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 399 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 399 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.28723, 0.72173, 0.25861, 0.18558, 0.29265, 0.052258, 0.17969, 0.26255, 0.35656, 0.28289]
Predicted label: 1
Correct prediction
Energy consumption = 213.574607 pJ
sum error= 171
Actual label: 6
Output voltages: [0.29616, 0.18103, 0.27391, 0.12566, 0.30277, 0.3864, 0.73388, 0.060599, 0.39173, 0.14542]
Predicted label: 6
Correct prediction
Energy consumption = 195.592863 pJ
sum error= 171
Actual label: 9
Output voltages: [0.36775, 0.13324, 0.17122, 0.34144, 0.23679, 0.27189, 0.090915, 0.28201, 0.32066, 0.70489]
Predicted label: 9
Correct prediction
Energy consumption = 197.253068 pJ
sum error= 171
Actual label: 7
Output voltages: [0.36716, 0.2761, 0.25899, 0.29341, 0.14887, 0.05667, 0.045379, 0.75067, 0.26349, 0.33361]
Predicted label: 7
Correct prediction
Energy consumption = 195.628958 pJ
sum error= 171
Actual label: 5
Output voltages: [0.27984, 0.1484, 0.12261, 0.34229, 0.082963, 0.70211, 0.31154, 0.21268, 0.61196, 0.12369]
Predicted label: 5
Correct prediction
Energy consumption = 191.248034 pJ
sum error= 171
Actual label: 3
Output voltages: [0.29967, 0.07826, 0.20208, 0.71982, 0.19815, 0.43818, 0.20315, 0.18597, 0.42003, 0.22344]
Predicted label: 3
Correct prediction
Energy consumption = 180.713391 pJ
sum error= 171
Actual label: 4
Output voltages: [0.19552, 0.1067, 0.33329, 0.13359, 0.75638, 0.11304, 0.23988, 0.35302, 0.22076, 0.32068]
Predicted label: 4
Correct prediction
Energy consumption = 192.525627 pJ
sum error= 171
Actual label: 7
Output voltages: [0.27108, 0.1372, 0.1254, 0.40699, 0.13592, 0.25855, 0.058044, 0.69142, 0.33436, 0.28256]
Predicted label: 7
Correct prediction
Energy consumption = 197.893619 pJ
sum error= 171
Actual label: 4
Output voltages: [0.13505, 0.20117, 0.2669, 0.088639, 0.71598, 0.092373, 0.47203, 0.24623, 0.27068, 0.18408]
Predicted label: 4
Correct prediction
Energy consumption = 198.196868 pJ
sum error= 171
Actual label: 9
Output voltages: [0.37411, 0.13409, 0.19321, 0.34706, 0.31653, 0.26042, 0.10474, 0.29169, 0.29419, 0.70096]
Predicted label: 9
Correct prediction
Energy consumption = 189.362052 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 400 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 400 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 400 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30727, 0.062491, 0.30949, 0.24223, 0.43352, 0.23139, 0.11944, 0.074762, 0.39492, 0.61218]
Predicted label: 9
Correct prediction
Energy consumption = 199.504966 pJ
sum error= 171
Actual label: 4
Output voltages: [0.11119, 0.11319, 0.2515, 0.16531, 0.72921, 0.097523, 0.20674, 0.39659, 0.26742, 0.30674]
Predicted label: 4
Correct prediction
Energy consumption = 186.080937 pJ
sum error= 171
Actual label: 3
Output voltages: [0.19907, 0.17389, 0.25779, 0.62738, 0.15465, 0.31787, 0.17272, 0.082677, 0.59159, 0.20697]
Predicted label: 3
Correct prediction
Energy consumption = 194.853581 pJ
sum error= 171
Actual label: 6
Output voltages: [0.31268, 0.17856, 0.2419, 0.12028, 0.31437, 0.34843, 0.72151, 0.079382, 0.48319, 0.13776]
Predicted label: 6
Correct prediction
Energy consumption = 182.768649 pJ
sum error= 171
Actual label: 3
Output voltages: [0.37615, 0.22123, 0.25859, 0.75971, 0.18224, 0.23913, 0.24329, 0.21528, 0.39427, 0.16599]
Predicted label: 3
Correct prediction
Energy consumption = 188.223533 pJ
sum error= 171
Actual label: 1
Output voltages: [0.19894, 0.75067, 0.23532, 0.34664, 0.16021, 0.067214, 0.24033, 0.1694, 0.42905, 0.25749]
Predicted label: 1
Correct prediction
Energy consumption = 214.278888 pJ
sum error= 171
Actual label: 1
Output voltages: [0.17221, 0.7678, 0.23141, 0.32011, 0.20777, 0.090623, 0.31937, 0.17959, 0.27882, 0.24684]
Predicted label: 1
Correct prediction
Energy consumption = 212.075946 pJ
sum error= 171
Actual label: 7
Output voltages: [0.29759, 0.23731, 0.081848, 0.39872, 0.34996, 0.18475, 0.15677, 0.53037, 0.23796, 0.32306]
Predicted label: 7
Correct prediction
Energy consumption = 209.308733 pJ
sum error= 171
Actual label: 6
Output voltages: [0.33853, 0.19464, 0.3102, 0.09051, 0.32669, 0.32805, 0.73451, 0.065466, 0.40321, 0.16237]
Predicted label: 6
Correct prediction
Energy consumption = 191.127217 pJ
sum error= 171
Actual label: 9
Output voltages: [0.35288, 0.20269, 0.21567, 0.32104, 0.42816, 0.12703, 0.1473, 0.21318, 0.26494, 0.67036]
Predicted label: 9
Correct prediction
Energy consumption = 202.090862 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 401 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 401 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 401 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.26736, 0.76011, 0.3539, 0.23923, 0.23486, 0.054916, 0.35369, 0.060457, 0.30844, 0.26699]
Predicted label: 1
Correct prediction
Energy consumption = 210.266943 pJ
sum error= 171
Actual label: 8
Output voltages: [0.28396, 0.16032, 0.26411, 0.36911, 0.18281, 0.18165, 0.17788, 0.098219, 0.71678, 0.33282]
Predicted label: 8
Correct prediction
Energy consumption = 199.759716 pJ
sum error= 171
Actual label: 4
Output voltages: [0.14456, 0.1875, 0.26899, 0.22766, 0.75056, 0.21255, 0.23882, 0.24441, 0.20566, 0.38546]
Predicted label: 4
Correct prediction
Energy consumption = 200.365715 pJ
sum error= 171
Actual label: 1
Output voltages: [0.14209, 0.7306, 0.35287, 0.3221, 0.4159, 0.1414, 0.26062, 0.1439, 0.29064, 0.2046]
Predicted label: 1
Correct prediction
Energy consumption = 201.665693 pJ
sum error= 171
Actual label: 1
Output voltages: [0.17623, 0.75935, 0.32129, 0.33476, 0.20922, 0.049088, 0.28451, 0.16255, 0.29996, 0.21526]
Predicted label: 1
Correct prediction
Energy consumption = 212.217240 pJ
sum error= 171
Actual label: 9
Output voltages: [0.41058, 0.11359, 0.2069, 0.27867, 0.37724, 0.20175, 0.1161, 0.074546, 0.30811, 0.6368]
Predicted label: 9
Correct prediction
Energy consumption = 199.068264 pJ
sum error= 171
Actual label: 9
Output voltages: [0.3323, 0.15847, 0.19859, 0.26239, 0.30404, 0.14387, 0.069676, 0.17765, 0.38534, 0.68825]
Predicted label: 9
Correct prediction
Energy consumption = 182.599091 pJ
sum error= 171
Actual label: 4
Output voltages: [0.18177, 0.12338, 0.083969, 0.21082, 0.53141, 0.21059, 0.29543, 0.14963, 0.34604, 0.4055]
Predicted label: 4
Correct prediction
Energy consumption = 188.827211 pJ
sum error= 171
Actual label: 3
Output voltages: [0.35866, 0.22611, 0.30875, 0.73738, 0.067351, 0.2756, 0.12368, 0.24682, 0.44393, 0.15686]
Predicted label: 3
Correct prediction
Energy consumption = 190.627342 pJ
sum error= 171
Actual label: 6
Output voltages: [0.34268, 0.211, 0.20216, 0.18997, 0.26951, 0.40125, 0.72423, 0.069582, 0.39597, 0.16822]
Predicted label: 6
Correct prediction
Energy consumption = 191.065568 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 402 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 402 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 402 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.24864, 0.21253, 0.24397, 0.25026, 0.16494, 0.23834, 0.1825, 0.14315, 0.74532, 0.28933]
Predicted label: 8
Correct prediction
Energy consumption = 193.936755 pJ
sum error= 171
Actual label: 1
Output voltages: [0.20069, 0.76906, 0.2548, 0.22967, 0.13161, 0.062679, 0.41002, 0.0838, 0.34113, 0.23176]
Predicted label: 1
Correct prediction
Energy consumption = 206.094806 pJ
sum error= 171
Actual label: 6
Output voltages: [0.28002, 0.11653, 0.18885, 0.17614, 0.28499, 0.47331, 0.68361, 0.056546, 0.44876, 0.18843]
Predicted label: 6
Correct prediction
Energy consumption = 188.681226 pJ
sum error= 171
Actual label: 0
Output voltages: [0.72479, 0.23461, 0.15303, 0.21513, 0.10469, 0.37042, 0.32569, 0.14376, 0.29777, 0.27657]
Predicted label: 0
Correct prediction
Energy consumption = 191.924482 pJ
sum error= 171
Actual label: 4
Output voltages: [0.15848, 0.19309, 0.22773, 0.21645, 0.75177, 0.087955, 0.22848, 0.29428, 0.20399, 0.21308]
Predicted label: 4
Correct prediction
Energy consumption = 197.549781 pJ
sum error= 171
Actual label: 1
Output voltages: [0.2483, 0.75584, 0.26906, 0.27257, 0.29968, 0.101, 0.39611, 0.05074, 0.2057, 0.28401]
Predicted label: 1
Correct prediction
Energy consumption = 203.016435 pJ
sum error= 171
Actual label: 3
Output voltages: [0.2782, 0.19142, 0.30869, 0.75578, 0.16935, 0.15362, 0.16337, 0.19305, 0.44069, 0.23918]
Predicted label: 3
Correct prediction
Energy consumption = 183.507009 pJ
sum error= 171
Actual label: 7
Output voltages: [0.27922, 0.37009, 0.20015, 0.1772, 0.37881, 0.0513, 0.083751, 0.60183, 0.23322, 0.45132]
Predicted label: 7
Correct prediction
Energy consumption = 207.167235 pJ
sum error= 171
Actual label: 7
Output voltages: [0.32852, 0.23082, 0.20428, 0.2319, 0.089362, 0.10087, 0.044493, 0.73349, 0.38572, 0.38521]
Predicted label: 7
Correct prediction
Energy consumption = 200.011594 pJ
sum error= 171
Actual label: 4
Output voltages: [0.17312, 0.1336, 0.22453, 0.13941, 0.60865, 0.11245, 0.1631, 0.18351, 0.38516, 0.38995]
Predicted label: 4
Correct prediction
Energy consumption = 194.381694 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 403 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 403 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 403 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33134, 0.17999, 0.22946, 0.26088, 0.26557, 0.13619, 0.096188, 0.22675, 0.33508, 0.72061]
Predicted label: 9
Correct prediction
Energy consumption = 195.847442 pJ
sum error= 171
Actual label: 5
Output voltages: [0.25942, 0.07189, 0.11341, 0.47917, 0.12605, 0.61739, 0.28918, 0.13841, 0.53933, 0.28777]
Predicted label: 5
Correct prediction
Energy consumption = 195.604234 pJ
sum error= 171
Actual label: 1
Output voltages: [0.11321, 0.71561, 0.16668, 0.18002, 0.2681, 0.166, 0.46282, 0.10319, 0.4713, 0.18456]
Predicted label: 1
Correct prediction
Energy consumption = 214.389459 pJ
sum error= 171
Actual label: 0
Output voltages: [0.71864, 0.2509, 0.283, 0.16921, 0.099988, 0.17369, 0.39978, 0.1521, 0.29016, 0.29802]
Predicted label: 0
Correct prediction
Energy consumption = 193.109479 pJ
sum error= 171
Actual label: 0
Output voltages: [0.74657, 0.19743, 0.34931, 0.24866, 0.15254, 0.17338, 0.33586, 0.27123, 0.27372, 0.15623]
Predicted label: 0
Correct prediction
Energy consumption = 193.234060 pJ
sum error= 171
Actual label: 1
Output voltages: [0.2097, 0.7549, 0.33733, 0.28829, 0.16663, 0.060679, 0.31364, 0.16237, 0.38063, 0.19742]
Predicted label: 1
Correct prediction
Energy consumption = 208.674145 pJ
sum error= 171
Actual label: 1
Output voltages: [0.18589, 0.76692, 0.25305, 0.25195, 0.25018, 0.11074, 0.39864, 0.10696, 0.30299, 0.21178]
Predicted label: 1
Correct prediction
Energy consumption = 199.818658 pJ
sum error= 171
Actual label: 6
Output voltages: [0.34411, 0.34688, 0.11356, 0.31471, 0.14814, 0.35967, 0.64555, 0.13784, 0.56473, 0.090083]
Predicted label: 6
Correct prediction
Energy consumption = 197.063939 pJ
sum error= 171
Actual label: 2
Output voltages: [0.36097, 0.38137, 0.71969, 0.38494, 0.14084, 0.024275, 0.30725, 0.18783, 0.35393, 0.21759]
Predicted label: 2
Correct prediction
Energy consumption = 188.872210 pJ
sum error= 171
Actual label: 1
Output voltages: [0.20755, 0.76042, 0.25899, 0.23986, 0.25375, 0.057728, 0.35783, 0.089419, 0.30097, 0.24872]
Predicted label: 1
Correct prediction
Energy consumption = 202.334794 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 404 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 404 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 404 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39912, 0.090165, 0.22243, 0.26086, 0.37988, 0.201, 0.11674, 0.29586, 0.30945, 0.64603]
Predicted label: 9
Correct prediction
Energy consumption = 195.695770 pJ
sum error= 171
Actual label: 8
Output voltages: [0.29554, 0.16086, 0.26721, 0.34743, 0.14035, 0.33426, 0.16714, 0.19199, 0.74949, 0.26126]
Predicted label: 8
Correct prediction
Energy consumption = 190.856416 pJ
sum error= 171
Actual label: 4
Output voltages: [0.17216, 0.13135, 0.30806, 0.0904, 0.75535, 0.076257, 0.29665, 0.34654, 0.24487, 0.31787]
Predicted label: 4
Correct prediction
Energy consumption = 197.979939 pJ
sum error= 171
Actual label: 0
Output voltages: [0.7184, 0.24189, 0.19211, 0.16056, 0.14946, 0.28896, 0.35772, 0.14113, 0.35947, 0.26187]
Predicted label: 0
Correct prediction
Energy consumption = 198.617779 pJ
sum error= 171
Actual label: 3
Output voltages: [0.3919, 0.2334, 0.12904, 0.69624, 0.15667, 0.502, 0.2684, 0.29557, 0.30195, 0.075891]
Predicted label: 3
Correct prediction
Energy consumption = 195.789129 pJ
sum error= 171
Actual label: 6
Output voltages: [0.2833, 0.18947, 0.36311, 0.1068, 0.23022, 0.35054, 0.71488, 0.046762, 0.41941, 0.17003]
Predicted label: 6
Correct prediction
Energy consumption = 180.994971 pJ
sum error= 171
Actual label: 4
Output voltages: [0.18119, 0.19221, 0.29376, 0.11801, 0.75299, 0.058902, 0.36279, 0.24597, 0.19503, 0.28407]
Predicted label: 4
Correct prediction
Energy consumption = 195.314148 pJ
sum error= 171
Actual label: 9
Output voltages: [0.33488, 0.18186, 0.19096, 0.31954, 0.24668, 0.22006, 0.089797, 0.23556, 0.36626, 0.70617]
Predicted label: 9
Correct prediction
Energy consumption = 190.420492 pJ
sum error= 171
Actual label: 0
Output voltages: [0.73456, 0.30226, 0.37793, 0.29829, 0.069766, 0.14335, 0.34591, 0.14651, 0.28807, 0.3492]
Predicted label: 0
Correct prediction
Energy consumption = 196.811377 pJ
sum error= 171
Actual label: 7
Output voltages: [0.34866, 0.21783, 0.23282, 0.26166, 0.11435, 0.092583, 0.035174, 0.72654, 0.45263, 0.41476]
Predicted label: 7
Correct prediction
Energy consumption = 193.610941 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 405 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 405 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 405 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.22968, 0.76376, 0.19642, 0.28044, 0.21107, 0.19289, 0.43393, 0.1224, 0.29124, 0.23963]
Predicted label: 1
Correct prediction
Energy consumption = 218.276390 pJ
sum error= 171
Actual label: 6
Output voltages: [0.47455, 0.24164, 0.2593, 0.10635, 0.24818, 0.28703, 0.71752, 0.10115, 0.29226, 0.26197]
Predicted label: 6
Correct prediction
Energy consumption = 201.495097 pJ
sum error= 171
Actual label: 5
Output voltages: [0.27977, 0.053396, 0.053308, 0.37868, 0.2687, 0.68357, 0.33002, 0.12299, 0.47559, 0.29579]
Predicted label: 5
Correct prediction
Energy consumption = 193.944021 pJ
sum error= 171
Actual label: 7
Output voltages: [0.28623, 0.19313, 0.11453, 0.25323, 0.24346, 0.12444, 0.038423, 0.70998, 0.41061, 0.35607]
Predicted label: 7
Correct prediction
Energy consumption = 206.154058 pJ
sum error= 171
Actual label: 5
Output voltages: [0.228, 0.054561, 0.10663, 0.48758, 0.22101, 0.65888, 0.25859, 0.20423, 0.46832, 0.26295]
Predicted label: 5
Correct prediction
Energy consumption = 191.719163 pJ
sum error= 171
Actual label: 2
Output voltages: [0.3753, 0.16456, 0.69018, 0.40783, 0.092514, 0.040001, 0.27771, 0.27127, 0.53359, 0.13317]
Predicted label: 2
Correct prediction
Energy consumption = 183.265148 pJ
sum error= 171
Actual label: 5
Output voltages: [0.14219, 0.13496, 0.1178, 0.34887, 0.27339, 0.69202, 0.18283, 0.16228, 0.50176, 0.31346]
Predicted label: 5
Correct prediction
Energy consumption = 192.513832 pJ
sum error= 171
Actual label: 1
Output voltages: [0.25893, 0.76851, 0.24, 0.31863, 0.16831, 0.12175, 0.33146, 0.076509, 0.37017, 0.2514]
Predicted label: 1
Correct prediction
Energy consumption = 208.186519 pJ
sum error= 171
Actual label: 8
Output voltages: [0.21866, 0.1704, 0.26351, 0.37463, 0.091556, 0.22831, 0.13429, 0.12518, 0.74248, 0.27911]
Predicted label: 8
Correct prediction
Energy consumption = 201.334149 pJ
sum error= 171
Actual label: 5
Output voltages: [0.17958, 0.051076, 0.20401, 0.31712, 0.18897, 0.60337, 0.30589, 0.1308, 0.57042, 0.25798]
Predicted label: 5
Correct prediction
Energy consumption = 187.534266 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 406 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 406 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 406 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.21589, 0.15317, 0.30083, 0.18301, 0.74862, 0.11466, 0.34669, 0.28353, 0.19263, 0.35382]
Predicted label: 4
Correct prediction
Energy consumption = 201.168385 pJ
sum error= 171
Actual label: 7
Output voltages: [0.26654, 0.25869, 0.25144, 0.16278, 0.18598, 0.08125, 0.037578, 0.7455, 0.36659, 0.35345]
Predicted label: 7
Correct prediction
Energy consumption = 197.552042 pJ
sum error= 171
Actual label: 0
Output voltages: [0.71641, 0.23406, 0.26955, 0.20559, 0.12591, 0.163, 0.36533, 0.16758, 0.32388, 0.30408]
Predicted label: 0
Correct prediction
Energy consumption = 196.059872 pJ
sum error= 171
Actual label: 6
Output voltages: [0.36656, 0.17222, 0.12498, 0.29284, 0.19628, 0.53557, 0.6358, 0.066791, 0.45247, 0.15619]
Predicted label: 6
Correct prediction
Energy consumption = 192.353336 pJ
sum error= 171
Actual label: 7
Output voltages: [0.31142, 0.23794, 0.31444, 0.22111, 0.12288, 0.071919, 0.043747, 0.75422, 0.37766, 0.28462]
Predicted label: 7
Correct prediction
Energy consumption = 199.585293 pJ
sum error= 171
Actual label: 0
Output voltages: [0.60914, 0.16263, 0.37999, 0.44652, 0.06959, 0.19126, 0.42432, 0.31889, 0.36, 0.1745]
Predicted label: 0
Correct prediction
Energy consumption = 198.160840 pJ
sum error= 171
Actual label: 2
Output voltages: [0.33993, 0.32824, 0.72388, 0.3604, 0.12995, 0.028286, 0.27181, 0.25554, 0.38599, 0.24362]
Predicted label: 2
Correct prediction
Energy consumption = 184.076408 pJ
sum error= 171
Actual label: 5
Output voltages: [0.22622, 0.073815, 0.084927, 0.52188, 0.18883, 0.6778, 0.1936, 0.20151, 0.46854, 0.22773]
Predicted label: 5
Correct prediction
Energy consumption = 189.005919 pJ
sum error= 171
Actual label: 8
Output voltages: [0.33971, 0.10397, 0.34483, 0.34711, 0.112, 0.28975, 0.27925, 0.15837, 0.70255, 0.21114]
Predicted label: 8
Correct prediction
Energy consumption = 196.805239 pJ
sum error= 171
Actual label: 1
Output voltages: [0.25409, 0.76474, 0.24835, 0.30636, 0.27769, 0.087972, 0.31261, 0.20091, 0.25402, 0.25926]
Predicted label: 1
Correct prediction
Energy consumption = 214.346418 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 407 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 407 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 407 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73963, 0.28172, 0.27159, 0.18894, 0.14198, 0.25078, 0.36906, 0.1425, 0.23989, 0.32834]
Predicted label: 0
Correct prediction
Energy consumption = 194.626249 pJ
sum error= 171
Actual label: 4
Output voltages: [0.29298, 0.15849, 0.23752, 0.16744, 0.68555, 0.061138, 0.34126, 0.26441, 0.19806, 0.24652]
Predicted label: 4
Correct prediction
Energy consumption = 198.961129 pJ
sum error= 171
Actual label: 5
Output voltages: [0.24354, 0.14134, 0.053488, 0.41082, 0.19441, 0.7452, 0.2809, 0.13944, 0.50859, 0.22934]
Predicted label: 5
Correct prediction
Energy consumption = 195.470221 pJ
sum error= 171
Actual label: 7
Output voltages: [0.32075, 0.21112, 0.15734, 0.29379, 0.19114, 0.11084, 0.039661, 0.75556, 0.38319, 0.36544]
Predicted label: 7
Correct prediction
Energy consumption = 197.297376 pJ
sum error= 171
Actual label: 1
Output voltages: [0.21045, 0.77153, 0.15393, 0.29941, 0.23592, 0.14774, 0.31243, 0.15994, 0.24507, 0.32627]
Predicted label: 1
Correct prediction
Energy consumption = 212.249741 pJ
sum error= 171
Actual label: 8
Output voltages: [0.55313, 0.18055, 0.25414, 0.43116, 0.082231, 0.24526, 0.41477, 0.1524, 0.49912, 0.13648]
Predicted label: 0
Wrong prediction!
Energy consumption = 208.991342 pJ
sum error= 172
Actual label: 5
Output voltages: [0.31814, 0.11882, 0.1199, 0.35086, 0.19859, 0.60109, 0.38175, 0.061047, 0.50258, 0.26095]
Predicted label: 5
Correct prediction
Energy consumption = 195.992358 pJ
sum error= 172
Actual label: 1
Output voltages: [0.10729, 0.74532, 0.2929, 0.39485, 0.30955, 0.14069, 0.21729, 0.2995, 0.17521, 0.21937]
Predicted label: 1
Correct prediction
Energy consumption = 209.947978 pJ
sum error= 172
Actual label: 9
Output voltages: [0.35454, 0.094808, 0.5049, 0.37425, 0.18974, 0.05388, 0.13887, 0.31608, 0.53807, 0.25795]
Predicted label: 8
Wrong prediction!
Energy consumption = 199.994218 pJ
sum error= 173
Actual label: 0
Output voltages: [0.71746, 0.24233, 0.18972, 0.19502, 0.18257, 0.25326, 0.41004, 0.11493, 0.331, 0.31959]
Predicted label: 0
Correct prediction
Energy consumption = 198.135202 pJ
sum error= 173
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 408 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 408 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 408 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.70705, 0.241, 0.28496, 0.14516, 0.16547, 0.12438, 0.37985, 0.17356, 0.36372, 0.30455]
Predicted label: 0
Correct prediction
Energy consumption = 206.176374 pJ
sum error= 173
Actual label: 6
Output voltages: [0.31172, 0.13659, 0.20197, 0.19929, 0.31393, 0.32956, 0.62699, 0.097461, 0.53, 0.14087]
Predicted label: 6
Correct prediction
Energy consumption = 188.473743 pJ
sum error= 173
Actual label: 0
Output voltages: [0.69467, 0.14416, 0.25663, 0.14418, 0.1785, 0.34792, 0.39858, 0.10539, 0.30951, 0.31433]
Predicted label: 0
Correct prediction
Energy consumption = 194.423897 pJ
sum error= 173
Actual label: 7
Output voltages: [0.32456, 0.1827, 0.29244, 0.26901, 0.089001, 0.079464, 0.044417, 0.75771, 0.41394, 0.32542]
Predicted label: 7
Correct prediction
Energy consumption = 192.240962 pJ
sum error= 173
Actual label: 3
Output voltages: [0.36958, 0.23879, 0.26623, 0.75959, 0.10101, 0.14939, 0.093305, 0.31102, 0.41118, 0.29021]
Predicted label: 3
Correct prediction
Energy consumption = 184.074405 pJ
sum error= 173
Actual label: 1
Output voltages: [0.22675, 0.77094, 0.2452, 0.27742, 0.15563, 0.10266, 0.29935, 0.16056, 0.35899, 0.26177]
Predicted label: 1
Correct prediction
Energy consumption = 208.301398 pJ
sum error= 173
Actual label: 8
Output voltages: [0.219, 0.1036, 0.28134, 0.17831, 0.19113, 0.35125, 0.34731, 0.21018, 0.72451, 0.2134]
Predicted label: 8
Correct prediction
Energy consumption = 196.205276 pJ
sum error= 173
Actual label: 3
Output voltages: [0.26133, 0.13372, 0.38355, 0.70212, 0.24125, 0.18475, 0.076859, 0.16805, 0.50272, 0.22438]
Predicted label: 3
Correct prediction
Energy consumption = 187.594228 pJ
sum error= 173
Actual label: 9
Output voltages: [0.35469, 0.11893, 0.29889, 0.20894, 0.34778, 0.12511, 0.10889, 0.16435, 0.36992, 0.67929]
Predicted label: 9
Correct prediction
Energy consumption = 193.973290 pJ
sum error= 173
Actual label: 7
Output voltages: [0.27073, 0.25361, 0.36, 0.26152, 0.06001, 0.067698, 0.054776, 0.70702, 0.53084, 0.27254]
Predicted label: 7
Correct prediction
Energy consumption = 195.697309 pJ
sum error= 173
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 409 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 409 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 409 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73072, 0.25135, 0.19224, 0.25882, 0.15592, 0.21354, 0.40467, 0.14152, 0.29941, 0.29004]
Predicted label: 0
Correct prediction
Energy consumption = 206.606026 pJ
sum error= 173
Actual label: 0
Output voltages: [0.72157, 0.22467, 0.25478, 0.29764, 0.074974, 0.15376, 0.37373, 0.18136, 0.31904, 0.29154]
Predicted label: 0
Correct prediction
Energy consumption = 198.057511 pJ
sum error= 173
Actual label: 8
Output voltages: [0.30711, 0.26733, 0.2043, 0.29691, 0.095129, 0.30738, 0.34804, 0.15923, 0.71918, 0.16366]
Predicted label: 8
Correct prediction
Energy consumption = 203.697138 pJ
sum error= 173
Actual label: 9
Output voltages: [0.32916, 0.16196, 0.19958, 0.20272, 0.5946, 0.19791, 0.27998, 0.19384, 0.18573, 0.57499]
Predicted label: 4
Wrong prediction!
Energy consumption = 198.039613 pJ
sum error= 174
Actual label: 5
Output voltages: [0.27593, 0.051126, 0.16389, 0.3771, 0.17407, 0.61076, 0.29614, 0.13413, 0.50218, 0.27175]
Predicted label: 5
Correct prediction
Energy consumption = 194.740147 pJ
sum error= 174
Actual label: 9
Output voltages: [0.36308, 0.12312, 0.16917, 0.28016, 0.31377, 0.24467, 0.092566, 0.277, 0.35744, 0.70192]
Predicted label: 9
Correct prediction
Energy consumption = 191.978009 pJ
sum error= 174
Actual label: 8
Output voltages: [0.14903, 0.20978, 0.2933, 0.29993, 0.17966, 0.25718, 0.15918, 0.1257, 0.74055, 0.26251]
Predicted label: 8
Correct prediction
Energy consumption = 185.601561 pJ
sum error= 174
Actual label: 3
Output voltages: [0.36995, 0.17356, 0.33706, 0.75443, 0.21152, 0.12293, 0.15668, 0.19815, 0.40916, 0.24476]
Predicted label: 3
Correct prediction
Energy consumption = 181.791954 pJ
sum error= 174
Actual label: 2
Output voltages: [0.34454, 0.2548, 0.74608, 0.29019, 0.17748, 0.041821, 0.25258, 0.32676, 0.38614, 0.22375]
Predicted label: 2
Correct prediction
Energy consumption = 183.876929 pJ
sum error= 174
Actual label: 7
Output voltages: [0.3468, 0.17686, 0.55205, 0.24358, 0.068211, 0.04139, 0.063341, 0.66503, 0.45713, 0.29843]
Predicted label: 7
Correct prediction
Energy consumption = 189.945495 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 410 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 410 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 410 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33481, 0.21298, 0.6373, 0.51899, 0.12262, 0.040824, 0.2208, 0.16287, 0.49143, 0.16644]
Predicted label: 2
Correct prediction
Energy consumption = 185.251022 pJ
sum error= 174
Actual label: 9
Output voltages: [0.34559, 0.10195, 0.23267, 0.19149, 0.27573, 0.14838, 0.064105, 0.27614, 0.45407, 0.64755]
Predicted label: 9
Correct prediction
Energy consumption = 191.994531 pJ
sum error= 174
Actual label: 7
Output voltages: [0.29596, 0.13903, 0.056768, 0.42777, 0.42967, 0.28219, 0.062474, 0.50828, 0.1868, 0.46918]
Predicted label: 7
Correct prediction
Energy consumption = 197.337685 pJ
sum error= 174
Actual label: 2
Output voltages: [0.32467, 0.34911, 0.73404, 0.39451, 0.20863, 0.030025, 0.26895, 0.26715, 0.31631, 0.22323]
Predicted label: 2
Correct prediction
Energy consumption = 186.279321 pJ
sum error= 174
Actual label: 1
Output voltages: [0.24965, 0.7271, 0.29309, 0.24627, 0.28565, 0.053337, 0.37636, 0.11525, 0.35973, 0.19332]
Predicted label: 1
Correct prediction
Energy consumption = 207.814834 pJ
sum error= 174
Actual label: 1
Output voltages: [0.15676, 0.75726, 0.24952, 0.24931, 0.25426, 0.092202, 0.37374, 0.10867, 0.37049, 0.21509]
Predicted label: 1
Correct prediction
Energy consumption = 205.135994 pJ
sum error= 174
Actual label: 3
Output voltages: [0.26928, 0.26797, 0.27741, 0.74717, 0.10594, 0.15069, 0.1207, 0.13159, 0.53908, 0.25389]
Predicted label: 3
Correct prediction
Energy consumption = 184.287040 pJ
sum error= 174
Actual label: 7
Output voltages: [0.23291, 0.22274, 0.52757, 0.34505, 0.14949, 0.038333, 0.11131, 0.70761, 0.33616, 0.30373]
Predicted label: 7
Correct prediction
Energy consumption = 188.087255 pJ
sum error= 174
Actual label: 5
Output voltages: [0.27499, 0.12635, 0.049082, 0.37831, 0.18479, 0.70663, 0.18013, 0.10099, 0.43555, 0.24043]
Predicted label: 5
Correct prediction
Energy consumption = 195.202271 pJ
sum error= 174
Actual label: 3
Output voltages: [0.37087, 0.1745, 0.26296, 0.74241, 0.10334, 0.26074, 0.21104, 0.20165, 0.37307, 0.14504]
Predicted label: 3
Correct prediction
Energy consumption = 186.684411 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 411 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 411 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 411 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20727, 0.75233, 0.08987, 0.20351, 0.41294, 0.12942, 0.33681, 0.09842, 0.29804, 0.29643]
Predicted label: 1
Correct prediction
Energy consumption = 213.868276 pJ
sum error= 174
Actual label: 9
Output voltages: [0.32282, 0.059509, 0.39902, 0.21723, 0.26514, 0.20861, 0.32308, 0.12619, 0.38623, 0.58879]
Predicted label: 9
Correct prediction
Energy consumption = 203.518051 pJ
sum error= 174
Actual label: 8
Output voltages: [0.31533, 0.12874, 0.33211, 0.34343, 0.13222, 0.2084, 0.21531, 0.15132, 0.73939, 0.25034]
Predicted label: 8
Correct prediction
Energy consumption = 192.723500 pJ
sum error= 174
Actual label: 2
Output voltages: [0.3615, 0.36176, 0.67599, 0.42754, 0.20314, 0.025479, 0.27555, 0.22599, 0.32028, 0.18233]
Predicted label: 2
Correct prediction
Energy consumption = 194.589835 pJ
sum error= 174
Actual label: 2
Output voltages: [0.28602, 0.39647, 0.70253, 0.3347, 0.05642, 0.039963, 0.19492, 0.32791, 0.41276, 0.25857]
Predicted label: 2
Correct prediction
Energy consumption = 183.777238 pJ
sum error= 174
Actual label: 2
Output voltages: [0.4202, 0.17593, 0.71373, 0.41833, 0.15612, 0.034076, 0.21539, 0.28619, 0.44445, 0.17103]
Predicted label: 2
Correct prediction
Energy consumption = 187.688482 pJ
sum error= 174
Actual label: 8
Output voltages: [0.3379, 0.12159, 0.29287, 0.32629, 0.20237, 0.31723, 0.41286, 0.057459, 0.60302, 0.33013]
Predicted label: 8
Correct prediction
Energy consumption = 205.795766 pJ
sum error= 174
Actual label: 8
Output voltages: [0.26089, 0.17399, 0.44385, 0.23269, 0.17152, 0.11177, 0.22732, 0.10049, 0.70628, 0.3606]
Predicted label: 8
Correct prediction
Energy consumption = 186.183177 pJ
sum error= 174
Actual label: 5
Output voltages: [0.1758, 0.051292, 0.11843, 0.33095, 0.24496, 0.6209, 0.36716, 0.10009, 0.5384, 0.25066]
Predicted label: 5
Correct prediction
Energy consumption = 183.166231 pJ
sum error= 174
Actual label: 7
Output voltages: [0.21703, 0.36689, 0.34042, 0.28118, 0.13613, 0.036122, 0.052, 0.7471, 0.3003, 0.28769]
Predicted label: 7
Correct prediction
Energy consumption = 193.958060 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 412 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 412 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 412 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.50764, 0.20889, 0.23922, 0.7578, 0.075561, 0.31419, 0.082567, 0.26936, 0.33541, 0.17729]
Predicted label: 3
Correct prediction
Energy consumption = 189.772165 pJ
sum error= 174
Actual label: 8
Output voltages: [0.31331, 0.18971, 0.30429, 0.41533, 0.13925, 0.15496, 0.20873, 0.10025, 0.72936, 0.24463]
Predicted label: 8
Correct prediction
Energy consumption = 192.588496 pJ
sum error= 174
Actual label: 9
Output voltages: [0.3611, 0.086567, 0.16038, 0.25838, 0.34696, 0.28348, 0.10843, 0.35637, 0.29426, 0.6838]
Predicted label: 9
Correct prediction
Energy consumption = 191.507384 pJ
sum error= 174
Actual label: 8
Output voltages: [0.2889, 0.15157, 0.35746, 0.48159, 0.083941, 0.17811, 0.13451, 0.148, 0.66935, 0.32648]
Predicted label: 8
Correct prediction
Energy consumption = 194.845148 pJ
sum error= 174
Actual label: 8
Output voltages: [0.3524, 0.13861, 0.28208, 0.46452, 0.11155, 0.1334, 0.21788, 0.066651, 0.61635, 0.32663]
Predicted label: 8
Correct prediction
Energy consumption = 209.472144 pJ
sum error= 174
Actual label: 6
Output voltages: [0.30261, 0.21314, 0.30886, 0.07458, 0.3343, 0.29492, 0.74189, 0.088008, 0.39358, 0.10517]
Predicted label: 6
Correct prediction
Energy consumption = 186.946634 pJ
sum error= 174
Actual label: 8
Output voltages: [0.31655, 0.28199, 0.31927, 0.32178, 0.14503, 0.059328, 0.17651, 0.18886, 0.65166, 0.28156]
Predicted label: 8
Correct prediction
Energy consumption = 209.454145 pJ
sum error= 174
Actual label: 2
Output voltages: [0.3856, 0.33056, 0.73744, 0.25767, 0.15275, 0.023755, 0.30792, 0.25757, 0.37704, 0.25403]
Predicted label: 2
Correct prediction
Energy consumption = 187.412049 pJ
sum error= 174
Actual label: 3
Output voltages: [0.27182, 0.15908, 0.26744, 0.75432, 0.23708, 0.25832, 0.19269, 0.19648, 0.40229, 0.26767]
Predicted label: 3
Correct prediction
Energy consumption = 187.368973 pJ
sum error= 174
Actual label: 9
Output voltages: [0.35489, 0.18153, 0.18681, 0.344, 0.28307, 0.17506, 0.12348, 0.20975, 0.29992, 0.69768]
Predicted label: 9
Correct prediction
Energy consumption = 194.646978 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 413 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 413 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 413 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24354, 0.21027, 0.32376, 0.24615, 0.10322, 0.074803, 0.039786, 0.74127, 0.53196, 0.29761]
Predicted label: 7
Correct prediction
Energy consumption = 200.614643 pJ
sum error= 174
Actual label: 5
Output voltages: [0.28844, 0.19491, 0.068672, 0.41668, 0.09502, 0.73126, 0.22351, 0.14574, 0.52886, 0.16137]
Predicted label: 5
Correct prediction
Energy consumption = 204.071917 pJ
sum error= 174
Actual label: 6
Output voltages: [0.35344, 0.24051, 0.26625, 0.15416, 0.31735, 0.3371, 0.74777, 0.090993, 0.39743, 0.1326]
Predicted label: 6
Correct prediction
Energy consumption = 189.813421 pJ
sum error= 174
Actual label: 2
Output voltages: [0.31115, 0.19502, 0.75533, 0.26028, 0.16348, 0.041363, 0.25859, 0.25043, 0.41646, 0.18459]
Predicted label: 2
Correct prediction
Energy consumption = 182.536467 pJ
sum error= 174
Actual label: 9
Output voltages: [0.34995, 0.17658, 0.18228, 0.22527, 0.38734, 0.098186, 0.1956, 0.16972, 0.3557, 0.64739]
Predicted label: 9
Correct prediction
Energy consumption = 201.784752 pJ
sum error= 174
Actual label: 2
Output voltages: [0.35461, 0.29456, 0.68011, 0.31177, 0.21605, 0.028265, 0.28397, 0.30448, 0.36673, 0.21403]
Predicted label: 2
Correct prediction
Energy consumption = 195.341608 pJ
sum error= 174
Actual label: 8
Output voltages: [0.24941, 0.18319, 0.43682, 0.28033, 0.17287, 0.073272, 0.24834, 0.1185, 0.72848, 0.31488]
Predicted label: 8
Correct prediction
Energy consumption = 191.280838 pJ
sum error= 174
Actual label: 8
Output voltages: [0.14717, 0.23045, 0.21636, 0.26072, 0.19506, 0.30239, 0.41727, 0.14999, 0.70878, 0.16241]
Predicted label: 8
Correct prediction
Energy consumption = 201.438409 pJ
sum error= 174
Actual label: 1
Output voltages: [0.20799, 0.76526, 0.19997, 0.24788, 0.24912, 0.087373, 0.39331, 0.12779, 0.29818, 0.23785]
Predicted label: 1
Correct prediction
Energy consumption = 206.251961 pJ
sum error= 174
Actual label: 6
Output voltages: [0.25998, 0.14734, 0.3309, 0.061866, 0.3998, 0.27608, 0.68836, 0.066011, 0.41397, 0.21947]
Predicted label: 6
Correct prediction
Energy consumption = 182.517331 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 414 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 414 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 414 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.30131, 0.097, 0.46987, 0.25172, 0.15569, 0.11159, 0.20219, 0.11406, 0.6868, 0.33489]
Predicted label: 8
Correct prediction
Energy consumption = 198.601761 pJ
sum error= 174
Actual label: 8
Output voltages: [0.20886, 0.22224, 0.28514, 0.21423, 0.15028, 0.14905, 0.15808, 0.15708, 0.7395, 0.3787]
Predicted label: 8
Correct prediction
Energy consumption = 196.908431 pJ
sum error= 174
Actual label: 7
Output voltages: [0.3533, 0.16206, 0.39678, 0.23563, 0.086848, 0.080857, 0.046579, 0.73699, 0.45251, 0.34923]
Predicted label: 7
Correct prediction
Energy consumption = 187.427473 pJ
sum error= 174
Actual label: 9
Output voltages: [0.34052, 0.20944, 0.21672, 0.27991, 0.39254, 0.074038, 0.11033, 0.17601, 0.2992, 0.66963]
Predicted label: 9
Correct prediction
Energy consumption = 197.730630 pJ
sum error= 174
Actual label: 1
Output voltages: [0.18554, 0.76957, 0.2989, 0.29674, 0.16496, 0.081354, 0.34626, 0.11437, 0.32586, 0.26047]
Predicted label: 1
Correct prediction
Energy consumption = 205.909457 pJ
sum error= 174
Actual label: 8
Output voltages: [0.38095, 0.14826, 0.29333, 0.46905, 0.083336, 0.25496, 0.21168, 0.084664, 0.7042, 0.25363]
Predicted label: 8
Correct prediction
Energy consumption = 202.611812 pJ
sum error= 174
Actual label: 0
Output voltages: [0.63206, 0.16866, 0.1344, 0.18692, 0.23875, 0.31125, 0.52618, 0.16537, 0.33076, 0.22648]
Predicted label: 0
Correct prediction
Energy consumption = 199.104667 pJ
sum error= 174
Actual label: 1
Output voltages: [0.25093, 0.74819, 0.31473, 0.19214, 0.30495, 0.045108, 0.236, 0.21278, 0.28715, 0.28085]
Predicted label: 1
Correct prediction
Energy consumption = 209.390846 pJ
sum error= 174
Actual label: 7
Output voltages: [0.30412, 0.27288, 0.5174, 0.40475, 0.18447, 0.026661, 0.088686, 0.64698, 0.24947, 0.28279]
Predicted label: 7
Correct prediction
Energy consumption = 188.022850 pJ
sum error= 174
Actual label: 2
Output voltages: [0.41408, 0.17126, 0.65147, 0.51185, 0.11076, 0.050187, 0.25093, 0.30268, 0.36888, 0.12881]
Predicted label: 2
Correct prediction
Energy consumption = 189.018384 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 415 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 415 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 415 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72854, 0.26852, 0.26552, 0.14524, 0.17039, 0.14342, 0.42089, 0.19284, 0.27377, 0.28686]
Predicted label: 0
Correct prediction
Energy consumption = 189.156581 pJ
sum error= 174
Actual label: 7
Output voltages: [0.48913, 0.21948, 0.11722, 0.16588, 0.17991, 0.25545, 0.10287, 0.71677, 0.3401, 0.37447]
Predicted label: 7
Correct prediction
Energy consumption = 195.214710 pJ
sum error= 174
Actual label: 5
Output voltages: [0.30213, 0.42035, 0.04565, 0.23709, 0.10942, 0.72809, 0.31401, 0.20313, 0.42348, 0.21753]
Predicted label: 5
Correct prediction
Energy consumption = 201.803623 pJ
sum error= 174
Actual label: 1
Output voltages: [0.28687, 0.75647, 0.29086, 0.21557, 0.27821, 0.073232, 0.34246, 0.10455, 0.31358, 0.20672]
Predicted label: 1
Correct prediction
Energy consumption = 208.079476 pJ
sum error= 174
Actual label: 9
Output voltages: [0.42624, 0.092402, 0.27172, 0.18275, 0.49195, 0.12807, 0.16784, 0.23929, 0.23056, 0.59227]
Predicted label: 9
Correct prediction
Energy consumption = 195.603209 pJ
sum error= 174
Actual label: 0
Output voltages: [0.7419, 0.2868, 0.21684, 0.21084, 0.075462, 0.24734, 0.37894, 0.12375, 0.30051, 0.28611]
Predicted label: 0
Correct prediction
Energy consumption = 195.221721 pJ
sum error= 174
Actual label: 2
Output voltages: [0.31778, 0.30764, 0.55536, 0.43934, 0.11212, 0.037694, 0.2553, 0.20534, 0.52408, 0.27141]
Predicted label: 2
Correct prediction
Energy consumption = 197.926575 pJ
sum error= 174
Actual label: 0
Output voltages: [0.70273, 0.24771, 0.25506, 0.19365, 0.18796, 0.073741, 0.38076, 0.16459, 0.3564, 0.25808]
Predicted label: 0
Correct prediction
Energy consumption = 185.665596 pJ
sum error= 174
Actual label: 9
Output voltages: [0.36078, 0.093954, 0.15771, 0.29114, 0.29324, 0.38339, 0.17622, 0.29536, 0.31522, 0.61339]
Predicted label: 9
Correct prediction
Energy consumption = 190.875131 pJ
sum error= 174
Actual label: 8
Output voltages: [0.26883, 0.13164, 0.37415, 0.42958, 0.17543, 0.12059, 0.14643, 0.19358, 0.68967, 0.29631]
Predicted label: 8
Correct prediction
Energy consumption = 201.059752 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 416 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 416 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 416 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.38885, 0.26187, 0.21929, 0.10107, 0.26185, 0.33378, 0.71328, 0.12664, 0.3991, 0.12712]
Predicted label: 6
Correct prediction
Energy consumption = 190.547824 pJ
sum error= 174
Actual label: 2
Output voltages: [0.41263, 0.21266, 0.72137, 0.37559, 0.15688, 0.048695, 0.29355, 0.28528, 0.3259, 0.18463]
Predicted label: 2
Correct prediction
Energy consumption = 197.095963 pJ
sum error= 174
Actual label: 3
Output voltages: [0.24928, 0.1945, 0.30805, 0.75572, 0.1665, 0.1853, 0.14193, 0.22639, 0.45755, 0.27907]
Predicted label: 3
Correct prediction
Energy consumption = 179.488315 pJ
sum error= 174
Actual label: 9
Output voltages: [0.56486, 0.14519, 0.12027, 0.38572, 0.28643, 0.22558, 0.19842, 0.32227, 0.28235, 0.4705]
Predicted label: 0
Wrong prediction!
Energy consumption = 196.712616 pJ
sum error= 175
Actual label: 3
Output voltages: [0.29913, 0.11916, 0.31756, 0.74014, 0.28394, 0.21559, 0.14092, 0.21321, 0.46299, 0.17334]
Predicted label: 3
Correct prediction
Energy consumption = 183.825813 pJ
sum error= 175
Actual label: 8
Output voltages: [0.38979, 0.42592, 0.30479, 0.25533, 0.058857, 0.13763, 0.53131, 0.083068, 0.52954, 0.16716]
Predicted label: 6
Wrong prediction!
Energy consumption = 205.116087 pJ
sum error= 176
Actual label: 0
Output voltages: [0.65073, 0.24855, 0.24706, 0.18924, 0.1419, 0.13102, 0.37499, 0.18466, 0.4373, 0.30531]
Predicted label: 0
Correct prediction
Energy consumption = 201.332293 pJ
sum error= 176
Actual label: 2
Output voltages: [0.34374, 0.17355, 0.65875, 0.41094, 0.075402, 0.042407, 0.22407, 0.28897, 0.56998, 0.20808]
Predicted label: 2
Correct prediction
Energy consumption = 189.597308 pJ
sum error= 176
Actual label: 1
Output voltages: [0.27518, 0.7328, 0.14881, 0.34958, 0.15192, 0.24847, 0.49503, 0.10653, 0.36005, 0.12715]
Predicted label: 1
Correct prediction
Energy consumption = 209.820916 pJ
sum error= 176
Actual label: 1
Output voltages: [0.1497, 0.75933, 0.21665, 0.26346, 0.20683, 0.13337, 0.47238, 0.14464, 0.32427, 0.1807]
Predicted label: 1
Correct prediction
Energy consumption = 201.305846 pJ
sum error= 176
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 417 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 417 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 417 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16687, 0.74722, 0.24344, 0.24882, 0.20692, 0.1807, 0.36986, 0.10088, 0.37109, 0.17808]
Predicted label: 1
Correct prediction
Energy consumption = 211.051268 pJ
sum error= 176
Actual label: 1
Output voltages: [0.20928, 0.73061, 0.24251, 0.29992, 0.15674, 0.065681, 0.25432, 0.15077, 0.43258, 0.27043]
Predicted label: 1
Correct prediction
Energy consumption = 203.466856 pJ
sum error= 176
Actual label: 4
Output voltages: [0.1463, 0.18425, 0.25335, 0.1586, 0.7039, 0.075314, 0.15268, 0.20951, 0.27097, 0.3986]
Predicted label: 4
Correct prediction
Energy consumption = 198.252088 pJ
sum error= 176
Actual label: 2
Output voltages: [0.31723, 0.22321, 0.72051, 0.34133, 0.33646, 0.039994, 0.23005, 0.21732, 0.33554, 0.21992]
Predicted label: 2
Correct prediction
Energy consumption = 187.231154 pJ
sum error= 176
Actual label: 9
Output voltages: [0.31706, 0.15048, 0.21613, 0.23344, 0.34649, 0.1336, 0.073415, 0.15405, 0.37426, 0.66395]
Predicted label: 9
Correct prediction
Energy consumption = 194.991570 pJ
sum error= 176
Actual label: 7
Output voltages: [0.34261, 0.29287, 0.38696, 0.23927, 0.1451, 0.054962, 0.043947, 0.73781, 0.31483, 0.3446]
Predicted label: 7
Correct prediction
Energy consumption = 195.357361 pJ
sum error= 176
Actual label: 2
Output voltages: [0.2337, 0.17371, 0.31045, 0.11198, 0.11261, 0.21863, 0.30267, 0.47972, 0.64142, 0.13949]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.038999 pJ
sum error= 177
Actual label: 5
Output voltages: [0.23597, 0.055276, 0.10951, 0.27064, 0.38731, 0.6819, 0.3261, 0.079907, 0.42671, 0.23318]
Predicted label: 5
Correct prediction
Energy consumption = 191.249740 pJ
sum error= 177
Actual label: 1
Output voltages: [0.26979, 0.71722, 0.1746, 0.16175, 0.26876, 0.24192, 0.50341, 0.12643, 0.33678, 0.22217]
Predicted label: 1
Correct prediction
Energy consumption = 205.467025 pJ
sum error= 177
Actual label: 1
Output voltages: [0.17601, 0.7661, 0.31465, 0.31084, 0.1766, 0.069431, 0.39825, 0.14895, 0.30263, 0.26229]
Predicted label: 1
Correct prediction
Energy consumption = 204.438491 pJ
sum error= 177
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 418 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 418 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 418 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.44381, 0.33329, 0.60989, 0.36502, 0.15979, 0.055041, 0.35033, 0.078102, 0.43729, 0.17575]
Predicted label: 2
Correct prediction
Energy consumption = 197.633990 pJ
sum error= 177
Actual label: 1
Output voltages: [0.17233, 0.74081, 0.29768, 0.20184, 0.18111, 0.12624, 0.44441, 0.0955, 0.4043, 0.20898]
Predicted label: 1
Correct prediction
Energy consumption = 211.360289 pJ
sum error= 177
Actual label: 9
Output voltages: [0.36797, 0.11916, 0.20606, 0.2657, 0.36734, 0.21184, 0.12153, 0.30435, 0.31308, 0.66203]
Predicted label: 9
Correct prediction
Energy consumption = 195.792868 pJ
sum error= 177
Actual label: 9
Output voltages: [0.39161, 0.12027, 0.17352, 0.30394, 0.32198, 0.27938, 0.12198, 0.27706, 0.28675, 0.70344]
Predicted label: 9
Correct prediction
Energy consumption = 188.506488 pJ
sum error= 177
Actual label: 9
Output voltages: [0.3581, 0.17998, 0.17012, 0.32728, 0.34688, 0.18024, 0.12041, 0.23092, 0.30824, 0.6949]
Predicted label: 9
Correct prediction
Energy consumption = 195.707895 pJ
sum error= 177
Actual label: 1
Output voltages: [0.29471, 0.69605, 0.20658, 0.13675, 0.36152, 0.1303, 0.32753, 0.13117, 0.35949, 0.24426]
Predicted label: 1
Correct prediction
Energy consumption = 201.324739 pJ
sum error= 177
Actual label: 0
Output voltages: [0.68376, 0.25829, 0.31286, 0.18962, 0.16409, 0.080522, 0.40386, 0.13463, 0.35714, 0.24965]
Predicted label: 0
Correct prediction
Energy consumption = 197.012746 pJ
sum error= 177
Actual label: 2
Output voltages: [0.26005, 0.15695, 0.71132, 0.37718, 0.11442, 0.044141, 0.23679, 0.46336, 0.37936, 0.24366]
Predicted label: 2
Correct prediction
Energy consumption = 186.159202 pJ
sum error= 177
Actual label: 0
Output voltages: [0.68404, 0.23373, 0.24646, 0.19824, 0.089826, 0.15319, 0.3216, 0.21015, 0.38454, 0.28147]
Predicted label: 0
Correct prediction
Energy consumption = 193.186310 pJ
sum error= 177
Actual label: 2
Output voltages: [0.41723, 0.18421, 0.68684, 0.36506, 0.096217, 0.034545, 0.22777, 0.28192, 0.49615, 0.23178]
Predicted label: 2
Correct prediction
Energy consumption = 185.413764 pJ
sum error= 177
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 419 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 419 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 419 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.18456, 0.76207, 0.26529, 0.40896, 0.20851, 0.10191, 0.30613, 0.16662, 0.23602, 0.29172]
Predicted label: 1
Correct prediction
Energy consumption = 214.954640 pJ
sum error= 177
Actual label: 1
Output voltages: [0.18174, 0.77039, 0.19681, 0.25973, 0.27699, 0.15133, 0.31963, 0.17533, 0.30105, 0.26906]
Predicted label: 1
Correct prediction
Energy consumption = 212.555131 pJ
sum error= 177
Actual label: 4
Output voltages: [0.20703, 0.12478, 0.28084, 0.14504, 0.74574, 0.12808, 0.27455, 0.22347, 0.21427, 0.34133]
Predicted label: 4
Correct prediction
Energy consumption = 199.860220 pJ
sum error= 177
Actual label: 6
Output voltages: [0.35685, 0.2493, 0.34325, 0.055447, 0.29193, 0.25816, 0.72092, 0.14294, 0.35276, 0.089391]
Predicted label: 6
Correct prediction
Energy consumption = 196.319580 pJ
sum error= 177
Actual label: 4
Output voltages: [0.23788, 0.21101, 0.2959, 0.23752, 0.67601, 0.063184, 0.12355, 0.23669, 0.17927, 0.50539]
Predicted label: 4
Correct prediction
Energy consumption = 201.593683 pJ
sum error= 177
Actual label: 1
Output voltages: [0.24007, 0.75653, 0.24319, 0.39778, 0.26126, 0.067139, 0.24561, 0.20471, 0.20319, 0.35954]
Predicted label: 1
Correct prediction
Energy consumption = 212.468363 pJ
sum error= 177
Actual label: 5
Output voltages: [0.3218, 0.072651, 0.10389, 0.51134, 0.15589, 0.57898, 0.13205, 0.30675, 0.38512, 0.33748]
Predicted label: 5
Correct prediction
Energy consumption = 195.776817 pJ
sum error= 177
Actual label: 4
Output voltages: [0.14471, 0.23989, 0.28418, 0.1943, 0.71946, 0.087535, 0.42948, 0.17635, 0.17959, 0.3259]
Predicted label: 4
Correct prediction
Energy consumption = 208.107481 pJ
sum error= 177
Actual label: 9
Output voltages: [0.3751, 0.12186, 0.20843, 0.20943, 0.35844, 0.16268, 0.077815, 0.21841, 0.40657, 0.68129]
Predicted label: 9
Correct prediction
Energy consumption = 188.474217 pJ
sum error= 177
Actual label: 7
Output voltages: [0.32065, 0.35672, 0.23734, 0.14921, 0.36612, 0.098211, 0.050995, 0.59548, 0.12907, 0.46303]
Predicted label: 7
Correct prediction
Energy consumption = 205.098048 pJ
sum error= 177
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 420 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 420 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 420 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37571, 0.30029, 0.2082, 0.23165, 0.13528, 0.13052, 0.07327, 0.75111, 0.29542, 0.36085]
Predicted label: 7
Correct prediction
Energy consumption = 207.625627 pJ
sum error= 177
Actual label: 1
Output voltages: [0.36745, 0.47971, 0.099765, 0.1153, 0.33695, 0.095755, 0.14876, 0.50571, 0.22769, 0.3514]
Predicted label: 7
Wrong prediction!
Energy consumption = 217.579105 pJ
sum error= 178
Actual label: 5
Output voltages: [0.22207, 0.079894, 0.15363, 0.33381, 0.21178, 0.72275, 0.30989, 0.10689, 0.46573, 0.20225]
Predicted label: 5
Correct prediction
Energy consumption = 188.608410 pJ
sum error= 178
Actual label: 6
Output voltages: [0.39046, 0.19476, 0.30088, 0.093946, 0.40144, 0.24192, 0.70457, 0.16633, 0.34633, 0.12873]
Predicted label: 6
Correct prediction
Energy consumption = 200.400479 pJ
sum error= 178
Actual label: 2
Output voltages: [0.37456, 0.23535, 0.70995, 0.38693, 0.14789, 0.038527, 0.32804, 0.2519, 0.45358, 0.1419]
Predicted label: 2
Correct prediction
Energy consumption = 194.474852 pJ
sum error= 178
Actual label: 2
Output voltages: [0.45571, 0.40787, 0.5203, 0.097188, 0.18215, 0.03364, 0.38173, 0.25309, 0.36023, 0.26749]
Predicted label: 2
Correct prediction
Energy consumption = 204.940914 pJ
sum error= 178
Actual label: 2
Output voltages: [0.4545, 0.17809, 0.69929, 0.3659, 0.12898, 0.037207, 0.268, 0.22324, 0.43944, 0.20509]
Predicted label: 2
Correct prediction
Energy consumption = 182.992064 pJ
sum error= 178
Actual label: 8
Output voltages: [0.30856, 0.32817, 0.58152, 0.30533, 0.09478, 0.052537, 0.37474, 0.10158, 0.58358, 0.17749]
Predicted label: 8
Correct prediction
Energy consumption = 184.333549 pJ
sum error= 178
Actual label: 0
Output voltages: [0.68735, 0.21368, 0.28972, 0.16352, 0.10137, 0.12213, 0.44971, 0.15581, 0.31156, 0.30159]
Predicted label: 0
Correct prediction
Energy consumption = 191.604779 pJ
sum error= 178
Actual label: 6
Output voltages: [0.33749, 0.16085, 0.23103, 0.18272, 0.34409, 0.39313, 0.71506, 0.061913, 0.45239, 0.15859]
Predicted label: 6
Correct prediction
Energy consumption = 183.974701 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 421 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 421 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 421 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3888, 0.13956, 0.22197, 0.3001, 0.36211, 0.1702, 0.17903, 0.23977, 0.23579, 0.68577]
Predicted label: 9
Correct prediction
Energy consumption = 200.432542 pJ
sum error= 178
Actual label: 6
Output voltages: [0.36363, 0.13595, 0.16338, 0.30288, 0.21464, 0.48917, 0.48019, 0.1299, 0.59372, 0.081622]
Predicted label: 8
Wrong prediction!
Energy consumption = 198.210259 pJ
sum error= 179
Actual label: 1
Output voltages: [0.21934, 0.59437, 0.52978, 0.38524, 0.20908, 0.038083, 0.16119, 0.26622, 0.21286, 0.17834]
Predicted label: 1
Correct prediction
Energy consumption = 200.333165 pJ
sum error= 179
Actual label: 9
Output voltages: [0.32616, 0.089959, 0.18202, 0.29298, 0.33075, 0.17135, 0.1017, 0.31834, 0.40358, 0.63808]
Predicted label: 9
Correct prediction
Energy consumption = 197.940034 pJ
sum error= 179
Actual label: 7
Output voltages: [0.32021, 0.20552, 0.14732, 0.21528, 0.2544, 0.17815, 0.047017, 0.75836, 0.32511, 0.35251]
Predicted label: 7
Correct prediction
Energy consumption = 196.648827 pJ
sum error= 179
Actual label: 7
Output voltages: [0.21814, 0.17022, 0.29242, 0.47711, 0.24829, 0.080505, 0.037299, 0.70458, 0.40996, 0.3027]
Predicted label: 7
Correct prediction
Energy consumption = 183.900111 pJ
sum error= 179
Actual label: 1
Output voltages: [0.17576, 0.76303, 0.15198, 0.21592, 0.1114, 0.14452, 0.41817, 0.11565, 0.3658, 0.25656]
Predicted label: 1
Correct prediction
Energy consumption = 205.819115 pJ
sum error= 179
Actual label: 4
Output voltages: [0.13905, 0.12823, 0.27189, 0.18138, 0.75775, 0.19912, 0.24291, 0.21703, 0.25398, 0.37626]
Predicted label: 4
Correct prediction
Energy consumption = 200.074339 pJ
sum error= 179
Actual label: 8
Output voltages: [0.27599, 0.20399, 0.33663, 0.22382, 0.17053, 0.244, 0.34842, 0.12432, 0.7296, 0.22364]
Predicted label: 8
Correct prediction
Energy consumption = 190.472420 pJ
sum error= 179
Actual label: 5
Output voltages: [0.22211, 0.10726, 0.11928, 0.37813, 0.17963, 0.68566, 0.27397, 0.14643, 0.46349, 0.29253]
Predicted label: 5
Correct prediction
Energy consumption = 181.609059 pJ
sum error= 179
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 422 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 422 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 422 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34115, 0.11224, 0.26199, 0.7516, 0.24498, 0.28669, 0.15288, 0.17659, 0.41368, 0.22784]
Predicted label: 3
Correct prediction
Energy consumption = 192.219673 pJ
sum error= 179
Actual label: 4
Output voltages: [0.17559, 0.24142, 0.26029, 0.32972, 0.73772, 0.11811, 0.2568, 0.18747, 0.11935, 0.36356]
Predicted label: 4
Correct prediction
Energy consumption = 198.146870 pJ
sum error= 179
Actual label: 3
Output voltages: [0.41381, 0.14093, 0.39027, 0.73438, 0.11844, 0.11854, 0.12678, 0.14298, 0.48368, 0.19495]
Predicted label: 3
Correct prediction
Energy consumption = 189.883009 pJ
sum error= 179
Actual label: 4
Output voltages: [0.16583, 0.10301, 0.38737, 0.090356, 0.63923, 0.19711, 0.29416, 0.14032, 0.33643, 0.41295]
Predicted label: 4
Correct prediction
Energy consumption = 191.629287 pJ
sum error= 179
Actual label: 9
Output voltages: [0.30801, 0.3059, 0.18637, 0.26549, 0.18346, 0.087996, 0.039713, 0.67338, 0.2364, 0.4763]
Predicted label: 7
Wrong prediction!
Energy consumption = 208.608566 pJ
sum error= 180
Actual label: 7
Output voltages: [0.27471, 0.16882, 0.38897, 0.39176, 0.19042, 0.056723, 0.050501, 0.71308, 0.32637, 0.29457]
Predicted label: 7
Correct prediction
Energy consumption = 183.508264 pJ
sum error= 180
Actual label: 5
Output voltages: [0.18411, 0.056346, 0.14782, 0.41718, 0.20668, 0.68059, 0.20527, 0.24647, 0.52571, 0.30502]
Predicted label: 5
Correct prediction
Energy consumption = 180.030922 pJ
sum error= 180
Actual label: 0
Output voltages: [0.71442, 0.21889, 0.23089, 0.18507, 0.17169, 0.18272, 0.45383, 0.16851, 0.28656, 0.33868]
Predicted label: 0
Correct prediction
Energy consumption = 197.140905 pJ
sum error= 180
Actual label: 7
Output voltages: [0.23221, 0.18327, 0.50193, 0.30251, 0.23253, 0.037791, 0.059467, 0.71745, 0.30748, 0.27356]
Predicted label: 7
Correct prediction
Energy consumption = 190.121337 pJ
sum error= 180
Actual label: 4
Output voltages: [0.15223, 0.11667, 0.3453, 0.1961, 0.73432, 0.049928, 0.1673, 0.25038, 0.25342, 0.29597]
Predicted label: 4
Correct prediction
Energy consumption = 192.054838 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 423 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 423 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 423 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.24958, 0.20204, 0.37497, 0.17494, 0.19403, 0.065652, 0.36054, 0.11069, 0.70393, 0.28062]
Predicted label: 8
Correct prediction
Energy consumption = 192.271070 pJ
sum error= 180
Actual label: 8
Output voltages: [0.17063, 0.23619, 0.29921, 0.27037, 0.14524, 0.14862, 0.17579, 0.14294, 0.74317, 0.32693]
Predicted label: 8
Correct prediction
Energy consumption = 187.965794 pJ
sum error= 180
Actual label: 1
Output voltages: [0.22737, 0.76838, 0.11866, 0.31925, 0.12248, 0.27083, 0.36206, 0.19745, 0.33445, 0.19804]
Predicted label: 1
Correct prediction
Energy consumption = 210.718913 pJ
sum error= 180
Actual label: 5
Output voltages: [0.27944, 0.065866, 0.11001, 0.27754, 0.17248, 0.74032, 0.26799, 0.16786, 0.57319, 0.20201]
Predicted label: 5
Correct prediction
Energy consumption = 194.797859 pJ
sum error= 180
Actual label: 3
Output voltages: [0.29499, 0.16379, 0.32015, 0.75614, 0.19407, 0.18542, 0.15967, 0.17946, 0.45106, 0.26057]
Predicted label: 3
Correct prediction
Energy consumption = 183.031714 pJ
sum error= 180
Actual label: 9
Output voltages: [0.42967, 0.11096, 0.212, 0.33742, 0.24684, 0.23719, 0.063529, 0.34544, 0.34901, 0.64082]
Predicted label: 9
Correct prediction
Energy consumption = 193.164318 pJ
sum error= 180
Actual label: 5
Output voltages: [0.27505, 0.044093, 0.069536, 0.31515, 0.2688, 0.7085, 0.35516, 0.16675, 0.50613, 0.23076]
Predicted label: 5
Correct prediction
Energy consumption = 181.249676 pJ
sum error= 180
Actual label: 9
Output voltages: [0.41272, 0.13057, 0.24197, 0.27218, 0.46149, 0.1497, 0.14054, 0.20991, 0.2528, 0.67682]
Predicted label: 9
Correct prediction
Energy consumption = 193.080989 pJ
sum error= 180
Actual label: 7
Output voltages: [0.36036, 0.14057, 0.30175, 0.5909, 0.21398, 0.049057, 0.045493, 0.52931, 0.35744, 0.35425]
Predicted label: 3
Wrong prediction!
Energy consumption = 188.237971 pJ
sum error= 181
Actual label: 6
Output voltages: [0.28828, 0.10038, 0.24067, 0.17429, 0.31699, 0.3984, 0.65954, 0.049251, 0.49775, 0.1981]
Predicted label: 6
Correct prediction
Energy consumption = 181.485278 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 424 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 424 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 424 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.27643, 0.11587, 0.24561, 0.36126, 0.27752, 0.19644, 0.1022, 0.22201, 0.35443, 0.6945]
Predicted label: 9
Correct prediction
Energy consumption = 201.615365 pJ
sum error= 181
Actual label: 0
Output voltages: [0.71599, 0.21627, 0.23982, 0.13863, 0.18739, 0.23241, 0.45499, 0.17495, 0.30191, 0.26283]
Predicted label: 0
Correct prediction
Energy consumption = 194.137602 pJ
sum error= 181
Actual label: 3
Output voltages: [0.30857, 0.15104, 0.26234, 0.75675, 0.21452, 0.2751, 0.16494, 0.13603, 0.45163, 0.23009]
Predicted label: 3
Correct prediction
Energy consumption = 181.535597 pJ
sum error= 181
Actual label: 6
Output voltages: [0.33978, 0.21104, 0.21076, 0.18713, 0.23922, 0.4412, 0.71637, 0.13092, 0.43383, 0.17894]
Predicted label: 6
Correct prediction
Energy consumption = 192.178443 pJ
sum error= 181
Actual label: 3
Output voltages: [0.34499, 0.212, 0.31942, 0.74012, 0.23184, 0.11202, 0.16299, 0.27842, 0.33455, 0.19866]
Predicted label: 3
Correct prediction
Energy consumption = 199.457088 pJ
sum error= 181
Actual label: 9
Output voltages: [0.34984, 0.092049, 0.24697, 0.23259, 0.35425, 0.20884, 0.1979, 0.22789, 0.33241, 0.69999]
Predicted label: 9
Correct prediction
Energy consumption = 193.345015 pJ
sum error= 181
Actual label: 8
Output voltages: [0.23296, 0.16019, 0.29379, 0.22498, 0.16661, 0.20133, 0.14642, 0.15451, 0.73006, 0.38703]
Predicted label: 8
Correct prediction
Energy consumption = 192.460598 pJ
sum error= 181
Actual label: 2
Output voltages: [0.28896, 0.33393, 0.71268, 0.32435, 0.14179, 0.028462, 0.25793, 0.24483, 0.40394, 0.18484]
Predicted label: 2
Correct prediction
Energy consumption = 188.089478 pJ
sum error= 181
Actual label: 2
Output voltages: [0.3196, 0.54753, 0.42461, 0.045511, 0.34795, 0.047088, 0.31258, 0.2401, 0.3963, 0.27839]
Predicted label: 1
Wrong prediction!
Energy consumption = 211.887971 pJ
sum error= 182
Actual label: 1
Output voltages: [0.20334, 0.77455, 0.23524, 0.2783, 0.21929, 0.14441, 0.4079, 0.089186, 0.2484, 0.26132]
Predicted label: 1
Correct prediction
Energy consumption = 199.924889 pJ
sum error= 182
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 425 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 425 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 425 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33881, 0.30063, 0.74353, 0.3246, 0.16024, 0.031886, 0.24522, 0.28223, 0.35075, 0.22682]
Predicted label: 2
Correct prediction
Energy consumption = 189.525545 pJ
sum error= 182
Actual label: 8
Output voltages: [0.20431, 0.30363, 0.2887, 0.33837, 0.072863, 0.20918, 0.16627, 0.33051, 0.74752, 0.23107]
Predicted label: 8
Correct prediction
Energy consumption = 198.791073 pJ
sum error= 182
Actual label: 6
Output voltages: [0.28086, 0.26993, 0.2474, 0.21591, 0.26912, 0.40129, 0.74233, 0.10308, 0.42849, 0.088097]
Predicted label: 6
Correct prediction
Energy consumption = 198.358100 pJ
sum error= 182
Actual label: 8
Output voltages: [0.23443, 0.099934, 0.39239, 0.19506, 0.20429, 0.18604, 0.26442, 0.079129, 0.72323, 0.30705]
Predicted label: 8
Correct prediction
Energy consumption = 192.176789 pJ
sum error= 182
Actual label: 5
Output voltages: [0.2233, 0.071569, 0.070669, 0.4184, 0.22042, 0.73864, 0.22255, 0.20969, 0.48131, 0.26727]
Predicted label: 5
Correct prediction
Energy consumption = 200.026138 pJ
sum error= 182
Actual label: 5
Output voltages: [0.38063, 0.12665, 0.11845, 0.39384, 0.14713, 0.57414, 0.40123, 0.19937, 0.35317, 0.13908]
Predicted label: 5
Correct prediction
Energy consumption = 196.801488 pJ
sum error= 182
Actual label: 3
Output voltages: [0.56434, 0.22457, 0.352, 0.65531, 0.042782, 0.17438, 0.25806, 0.23609, 0.27134, 0.11345]
Predicted label: 3
Correct prediction
Energy consumption = 193.377816 pJ
sum error= 182
Actual label: 9
Output voltages: [0.37941, 0.12614, 0.1933, 0.21252, 0.34356, 0.16927, 0.24088, 0.25618, 0.25285, 0.69343]
Predicted label: 9
Correct prediction
Energy consumption = 194.948394 pJ
sum error= 182
Actual label: 4
Output voltages: [0.1656, 0.14975, 0.30187, 0.20746, 0.7371, 0.062029, 0.20723, 0.2444, 0.26162, 0.33108]
Predicted label: 4
Correct prediction
Energy consumption = 199.874237 pJ
sum error= 182
Actual label: 9
Output voltages: [0.38443, 0.27724, 0.069852, 0.32012, 0.5089, 0.25948, 0.23073, 0.22552, 0.1787, 0.56636]
Predicted label: 9
Correct prediction
Energy consumption = 200.020788 pJ
sum error= 182
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 426 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 426 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 426 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.37094, 0.40706, 0.71577, 0.24664, 0.12075, 0.029432, 0.2143, 0.4088, 0.32275, 0.2354]
Predicted label: 2
Correct prediction
Energy consumption = 194.801395 pJ
sum error= 182
Actual label: 5
Output voltages: [0.13677, 0.050868, 0.14313, 0.38668, 0.3089, 0.61403, 0.375, 0.13087, 0.47369, 0.27293]
Predicted label: 5
Correct prediction
Energy consumption = 191.484804 pJ
sum error= 182
Actual label: 1
Output voltages: [0.24631, 0.70536, 0.29526, 0.20487, 0.44333, 0.062436, 0.35052, 0.059743, 0.28528, 0.2926]
Predicted label: 1
Correct prediction
Energy consumption = 204.861174 pJ
sum error= 182
Actual label: 5
Output voltages: [0.26784, 0.058743, 0.1163, 0.45628, 0.17265, 0.70798, 0.19653, 0.23225, 0.52267, 0.28539]
Predicted label: 5
Correct prediction
Energy consumption = 187.665412 pJ
sum error= 182
Actual label: 1
Output voltages: [0.27462, 0.7691, 0.26332, 0.32627, 0.23851, 0.15996, 0.38402, 0.16058, 0.23499, 0.24003]
Predicted label: 1
Correct prediction
Energy consumption = 216.976850 pJ
sum error= 182
Actual label: 4
Output voltages: [0.37864, 0.44801, 0.06478, 0.43189, 0.41744, 0.078978, 0.16758, 0.30129, 0.27731, 0.34613]
Predicted label: 1
Wrong prediction!
Energy consumption = 209.807752 pJ
sum error= 183
Actual label: 4
Output voltages: [0.15627, 0.14854, 0.22456, 0.15404, 0.70697, 0.11632, 0.23017, 0.28971, 0.32917, 0.29974]
Predicted label: 4
Correct prediction
Energy consumption = 196.722257 pJ
sum error= 183
Actual label: 1
Output voltages: [0.19215, 0.75742, 0.21343, 0.21191, 0.32091, 0.095781, 0.44631, 0.14248, 0.26899, 0.21121]
Predicted label: 1
Correct prediction
Energy consumption = 205.000357 pJ
sum error= 183
Actual label: 4
Output voltages: [0.14275, 0.059002, 0.30966, 0.29173, 0.66331, 0.33075, 0.34406, 0.16465, 0.21413, 0.29549]
Predicted label: 4
Correct prediction
Energy consumption = 198.320560 pJ
sum error= 183
Actual label: 4
Output voltages: [0.30283, 0.059781, 0.37782, 0.044626, 0.70614, 0.11523, 0.37212, 0.24822, 0.29166, 0.22744]
Predicted label: 4
Correct prediction
Energy consumption = 194.600707 pJ
sum error= 183
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 427 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 427 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 427 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29405, 0.16465, 0.32034, 0.75277, 0.17831, 0.29602, 0.10776, 0.17842, 0.48107, 0.18322]
Predicted label: 3
Correct prediction
Energy consumption = 188.104972 pJ
sum error= 183
Actual label: 5
Output voltages: [0.35582, 0.16738, 0.11247, 0.71572, 0.11735, 0.45231, 0.18826, 0.1686, 0.42551, 0.29769]
Predicted label: 3
Wrong prediction!
Energy consumption = 192.808182 pJ
sum error= 184
Actual label: 9
Output voltages: [0.3856, 0.078001, 0.24953, 0.3394, 0.30085, 0.20765, 0.11851, 0.33785, 0.30445, 0.66939]
Predicted label: 9
Correct prediction
Energy consumption = 192.931669 pJ
sum error= 184
Actual label: 1
Output voltages: [0.18694, 0.76855, 0.22774, 0.30137, 0.23447, 0.12123, 0.26916, 0.1585, 0.31919, 0.27466]
Predicted label: 1
Correct prediction
Energy consumption = 215.522102 pJ
sum error= 184
Actual label: 2
Output voltages: [0.33863, 0.28433, 0.71163, 0.41337, 0.16494, 0.026786, 0.31295, 0.20169, 0.42455, 0.216]
Predicted label: 2
Correct prediction
Energy consumption = 190.947575 pJ
sum error= 184
Actual label: 2
Output voltages: [0.31685, 0.21732, 0.73072, 0.36744, 0.11851, 0.037527, 0.19738, 0.30732, 0.45367, 0.15415]
Predicted label: 2
Correct prediction
Energy consumption = 179.873338 pJ
sum error= 184
Actual label: 3
Output voltages: [0.2556, 0.16347, 0.26215, 0.75546, 0.24394, 0.30709, 0.19648, 0.19675, 0.38717, 0.30988]
Predicted label: 3
Correct prediction
Energy consumption = 179.735220 pJ
sum error= 184
Actual label: 3
Output voltages: [0.42497, 0.21686, 0.20857, 0.73582, 0.086584, 0.30266, 0.24652, 0.26652, 0.30627, 0.094821]
Predicted label: 3
Correct prediction
Energy consumption = 184.269794 pJ
sum error= 184
Actual label: 0
Output voltages: [0.7281, 0.27957, 0.22391, 0.17133, 0.13725, 0.2474, 0.39204, 0.15059, 0.26073, 0.28044]
Predicted label: 0
Correct prediction
Energy consumption = 194.126594 pJ
sum error= 184
Actual label: 2
Output voltages: [0.3056, 0.10646, 0.71767, 0.41129, 0.22194, 0.042903, 0.16593, 0.21573, 0.44515, 0.30375]
Predicted label: 2
Correct prediction
Energy consumption = 184.905982 pJ
sum error= 184
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 428 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 428 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 428 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28069, 0.20674, 0.27688, 0.1632, 0.46666, 0.082234, 0.082957, 0.16345, 0.3226, 0.63051]
Predicted label: 9
Correct prediction
Energy consumption = 196.508769 pJ
sum error= 184
Actual label: 0
Output voltages: [0.67941, 0.2207, 0.30352, 0.20732, 0.17675, 0.05839, 0.42206, 0.17034, 0.33295, 0.26162]
Predicted label: 0
Correct prediction
Energy consumption = 203.830826 pJ
sum error= 184
Actual label: 0
Output voltages: [0.72585, 0.25984, 0.26491, 0.11491, 0.14175, 0.14511, 0.39964, 0.25881, 0.27321, 0.26789]
Predicted label: 0
Correct prediction
Energy consumption = 185.371200 pJ
sum error= 184
Actual label: 9
Output voltages: [0.38715, 0.11441, 0.18371, 0.25832, 0.33279, 0.28254, 0.23715, 0.22513, 0.24458, 0.66283]
Predicted label: 9
Correct prediction
Energy consumption = 192.167288 pJ
sum error= 184
Actual label: 9
Output voltages: [0.25887, 0.076649, 0.11914, 0.33004, 0.33048, 0.3848, 0.13779, 0.2321, 0.39071, 0.45318]
Predicted label: 9
Correct prediction
Energy consumption = 203.632345 pJ
sum error= 184
Actual label: 6
Output voltages: [0.34797, 0.14489, 0.21778, 0.20766, 0.27999, 0.41899, 0.695, 0.047452, 0.44691, 0.25067]
Predicted label: 6
Correct prediction
Energy consumption = 190.058687 pJ
sum error= 184
Actual label: 0
Output voltages: [0.72867, 0.22893, 0.3255, 0.36473, 0.050576, 0.22519, 0.30207, 0.13119, 0.33682, 0.2503]
Predicted label: 0
Correct prediction
Energy consumption = 199.201429 pJ
sum error= 184
Actual label: 9
Output voltages: [0.44256, 0.056876, 0.29076, 0.15631, 0.38277, 0.15306, 0.23921, 0.15879, 0.36518, 0.64321]
Predicted label: 9
Correct prediction
Energy consumption = 197.510842 pJ
sum error= 184
Actual label: 3
Output voltages: [0.29791, 0.22128, 0.30577, 0.76373, 0.1521, 0.17028, 0.12787, 0.24925, 0.43545, 0.23821]
Predicted label: 3
Correct prediction
Energy consumption = 186.494974 pJ
sum error= 184
Actual label: 2
Output voltages: [0.36975, 0.19643, 0.56387, 0.22238, 0.076705, 0.047063, 0.19825, 0.49404, 0.49304, 0.22332]
Predicted label: 2
Correct prediction
Energy consumption = 187.667203 pJ
sum error= 184
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 429 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 429 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 429 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20574, 0.12394, 0.27133, 0.27301, 0.161, 0.33813, 0.22915, 0.15361, 0.74561, 0.27781]
Predicted label: 8
Correct prediction
Energy consumption = 197.516901 pJ
sum error= 184
Actual label: 4
Output voltages: [0.25541, 0.15144, 0.22994, 0.088872, 0.72207, 0.099511, 0.30462, 0.23749, 0.24129, 0.41293]
Predicted label: 4
Correct prediction
Energy consumption = 204.630798 pJ
sum error= 184
Actual label: 1
Output voltages: [0.24346, 0.76402, 0.23329, 0.19055, 0.12467, 0.11762, 0.36571, 0.09911, 0.43616, 0.23224]
Predicted label: 1
Correct prediction
Energy consumption = 210.859023 pJ
sum error= 184
Actual label: 9
Output voltages: [0.39915, 0.1005, 0.24578, 0.25972, 0.40238, 0.19418, 0.27104, 0.20268, 0.25873, 0.68718]
Predicted label: 9
Correct prediction
Energy consumption = 199.356409 pJ
sum error= 184
Actual label: 9
Output voltages: [0.43002, 0.13117, 0.045002, 0.34503, 0.3563, 0.44797, 0.12881, 0.36215, 0.27616, 0.5536]
Predicted label: 9
Correct prediction
Energy consumption = 194.668731 pJ
sum error= 184
Actual label: 7
Output voltages: [0.27889, 0.31799, 0.27289, 0.3264, 0.14087, 0.049781, 0.052547, 0.7418, 0.30787, 0.36486]
Predicted label: 7
Correct prediction
Energy consumption = 203.278128 pJ
sum error= 184
Actual label: 2
Output voltages: [0.2838, 0.26573, 0.73473, 0.30851, 0.20128, 0.046007, 0.32412, 0.21831, 0.38611, 0.24243]
Predicted label: 2
Correct prediction
Energy consumption = 193.007013 pJ
sum error= 184
Actual label: 7
Output voltages: [0.31872, 0.42506, 0.35294, 0.43744, 0.052573, 0.052238, 0.058272, 0.59322, 0.46109, 0.2841]
Predicted label: 7
Correct prediction
Energy consumption = 196.956363 pJ
sum error= 184
Actual label: 9
Output voltages: [0.28173, 0.11803, 0.18822, 0.42073, 0.24461, 0.35889, 0.148, 0.25885, 0.34734, 0.63431]
Predicted label: 9
Correct prediction
Energy consumption = 192.918105 pJ
sum error= 184
Actual label: 9
Output voltages: [0.32113, 0.17126, 0.21928, 0.27752, 0.42946, 0.05306, 0.064709, 0.15316, 0.33665, 0.58206]
Predicted label: 9
Correct prediction
Energy consumption = 197.289458 pJ
sum error= 184
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 430 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 430 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 430 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.34549, 0.25289, 0.060392, 0.43834, 0.085932, 0.52535, 0.48475, 0.081873, 0.53406, 0.15431]
Predicted label: 8
Wrong prediction!
Energy consumption = 206.093220 pJ
sum error= 185
Actual label: 9
Output voltages: [0.40544, 0.078384, 0.15872, 0.24964, 0.30636, 0.32062, 0.24783, 0.21113, 0.2559, 0.60646]
Predicted label: 9
Correct prediction
Energy consumption = 194.752464 pJ
sum error= 185
Actual label: 5
Output voltages: [0.36643, 0.055869, 0.067613, 0.37128, 0.3071, 0.70577, 0.28409, 0.10829, 0.41886, 0.20607]
Predicted label: 5
Correct prediction
Energy consumption = 188.718660 pJ
sum error= 185
Actual label: 1
Output voltages: [0.25508, 0.7327, 0.22474, 0.18242, 0.35256, 0.14973, 0.38151, 0.19655, 0.25842, 0.21648]
Predicted label: 1
Correct prediction
Energy consumption = 208.502846 pJ
sum error= 185
Actual label: 1
Output voltages: [0.15079, 0.76635, 0.22865, 0.25956, 0.16568, 0.2148, 0.37491, 0.15194, 0.36869, 0.19038]
Predicted label: 1
Correct prediction
Energy consumption = 207.549113 pJ
sum error= 185
Actual label: 8
Output voltages: [0.3536, 0.22114, 0.43667, 0.1804, 0.14627, 0.06425, 0.26538, 0.11979, 0.69032, 0.31559]
Predicted label: 8
Correct prediction
Energy consumption = 188.355929 pJ
sum error= 185
Actual label: 3
Output voltages: [0.24549, 0.33648, 0.19184, 0.60685, 0.044268, 0.25387, 0.047744, 0.46273, 0.54124, 0.20763]
Predicted label: 3
Correct prediction
Energy consumption = 189.004163 pJ
sum error= 185
Actual label: 5
Output voltages: [0.2831, 0.105, 0.091413, 0.41029, 0.18543, 0.7413, 0.31272, 0.15099, 0.50063, 0.1962]
Predicted label: 5
Correct prediction
Energy consumption = 191.281145 pJ
sum error= 185
Actual label: 1
Output voltages: [0.27149, 0.73684, 0.18935, 0.17374, 0.17747, 0.17892, 0.49168, 0.090664, 0.36926, 0.21036]
Predicted label: 1
Correct prediction
Energy consumption = 208.478864 pJ
sum error= 185
Actual label: 9
Output voltages: [0.37464, 0.13794, 0.23779, 0.23352, 0.32626, 0.14441, 0.082923, 0.19446, 0.36069, 0.68054]
Predicted label: 9
Correct prediction
Energy consumption = 194.392593 pJ
sum error= 185
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 431 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 431 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 431 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.31552, 0.11561, 0.041911, 0.27101, 0.17663, 0.75132, 0.28305, 0.21729, 0.53072, 0.11192]
Predicted label: 5
Correct prediction
Energy consumption = 196.853580 pJ
sum error= 185
Actual label: 3
Output voltages: [0.30806, 0.12351, 0.27224, 0.74344, 0.20796, 0.35814, 0.17139, 0.1099, 0.42467, 0.2062]
Predicted label: 3
Correct prediction
Energy consumption = 188.146098 pJ
sum error= 185
Actual label: 5
Output voltages: [0.28375, 0.15448, 0.039244, 0.38834, 0.19818, 0.74577, 0.30791, 0.096086, 0.45035, 0.15159]
Predicted label: 5
Correct prediction
Energy consumption = 190.563593 pJ
sum error= 185
Actual label: 4
Output voltages: [0.059472, 0.31073, 0.13382, 0.080387, 0.65508, 0.14183, 0.23242, 0.28343, 0.39443, 0.31165]
Predicted label: 4
Correct prediction
Energy consumption = 196.290251 pJ
sum error= 185
Actual label: 9
Output voltages: [0.32368, 0.1641, 0.21068, 0.30512, 0.22764, 0.059449, 0.057134, 0.23844, 0.44734, 0.61967]
Predicted label: 9
Correct prediction
Energy consumption = 197.939951 pJ
sum error= 185
Actual label: 5
Output voltages: [0.18228, 0.055531, 0.13557, 0.5056, 0.25986, 0.6125, 0.34809, 0.21638, 0.43674, 0.30573]
Predicted label: 5
Correct prediction
Energy consumption = 191.671320 pJ
sum error= 185
Actual label: 9
Output voltages: [0.36407, 0.14812, 0.19889, 0.3117, 0.33278, 0.091688, 0.051128, 0.20252, 0.33739, 0.69839]
Predicted label: 9
Correct prediction
Energy consumption = 187.608586 pJ
sum error= 185
Actual label: 3
Output voltages: [0.39534, 0.18937, 0.10502, 0.71813, 0.1042, 0.31, 0.068577, 0.28852, 0.33083, 0.36556]
Predicted label: 3
Correct prediction
Energy consumption = 189.449728 pJ
sum error= 185
Actual label: 1
Output voltages: [0.20399, 0.74701, 0.24236, 0.18182, 0.22262, 0.16165, 0.40086, 0.091272, 0.34612, 0.22198]
Predicted label: 1
Correct prediction
Energy consumption = 205.327104 pJ
sum error= 185
Actual label: 9
Output voltages: [0.37987, 0.11916, 0.19376, 0.35284, 0.36993, 0.22794, 0.12244, 0.31786, 0.25814, 0.68984]
Predicted label: 9
Correct prediction
Energy consumption = 201.406849 pJ
sum error= 185
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 432 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 432 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 432 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69464, 0.26029, 0.31697, 0.14702, 0.15184, 0.064312, 0.44793, 0.18542, 0.34256, 0.29499]
Predicted label: 0
Correct prediction
Energy consumption = 188.249560 pJ
sum error= 185
Actual label: 9
Output voltages: [0.3729, 0.16397, 0.20455, 0.39747, 0.20066, 0.19797, 0.12866, 0.212, 0.34577, 0.66179]
Predicted label: 9
Correct prediction
Energy consumption = 197.238479 pJ
sum error= 185
Actual label: 7
Output voltages: [0.33409, 0.29041, 0.28376, 0.2049, 0.17443, 0.055936, 0.059709, 0.75634, 0.31937, 0.26387]
Predicted label: 7
Correct prediction
Energy consumption = 203.059605 pJ
sum error= 185
Actual label: 5
Output voltages: [0.25132, 0.16699, 0.055629, 0.48848, 0.14227, 0.6668, 0.24537, 0.082328, 0.44043, 0.2041]
Predicted label: 5
Correct prediction
Energy consumption = 191.828520 pJ
sum error= 185
Actual label: 4
Output voltages: [0.14528, 0.16672, 0.32136, 0.15381, 0.74524, 0.083745, 0.21609, 0.27273, 0.2681, 0.33022]
Predicted label: 4
Correct prediction
Energy consumption = 200.524835 pJ
sum error= 185
Actual label: 9
Output voltages: [0.3268, 0.13481, 0.1534, 0.19232, 0.27369, 0.1278, 0.05133, 0.24465, 0.42392, 0.66496]
Predicted label: 9
Correct prediction
Energy consumption = 196.432417 pJ
sum error= 185
Actual label: 2
Output voltages: [0.44155, 0.20119, 0.68621, 0.36405, 0.17874, 0.034109, 0.25339, 0.36643, 0.35177, 0.15785]
Predicted label: 2
Correct prediction
Energy consumption = 195.002353 pJ
sum error= 185
Actual label: 0
Output voltages: [0.73319, 0.1944, 0.18616, 0.43703, 0.052314, 0.43772, 0.24436, 0.090761, 0.35166, 0.32082]
Predicted label: 0
Correct prediction
Energy consumption = 200.873942 pJ
sum error= 185
Actual label: 1
Output voltages: [0.2387, 0.76907, 0.26845, 0.28725, 0.1981, 0.13072, 0.38663, 0.105, 0.29431, 0.24029]
Predicted label: 1
Correct prediction
Energy consumption = 213.549487 pJ
sum error= 185
Actual label: 0
Output voltages: [0.69844, 0.14675, 0.32793, 0.15387, 0.10735, 0.24606, 0.4153, 0.11543, 0.30607, 0.28283]
Predicted label: 0
Correct prediction
Energy consumption = 201.343823 pJ
sum error= 185
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 433 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 433 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 433 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.21287, 0.050352, 0.17386, 0.3413, 0.13016, 0.47827, 0.29298, 0.067842, 0.61908, 0.26854]
Predicted label: 8
Wrong prediction!
Energy consumption = 194.235852 pJ
sum error= 186
Actual label: 1
Output voltages: [0.21824, 0.77065, 0.24148, 0.28873, 0.30586, 0.17078, 0.30002, 0.15687, 0.18134, 0.32712]
Predicted label: 1
Correct prediction
Energy consumption = 215.915300 pJ
sum error= 186
Actual label: 4
Output voltages: [0.19439, 0.19735, 0.25077, 0.19829, 0.74276, 0.05747, 0.25588, 0.20747, 0.1867, 0.248]
Predicted label: 4
Correct prediction
Energy consumption = 204.325982 pJ
sum error= 186
Actual label: 9
Output voltages: [0.35749, 0.1756, 0.13552, 0.37015, 0.41485, 0.25494, 0.15055, 0.32992, 0.2045, 0.61809]
Predicted label: 9
Correct prediction
Energy consumption = 201.947981 pJ
sum error= 186
Actual label: 3
Output voltages: [0.3519, 0.18139, 0.19542, 0.74688, 0.19961, 0.35792, 0.21631, 0.24893, 0.35539, 0.13738]
Predicted label: 3
Correct prediction
Energy consumption = 193.732684 pJ
sum error= 186
Actual label: 3
Output voltages: [0.21831, 0.23535, 0.31065, 0.75038, 0.18728, 0.19005, 0.06964, 0.21245, 0.42066, 0.33722]
Predicted label: 3
Correct prediction
Energy consumption = 180.077297 pJ
sum error= 186
Actual label: 6
Output voltages: [0.33228, 0.27364, 0.30148, 0.10407, 0.36914, 0.32221, 0.74489, 0.07997, 0.36312, 0.10841]
Predicted label: 6
Correct prediction
Energy consumption = 193.407493 pJ
sum error= 186
Actual label: 1
Output voltages: [0.22314, 0.7651, 0.23166, 0.31553, 0.19125, 0.14017, 0.37384, 0.056606, 0.35205, 0.2897]
Predicted label: 1
Correct prediction
Energy consumption = 206.213633 pJ
sum error= 186
Actual label: 5
Output voltages: [0.32105, 0.041275, 0.15743, 0.36034, 0.18158, 0.68704, 0.2669, 0.24872, 0.52726, 0.27498]
Predicted label: 5
Correct prediction
Energy consumption = 197.055145 pJ
sum error= 186
Actual label: 2
Output voltages: [0.35693, 0.39073, 0.71495, 0.29167, 0.12921, 0.022833, 0.27105, 0.27208, 0.34573, 0.24835]
Predicted label: 2
Correct prediction
Energy consumption = 189.898026 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 434 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 434 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 434 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.26615, 0.050094, 0.088322, 0.37963, 0.19768, 0.71635, 0.23158, 0.24982, 0.50182, 0.30621]
Predicted label: 5
Correct prediction
Energy consumption = 191.462279 pJ
sum error= 186
Actual label: 2
Output voltages: [0.3971, 0.13353, 0.62148, 0.48743, 0.16873, 0.031967, 0.21155, 0.24982, 0.49935, 0.21712]
Predicted label: 2
Correct prediction
Energy consumption = 190.936563 pJ
sum error= 186
Actual label: 2
Output voltages: [0.35055, 0.26255, 0.72432, 0.32725, 0.18721, 0.027443, 0.26457, 0.21638, 0.42786, 0.22637]
Predicted label: 2
Correct prediction
Energy consumption = 181.935674 pJ
sum error= 186
Actual label: 0
Output voltages: [0.65674, 0.19561, 0.25493, 0.29668, 0.11163, 0.17897, 0.2732, 0.082747, 0.52337, 0.28706]
Predicted label: 0
Correct prediction
Energy consumption = 195.369712 pJ
sum error= 186
Actual label: 9
Output voltages: [0.3077, 0.067127, 0.29439, 0.33421, 0.32379, 0.26246, 0.18811, 0.42234, 0.23684, 0.57512]
Predicted label: 9
Correct prediction
Energy consumption = 198.526808 pJ
sum error= 186
Actual label: 2
Output voltages: [0.3406, 0.23232, 0.75796, 0.23591, 0.18181, 0.047766, 0.28644, 0.20943, 0.36863, 0.15089]
Predicted label: 2
Correct prediction
Energy consumption = 188.587570 pJ
sum error= 186
Actual label: 6
Output voltages: [0.25608, 0.19609, 0.32268, 0.076577, 0.36162, 0.40028, 0.7336, 0.078835, 0.34117, 0.10038]
Predicted label: 6
Correct prediction
Energy consumption = 193.034760 pJ
sum error= 186
Actual label: 6
Output voltages: [0.291, 0.23264, 0.25277, 0.15777, 0.31455, 0.3274, 0.73931, 0.080003, 0.42225, 0.12173]
Predicted label: 6
Correct prediction
Energy consumption = 189.397965 pJ
sum error= 186
Actual label: 0
Output voltages: [0.7307, 0.24717, 0.2836, 0.17828, 0.17156, 0.1019, 0.42338, 0.14185, 0.31478, 0.23264]
Predicted label: 0
Correct prediction
Energy consumption = 190.145414 pJ
sum error= 186
Actual label: 1
Output voltages: [0.23411, 0.7415, 0.18315, 0.33326, 0.24197, 0.12548, 0.38903, 0.056746, 0.42245, 0.22646]
Predicted label: 1
Correct prediction
Energy consumption = 207.062413 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 435 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 435 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 435 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.28776, 0.2772, 0.50043, 0.51494, 0.067907, 0.17087, 0.1682, 0.095326, 0.57612, 0.16925]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.707650 pJ
sum error= 187
Actual label: 0
Output voltages: [0.74581, 0.24044, 0.24942, 0.18939, 0.14509, 0.24478, 0.36376, 0.13865, 0.25576, 0.27032]
Predicted label: 0
Correct prediction
Energy consumption = 190.483454 pJ
sum error= 187
Actual label: 3
Output voltages: [0.275, 0.22969, 0.25334, 0.76269, 0.15064, 0.19901, 0.11841, 0.22358, 0.46147, 0.29745]
Predicted label: 3
Correct prediction
Energy consumption = 180.448432 pJ
sum error= 187
Actual label: 0
Output voltages: [0.72623, 0.16217, 0.26845, 0.22157, 0.22474, 0.15038, 0.32717, 0.16326, 0.36231, 0.29614]
Predicted label: 0
Correct prediction
Energy consumption = 205.672471 pJ
sum error= 187
Actual label: 2
Output voltages: [0.35391, 0.38961, 0.7286, 0.30657, 0.12631, 0.022442, 0.2777, 0.29343, 0.35206, 0.21633]
Predicted label: 2
Correct prediction
Energy consumption = 188.091780 pJ
sum error= 187
Actual label: 5
Output voltages: [0.21443, 0.05871, 0.084361, 0.4058, 0.27673, 0.68269, 0.25637, 0.16619, 0.4958, 0.30416]
Predicted label: 5
Correct prediction
Energy consumption = 190.250338 pJ
sum error= 187
Actual label: 5
Output voltages: [0.29574, 0.047949, 0.11269, 0.44644, 0.13747, 0.63108, 0.25697, 0.12675, 0.56318, 0.20953]
Predicted label: 5
Correct prediction
Energy consumption = 199.083362 pJ
sum error= 187
Actual label: 7
Output voltages: [0.38704, 0.28058, 0.16354, 0.38778, 0.1311, 0.19815, 0.035506, 0.74592, 0.28472, 0.41686]
Predicted label: 7
Correct prediction
Energy consumption = 193.709416 pJ
sum error= 187
Actual label: 9
Output voltages: [0.34577, 0.10346, 0.17493, 0.29989, 0.34496, 0.096521, 0.057382, 0.19787, 0.39079, 0.6238]
Predicted label: 9
Correct prediction
Energy consumption = 196.697168 pJ
sum error= 187
Actual label: 5
Output voltages: [0.396, 0.13453, 0.064747, 0.36204, 0.10797, 0.62207, 0.15188, 0.38786, 0.33724, 0.3609]
Predicted label: 5
Correct prediction
Energy consumption = 197.346143 pJ
sum error= 187
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 436 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 436 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 436 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.32264, 0.074081, 0.064617, 0.57423, 0.27782, 0.54211, 0.25496, 0.12807, 0.37579, 0.30135]
Predicted label: 3
Wrong prediction!
Energy consumption = 205.076881 pJ
sum error= 188
Actual label: 0
Output voltages: [0.74305, 0.18563, 0.25154, 0.17597, 0.23266, 0.13038, 0.40132, 0.25153, 0.30023, 0.26288]
Predicted label: 0
Correct prediction
Energy consumption = 206.179789 pJ
sum error= 188
Actual label: 8
Output voltages: [0.2884, 0.19801, 0.37348, 0.34572, 0.12402, 0.17466, 0.29228, 0.10713, 0.73494, 0.25426]
Predicted label: 8
Correct prediction
Energy consumption = 197.581990 pJ
sum error= 188
Actual label: 9
Output voltages: [0.19001, 0.083129, 0.17257, 0.31758, 0.30471, 0.52173, 0.24478, 0.23923, 0.33624, 0.53039]
Predicted label: 9
Correct prediction
Energy consumption = 191.728022 pJ
sum error= 188
Actual label: 5
Output voltages: [0.30446, 0.069425, 0.053706, 0.39185, 0.20811, 0.65427, 0.25811, 0.069042, 0.54776, 0.1914]
Predicted label: 5
Correct prediction
Energy consumption = 184.406261 pJ
sum error= 188
Actual label: 0
Output voltages: [0.70779, 0.26464, 0.26553, 0.22768, 0.14823, 0.099617, 0.43198, 0.15731, 0.30118, 0.35116]
Predicted label: 0
Correct prediction
Energy consumption = 199.782300 pJ
sum error= 188
Actual label: 3
Output voltages: [0.32571, 0.18828, 0.31806, 0.76003, 0.16775, 0.22766, 0.1396, 0.2164, 0.46866, 0.23195]
Predicted label: 3
Correct prediction
Energy consumption = 180.981489 pJ
sum error= 188
Actual label: 2
Output voltages: [0.3673, 0.384, 0.70351, 0.3137, 0.27341, 0.039248, 0.31594, 0.22164, 0.29017, 0.15505]
Predicted label: 2
Correct prediction
Energy consumption = 180.922717 pJ
sum error= 188
Actual label: 5
Output voltages: [0.34116, 0.060693, 0.12019, 0.36375, 0.11547, 0.69746, 0.29973, 0.28323, 0.49956, 0.17512]
Predicted label: 5
Correct prediction
Energy consumption = 197.431527 pJ
sum error= 188
Actual label: 9
Output voltages: [0.33225, 0.17576, 0.21961, 0.31446, 0.53205, 0.05486, 0.061925, 0.14871, 0.27976, 0.62386]
Predicted label: 9
Correct prediction
Energy consumption = 186.950857 pJ
sum error= 188
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 437 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 437 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 437 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.66246, 0.27482, 0.27419, 0.21318, 0.27388, 0.12019, 0.42973, 0.14908, 0.37672, 0.1802]
Predicted label: 0
Correct prediction
Energy consumption = 203.643201 pJ
sum error= 188
Actual label: 8
Output voltages: [0.23566, 0.29465, 0.23686, 0.4292, 0.078514, 0.22221, 0.15595, 0.12642, 0.73463, 0.23784]
Predicted label: 8
Correct prediction
Energy consumption = 199.582412 pJ
sum error= 188
Actual label: 8
Output voltages: [0.21177, 0.19723, 0.32541, 0.24423, 0.16346, 0.22508, 0.20202, 0.16773, 0.75163, 0.26841]
Predicted label: 8
Correct prediction
Energy consumption = 186.188850 pJ
sum error= 188
Actual label: 4
Output voltages: [0.17324, 0.20857, 0.32687, 0.086531, 0.72243, 0.05389, 0.33365, 0.29119, 0.27064, 0.33063]
Predicted label: 4
Correct prediction
Energy consumption = 201.872107 pJ
sum error= 188
Actual label: 5
Output voltages: [0.33089, 0.048555, 0.13612, 0.31593, 0.14665, 0.6713, 0.35359, 0.19031, 0.52557, 0.25073]
Predicted label: 5
Correct prediction
Energy consumption = 192.972571 pJ
sum error= 188
Actual label: 8
Output voltages: [0.23473, 0.21034, 0.32695, 0.32759, 0.10991, 0.2591, 0.28073, 0.10321, 0.73667, 0.20991]
Predicted label: 8
Correct prediction
Energy consumption = 195.442006 pJ
sum error= 188
Actual label: 8
Output voltages: [0.1411, 0.1999, 0.19649, 0.36684, 0.18139, 0.31329, 0.087128, 0.16252, 0.72803, 0.2651]
Predicted label: 8
Correct prediction
Energy consumption = 192.772230 pJ
sum error= 188
Actual label: 4
Output voltages: [0.1352, 0.18046, 0.2619, 0.16979, 0.75039, 0.054447, 0.24226, 0.27192, 0.20184, 0.26573]
Predicted label: 4
Correct prediction
Energy consumption = 190.100350 pJ
sum error= 188
Actual label: 5
Output voltages: [0.22548, 0.055542, 0.16556, 0.37256, 0.16134, 0.69416, 0.26732, 0.16165, 0.57237, 0.20776]
Predicted label: 5
Correct prediction
Energy consumption = 186.200078 pJ
sum error= 188
Actual label: 4
Output voltages: [0.22148, 0.19358, 0.2666, 0.17741, 0.74788, 0.07353, 0.27449, 0.31818, 0.18903, 0.31156]
Predicted label: 4
Correct prediction
Energy consumption = 195.546874 pJ
sum error= 188
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 438 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 438 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 438 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18223, 0.1529, 0.20061, 0.31442, 0.18916, 0.33581, 0.42005, 0.05504, 0.65404, 0.25635]
Predicted label: 8
Correct prediction
Energy consumption = 197.340493 pJ
sum error= 188
Actual label: 5
Output voltages: [0.20074, 0.059242, 0.18893, 0.40108, 0.18067, 0.64578, 0.23395, 0.20241, 0.55916, 0.2445]
Predicted label: 5
Correct prediction
Energy consumption = 186.546674 pJ
sum error= 188
Actual label: 4
Output voltages: [0.21642, 0.18719, 0.24642, 0.17442, 0.62501, 0.083736, 0.16561, 0.32092, 0.23178, 0.45728]
Predicted label: 4
Correct prediction
Energy consumption = 199.856617 pJ
sum error= 188
Actual label: 9
Output voltages: [0.34164, 0.10467, 0.22565, 0.39214, 0.40871, 0.13405, 0.073805, 0.29744, 0.2724, 0.64836]
Predicted label: 9
Correct prediction
Energy consumption = 195.815833 pJ
sum error= 188
Actual label: 2
Output voltages: [0.29435, 0.5683, 0.52564, 0.33327, 0.24207, 0.037473, 0.4255, 0.089878, 0.29561, 0.15282]
Predicted label: 1
Wrong prediction!
Energy consumption = 201.388629 pJ
sum error= 189
Actual label: 2
Output voltages: [0.33345, 0.37183, 0.71074, 0.33873, 0.14653, 0.025724, 0.32384, 0.19218, 0.37963, 0.2301]
Predicted label: 2
Correct prediction
Energy consumption = 180.693852 pJ
sum error= 189
Actual label: 1
Output voltages: [0.20304, 0.75868, 0.16589, 0.27731, 0.21395, 0.13875, 0.40026, 0.094284, 0.37566, 0.18829]
Predicted label: 1
Correct prediction
Energy consumption = 209.802319 pJ
sum error= 189
Actual label: 2
Output voltages: [0.25704, 0.38209, 0.67988, 0.2673, 0.25064, 0.044115, 0.24645, 0.19604, 0.34885, 0.133]
Predicted label: 2
Correct prediction
Energy consumption = 187.418799 pJ
sum error= 189
Actual label: 6
Output voltages: [0.32855, 0.20555, 0.22941, 0.17799, 0.27005, 0.42607, 0.73243, 0.09725, 0.34201, 0.24051]
Predicted label: 6
Correct prediction
Energy consumption = 191.490915 pJ
sum error= 189
Actual label: 8
Output voltages: [0.20982, 0.31457, 0.26942, 0.33687, 0.087749, 0.15023, 0.30068, 0.13458, 0.72214, 0.2531]
Predicted label: 8
Correct prediction
Energy consumption = 204.603543 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 439 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 439 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 439 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.27534, 0.16127, 0.43975, 0.20675, 0.16975, 0.10111, 0.24396, 0.12835, 0.74601, 0.31673]
Predicted label: 8
Correct prediction
Energy consumption = 198.703684 pJ
sum error= 189
Actual label: 7
Output voltages: [0.42108, 0.20389, 0.15085, 0.11114, 0.28173, 0.18076, 0.11108, 0.72803, 0.29684, 0.40551]
Predicted label: 7
Correct prediction
Energy consumption = 200.251212 pJ
sum error= 189
Actual label: 0
Output voltages: [0.7211, 0.23832, 0.27448, 0.14983, 0.12473, 0.19706, 0.39016, 0.15518, 0.25868, 0.29695]
Predicted label: 0
Correct prediction
Energy consumption = 192.438539 pJ
sum error= 189
Actual label: 3
Output voltages: [0.38206, 0.1907, 0.32866, 0.7375, 0.081442, 0.28323, 0.2485, 0.18559, 0.35476, 0.12277]
Predicted label: 3
Correct prediction
Energy consumption = 195.722589 pJ
sum error= 189
Actual label: 6
Output voltages: [0.2631, 0.18518, 0.35093, 0.06576, 0.41281, 0.27169, 0.72716, 0.069484, 0.32577, 0.14442]
Predicted label: 6
Correct prediction
Energy consumption = 188.903873 pJ
sum error= 189
Actual label: 6
Output voltages: [0.28415, 0.34836, 0.32181, 0.07143, 0.44119, 0.27924, 0.72668, 0.060362, 0.2759, 0.1749]
Predicted label: 6
Correct prediction
Energy consumption = 194.411018 pJ
sum error= 189
Actual label: 4
Output voltages: [0.20838, 0.22261, 0.22835, 0.15332, 0.70713, 0.10433, 0.25193, 0.12811, 0.27534, 0.28368]
Predicted label: 4
Correct prediction
Energy consumption = 202.596724 pJ
sum error= 189
Actual label: 3
Output voltages: [0.30304, 0.17172, 0.24692, 0.75659, 0.30361, 0.29614, 0.23318, 0.23192, 0.42087, 0.17399]
Predicted label: 3
Correct prediction
Energy consumption = 187.201832 pJ
sum error= 189
Actual label: 8
Output voltages: [0.21309, 0.21624, 0.26831, 0.38577, 0.084889, 0.20448, 0.13731, 0.22374, 0.74342, 0.29312]
Predicted label: 8
Correct prediction
Energy consumption = 185.372124 pJ
sum error= 189
Actual label: 8
Output voltages: [0.41567, 0.14753, 0.27579, 0.33836, 0.1854, 0.18571, 0.33581, 0.062052, 0.62481, 0.33465]
Predicted label: 8
Correct prediction
Energy consumption = 195.875097 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 440 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 440 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 440 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.17935, 0.51627, 0.44606, 0.2338, 0.26213, 0.032352, 0.10739, 0.51662, 0.20971, 0.27124]
Predicted label: 7
Correct prediction
Energy consumption = 201.302191 pJ
sum error= 189
Actual label: 2
Output voltages: [0.38938, 0.26635, 0.59662, 0.51505, 0.08907, 0.040924, 0.13707, 0.3678, 0.43693, 0.22062]
Predicted label: 2
Correct prediction
Energy consumption = 199.379657 pJ
sum error= 189
Actual label: 2
Output voltages: [0.34052, 0.38648, 0.72148, 0.32669, 0.16087, 0.024688, 0.26093, 0.23118, 0.30566, 0.22145]
Predicted label: 2
Correct prediction
Energy consumption = 182.258675 pJ
sum error= 189
Actual label: 0
Output voltages: [0.61838, 0.13328, 0.33684, 0.19067, 0.14629, 0.25039, 0.42042, 0.060282, 0.41938, 0.35262]
Predicted label: 0
Correct prediction
Energy consumption = 194.930303 pJ
sum error= 189
Actual label: 0
Output voltages: [0.71272, 0.16847, 0.25445, 0.13035, 0.23106, 0.1903, 0.42127, 0.15083, 0.3034, 0.28397]
Predicted label: 0
Correct prediction
Energy consumption = 194.529637 pJ
sum error= 189
Actual label: 9
Output voltages: [0.35129, 0.092048, 0.2589, 0.19059, 0.53468, 0.11131, 0.13884, 0.24956, 0.26229, 0.61515]
Predicted label: 9
Correct prediction
Energy consumption = 200.892640 pJ
sum error= 189
Actual label: 3
Output voltages: [0.29465, 0.17008, 0.30166, 0.74711, 0.14081, 0.17223, 0.14622, 0.15485, 0.51018, 0.24955]
Predicted label: 3
Correct prediction
Energy consumption = 182.111913 pJ
sum error= 189
Actual label: 9
Output voltages: [0.35678, 0.13128, 0.22422, 0.25703, 0.29936, 0.12298, 0.066313, 0.20088, 0.44272, 0.65939]
Predicted label: 9
Correct prediction
Energy consumption = 185.050410 pJ
sum error= 189
Actual label: 9
Output voltages: [0.39937, 0.11801, 0.23477, 0.26759, 0.32899, 0.183, 0.29826, 0.16622, 0.28298, 0.66732]
Predicted label: 9
Correct prediction
Energy consumption = 192.237256 pJ
sum error= 189
Actual label: 1
Output voltages: [0.19875, 0.7631, 0.25139, 0.26544, 0.27465, 0.082563, 0.3815, 0.11231, 0.30356, 0.26081]
Predicted label: 1
Correct prediction
Energy consumption = 207.157752 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 441 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 441 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 441 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34359, 0.10794, 0.20774, 0.20516, 0.30775, 0.16202, 0.062532, 0.20495, 0.44512, 0.65007]
Predicted label: 9
Correct prediction
Energy consumption = 191.246178 pJ
sum error= 189
Actual label: 8
Output voltages: [0.18085, 0.19191, 0.25513, 0.31624, 0.11285, 0.30853, 0.15708, 0.20816, 0.75222, 0.25299]
Predicted label: 8
Correct prediction
Energy consumption = 186.864539 pJ
sum error= 189
Actual label: 6
Output voltages: [0.3126, 0.26612, 0.31143, 0.093108, 0.29025, 0.28814, 0.74631, 0.12375, 0.40024, 0.12107]
Predicted label: 6
Correct prediction
Energy consumption = 193.165598 pJ
sum error= 189
Actual label: 6
Output voltages: [0.31771, 0.3386, 0.208, 0.28129, 0.21395, 0.31927, 0.72511, 0.078074, 0.48829, 0.12087]
Predicted label: 6
Correct prediction
Energy consumption = 193.134942 pJ
sum error= 189
Actual label: 4
Output voltages: [0.18466, 0.12281, 0.33949, 0.19582, 0.74188, 0.07876, 0.26174, 0.21292, 0.24363, 0.30692]
Predicted label: 4
Correct prediction
Energy consumption = 193.179164 pJ
sum error= 189
Actual label: 2
Output voltages: [0.45695, 0.22893, 0.73126, 0.30713, 0.10759, 0.048214, 0.30239, 0.2395, 0.37806, 0.20316]
Predicted label: 2
Correct prediction
Energy consumption = 197.320025 pJ
sum error= 189
Actual label: 6
Output voltages: [0.3224, 0.27675, 0.31009, 0.08048, 0.28559, 0.35313, 0.7475, 0.075936, 0.38525, 0.18159]
Predicted label: 6
Correct prediction
Energy consumption = 193.340466 pJ
sum error= 189
Actual label: 9
Output voltages: [0.34713, 0.14367, 0.2272, 0.30278, 0.3015, 0.18724, 0.13057, 0.3025, 0.33092, 0.69439]
Predicted label: 9
Correct prediction
Energy consumption = 198.184568 pJ
sum error= 189
Actual label: 2
Output voltages: [0.40551, 0.2198, 0.71846, 0.36515, 0.17915, 0.028641, 0.28677, 0.29085, 0.3605, 0.17985]
Predicted label: 2
Correct prediction
Energy consumption = 183.596289 pJ
sum error= 189
Actual label: 8
Output voltages: [0.22434, 0.1631, 0.16364, 0.30324, 0.18351, 0.38246, 0.24405, 0.26254, 0.72729, 0.18361]
Predicted label: 8
Correct prediction
Energy consumption = 196.591727 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 442 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 442 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 442 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.28976, 0.056502, 0.12013, 0.44423, 0.14591, 0.71313, 0.21655, 0.26965, 0.48027, 0.27502]
Predicted label: 5
Correct prediction
Energy consumption = 192.248444 pJ
sum error= 189
Actual label: 4
Output voltages: [0.25841, 0.10765, 0.30089, 0.097014, 0.75346, 0.073972, 0.35331, 0.1898, 0.21028, 0.30089]
Predicted label: 4
Correct prediction
Energy consumption = 200.659757 pJ
sum error= 189
Actual label: 5
Output voltages: [0.23037, 0.050138, 0.091633, 0.39075, 0.22621, 0.70723, 0.27042, 0.26481, 0.47346, 0.34178]
Predicted label: 5
Correct prediction
Energy consumption = 194.144655 pJ
sum error= 189
Actual label: 7
Output voltages: [0.19346, 0.17031, 0.27404, 0.36625, 0.22161, 0.09203, 0.047773, 0.71278, 0.37654, 0.27614]
Predicted label: 7
Correct prediction
Energy consumption = 192.726007 pJ
sum error= 189
Actual label: 9
Output voltages: [0.33207, 0.17804, 0.20789, 0.31653, 0.38464, 0.12459, 0.13944, 0.2648, 0.24824, 0.69254]
Predicted label: 9
Correct prediction
Energy consumption = 195.429106 pJ
sum error= 189
Actual label: 9
Output voltages: [0.30078, 0.15968, 0.23362, 0.20387, 0.57059, 0.116, 0.23134, 0.19752, 0.22934, 0.55377]
Predicted label: 4
Wrong prediction!
Energy consumption = 195.909138 pJ
sum error= 190
Actual label: 9
Output voltages: [0.32399, 0.18406, 0.21551, 0.22763, 0.4109, 0.094506, 0.10632, 0.1577, 0.33901, 0.66804]
Predicted label: 9
Correct prediction
Energy consumption = 192.719691 pJ
sum error= 190
Actual label: 2
Output voltages: [0.32749, 0.37914, 0.65961, 0.40419, 0.078129, 0.029853, 0.24871, 0.23172, 0.39005, 0.24094]
Predicted label: 2
Correct prediction
Energy consumption = 194.441320 pJ
sum error= 190
Actual label: 1
Output voltages: [0.20169, 0.76492, 0.14095, 0.27848, 0.2021, 0.19184, 0.4573, 0.11346, 0.30817, 0.18533]
Predicted label: 1
Correct prediction
Energy consumption = 207.701493 pJ
sum error= 190
Actual label: 8
Output voltages: [0.36061, 0.1324, 0.2815, 0.25262, 0.096795, 0.3653, 0.34728, 0.086075, 0.58774, 0.25952]
Predicted label: 8
Correct prediction
Energy consumption = 196.320690 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 443 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 443 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 443 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33294, 0.16932, 0.32135, 0.75451, 0.19514, 0.18983, 0.19171, 0.1411, 0.43374, 0.18862]
Predicted label: 3
Correct prediction
Energy consumption = 188.896339 pJ
sum error= 190
Actual label: 4
Output voltages: [0.12386, 0.20048, 0.22771, 0.14709, 0.74441, 0.11167, 0.19297, 0.24381, 0.32927, 0.30397]
Predicted label: 4
Correct prediction
Energy consumption = 203.698124 pJ
sum error= 190
Actual label: 0
Output voltages: [0.72269, 0.24509, 0.2066, 0.25686, 0.15139, 0.16147, 0.38312, 0.1509, 0.34527, 0.32018]
Predicted label: 0
Correct prediction
Energy consumption = 200.379745 pJ
sum error= 190
Actual label: 7
Output voltages: [0.23079, 0.17957, 0.32451, 0.47559, 0.47065, 0.090408, 0.088055, 0.59193, 0.29615, 0.18281]
Predicted label: 7
Correct prediction
Energy consumption = 202.098718 pJ
sum error= 190
Actual label: 8
Output voltages: [0.16241, 0.30345, 0.25356, 0.29735, 0.099475, 0.19812, 0.22872, 0.2181, 0.73806, 0.31025]
Predicted label: 8
Correct prediction
Energy consumption = 197.186807 pJ
sum error= 190
Actual label: 3
Output voltages: [0.254, 0.28162, 0.27319, 0.6948, 0.070312, 0.097188, 0.066217, 0.43386, 0.3497, 0.46356]
Predicted label: 3
Correct prediction
Energy consumption = 191.906316 pJ
sum error= 190
Actual label: 9
Output voltages: [0.32834, 0.13213, 0.23293, 0.31306, 0.22716, 0.1902, 0.098711, 0.28071, 0.40557, 0.67534]
Predicted label: 9
Correct prediction
Energy consumption = 189.456482 pJ
sum error= 190
Actual label: 3
Output voltages: [0.43495, 0.17825, 0.42744, 0.71537, 0.066245, 0.075241, 0.20157, 0.21329, 0.42347, 0.22677]
Predicted label: 3
Correct prediction
Energy consumption = 197.198611 pJ
sum error= 190
Actual label: 4
Output voltages: [0.23535, 0.17452, 0.2352, 0.26875, 0.70071, 0.081014, 0.245, 0.13044, 0.20698, 0.29956]
Predicted label: 4
Correct prediction
Energy consumption = 197.164119 pJ
sum error= 190
Actual label: 6
Output voltages: [0.36459, 0.23112, 0.24878, 0.071235, 0.40033, 0.2062, 0.69335, 0.12116, 0.27691, 0.27301]
Predicted label: 6
Correct prediction
Energy consumption = 200.750913 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 444 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 444 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 444 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.23863, 0.04893, 0.1248, 0.40308, 0.15723, 0.67166, 0.16237, 0.27359, 0.49164, 0.31933]
Predicted label: 5
Correct prediction
Energy consumption = 190.459761 pJ
sum error= 190
Actual label: 6
Output voltages: [0.31963, 0.2147, 0.32948, 0.087662, 0.28035, 0.24203, 0.73835, 0.073497, 0.35931, 0.18062]
Predicted label: 6
Correct prediction
Energy consumption = 192.897459 pJ
sum error= 190
Actual label: 2
Output voltages: [0.3135, 0.37656, 0.69318, 0.36238, 0.25508, 0.03053, 0.28548, 0.15952, 0.32053, 0.21038]
Predicted label: 2
Correct prediction
Energy consumption = 188.997734 pJ
sum error= 190
Actual label: 3
Output voltages: [0.3163, 0.46909, 0.38334, 0.60073, 0.077897, 0.088399, 0.18826, 0.27131, 0.42513, 0.16677]
Predicted label: 3
Correct prediction
Energy consumption = 198.342818 pJ
sum error= 190
Actual label: 9
Output voltages: [0.36286, 0.10602, 0.23023, 0.22666, 0.38937, 0.21312, 0.16175, 0.16873, 0.33585, 0.6236]
Predicted label: 9
Correct prediction
Energy consumption = 201.173501 pJ
sum error= 190
Actual label: 2
Output voltages: [0.35692, 0.22327, 0.7479, 0.36329, 0.19919, 0.041402, 0.17883, 0.27579, 0.33331, 0.25067]
Predicted label: 2
Correct prediction
Energy consumption = 191.758571 pJ
sum error= 190
Actual label: 6
Output voltages: [0.25628, 0.21009, 0.31057, 0.072385, 0.35833, 0.34611, 0.74308, 0.062939, 0.31392, 0.1516]
Predicted label: 6
Correct prediction
Energy consumption = 189.757278 pJ
sum error= 190
Actual label: 0
Output voltages: [0.69475, 0.19572, 0.1974, 0.16272, 0.24813, 0.14067, 0.41704, 0.17704, 0.35706, 0.28367]
Predicted label: 0
Correct prediction
Energy consumption = 198.672382 pJ
sum error= 190
Actual label: 0
Output voltages: [0.73908, 0.32253, 0.29785, 0.21167, 0.092385, 0.15499, 0.35607, 0.18662, 0.27436, 0.26615]
Predicted label: 0
Correct prediction
Energy consumption = 191.477556 pJ
sum error= 190
Actual label: 6
Output voltages: [0.46692, 0.21182, 0.22718, 0.10127, 0.28321, 0.34637, 0.67382, 0.1453, 0.40016, 0.090025]
Predicted label: 6
Correct prediction
Energy consumption = 182.398908 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 445 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 445 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 445 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.21457, 0.76122, 0.10891, 0.38526, 0.1737, 0.22715, 0.29177, 0.19132, 0.31356, 0.25222]
Predicted label: 1
Correct prediction
Energy consumption = 215.044189 pJ
sum error= 190
Actual label: 2
Output voltages: [0.25182, 0.42416, 0.62334, 0.32117, 0.081634, 0.040226, 0.26279, 0.24882, 0.43123, 0.22949]
Predicted label: 2
Correct prediction
Energy consumption = 196.711502 pJ
sum error= 190
Actual label: 8
Output voltages: [0.24495, 0.207, 0.3644, 0.26441, 0.14512, 0.1809, 0.2412, 0.11889, 0.72663, 0.2452]
Predicted label: 8
Correct prediction
Energy consumption = 191.975050 pJ
sum error= 190
Actual label: 7
Output voltages: [0.24297, 0.33404, 0.38061, 0.24686, 0.13622, 0.034564, 0.038469, 0.73855, 0.37564, 0.28729]
Predicted label: 7
Correct prediction
Energy consumption = 194.140388 pJ
sum error= 190
Actual label: 9
Output voltages: [0.39251, 0.059838, 0.28556, 0.22484, 0.34021, 0.14523, 0.070812, 0.13181, 0.50134, 0.53195]
Predicted label: 9
Correct prediction
Energy consumption = 197.087786 pJ
sum error= 190
Actual label: 8
Output voltages: [0.37331, 0.15326, 0.35315, 0.18002, 0.25558, 0.080593, 0.32339, 0.060562, 0.6424, 0.33612]
Predicted label: 8
Correct prediction
Energy consumption = 184.442849 pJ
sum error= 190
Actual label: 2
Output voltages: [0.36759, 0.30626, 0.70629, 0.36413, 0.14358, 0.02818, 0.31757, 0.18209, 0.44312, 0.22157]
Predicted label: 2
Correct prediction
Energy consumption = 188.545332 pJ
sum error= 190
Actual label: 0
Output voltages: [0.72952, 0.17581, 0.23118, 0.16222, 0.21322, 0.1919, 0.45001, 0.18202, 0.29702, 0.31436]
Predicted label: 0
Correct prediction
Energy consumption = 193.240127 pJ
sum error= 190
Actual label: 4
Output voltages: [0.14182, 0.21462, 0.28086, 0.17537, 0.74895, 0.091425, 0.18708, 0.25919, 0.23792, 0.34741]
Predicted label: 4
Correct prediction
Energy consumption = 198.342458 pJ
sum error= 190
Actual label: 7
Output voltages: [0.3045, 0.21363, 0.30776, 0.33164, 0.13746, 0.045721, 0.053026, 0.7468, 0.38022, 0.30474]
Predicted label: 7
Correct prediction
Energy consumption = 199.945129 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 446 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 446 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 446 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30353, 0.30922, 0.39125, 0.47666, 0.12247, 0.040842, 0.053581, 0.61502, 0.22534, 0.39965]
Predicted label: 7
Correct prediction
Energy consumption = 207.270531 pJ
sum error= 190
Actual label: 5
Output voltages: [0.21407, 0.097586, 0.065552, 0.4062, 0.15746, 0.67353, 0.19803, 0.21604, 0.45825, 0.34262]
Predicted label: 5
Correct prediction
Energy consumption = 193.695120 pJ
sum error= 190
Actual label: 0
Output voltages: [0.69446, 0.18034, 0.16712, 0.11832, 0.22563, 0.30935, 0.44172, 0.14887, 0.24861, 0.34247]
Predicted label: 0
Correct prediction
Energy consumption = 197.537187 pJ
sum error= 190
Actual label: 5
Output voltages: [0.20535, 0.048016, 0.20825, 0.46033, 0.32534, 0.55254, 0.31302, 0.090614, 0.43052, 0.27617]
Predicted label: 5
Correct prediction
Energy consumption = 189.360181 pJ
sum error= 190
Actual label: 6
Output voltages: [0.31287, 0.25263, 0.3214, 0.080431, 0.28644, 0.30002, 0.74036, 0.059019, 0.349, 0.19628]
Predicted label: 6
Correct prediction
Energy consumption = 191.539512 pJ
sum error= 190
Actual label: 4
Output voltages: [0.26629, 0.2437, 0.41224, 0.27306, 0.67696, 0.037658, 0.19484, 0.37468, 0.13749, 0.37445]
Predicted label: 4
Correct prediction
Energy consumption = 195.365107 pJ
sum error= 190
Actual label: 6
Output voltages: [0.33374, 0.27973, 0.32734, 0.13526, 0.34464, 0.2868, 0.73885, 0.10509, 0.42289, 0.11225]
Predicted label: 6
Correct prediction
Energy consumption = 195.366621 pJ
sum error= 190
Actual label: 7
Output voltages: [0.24558, 0.19356, 0.23293, 0.23769, 0.24159, 0.090151, 0.027819, 0.70924, 0.47927, 0.34085]
Predicted label: 7
Correct prediction
Energy consumption = 203.814711 pJ
sum error= 190
Actual label: 4
Output voltages: [0.1785, 0.17159, 0.24732, 0.15309, 0.74022, 0.084207, 0.2476, 0.27263, 0.25394, 0.19514]
Predicted label: 4
Correct prediction
Energy consumption = 191.810470 pJ
sum error= 190
Actual label: 3
Output voltages: [0.31902, 0.33624, 0.28019, 0.75007, 0.081016, 0.19037, 0.12445, 0.24611, 0.35115, 0.2598]
Predicted label: 3
Correct prediction
Energy consumption = 199.286001 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 447 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 447 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 447 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7251, 0.21201, 0.25169, 0.17612, 0.1586, 0.15842, 0.35272, 0.20301, 0.38218, 0.25367]
Predicted label: 0
Correct prediction
Energy consumption = 203.085281 pJ
sum error= 190
Actual label: 7
Output voltages: [0.38469, 0.22306, 0.31522, 0.22441, 0.094127, 0.067576, 0.080875, 0.72961, 0.47855, 0.31159]
Predicted label: 7
Correct prediction
Energy consumption = 201.190675 pJ
sum error= 190
Actual label: 5
Output voltages: [0.23954, 0.067803, 0.11997, 0.23645, 0.20719, 0.68068, 0.3787, 0.093555, 0.59655, 0.18109]
Predicted label: 5
Correct prediction
Energy consumption = 193.401388 pJ
sum error= 190
Actual label: 0
Output voltages: [0.72388, 0.21267, 0.29599, 0.20096, 0.18452, 0.16467, 0.3956, 0.20666, 0.38353, 0.23698]
Predicted label: 0
Correct prediction
Energy consumption = 200.410765 pJ
sum error= 190
Actual label: 7
Output voltages: [0.38435, 0.19779, 0.32754, 0.23427, 0.14284, 0.047257, 0.056259, 0.74401, 0.40654, 0.32325]
Predicted label: 7
Correct prediction
Energy consumption = 206.244157 pJ
sum error= 190
Actual label: 4
Output voltages: [0.14444, 0.13418, 0.36322, 0.22563, 0.75992, 0.095627, 0.31743, 0.30626, 0.19192, 0.31439]
Predicted label: 4
Correct prediction
Energy consumption = 192.177813 pJ
sum error= 190
Actual label: 2
Output voltages: [0.29713, 0.47555, 0.67352, 0.34164, 0.15767, 0.023733, 0.27257, 0.23172, 0.32088, 0.22596]
Predicted label: 2
Correct prediction
Energy consumption = 188.049844 pJ
sum error= 190
Actual label: 0
Output voltages: [0.63491, 0.33964, 0.17559, 0.21119, 0.22583, 0.22304, 0.5592, 0.16881, 0.35026, 0.20136]
Predicted label: 0
Correct prediction
Energy consumption = 208.029151 pJ
sum error= 190
Actual label: 8
Output voltages: [0.25206, 0.25327, 0.27945, 0.28507, 0.19971, 0.11855, 0.27813, 0.086821, 0.71304, 0.31256]
Predicted label: 8
Correct prediction
Energy consumption = 202.153361 pJ
sum error= 190
Actual label: 9
Output voltages: [0.33227, 0.23991, 0.16625, 0.35951, 0.29051, 0.109, 0.050419, 0.38345, 0.21755, 0.62255]
Predicted label: 9
Correct prediction
Energy consumption = 202.660970 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 448 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 448 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 448 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34549, 0.083438, 0.137, 0.22882, 0.23435, 0.31909, 0.075249, 0.3807, 0.48798, 0.58588]
Predicted label: 9
Correct prediction
Energy consumption = 197.929148 pJ
sum error= 190
Actual label: 4
Output voltages: [0.14904, 0.28784, 0.23824, 0.33814, 0.69439, 0.049386, 0.11294, 0.28008, 0.22733, 0.30499]
Predicted label: 4
Correct prediction
Energy consumption = 193.537687 pJ
sum error= 190
Actual label: 2
Output voltages: [0.44867, 0.071847, 0.57481, 0.50499, 0.15571, 0.065775, 0.1439, 0.16572, 0.48479, 0.25669]
Predicted label: 2
Correct prediction
Energy consumption = 196.475952 pJ
sum error= 190
Actual label: 4
Output voltages: [0.23648, 0.18879, 0.3658, 0.17152, 0.54126, 0.039892, 0.077604, 0.24391, 0.30851, 0.46766]
Predicted label: 4
Correct prediction
Energy consumption = 207.672775 pJ
sum error= 190
Actual label: 6
Output voltages: [0.32495, 0.15894, 0.18281, 0.17242, 0.3089, 0.4173, 0.70233, 0.065228, 0.37691, 0.14467]
Predicted label: 6
Correct prediction
Energy consumption = 193.193653 pJ
sum error= 190
Actual label: 7
Output voltages: [0.35361, 0.20401, 0.23625, 0.23816, 0.17213, 0.1211, 0.038937, 0.74889, 0.45987, 0.28265]
Predicted label: 7
Correct prediction
Energy consumption = 199.003849 pJ
sum error= 190
Actual label: 8
Output voltages: [0.25911, 0.19704, 0.23912, 0.30108, 0.18671, 0.27175, 0.26925, 0.065925, 0.7123, 0.2874]
Predicted label: 8
Correct prediction
Energy consumption = 202.331841 pJ
sum error= 190
Actual label: 7
Output voltages: [0.32047, 0.20652, 0.40461, 0.24578, 0.059378, 0.093465, 0.084638, 0.475, 0.61242, 0.32394]
Predicted label: 8
Wrong prediction!
Energy consumption = 189.589525 pJ
sum error= 191
Actual label: 6
Output voltages: [0.29398, 0.18348, 0.24966, 0.17197, 0.31825, 0.37231, 0.72609, 0.063886, 0.42831, 0.11815]
Predicted label: 6
Correct prediction
Energy consumption = 194.986487 pJ
sum error= 191
Actual label: 9
Output voltages: [0.28457, 0.16803, 0.23931, 0.39683, 0.18359, 0.18944, 0.13075, 0.066835, 0.504, 0.53847]
Predicted label: 9
Correct prediction
Energy consumption = 193.547927 pJ
sum error= 191
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 449 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 449 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 449 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19743, 0.15553, 0.2615, 0.13303, 0.72643, 0.11563, 0.35303, 0.18006, 0.2322, 0.30695]
Predicted label: 4
Correct prediction
Energy consumption = 203.443967 pJ
sum error= 191
Actual label: 1
Output voltages: [0.17787, 0.75613, 0.35404, 0.33146, 0.24625, 0.080898, 0.34135, 0.095313, 0.18064, 0.25838]
Predicted label: 1
Correct prediction
Energy consumption = 202.372580 pJ
sum error= 191
Actual label: 3
Output voltages: [0.24358, 0.23892, 0.26271, 0.76242, 0.16733, 0.16752, 0.11445, 0.26777, 0.42726, 0.2322]
Predicted label: 3
Correct prediction
Energy consumption = 190.681186 pJ
sum error= 191
Actual label: 7
Output voltages: [0.3318, 0.33258, 0.39119, 0.24551, 0.1212, 0.03119, 0.066853, 0.7182, 0.29067, 0.31183]
Predicted label: 7
Correct prediction
Energy consumption = 194.067983 pJ
sum error= 191
Actual label: 3
Output voltages: [0.37029, 0.12905, 0.17999, 0.68562, 0.31384, 0.39173, 0.18085, 0.18489, 0.30737, 0.20402]
Predicted label: 3
Correct prediction
Energy consumption = 206.322450 pJ
sum error= 191
Actual label: 0
Output voltages: [0.7387, 0.24303, 0.26464, 0.17783, 0.17925, 0.11889, 0.33883, 0.176, 0.3563, 0.21766]
Predicted label: 0
Correct prediction
Energy consumption = 196.573903 pJ
sum error= 191
Actual label: 8
Output voltages: [0.23795, 0.24088, 0.27561, 0.2691, 0.16659, 0.15683, 0.20855, 0.10295, 0.74288, 0.36769]
Predicted label: 8
Correct prediction
Energy consumption = 197.726701 pJ
sum error= 191
Actual label: 8
Output voltages: [0.22007, 0.33141, 0.35757, 0.12714, 0.16381, 0.063261, 0.06836, 0.56582, 0.63273, 0.22163]
Predicted label: 8
Correct prediction
Energy consumption = 192.136262 pJ
sum error= 191
Actual label: 7
Output voltages: [0.24088, 0.20204, 0.35181, 0.36042, 0.23373, 0.066705, 0.19475, 0.46669, 0.64371, 0.10734]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.503008 pJ
sum error= 192
Actual label: 6
Output voltages: [0.37668, 0.29901, 0.25987, 0.10748, 0.24, 0.30316, 0.72412, 0.128, 0.41896, 0.15522]
Predicted label: 6
Correct prediction
Energy consumption = 195.172695 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 450 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 450 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 450 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32686, 0.37135, 0.18533, 0.20898, 0.30154, 0.079721, 0.07003, 0.080708, 0.34345, 0.62815]
Predicted label: 9
Correct prediction
Energy consumption = 212.770805 pJ
sum error= 192
Actual label: 3
Output voltages: [0.46321, 0.13195, 0.25277, 0.74572, 0.17257, 0.29793, 0.11619, 0.22351, 0.38032, 0.20101]
Predicted label: 3
Correct prediction
Energy consumption = 190.393832 pJ
sum error= 192
Actual label: 9
Output voltages: [0.33616, 0.09008, 0.28967, 0.24689, 0.3116, 0.1257, 0.096962, 0.25345, 0.36899, 0.62936]
Predicted label: 9
Correct prediction
Energy consumption = 193.629967 pJ
sum error= 192
Actual label: 2
Output voltages: [0.36205, 0.45229, 0.66064, 0.38233, 0.13521, 0.02584, 0.2773, 0.21633, 0.33579, 0.21069]
Predicted label: 2
Correct prediction
Energy consumption = 192.827128 pJ
sum error= 192
Actual label: 2
Output voltages: [0.25829, 0.24612, 0.72496, 0.30803, 0.19506, 0.031874, 0.18498, 0.43856, 0.37048, 0.15052]
Predicted label: 2
Correct prediction
Energy consumption = 186.733401 pJ
sum error= 192
Actual label: 9
Output voltages: [0.28019, 0.095985, 0.11246, 0.39132, 0.36091, 0.281, 0.05988, 0.36184, 0.3157, 0.58246]
Predicted label: 9
Correct prediction
Energy consumption = 205.386942 pJ
sum error= 192
Actual label: 2
Output voltages: [0.42798, 0.12476, 0.68867, 0.44463, 0.11563, 0.041894, 0.18332, 0.25753, 0.45917, 0.19006]
Predicted label: 2
Correct prediction
Energy consumption = 185.887545 pJ
sum error= 192
Actual label: 1
Output voltages: [0.27982, 0.59337, 0.438, 0.22612, 0.14925, 0.054536, 0.13297, 0.3165, 0.43545, 0.27627]
Predicted label: 1
Correct prediction
Energy consumption = 199.776534 pJ
sum error= 192
Actual label: 8
Output voltages: [0.28074, 0.17821, 0.32951, 0.39581, 0.078417, 0.23585, 0.10792, 0.26182, 0.73726, 0.25463]
Predicted label: 8
Correct prediction
Energy consumption = 198.260581 pJ
sum error= 192
Actual label: 3
Output voltages: [0.27823, 0.30811, 0.3967, 0.74269, 0.16343, 0.050759, 0.10989, 0.18015, 0.32087, 0.32033]
Predicted label: 3
Correct prediction
Energy consumption = 185.067256 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 451 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 451 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 451 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32921, 0.22494, 0.75066, 0.22575, 0.15933, 0.033398, 0.23343, 0.31399, 0.3942, 0.23797]
Predicted label: 2
Correct prediction
Energy consumption = 194.926000 pJ
sum error= 192
Actual label: 9
Output voltages: [0.25645, 0.10886, 0.36678, 0.24493, 0.58532, 0.079436, 0.098372, 0.24499, 0.2158, 0.53977]
Predicted label: 4
Wrong prediction!
Energy consumption = 199.646012 pJ
sum error= 193
Actual label: 6
Output voltages: [0.2821, 0.21005, 0.25921, 0.13986, 0.32823, 0.34384, 0.73497, 0.093424, 0.4323, 0.087215]
Predicted label: 6
Correct prediction
Energy consumption = 191.190441 pJ
sum error= 193
Actual label: 8
Output voltages: [0.28008, 0.068824, 0.26312, 0.35117, 0.077536, 0.40205, 0.23005, 0.089347, 0.69568, 0.23623]
Predicted label: 8
Correct prediction
Energy consumption = 187.281758 pJ
sum error= 193
Actual label: 4
Output voltages: [0.19258, 0.13657, 0.28127, 0.18124, 0.66665, 0.056982, 0.14749, 0.10754, 0.35966, 0.32272]
Predicted label: 4
Correct prediction
Energy consumption = 194.695766 pJ
sum error= 193
Actual label: 0
Output voltages: [0.70048, 0.13757, 0.29524, 0.15132, 0.21047, 0.081376, 0.31605, 0.21428, 0.42587, 0.32651]
Predicted label: 0
Correct prediction
Energy consumption = 195.606289 pJ
sum error= 193
Actual label: 1
Output voltages: [0.2264, 0.75579, 0.13604, 0.28271, 0.13754, 0.23227, 0.43679, 0.12771, 0.35852, 0.14795]
Predicted label: 1
Correct prediction
Energy consumption = 208.327453 pJ
sum error= 193
Actual label: 2
Output voltages: [0.42745, 0.15567, 0.74944, 0.33761, 0.19868, 0.054587, 0.2411, 0.22273, 0.42894, 0.18548]
Predicted label: 2
Correct prediction
Energy consumption = 186.406698 pJ
sum error= 193
Actual label: 8
Output voltages: [0.21525, 0.21506, 0.30874, 0.30635, 0.12681, 0.17302, 0.17585, 0.18027, 0.74775, 0.26273]
Predicted label: 8
Correct prediction
Energy consumption = 188.684710 pJ
sum error= 193
Actual label: 4
Output voltages: [0.17255, 0.17346, 0.27779, 0.22018, 0.73798, 0.060919, 0.23221, 0.23049, 0.19043, 0.33356]
Predicted label: 4
Correct prediction
Energy consumption = 195.566503 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 452 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 452 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 452 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.26625, 0.074291, 0.081611, 0.28817, 0.20186, 0.68106, 0.19959, 0.19107, 0.50927, 0.34432]
Predicted label: 5
Correct prediction
Energy consumption = 195.087977 pJ
sum error= 193
Actual label: 2
Output voltages: [0.39401, 0.34573, 0.74144, 0.32261, 0.0978, 0.029437, 0.22602, 0.44461, 0.28229, 0.25798]
Predicted label: 2
Correct prediction
Energy consumption = 185.832660 pJ
sum error= 193
Actual label: 7
Output voltages: [0.30914, 0.23175, 0.16755, 0.33258, 0.10248, 0.12834, 0.036111, 0.73959, 0.42334, 0.39966]
Predicted label: 7
Correct prediction
Energy consumption = 198.466668 pJ
sum error= 193
Actual label: 8
Output voltages: [0.27907, 0.29777, 0.18276, 0.42711, 0.073361, 0.29067, 0.15805, 0.23221, 0.71802, 0.22223]
Predicted label: 8
Correct prediction
Energy consumption = 195.666429 pJ
sum error= 193
Actual label: 1
Output voltages: [0.2357, 0.75671, 0.21065, 0.20187, 0.27896, 0.082768, 0.41071, 0.12697, 0.32107, 0.25106]
Predicted label: 1
Correct prediction
Energy consumption = 209.213776 pJ
sum error= 193
Actual label: 1
Output voltages: [0.22176, 0.76634, 0.24695, 0.28558, 0.12795, 0.12721, 0.39882, 0.097495, 0.35851, 0.21028]
Predicted label: 1
Correct prediction
Energy consumption = 211.193293 pJ
sum error= 193
Actual label: 3
Output voltages: [0.26504, 0.24834, 0.35488, 0.74082, 0.18402, 0.10269, 0.10189, 0.19182, 0.42182, 0.19158]
Predicted label: 3
Correct prediction
Energy consumption = 189.921378 pJ
sum error= 193
Actual label: 0
Output voltages: [0.7321, 0.27399, 0.29087, 0.15231, 0.14291, 0.13555, 0.37399, 0.23998, 0.27138, 0.28459]
Predicted label: 0
Correct prediction
Energy consumption = 193.544556 pJ
sum error= 193
Actual label: 3
Output voltages: [0.24015, 0.11456, 0.28757, 0.73173, 0.2115, 0.33211, 0.21405, 0.15898, 0.40694, 0.25401]
Predicted label: 3
Correct prediction
Energy consumption = 185.262918 pJ
sum error= 193
Actual label: 5
Output voltages: [0.2456, 0.070679, 0.062561, 0.35446, 0.17588, 0.72337, 0.27893, 0.096021, 0.51398, 0.19553]
Predicted label: 5
Correct prediction
Energy consumption = 175.703114 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 453 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 453 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 453 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37402, 0.26795, 0.12408, 0.31541, 0.080232, 0.18897, 0.040269, 0.71775, 0.3875, 0.47681]
Predicted label: 7
Correct prediction
Energy consumption = 203.265282 pJ
sum error= 193
Actual label: 0
Output voltages: [0.71267, 0.18591, 0.1771, 0.13799, 0.15219, 0.21712, 0.38033, 0.19823, 0.33267, 0.31923]
Predicted label: 0
Correct prediction
Energy consumption = 196.511379 pJ
sum error= 193
Actual label: 3
Output voltages: [0.37521, 0.099228, 0.29222, 0.74753, 0.16652, 0.27928, 0.11059, 0.24099, 0.41954, 0.19561]
Predicted label: 3
Correct prediction
Energy consumption = 189.962012 pJ
sum error= 193
Actual label: 1
Output voltages: [0.17607, 0.76737, 0.2015, 0.24481, 0.18733, 0.1982, 0.4379, 0.080327, 0.28837, 0.24983]
Predicted label: 1
Correct prediction
Energy consumption = 215.322368 pJ
sum error= 193
Actual label: 9
Output voltages: [0.29003, 0.14395, 0.12597, 0.33203, 0.2107, 0.21964, 0.11911, 0.38494, 0.37584, 0.58178]
Predicted label: 9
Correct prediction
Energy consumption = 198.193416 pJ
sum error= 193
Actual label: 3
Output voltages: [0.3015, 0.2124, 0.2314, 0.76404, 0.12737, 0.20871, 0.12157, 0.24491, 0.44433, 0.25494]
Predicted label: 3
Correct prediction
Energy consumption = 177.915229 pJ
sum error= 193
Actual label: 6
Output voltages: [0.32402, 0.051699, 0.15171, 0.28069, 0.19878, 0.63177, 0.55211, 0.11488, 0.47525, 0.19499]
Predicted label: 5
Wrong prediction!
Energy consumption = 195.044912 pJ
sum error= 194
Actual label: 3
Output voltages: [0.31432, 0.21223, 0.34046, 0.75609, 0.18955, 0.14879, 0.19351, 0.18437, 0.38614, 0.24369]
Predicted label: 3
Correct prediction
Energy consumption = 182.092916 pJ
sum error= 194
Actual label: 1
Output voltages: [0.17819, 0.75058, 0.3179, 0.44503, 0.20912, 0.1041, 0.31616, 0.24794, 0.23253, 0.22805]
Predicted label: 1
Correct prediction
Energy consumption = 206.711128 pJ
sum error= 194
Actual label: 7
Output voltages: [0.28923, 0.29741, 0.35192, 0.14879, 0.13134, 0.04916, 0.050397, 0.75509, 0.41922, 0.21768]
Predicted label: 7
Correct prediction
Energy consumption = 196.341468 pJ
sum error= 194
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 454 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 454 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 454 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32785, 0.12418, 0.40242, 0.37923, 0.11214, 0.05782, 0.041089, 0.5379, 0.56467, 0.33778]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.668046 pJ
sum error= 195
Actual label: 3
Output voltages: [0.31329, 0.19118, 0.27863, 0.75398, 0.13281, 0.20472, 0.12054, 0.25503, 0.49244, 0.2145]
Predicted label: 3
Correct prediction
Energy consumption = 174.608647 pJ
sum error= 195
Actual label: 0
Output voltages: [0.73419, 0.25875, 0.22166, 0.17909, 0.17236, 0.18554, 0.42959, 0.14204, 0.26482, 0.26526]
Predicted label: 0
Correct prediction
Energy consumption = 193.830101 pJ
sum error= 195
Actual label: 8
Output voltages: [0.18228, 0.22659, 0.35049, 0.26834, 0.17768, 0.099226, 0.17973, 0.16389, 0.71561, 0.32283]
Predicted label: 8
Correct prediction
Energy consumption = 198.577167 pJ
sum error= 195
Actual label: 4
Output voltages: [0.11249, 0.19634, 0.24145, 0.13646, 0.72664, 0.11714, 0.38483, 0.33021, 0.26522, 0.20786]
Predicted label: 4
Correct prediction
Energy consumption = 197.051276 pJ
sum error= 195
Actual label: 8
Output voltages: [0.21441, 0.27014, 0.30284, 0.35142, 0.092241, 0.17366, 0.18241, 0.18039, 0.74979, 0.30162]
Predicted label: 8
Correct prediction
Energy consumption = 190.780353 pJ
sum error= 195
Actual label: 2
Output voltages: [0.29643, 0.34613, 0.72981, 0.26904, 0.10733, 0.026457, 0.31025, 0.19015, 0.39937, 0.24682]
Predicted label: 2
Correct prediction
Energy consumption = 187.256255 pJ
sum error= 195
Actual label: 6
Output voltages: [0.21808, 0.10085, 0.39711, 0.058451, 0.48077, 0.1927, 0.6165, 0.066923, 0.35272, 0.20504]
Predicted label: 6
Correct prediction
Energy consumption = 185.656314 pJ
sum error= 195
Actual label: 5
Output voltages: [0.35656, 0.13428, 0.11629, 0.36349, 0.15122, 0.71834, 0.44594, 0.20968, 0.38691, 0.13951]
Predicted label: 5
Correct prediction
Energy consumption = 190.480877 pJ
sum error= 195
Actual label: 2
Output voltages: [0.37095, 0.37146, 0.72818, 0.28901, 0.13644, 0.027939, 0.26871, 0.28217, 0.35265, 0.19838]
Predicted label: 2
Correct prediction
Energy consumption = 188.753689 pJ
sum error= 195
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 455 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 455 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 455 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.38472, 0.082501, 0.192, 0.31311, 0.35415, 0.23201, 0.13665, 0.28465, 0.30598, 0.68088]
Predicted label: 9
Correct prediction
Energy consumption = 202.842390 pJ
sum error= 195
Actual label: 7
Output voltages: [0.29482, 0.2001, 0.18552, 0.071568, 0.35409, 0.23886, 0.048091, 0.74724, 0.36618, 0.22592]
Predicted label: 7
Correct prediction
Energy consumption = 204.287258 pJ
sum error= 195
Actual label: 3
Output voltages: [0.45902, 0.098805, 0.18772, 0.7451, 0.13889, 0.31254, 0.12056, 0.2624, 0.43234, 0.22716]
Predicted label: 3
Correct prediction
Energy consumption = 199.129117 pJ
sum error= 195
Actual label: 9
Output voltages: [0.39301, 0.13296, 0.17365, 0.25069, 0.30721, 0.19783, 0.10217, 0.27109, 0.3479, 0.68635]
Predicted label: 9
Correct prediction
Energy consumption = 193.182252 pJ
sum error= 195
Actual label: 0
Output voltages: [0.68342, 0.18043, 0.3623, 0.095425, 0.10149, 0.16413, 0.38358, 0.19537, 0.30645, 0.28761]
Predicted label: 0
Correct prediction
Energy consumption = 189.967468 pJ
sum error= 195
Actual label: 9
Output voltages: [0.29131, 0.078207, 0.20922, 0.34827, 0.37623, 0.17872, 0.079558, 0.29547, 0.30591, 0.64718]
Predicted label: 9
Correct prediction
Energy consumption = 199.954103 pJ
sum error= 195
Actual label: 9
Output voltages: [0.22415, 0.25029, 0.23831, 0.17229, 0.4166, 0.13322, 0.11641, 0.14797, 0.30584, 0.67017]
Predicted label: 9
Correct prediction
Energy consumption = 196.700491 pJ
sum error= 195
Actual label: 6
Output voltages: [0.34076, 0.25634, 0.26851, 0.1242, 0.29146, 0.31098, 0.73796, 0.11365, 0.39297, 0.14085]
Predicted label: 6
Correct prediction
Energy consumption = 192.999770 pJ
sum error= 195
Actual label: 4
Output voltages: [0.22513, 0.1642, 0.26629, 0.058221, 0.70756, 0.10697, 0.5203, 0.17609, 0.30026, 0.21331]
Predicted label: 4
Correct prediction
Energy consumption = 188.916995 pJ
sum error= 195
Actual label: 2
Output voltages: [0.39424, 0.15708, 0.72919, 0.35295, 0.14489, 0.035765, 0.2252, 0.34502, 0.42918, 0.15917]
Predicted label: 2
Correct prediction
Energy consumption = 187.339728 pJ
sum error= 195
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 456 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 456 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 456 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31983, 0.11266, 0.26777, 0.28732, 0.33304, 0.20652, 0.22978, 0.22827, 0.30012, 0.68028]
Predicted label: 9
Correct prediction
Energy consumption = 200.117526 pJ
sum error= 195
Actual label: 7
Output voltages: [0.32804, 0.20562, 0.13449, 0.31107, 0.27944, 0.29078, 0.045449, 0.70725, 0.23827, 0.42109]
Predicted label: 7
Correct prediction
Energy consumption = 203.917077 pJ
sum error= 195
Actual label: 2
Output voltages: [0.37963, 0.092559, 0.69709, 0.38103, 0.16464, 0.043383, 0.21718, 0.2713, 0.51357, 0.18085]
Predicted label: 2
Correct prediction
Energy consumption = 193.928043 pJ
sum error= 195
Actual label: 1
Output voltages: [0.28796, 0.70689, 0.42486, 0.13822, 0.35439, 0.036149, 0.29226, 0.19452, 0.21527, 0.2855]
Predicted label: 1
Correct prediction
Energy consumption = 203.883580 pJ
sum error= 195
Actual label: 1
Output voltages: [0.18402, 0.72853, 0.20425, 0.22774, 0.28924, 0.20493, 0.51448, 0.054098, 0.37062, 0.20922]
Predicted label: 1
Correct prediction
Energy consumption = 204.026927 pJ
sum error= 195
Actual label: 6
Output voltages: [0.31407, 0.20899, 0.13307, 0.2177, 0.30402, 0.45993, 0.67627, 0.1395, 0.49325, 0.069585]
Predicted label: 6
Correct prediction
Energy consumption = 197.306902 pJ
sum error= 195
Actual label: 7
Output voltages: [0.23023, 0.27485, 0.54457, 0.30922, 0.20588, 0.024479, 0.066791, 0.65893, 0.38291, 0.23949]
Predicted label: 7
Correct prediction
Energy consumption = 191.862740 pJ
sum error= 195
Actual label: 4
Output voltages: [0.22678, 0.13327, 0.19058, 0.2574, 0.57868, 0.093654, 0.091182, 0.15602, 0.32356, 0.4511]
Predicted label: 4
Correct prediction
Energy consumption = 199.532886 pJ
sum error= 195
Actual label: 7
Output voltages: [0.38613, 0.30245, 0.40606, 0.15818, 0.1372, 0.044936, 0.05554, 0.65824, 0.30328, 0.37943]
Predicted label: 7
Correct prediction
Energy consumption = 200.717101 pJ
sum error= 195
Actual label: 5
Output voltages: [0.22766, 0.040878, 0.078461, 0.36084, 0.29834, 0.66651, 0.31044, 0.19469, 0.57644, 0.25553]
Predicted label: 5
Correct prediction
Energy consumption = 184.733867 pJ
sum error= 195
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 457 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 457 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 457 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.35119, 0.10758, 0.16805, 0.23659, 0.40135, 0.20692, 0.14528, 0.09092, 0.36162, 0.64328]
Predicted label: 9
Correct prediction
Energy consumption = 189.835641 pJ
sum error= 195
Actual label: 6
Output voltages: [0.42345, 0.161, 0.43925, 0.28909, 0.23799, 0.081522, 0.4663, 0.050225, 0.55167, 0.25628]
Predicted label: 8
Wrong prediction!
Energy consumption = 202.823783 pJ
sum error= 196
Actual label: 8
Output voltages: [0.29381, 0.18417, 0.3205, 0.30423, 0.17267, 0.16276, 0.26963, 0.080819, 0.73234, 0.29041]
Predicted label: 8
Correct prediction
Energy consumption = 191.885209 pJ
sum error= 196
Actual label: 2
Output voltages: [0.46266, 0.36401, 0.73203, 0.2269, 0.082606, 0.030593, 0.23864, 0.40993, 0.32892, 0.22942]
Predicted label: 2
Correct prediction
Energy consumption = 183.850362 pJ
sum error= 196
Actual label: 1
Output voltages: [0.20052, 0.75152, 0.30242, 0.29258, 0.22241, 0.13951, 0.43472, 0.10149, 0.35068, 0.19717]
Predicted label: 1
Correct prediction
Energy consumption = 206.658016 pJ
sum error= 196
Actual label: 4
Output voltages: [0.51459, 0.15304, 0.47005, 0.25617, 0.36966, 0.048154, 0.37153, 0.15344, 0.23079, 0.32033]
Predicted label: 0
Wrong prediction!
Energy consumption = 205.207703 pJ
sum error= 197
Actual label: 4
Output voltages: [0.14493, 0.16934, 0.31779, 0.19574, 0.75773, 0.066808, 0.21583, 0.26896, 0.20283, 0.31668]
Predicted label: 4
Correct prediction
Energy consumption = 197.441527 pJ
sum error= 197
Actual label: 5
Output voltages: [0.34989, 0.16765, 0.05995, 0.31458, 0.14158, 0.75377, 0.29659, 0.24085, 0.53902, 0.086115]
Predicted label: 5
Correct prediction
Energy consumption = 194.710043 pJ
sum error= 197
Actual label: 7
Output voltages: [0.3103, 0.35151, 0.14498, 0.40987, 0.23605, 0.12208, 0.04735, 0.5483, 0.15578, 0.47194]
Predicted label: 7
Correct prediction
Energy consumption = 211.289742 pJ
sum error= 197
Actual label: 6
Output voltages: [0.24166, 0.17739, 0.21508, 0.23045, 0.26494, 0.40961, 0.67922, 0.078691, 0.47784, 0.10064]
Predicted label: 6
Correct prediction
Energy consumption = 196.646925 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 458 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 458 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 458 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23657, 0.75094, 0.18854, 0.18029, 0.3493, 0.10824, 0.39467, 0.10872, 0.28848, 0.22105]
Predicted label: 1
Correct prediction
Energy consumption = 208.496228 pJ
sum error= 197
Actual label: 3
Output voltages: [0.38234, 0.15655, 0.34259, 0.7542, 0.20652, 0.21606, 0.17121, 0.1445, 0.43408, 0.20867]
Predicted label: 3
Correct prediction
Energy consumption = 190.515121 pJ
sum error= 197
Actual label: 2
Output voltages: [0.24591, 0.35455, 0.66475, 0.3206, 0.21971, 0.032548, 0.28344, 0.20216, 0.40285, 0.22283]
Predicted label: 2
Correct prediction
Energy consumption = 194.956720 pJ
sum error= 197
Actual label: 5
Output voltages: [0.36632, 0.057501, 0.11066, 0.22687, 0.21557, 0.73666, 0.28347, 0.24391, 0.49787, 0.17214]
Predicted label: 5
Correct prediction
Energy consumption = 193.599651 pJ
sum error= 197
Actual label: 9
Output voltages: [0.36958, 0.18734, 0.18257, 0.19744, 0.30476, 0.15871, 0.24016, 0.23944, 0.3082, 0.65709]
Predicted label: 9
Correct prediction
Energy consumption = 194.644398 pJ
sum error= 197
Actual label: 9
Output voltages: [0.32367, 0.17561, 0.18035, 0.38644, 0.36688, 0.21544, 0.25185, 0.26207, 0.22194, 0.63901]
Predicted label: 9
Correct prediction
Energy consumption = 191.880873 pJ
sum error= 197
Actual label: 3
Output voltages: [0.3838, 0.16865, 0.27617, 0.75353, 0.13485, 0.23234, 0.1162, 0.19964, 0.43409, 0.2819]
Predicted label: 3
Correct prediction
Energy consumption = 191.968874 pJ
sum error= 197
Actual label: 6
Output voltages: [0.27662, 0.14761, 0.2559, 0.12775, 0.35924, 0.41939, 0.71618, 0.048972, 0.42367, 0.16038]
Predicted label: 6
Correct prediction
Energy consumption = 188.020278 pJ
sum error= 197
Actual label: 1
Output voltages: [0.11945, 0.75198, 0.28364, 0.43341, 0.1602, 0.11858, 0.25838, 0.26618, 0.29917, 0.17144]
Predicted label: 1
Correct prediction
Energy consumption = 214.163573 pJ
sum error= 197
Actual label: 1
Output voltages: [0.23199, 0.75593, 0.18785, 0.18055, 0.35495, 0.12768, 0.41695, 0.15327, 0.23582, 0.25708]
Predicted label: 1
Correct prediction
Energy consumption = 199.406174 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 459 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 459 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 459 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15363, 0.19098, 0.2497, 0.18248, 0.75481, 0.0803, 0.2685, 0.25109, 0.20372, 0.25632]
Predicted label: 4
Correct prediction
Energy consumption = 207.160223 pJ
sum error= 197
Actual label: 6
Output voltages: [0.28223, 0.16521, 0.30627, 0.071723, 0.41557, 0.3209, 0.74229, 0.051575, 0.36137, 0.14049]
Predicted label: 6
Correct prediction
Energy consumption = 186.721780 pJ
sum error= 197
Actual label: 9
Output voltages: [0.40286, 0.10491, 0.20632, 0.26055, 0.42502, 0.20612, 0.16708, 0.19683, 0.28128, 0.69842]
Predicted label: 9
Correct prediction
Energy consumption = 191.159079 pJ
sum error= 197
Actual label: 7
Output voltages: [0.34387, 0.25192, 0.23699, 0.41851, 0.091262, 0.10273, 0.04679, 0.73406, 0.23363, 0.3633]
Predicted label: 7
Correct prediction
Energy consumption = 203.014584 pJ
sum error= 197
Actual label: 2
Output voltages: [0.44071, 0.37289, 0.72133, 0.29782, 0.084121, 0.028813, 0.23251, 0.3456, 0.29665, 0.289]
Predicted label: 2
Correct prediction
Energy consumption = 185.550387 pJ
sum error= 197
Actual label: 1
Output voltages: [0.14356, 0.7522, 0.21188, 0.32583, 0.25842, 0.061724, 0.27159, 0.14358, 0.39854, 0.24152]
Predicted label: 1
Correct prediction
Energy consumption = 203.385248 pJ
sum error= 197
Actual label: 5
Output voltages: [0.23453, 0.05446, 0.12734, 0.35684, 0.22407, 0.70337, 0.20516, 0.16461, 0.54215, 0.25073]
Predicted label: 5
Correct prediction
Energy consumption = 185.637015 pJ
sum error= 197
Actual label: 1
Output voltages: [0.23632, 0.75273, 0.24229, 0.26906, 0.32158, 0.07677, 0.31183, 0.15922, 0.27336, 0.22339]
Predicted label: 1
Correct prediction
Energy consumption = 210.773875 pJ
sum error= 197
Actual label: 4
Output voltages: [0.24819, 0.21762, 0.30313, 0.18641, 0.72698, 0.10937, 0.30128, 0.28925, 0.12319, 0.4402]
Predicted label: 4
Correct prediction
Energy consumption = 202.118445 pJ
sum error= 197
Actual label: 6
Output voltages: [0.35238, 0.29763, 0.23252, 0.22619, 0.32053, 0.44094, 0.73058, 0.072794, 0.40349, 0.076927]
Predicted label: 6
Correct prediction
Energy consumption = 195.402250 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 460 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 460 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 460 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36695, 0.20449, 0.29919, 0.76791, 0.16046, 0.17811, 0.12036, 0.23262, 0.40284, 0.26035]
Predicted label: 3
Correct prediction
Energy consumption = 181.900069 pJ
sum error= 197
Actual label: 8
Output voltages: [0.12087, 0.28237, 0.1964, 0.3604, 0.36472, 0.15796, 0.2124, 0.23627, 0.60663, 0.1482]
Predicted label: 8
Correct prediction
Energy consumption = 195.479452 pJ
sum error= 197
Actual label: 1
Output voltages: [0.20493, 0.75176, 0.29113, 0.23722, 0.29004, 0.085383, 0.3927, 0.1759, 0.27052, 0.21851]
Predicted label: 1
Correct prediction
Energy consumption = 208.339734 pJ
sum error= 197
Actual label: 1
Output voltages: [0.23297, 0.76918, 0.23467, 0.41141, 0.21145, 0.21391, 0.30411, 0.26887, 0.18939, 0.24268]
Predicted label: 1
Correct prediction
Energy consumption = 211.978654 pJ
sum error= 197
Actual label: 0
Output voltages: [0.64085, 0.11521, 0.23794, 0.10955, 0.17957, 0.21509, 0.50072, 0.23405, 0.30327, 0.23353]
Predicted label: 0
Correct prediction
Energy consumption = 195.428078 pJ
sum error= 197
Actual label: 3
Output voltages: [0.34889, 0.2285, 0.25085, 0.75403, 0.13051, 0.18577, 0.14447, 0.13731, 0.49751, 0.24647]
Predicted label: 3
Correct prediction
Energy consumption = 192.163693 pJ
sum error= 197
Actual label: 1
Output voltages: [0.23358, 0.75115, 0.27339, 0.24673, 0.34532, 0.090495, 0.32575, 0.22041, 0.24361, 0.19861]
Predicted label: 1
Correct prediction
Energy consumption = 204.095655 pJ
sum error= 197
Actual label: 6
Output voltages: [0.30804, 0.25093, 0.23233, 0.19046, 0.31009, 0.34511, 0.74135, 0.12074, 0.4324, 0.098378]
Predicted label: 6
Correct prediction
Energy consumption = 195.367794 pJ
sum error= 197
Actual label: 8
Output voltages: [0.35848, 0.097235, 0.29738, 0.37968, 0.19194, 0.15796, 0.30238, 0.052834, 0.67008, 0.23342]
Predicted label: 8
Correct prediction
Energy consumption = 193.896539 pJ
sum error= 197
Actual label: 4
Output voltages: [0.10898, 0.14816, 0.24866, 0.21218, 0.73224, 0.08644, 0.23153, 0.22385, 0.28467, 0.23463]
Predicted label: 4
Correct prediction
Energy consumption = 192.372390 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 461 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 461 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 461 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3, 0.099499, 0.22122, 0.30767, 0.32783, 0.14515, 0.087416, 0.32425, 0.34978, 0.63416]
Predicted label: 9
Correct prediction
Energy consumption = 191.789805 pJ
sum error= 197
Actual label: 0
Output voltages: [0.74186, 0.22778, 0.27131, 0.15337, 0.16708, 0.1785, 0.40949, 0.21636, 0.26692, 0.24251]
Predicted label: 0
Correct prediction
Energy consumption = 189.818150 pJ
sum error= 197
Actual label: 7
Output voltages: [0.28636, 0.24134, 0.2158, 0.23654, 0.15973, 0.08784, 0.036363, 0.74725, 0.43268, 0.3568]
Predicted label: 7
Correct prediction
Energy consumption = 193.485983 pJ
sum error= 197
Actual label: 3
Output voltages: [0.42014, 0.13251, 0.27192, 0.75244, 0.15927, 0.33369, 0.086552, 0.22552, 0.4238, 0.27845]
Predicted label: 3
Correct prediction
Energy consumption = 189.821575 pJ
sum error= 197
Actual label: 0
Output voltages: [0.69532, 0.075017, 0.21756, 0.20904, 0.1197, 0.27349, 0.36457, 0.20248, 0.34252, 0.30916]
Predicted label: 0
Correct prediction
Energy consumption = 185.315475 pJ
sum error= 197
Actual label: 2
Output voltages: [0.39265, 0.16453, 0.5188, 0.22182, 0.57143, 0.036279, 0.31878, 0.16373, 0.33013, 0.2177]
Predicted label: 4
Wrong prediction!
Energy consumption = 190.591817 pJ
sum error= 198
Actual label: 9
Output voltages: [0.39218, 0.1054, 0.18507, 0.32837, 0.27733, 0.30264, 0.1555, 0.32063, 0.34833, 0.6822]
Predicted label: 9
Correct prediction
Energy consumption = 195.364695 pJ
sum error= 198
Actual label: 0
Output voltages: [0.71565, 0.15015, 0.25354, 0.25426, 0.10541, 0.24572, 0.41932, 0.18244, 0.29387, 0.28785]
Predicted label: 0
Correct prediction
Energy consumption = 184.730981 pJ
sum error= 198
Actual label: 6
Output voltages: [0.28197, 0.23818, 0.32236, 0.060685, 0.28128, 0.32043, 0.7253, 0.072896, 0.41505, 0.11133]
Predicted label: 6
Correct prediction
Energy consumption = 185.899870 pJ
sum error= 198
Actual label: 6
Output voltages: [0.29518, 0.17689, 0.1847, 0.25762, 0.30177, 0.32258, 0.61072, 0.07546, 0.56725, 0.19161]
Predicted label: 6
Correct prediction
Energy consumption = 192.939304 pJ
sum error= 198
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 462 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 462 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 462 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.37562, 0.15377, 0.31808, 0.07204, 0.3556, 0.28792, 0.68697, 0.1181, 0.42201, 0.060201]
Predicted label: 6
Correct prediction
Energy consumption = 182.974100 pJ
sum error= 198
Actual label: 3
Output voltages: [0.36622, 0.14175, 0.33097, 0.74785, 0.25062, 0.32952, 0.20015, 0.18465, 0.36309, 0.1599]
Predicted label: 3
Correct prediction
Energy consumption = 187.468985 pJ
sum error= 198
Actual label: 6
Output voltages: [0.37644, 0.18389, 0.20501, 0.18381, 0.30556, 0.40799, 0.7227, 0.06127, 0.34295, 0.2291]
Predicted label: 6
Correct prediction
Energy consumption = 192.326527 pJ
sum error= 198
Actual label: 7
Output voltages: [0.38571, 0.268, 0.15138, 0.2908, 0.16033, 0.19757, 0.043903, 0.75408, 0.28854, 0.35578]
Predicted label: 7
Correct prediction
Energy consumption = 202.048035 pJ
sum error= 198
Actual label: 7
Output voltages: [0.346, 0.30054, 0.33572, 0.37566, 0.11791, 0.047027, 0.057484, 0.74094, 0.23182, 0.35784]
Predicted label: 7
Correct prediction
Energy consumption = 192.713350 pJ
sum error= 198
Actual label: 2
Output voltages: [0.27254, 0.34712, 0.66449, 0.39244, 0.11545, 0.02855, 0.23577, 0.24152, 0.42685, 0.18111]
Predicted label: 2
Correct prediction
Energy consumption = 184.931122 pJ
sum error= 198
Actual label: 8
Output voltages: [0.2057, 0.19802, 0.36043, 0.25322, 0.23678, 0.15822, 0.20002, 0.099809, 0.71955, 0.26588]
Predicted label: 8
Correct prediction
Energy consumption = 195.356830 pJ
sum error= 198
Actual label: 6
Output voltages: [0.23484, 0.20851, 0.39074, 0.05151, 0.38874, 0.26867, 0.7335, 0.049578, 0.33294, 0.13849]
Predicted label: 6
Correct prediction
Energy consumption = 185.144723 pJ
sum error= 198
Actual label: 0
Output voltages: [0.7211, 0.28414, 0.2027, 0.12727, 0.13588, 0.26053, 0.40766, 0.13707, 0.27943, 0.27736]
Predicted label: 0
Correct prediction
Energy consumption = 193.417713 pJ
sum error= 198
Actual label: 8
Output voltages: [0.19225, 0.20918, 0.33392, 0.1869, 0.15371, 0.16063, 0.18952, 0.16025, 0.74542, 0.33539]
Predicted label: 8
Correct prediction
Energy consumption = 184.592799 pJ
sum error= 198
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 463 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 463 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 463 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30774, 0.19194, 0.2587, 0.75312, 0.20962, 0.27819, 0.19413, 0.14765, 0.38768, 0.21029]
Predicted label: 3
Correct prediction
Energy consumption = 195.924428 pJ
sum error= 198
Actual label: 0
Output voltages: [0.73151, 0.21082, 0.28174, 0.1368, 0.18714, 0.16702, 0.41024, 0.18341, 0.25998, 0.27833]
Predicted label: 0
Correct prediction
Energy consumption = 194.537032 pJ
sum error= 198
Actual label: 2
Output voltages: [0.36373, 0.19628, 0.69113, 0.40324, 0.23147, 0.040538, 0.22796, 0.26567, 0.42808, 0.18907]
Predicted label: 2
Correct prediction
Energy consumption = 194.767999 pJ
sum error= 198
Actual label: 9
Output voltages: [0.39049, 0.095177, 0.22954, 0.31356, 0.31273, 0.1567, 0.099526, 0.3301, 0.35675, 0.59682]
Predicted label: 9
Correct prediction
Energy consumption = 198.243517 pJ
sum error= 198
Actual label: 8
Output voltages: [0.18338, 0.19795, 0.23237, 0.34933, 0.13045, 0.34471, 0.18206, 0.076754, 0.73153, 0.29061]
Predicted label: 8
Correct prediction
Energy consumption = 196.182816 pJ
sum error= 198
Actual label: 3
Output voltages: [0.41062, 0.21326, 0.24924, 0.75873, 0.079739, 0.27812, 0.23686, 0.21843, 0.35703, 0.14328]
Predicted label: 3
Correct prediction
Energy consumption = 193.349412 pJ
sum error= 198
Actual label: 2
Output voltages: [0.31904, 0.31451, 0.75432, 0.27482, 0.16495, 0.035763, 0.28775, 0.25208, 0.38859, 0.23409]
Predicted label: 2
Correct prediction
Energy consumption = 178.758442 pJ
sum error= 198
Actual label: 5
Output voltages: [0.24686, 0.066477, 0.18075, 0.31171, 0.14486, 0.66359, 0.26866, 0.14505, 0.57025, 0.25524]
Predicted label: 5
Correct prediction
Energy consumption = 183.029038 pJ
sum error= 198
Actual label: 3
Output voltages: [0.33204, 0.088539, 0.21934, 0.7237, 0.21668, 0.42848, 0.19277, 0.24537, 0.4158, 0.10776]
Predicted label: 3
Correct prediction
Energy consumption = 183.316422 pJ
sum error= 198
Actual label: 8
Output voltages: [0.28631, 0.089667, 0.19152, 0.15755, 0.31936, 0.21546, 0.071076, 0.24867, 0.48294, 0.56549]
Predicted label: 9
Wrong prediction!
Energy consumption = 201.536462 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 464 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 464 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 464 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.22677, 0.21664, 0.31114, 0.36042, 0.096601, 0.16795, 0.19105, 0.22198, 0.73735, 0.23729]
Predicted label: 8
Correct prediction
Energy consumption = 201.255966 pJ
sum error= 199
Actual label: 0
Output voltages: [0.75191, 0.26233, 0.19393, 0.21273, 0.1474, 0.24896, 0.40306, 0.16769, 0.31542, 0.24254]
Predicted label: 0
Correct prediction
Energy consumption = 205.573642 pJ
sum error= 199
Actual label: 0
Output voltages: [0.70793, 0.21694, 0.18797, 0.19133, 0.17398, 0.25502, 0.44711, 0.15908, 0.32611, 0.27523]
Predicted label: 0
Correct prediction
Energy consumption = 193.491740 pJ
sum error= 199
Actual label: 1
Output voltages: [0.29995, 0.72935, 0.17788, 0.36415, 0.22183, 0.06428, 0.17683, 0.13292, 0.36831, 0.35493]
Predicted label: 1
Correct prediction
Energy consumption = 206.561417 pJ
sum error= 199
Actual label: 9
Output voltages: [0.31342, 0.13837, 0.18469, 0.27037, 0.32232, 0.17999, 0.074883, 0.21459, 0.40201, 0.67641]
Predicted label: 9
Correct prediction
Energy consumption = 184.374264 pJ
sum error= 199
Actual label: 5
Output voltages: [0.20121, 0.064572, 0.14416, 0.23083, 0.21479, 0.61358, 0.31304, 0.1008, 0.5978, 0.26193]
Predicted label: 5
Correct prediction
Energy consumption = 182.596158 pJ
sum error= 199
Actual label: 1
Output voltages: [0.25248, 0.76445, 0.11002, 0.32735, 0.21588, 0.13693, 0.27807, 0.16753, 0.31765, 0.28848]
Predicted label: 1
Correct prediction
Energy consumption = 215.594530 pJ
sum error= 199
Actual label: 3
Output voltages: [0.2678, 0.21883, 0.26351, 0.76522, 0.2064, 0.18542, 0.15271, 0.35888, 0.35042, 0.26104]
Predicted label: 3
Correct prediction
Energy consumption = 192.096902 pJ
sum error= 199
Actual label: 9
Output voltages: [0.34049, 0.14729, 0.22929, 0.22821, 0.2602, 0.15496, 0.067927, 0.22214, 0.40867, 0.67816]
Predicted label: 9
Correct prediction
Energy consumption = 185.636560 pJ
sum error= 199
Actual label: 6
Output voltages: [0.32538, 0.21784, 0.25178, 0.13852, 0.29748, 0.39076, 0.73387, 0.13226, 0.44108, 0.14599]
Predicted label: 6
Correct prediction
Energy consumption = 188.870225 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 465 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 465 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 465 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.68907, 0.20633, 0.3377, 0.16954, 0.074979, 0.17838, 0.42428, 0.13795, 0.34434, 0.25185]
Predicted label: 0
Correct prediction
Energy consumption = 188.919395 pJ
sum error= 199
Actual label: 1
Output voltages: [0.18189, 0.76865, 0.29365, 0.31778, 0.19377, 0.10559, 0.41668, 0.20147, 0.27041, 0.22076]
Predicted label: 1
Correct prediction
Energy consumption = 214.742453 pJ
sum error= 199
Actual label: 4
Output voltages: [0.16593, 0.14226, 0.29903, 0.12958, 0.76034, 0.13596, 0.24046, 0.29928, 0.24988, 0.34629]
Predicted label: 4
Correct prediction
Energy consumption = 195.631022 pJ
sum error= 199
Actual label: 1
Output voltages: [0.17489, 0.76421, 0.21376, 0.21355, 0.19079, 0.18096, 0.42167, 0.20612, 0.36877, 0.14163]
Predicted label: 1
Correct prediction
Energy consumption = 215.218641 pJ
sum error= 199
Actual label: 7
Output voltages: [0.27745, 0.15062, 0.29095, 0.29307, 0.29285, 0.051965, 0.067254, 0.75632, 0.26935, 0.2629]
Predicted label: 7
Correct prediction
Energy consumption = 190.472918 pJ
sum error= 199
Actual label: 1
Output voltages: [0.21932, 0.75807, 0.12732, 0.29702, 0.28307, 0.2282, 0.33676, 0.1128, 0.28812, 0.24849]
Predicted label: 1
Correct prediction
Energy consumption = 211.188823 pJ
sum error= 199
Actual label: 2
Output voltages: [0.25194, 0.18063, 0.73291, 0.31283, 0.17405, 0.035227, 0.16941, 0.40153, 0.38196, 0.19442]
Predicted label: 2
Correct prediction
Energy consumption = 185.220619 pJ
sum error= 199
Actual label: 3
Output voltages: [0.24886, 0.32816, 0.44577, 0.70493, 0.075634, 0.060171, 0.10181, 0.2272, 0.36268, 0.21664]
Predicted label: 3
Correct prediction
Energy consumption = 181.063242 pJ
sum error= 199
Actual label: 7
Output voltages: [0.25025, 0.20125, 0.52754, 0.33254, 0.17445, 0.035537, 0.11424, 0.60918, 0.45873, 0.18318]
Predicted label: 7
Correct prediction
Energy consumption = 189.944050 pJ
sum error= 199
Actual label: 9
Output voltages: [0.31577, 0.07042, 0.29942, 0.31216, 0.33097, 0.17378, 0.11996, 0.28697, 0.27996, 0.70297]
Predicted label: 9
Correct prediction
Energy consumption = 195.654744 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 466 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 466 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 466 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30338, 0.15094, 0.29503, 0.38088, 0.22781, 0.060246, 0.043339, 0.70942, 0.2885, 0.34929]
Predicted label: 7
Correct prediction
Energy consumption = 197.627744 pJ
sum error= 199
Actual label: 4
Output voltages: [0.17646, 0.16793, 0.36575, 0.18082, 0.75651, 0.060603, 0.2785, 0.32464, 0.19045, 0.29767]
Predicted label: 4
Correct prediction
Energy consumption = 197.864609 pJ
sum error= 199
Actual label: 9
Output voltages: [0.35619, 0.065797, 0.20993, 0.28049, 0.3046, 0.18533, 0.067009, 0.39732, 0.38141, 0.62111]
Predicted label: 9
Correct prediction
Energy consumption = 190.951244 pJ
sum error= 199
Actual label: 9
Output voltages: [0.36331, 0.096768, 0.17306, 0.33414, 0.38252, 0.22567, 0.13557, 0.27458, 0.31485, 0.6426]
Predicted label: 9
Correct prediction
Energy consumption = 194.078907 pJ
sum error= 199
Actual label: 3
Output voltages: [0.29093, 0.16536, 0.28178, 0.75435, 0.26238, 0.33175, 0.16653, 0.16909, 0.38607, 0.24603]
Predicted label: 3
Correct prediction
Energy consumption = 190.005158 pJ
sum error= 199
Actual label: 9
Output voltages: [0.25624, 0.16179, 0.31509, 0.35169, 0.30702, 0.19015, 0.11836, 0.13705, 0.35339, 0.58188]
Predicted label: 9
Correct prediction
Energy consumption = 198.309150 pJ
sum error= 199
Actual label: 2
Output voltages: [0.30093, 0.36747, 0.7262, 0.33771, 0.12805, 0.032254, 0.28417, 0.17702, 0.43889, 0.25016]
Predicted label: 2
Correct prediction
Energy consumption = 189.221247 pJ
sum error= 199
Actual label: 8
Output voltages: [0.25905, 0.16758, 0.33384, 0.33867, 0.12243, 0.25136, 0.20247, 0.096325, 0.75038, 0.29004]
Predicted label: 8
Correct prediction
Energy consumption = 186.544360 pJ
sum error= 199
Actual label: 2
Output voltages: [0.24659, 0.34705, 0.6231, 0.411, 0.27782, 0.038175, 0.24856, 0.13707, 0.34913, 0.1669]
Predicted label: 2
Correct prediction
Energy consumption = 196.421804 pJ
sum error= 199
Actual label: 7
Output voltages: [0.2773, 0.23885, 0.17839, 0.25093, 0.18927, 0.15975, 0.047881, 0.75717, 0.35524, 0.3956]
Predicted label: 7
Correct prediction
Energy consumption = 199.326466 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 467 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 467 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 467 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.24427, 0.75565, 0.32204, 0.2684, 0.30637, 0.046995, 0.33901, 0.11309, 0.23902, 0.2376]
Predicted label: 1
Correct prediction
Energy consumption = 210.471990 pJ
sum error= 199
Actual label: 8
Output voltages: [0.33312, 0.126, 0.27275, 0.49513, 0.14074, 0.24817, 0.27747, 0.078765, 0.69301, 0.35236]
Predicted label: 8
Correct prediction
Energy consumption = 201.727284 pJ
sum error= 199
Actual label: 0
Output voltages: [0.7025, 0.26187, 0.20363, 0.16682, 0.17117, 0.22558, 0.45268, 0.23177, 0.26961, 0.2258]
Predicted label: 0
Correct prediction
Energy consumption = 204.377755 pJ
sum error= 199
Actual label: 9
Output voltages: [0.34293, 0.14851, 0.16449, 0.23168, 0.35415, 0.23362, 0.20023, 0.11175, 0.37127, 0.6438]
Predicted label: 9
Correct prediction
Energy consumption = 191.185889 pJ
sum error= 199
Actual label: 1
Output voltages: [0.16319, 0.74011, 0.2743, 0.17776, 0.23516, 0.17471, 0.55257, 0.10121, 0.35599, 0.17]
Predicted label: 1
Correct prediction
Energy consumption = 202.272140 pJ
sum error= 199
Actual label: 0
Output voltages: [0.72915, 0.25307, 0.1919, 0.19769, 0.13519, 0.22173, 0.40615, 0.17897, 0.31584, 0.33006]
Predicted label: 0
Correct prediction
Energy consumption = 199.420965 pJ
sum error= 199
Actual label: 1
Output voltages: [0.22253, 0.75887, 0.2109, 0.24435, 0.13099, 0.22322, 0.48931, 0.082075, 0.33539, 0.20448]
Predicted label: 1
Correct prediction
Energy consumption = 213.081783 pJ
sum error= 199
Actual label: 7
Output voltages: [0.25864, 0.34167, 0.39059, 0.29568, 0.12497, 0.037361, 0.043358, 0.73499, 0.38568, 0.26548]
Predicted label: 7
Correct prediction
Energy consumption = 201.847634 pJ
sum error= 199
Actual label: 7
Output voltages: [0.32897, 0.22719, 0.18954, 0.36534, 0.1667, 0.10814, 0.039201, 0.75621, 0.29449, 0.37932]
Predicted label: 7
Correct prediction
Energy consumption = 194.078029 pJ
sum error= 199
Actual label: 9
Output voltages: [0.36326, 0.15088, 0.10804, 0.34682, 0.28536, 0.30722, 0.10445, 0.33147, 0.34113, 0.65789]
Predicted label: 9
Correct prediction
Energy consumption = 182.529318 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 468 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 468 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 468 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.25479, 0.22815, 0.31167, 0.10465, 0.35774, 0.37298, 0.7436, 0.095726, 0.34125, 0.15641]
Predicted label: 6
Correct prediction
Energy consumption = 186.339841 pJ
sum error= 199
Actual label: 9
Output voltages: [0.37204, 0.067042, 0.28445, 0.15541, 0.45575, 0.10507, 0.26204, 0.2467, 0.22007, 0.59623]
Predicted label: 9
Correct prediction
Energy consumption = 205.360629 pJ
sum error= 199
Actual label: 9
Output voltages: [0.3478, 0.14189, 0.21233, 0.25321, 0.26658, 0.16025, 0.095585, 0.30191, 0.35625, 0.71555]
Predicted label: 9
Correct prediction
Energy consumption = 197.514116 pJ
sum error= 199
Actual label: 9
Output voltages: [0.367, 0.077341, 0.21958, 0.23644, 0.30552, 0.1562, 0.086585, 0.34507, 0.42357, 0.62467]
Predicted label: 9
Correct prediction
Energy consumption = 187.213187 pJ
sum error= 199
Actual label: 2
Output voltages: [0.32276, 0.22321, 0.72036, 0.30235, 0.11078, 0.037906, 0.24646, 0.31895, 0.50098, 0.21192]
Predicted label: 2
Correct prediction
Energy consumption = 189.474860 pJ
sum error= 199
Actual label: 1
Output voltages: [0.081327, 0.74592, 0.35328, 0.38342, 0.29457, 0.082996, 0.24648, 0.24057, 0.23798, 0.25723]
Predicted label: 1
Correct prediction
Energy consumption = 209.123588 pJ
sum error= 199
Actual label: 6
Output voltages: [0.39909, 0.30179, 0.28814, 0.0991, 0.21963, 0.23799, 0.70617, 0.060414, 0.32203, 0.20816]
Predicted label: 6
Correct prediction
Energy consumption = 196.829104 pJ
sum error= 199
Actual label: 1
Output voltages: [0.18134, 0.75797, 0.28828, 0.24524, 0.23045, 0.063213, 0.4093, 0.10321, 0.3037, 0.23392]
Predicted label: 1
Correct prediction
Energy consumption = 209.622692 pJ
sum error= 199
Actual label: 3
Output voltages: [0.22447, 0.13682, 0.26635, 0.74163, 0.19565, 0.16271, 0.18831, 0.16618, 0.52076, 0.23263]
Predicted label: 3
Correct prediction
Energy consumption = 185.915947 pJ
sum error= 199
Actual label: 5
Output voltages: [0.20492, 0.050654, 0.10016, 0.29361, 0.32432, 0.71338, 0.36993, 0.11149, 0.49842, 0.23988]
Predicted label: 5
Correct prediction
Energy consumption = 181.910424 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 469 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 469 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 469 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.39759, 0.095188, 0.48535, 0.41871, 0.19706, 0.054535, 0.10356, 0.39477, 0.33411, 0.2961]
Predicted label: 2
Wrong prediction!
Energy consumption = 201.086355 pJ
sum error= 200
Actual label: 1
Output voltages: [0.21061, 0.75422, 0.26612, 0.24375, 0.23401, 0.058922, 0.41672, 0.084576, 0.29341, 0.2129]
Predicted label: 1
Correct prediction
Energy consumption = 212.753332 pJ
sum error= 200
Actual label: 9
Output voltages: [0.47004, 0.12846, 0.14057, 0.34649, 0.33889, 0.21276, 0.11452, 0.19582, 0.27287, 0.68442]
Predicted label: 9
Correct prediction
Energy consumption = 199.557282 pJ
sum error= 200
Actual label: 7
Output voltages: [0.34804, 0.17325, 0.11911, 0.27747, 0.32931, 0.27794, 0.054492, 0.7016, 0.21188, 0.5199]
Predicted label: 7
Correct prediction
Energy consumption = 198.041134 pJ
sum error= 200
Actual label: 6
Output voltages: [0.25938, 0.19276, 0.28773, 0.073851, 0.31774, 0.35468, 0.73963, 0.065063, 0.37331, 0.13254]
Predicted label: 6
Correct prediction
Energy consumption = 189.784904 pJ
sum error= 200
Actual label: 4
Output voltages: [0.11528, 0.1938, 0.21669, 0.16253, 0.73477, 0.084063, 0.20816, 0.24313, 0.30186, 0.24076]
Predicted label: 4
Correct prediction
Energy consumption = 198.135581 pJ
sum error= 200
Actual label: 5
Output voltages: [0.24699, 0.12576, 0.13919, 0.47511, 0.10686, 0.72041, 0.26175, 0.24425, 0.44317, 0.21592]
Predicted label: 5
Correct prediction
Energy consumption = 191.124158 pJ
sum error= 200
Actual label: 7
Output voltages: [0.37678, 0.21758, 0.30425, 0.27972, 0.14393, 0.045931, 0.048979, 0.75137, 0.36979, 0.27567]
Predicted label: 7
Correct prediction
Energy consumption = 197.870448 pJ
sum error= 200
Actual label: 6
Output voltages: [0.30294, 0.20541, 0.30735, 0.082835, 0.3192, 0.30753, 0.73604, 0.09512, 0.38882, 0.15252]
Predicted label: 6
Correct prediction
Energy consumption = 193.219555 pJ
sum error= 200
Actual label: 6
Output voltages: [0.33266, 0.36641, 0.1837, 0.18067, 0.24522, 0.38556, 0.68221, 0.12457, 0.4547, 0.091788]
Predicted label: 6
Correct prediction
Energy consumption = 195.306698 pJ
sum error= 200
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 470 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 470 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 470 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3286, 0.16908, 0.22955, 0.27402, 0.33247, 0.17295, 0.081386, 0.20629, 0.30383, 0.70557]
Predicted label: 9
Correct prediction
Energy consumption = 202.223914 pJ
sum error= 200
Actual label: 9
Output voltages: [0.36259, 0.072338, 0.15887, 0.29787, 0.26312, 0.22126, 0.054833, 0.34003, 0.4239, 0.64178]
Predicted label: 9
Correct prediction
Energy consumption = 191.409447 pJ
sum error= 200
Actual label: 6
Output voltages: [0.25176, 0.14568, 0.26126, 0.18253, 0.2264, 0.4454, 0.63953, 0.047448, 0.4669, 0.17836]
Predicted label: 6
Correct prediction
Energy consumption = 195.489122 pJ
sum error= 200
Actual label: 3
Output voltages: [0.3803, 0.20779, 0.22819, 0.73792, 0.16903, 0.3363, 0.28176, 0.26842, 0.33092, 0.075976]
Predicted label: 3
Correct prediction
Energy consumption = 190.779147 pJ
sum error= 200
Actual label: 6
Output voltages: [0.33469, 0.25968, 0.21259, 0.21835, 0.31644, 0.34526, 0.73538, 0.095786, 0.42982, 0.12868]
Predicted label: 6
Correct prediction
Energy consumption = 191.819132 pJ
sum error= 200
Actual label: 2
Output voltages: [0.35035, 0.33517, 0.73676, 0.30971, 0.17338, 0.028646, 0.31849, 0.19712, 0.42283, 0.25053]
Predicted label: 2
Correct prediction
Energy consumption = 184.466008 pJ
sum error= 200
Actual label: 9
Output voltages: [0.28099, 0.13802, 0.22261, 0.17901, 0.49636, 0.1275, 0.092649, 0.30338, 0.31901, 0.54767]
Predicted label: 9
Correct prediction
Energy consumption = 191.585368 pJ
sum error= 200
Actual label: 8
Output voltages: [0.19593, 0.2232, 0.32521, 0.27261, 0.17794, 0.14902, 0.17809, 0.14367, 0.73646, 0.31381]
Predicted label: 8
Correct prediction
Energy consumption = 196.385049 pJ
sum error= 200
Actual label: 1
Output voltages: [0.13629, 0.76592, 0.22238, 0.24673, 0.24966, 0.15584, 0.44908, 0.15918, 0.29838, 0.18459]
Predicted label: 1
Correct prediction
Energy consumption = 212.215983 pJ
sum error= 200
Actual label: 2
Output voltages: [0.43985, 0.18724, 0.70453, 0.30172, 0.16824, 0.0596, 0.3509, 0.29243, 0.51849, 0.10087]
Predicted label: 2
Correct prediction
Energy consumption = 185.359013 pJ
sum error= 200
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 471 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 471 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 471 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.28985, 0.29902, 0.68007, 0.43509, 0.071451, 0.03845, 0.23732, 0.16544, 0.45243, 0.16581]
Predicted label: 2
Correct prediction
Energy consumption = 189.520551 pJ
sum error= 200
Actual label: 5
Output voltages: [0.23309, 0.10677, 0.20594, 0.28359, 0.10386, 0.58067, 0.21332, 0.059306, 0.62517, 0.26135]
Predicted label: 8
Wrong prediction!
Energy consumption = 194.889162 pJ
sum error= 201
Actual label: 5
Output voltages: [0.27309, 0.057418, 0.094619, 0.29807, 0.20909, 0.66556, 0.1924, 0.24218, 0.48546, 0.3531]
Predicted label: 5
Correct prediction
Energy consumption = 188.028522 pJ
sum error= 201
Actual label: 2
Output voltages: [0.35267, 0.14069, 0.66557, 0.45324, 0.14187, 0.072547, 0.35653, 0.18557, 0.4847, 0.079303]
Predicted label: 2
Correct prediction
Energy consumption = 184.066616 pJ
sum error= 201
Actual label: 3
Output voltages: [0.46994, 0.21163, 0.20044, 0.75569, 0.086456, 0.32635, 0.15756, 0.25222, 0.35077, 0.1805]
Predicted label: 3
Correct prediction
Energy consumption = 188.053380 pJ
sum error= 201
Actual label: 7
Output voltages: [0.3182, 0.24724, 0.2517, 0.34431, 0.11484, 0.11156, 0.050585, 0.75885, 0.31107, 0.3606]
Predicted label: 7
Correct prediction
Energy consumption = 197.602636 pJ
sum error= 201
Actual label: 2
Output voltages: [0.23569, 0.23913, 0.70801, 0.35254, 0.181, 0.036701, 0.2689, 0.20783, 0.47893, 0.21336]
Predicted label: 2
Correct prediction
Energy consumption = 193.226202 pJ
sum error= 201
Actual label: 1
Output voltages: [0.16841, 0.7616, 0.1808, 0.21763, 0.33063, 0.1271, 0.42251, 0.12309, 0.27476, 0.23342]
Predicted label: 1
Correct prediction
Energy consumption = 207.095702 pJ
sum error= 201
Actual label: 0
Output voltages: [0.73052, 0.28074, 0.24547, 0.15357, 0.16989, 0.19583, 0.43266, 0.15219, 0.30685, 0.24776]
Predicted label: 0
Correct prediction
Energy consumption = 197.346036 pJ
sum error= 201
Actual label: 1
Output voltages: [0.17375, 0.77046, 0.15698, 0.28914, 0.28612, 0.10114, 0.36381, 0.13843, 0.28358, 0.26186]
Predicted label: 1
Correct prediction
Energy consumption = 208.526017 pJ
sum error= 201
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 472 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 472 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 472 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72504, 0.1952, 0.4075, 0.30554, 0.12058, 0.09589, 0.33284, 0.16951, 0.31556, 0.34572]
Predicted label: 0
Correct prediction
Energy consumption = 204.486754 pJ
sum error= 201
Actual label: 4
Output voltages: [0.17706, 0.19748, 0.28047, 0.18439, 0.74346, 0.1623, 0.27636, 0.21301, 0.21464, 0.40824]
Predicted label: 4
Correct prediction
Energy consumption = 195.262627 pJ
sum error= 201
Actual label: 5
Output voltages: [0.38763, 0.038562, 0.089894, 0.40889, 0.12907, 0.73203, 0.28889, 0.3092, 0.43981, 0.22484]
Predicted label: 5
Correct prediction
Energy consumption = 187.609969 pJ
sum error= 201
Actual label: 2
Output voltages: [0.30703, 0.21716, 0.69862, 0.38412, 0.1229, 0.03626, 0.16347, 0.34447, 0.45017, 0.22293]
Predicted label: 2
Correct prediction
Energy consumption = 189.433158 pJ
sum error= 201
Actual label: 8
Output voltages: [0.40245, 0.092718, 0.29606, 0.34092, 0.22543, 0.18575, 0.36536, 0.055641, 0.65442, 0.20598]
Predicted label: 8
Correct prediction
Energy consumption = 197.881523 pJ
sum error= 201
Actual label: 2
Output voltages: [0.32741, 0.36417, 0.73871, 0.27208, 0.16696, 0.029716, 0.22898, 0.34833, 0.34938, 0.24279]
Predicted label: 2
Correct prediction
Energy consumption = 188.061917 pJ
sum error= 201
Actual label: 8
Output voltages: [0.19891, 0.33781, 0.25906, 0.2895, 0.13569, 0.15472, 0.2283, 0.17611, 0.73964, 0.29567]
Predicted label: 8
Correct prediction
Energy consumption = 202.707420 pJ
sum error= 201
Actual label: 3
Output voltages: [0.28782, 0.25346, 0.27053, 0.75559, 0.18339, 0.078265, 0.077544, 0.33877, 0.37128, 0.31892]
Predicted label: 3
Correct prediction
Energy consumption = 187.463489 pJ
sum error= 201
Actual label: 5
Output voltages: [0.28735, 0.057286, 0.059814, 0.44863, 0.29782, 0.71743, 0.30635, 0.15477, 0.44289, 0.18392]
Predicted label: 5
Correct prediction
Energy consumption = 184.551197 pJ
sum error= 201
Actual label: 1
Output voltages: [0.23561, 0.74033, 0.17439, 0.36077, 0.18338, 0.087895, 0.27441, 0.077699, 0.40109, 0.26553]
Predicted label: 1
Correct prediction
Energy consumption = 205.134809 pJ
sum error= 201
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 473 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 473 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 473 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.38239, 0.28985, 0.14586, 0.29225, 0.15248, 0.12872, 0.045243, 0.7558, 0.29924, 0.36162]
Predicted label: 7
Correct prediction
Energy consumption = 202.131153 pJ
sum error= 201
Actual label: 8
Output voltages: [0.31447, 0.26046, 0.50085, 0.31318, 0.098468, 0.040101, 0.14438, 0.36671, 0.59276, 0.18204]
Predicted label: 8
Correct prediction
Energy consumption = 197.471209 pJ
sum error= 201
Actual label: 1
Output voltages: [0.20469, 0.76037, 0.20178, 0.20446, 0.22863, 0.088511, 0.41758, 0.0724, 0.29961, 0.22647]
Predicted label: 1
Correct prediction
Energy consumption = 205.134457 pJ
sum error= 201
Actual label: 1
Output voltages: [0.2295, 0.70515, 0.054896, 0.19503, 0.36634, 0.30543, 0.42124, 0.13503, 0.33004, 0.19066]
Predicted label: 1
Correct prediction
Energy consumption = 206.419300 pJ
sum error= 201
Actual label: 2
Output voltages: [0.2984, 0.23463, 0.71575, 0.33539, 0.13325, 0.035171, 0.28121, 0.18845, 0.49905, 0.20134]
Predicted label: 2
Correct prediction
Energy consumption = 189.491270 pJ
sum error= 201
Actual label: 9
Output voltages: [0.38387, 0.14206, 0.21327, 0.33251, 0.3044, 0.16521, 0.079848, 0.37871, 0.29114, 0.66584]
Predicted label: 9
Correct prediction
Energy consumption = 199.371548 pJ
sum error= 201
Actual label: 7
Output voltages: [0.23998, 0.22848, 0.48745, 0.30258, 0.21384, 0.029658, 0.060479, 0.68567, 0.38081, 0.19466]
Predicted label: 7
Correct prediction
Energy consumption = 186.397499 pJ
sum error= 201
Actual label: 8
Output voltages: [0.26972, 0.16802, 0.25843, 0.25789, 0.080037, 0.32072, 0.41139, 0.1128, 0.66974, 0.19658]
Predicted label: 8
Correct prediction
Energy consumption = 188.139532 pJ
sum error= 201
Actual label: 4
Output voltages: [0.17518, 0.2113, 0.12562, 0.17965, 0.6845, 0.19626, 0.40667, 0.26069, 0.24578, 0.24251]
Predicted label: 4
Correct prediction
Energy consumption = 202.284037 pJ
sum error= 201
Actual label: 0
Output voltages: [0.60648, 0.082893, 0.33246, 0.075458, 0.28451, 0.122, 0.44691, 0.21541, 0.19246, 0.36787]
Predicted label: 0
Correct prediction
Energy consumption = 189.100225 pJ
sum error= 201
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 474 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 474 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 474 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.31757, 0.20138, 0.093628, 0.56367, 0.24732, 0.43563, 0.17683, 0.26284, 0.24328, 0.28341]
Predicted label: 3
Correct prediction
Energy consumption = 209.245653 pJ
sum error= 201
Actual label: 0
Output voltages: [0.652, 0.20098, 0.15241, 0.13576, 0.27578, 0.29223, 0.49562, 0.10045, 0.28844, 0.22359]
Predicted label: 0
Correct prediction
Energy consumption = 203.173035 pJ
sum error= 201
Actual label: 7
Output voltages: [0.25143, 0.2344, 0.42325, 0.29734, 0.21871, 0.036056, 0.058269, 0.74057, 0.3031, 0.25649]
Predicted label: 7
Correct prediction
Energy consumption = 193.298464 pJ
sum error= 201
Actual label: 8
Output voltages: [0.34012, 0.15199, 0.28867, 0.31653, 0.10629, 0.25571, 0.45789, 0.093816, 0.56277, 0.25242]
Predicted label: 8
Correct prediction
Energy consumption = 198.858462 pJ
sum error= 201
Actual label: 8
Output voltages: [0.2797, 0.22061, 0.2855, 0.53024, 0.081852, 0.14377, 0.22612, 0.1963, 0.70374, 0.23268]
Predicted label: 8
Correct prediction
Energy consumption = 204.977054 pJ
sum error= 201
Actual label: 4
Output voltages: [0.13125, 0.19403, 0.38125, 0.28933, 0.74337, 0.050618, 0.22496, 0.26827, 0.18937, 0.34096]
Predicted label: 4
Correct prediction
Energy consumption = 201.620306 pJ
sum error= 201
Actual label: 7
Output voltages: [0.34383, 0.14055, 0.070007, 0.18997, 0.32378, 0.28645, 0.046872, 0.73245, 0.38115, 0.38853]
Predicted label: 7
Correct prediction
Energy consumption = 202.203131 pJ
sum error= 201
Actual label: 7
Output voltages: [0.39214, 0.14337, 0.23524, 0.24044, 0.16536, 0.10771, 0.036699, 0.74145, 0.45281, 0.36471]
Predicted label: 7
Correct prediction
Energy consumption = 188.743525 pJ
sum error= 201
Actual label: 8
Output voltages: [0.21812, 0.1631, 0.26265, 0.27484, 0.13045, 0.1905, 0.14147, 0.22052, 0.74091, 0.34409]
Predicted label: 8
Correct prediction
Energy consumption = 188.162447 pJ
sum error= 201
Actual label: 5
Output voltages: [0.27792, 0.062549, 0.15148, 0.34726, 0.19837, 0.67332, 0.25952, 0.12216, 0.54037, 0.30954]
Predicted label: 5
Correct prediction
Energy consumption = 189.693161 pJ
sum error= 201
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 475 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 475 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 475 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.33703, 0.13388, 0.41505, 0.34946, 0.1507, 0.1305, 0.2414, 0.15672, 0.72724, 0.28374]
Predicted label: 8
Correct prediction
Energy consumption = 196.966470 pJ
sum error= 201
Actual label: 4
Output voltages: [0.22686, 0.27727, 0.24144, 0.15101, 0.6902, 0.11314, 0.52471, 0.24818, 0.17019, 0.16886]
Predicted label: 4
Correct prediction
Energy consumption = 202.692596 pJ
sum error= 201
Actual label: 9
Output voltages: [0.37735, 0.14458, 0.20309, 0.19202, 0.43412, 0.16223, 0.15743, 0.18884, 0.31018, 0.66248]
Predicted label: 9
Correct prediction
Energy consumption = 196.862543 pJ
sum error= 201
Actual label: 8
Output voltages: [0.18605, 0.28154, 0.22686, 0.35673, 0.10116, 0.24043, 0.15394, 0.19277, 0.73722, 0.28434]
Predicted label: 8
Correct prediction
Energy consumption = 200.007663 pJ
sum error= 201
Actual label: 1
Output voltages: [0.25387, 0.7531, 0.27547, 0.25088, 0.28047, 0.054175, 0.33919, 0.08006, 0.30654, 0.24373]
Predicted label: 1
Correct prediction
Energy consumption = 213.919751 pJ
sum error= 201
Actual label: 3
Output voltages: [0.31949, 0.33944, 0.30371, 0.75067, 0.23509, 0.20398, 0.1957, 0.28137, 0.33543, 0.11583]
Predicted label: 3
Correct prediction
Energy consumption = 200.816967 pJ
sum error= 201
Actual label: 8
Output voltages: [0.24571, 0.18893, 0.34891, 0.18549, 0.19398, 0.22222, 0.19268, 0.16281, 0.7368, 0.27701]
Predicted label: 8
Correct prediction
Energy consumption = 195.373318 pJ
sum error= 201
Actual label: 0
Output voltages: [0.72932, 0.25276, 0.29791, 0.18264, 0.13807, 0.13811, 0.37081, 0.15841, 0.29513, 0.34572]
Predicted label: 0
Correct prediction
Energy consumption = 193.141274 pJ
sum error= 201
Actual label: 3
Output voltages: [0.29835, 0.22696, 0.31397, 0.7596, 0.1525, 0.14701, 0.11494, 0.19292, 0.50556, 0.21268]
Predicted label: 3
Correct prediction
Energy consumption = 187.169741 pJ
sum error= 201
Actual label: 1
Output voltages: [0.19136, 0.71839, 0.18983, 0.387, 0.43269, 0.0726, 0.24845, 0.15105, 0.26059, 0.25701]
Predicted label: 1
Correct prediction
Energy consumption = 209.552301 pJ
sum error= 201
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 476 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 476 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 476 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35447, 0.31991, 0.25895, 0.36091, 0.14835, 0.050122, 0.049732, 0.72508, 0.27407, 0.42858]
Predicted label: 7
Correct prediction
Energy consumption = 207.807050 pJ
sum error= 201
Actual label: 9
Output voltages: [0.29415, 0.26619, 0.27006, 0.17353, 0.31683, 0.056808, 0.11632, 0.19477, 0.52043, 0.46821]
Predicted label: 8
Wrong prediction!
Energy consumption = 201.856838 pJ
sum error= 202
Actual label: 5
Output voltages: [0.20012, 0.049833, 0.1772, 0.3877, 0.1859, 0.67232, 0.20076, 0.1612, 0.58227, 0.22948]
Predicted label: 5
Correct prediction
Energy consumption = 194.431479 pJ
sum error= 202
Actual label: 5
Output voltages: [0.33578, 0.13855, 0.11411, 0.28724, 0.14612, 0.62468, 0.54618, 0.14277, 0.39391, 0.066132]
Predicted label: 5
Correct prediction
Energy consumption = 189.408153 pJ
sum error= 202
Actual label: 1
Output voltages: [0.20231, 0.76753, 0.17942, 0.26403, 0.22515, 0.12691, 0.36899, 0.16025, 0.3488, 0.19445]
Predicted label: 1
Correct prediction
Energy consumption = 215.978725 pJ
sum error= 202
Actual label: 6
Output voltages: [0.3898, 0.32489, 0.29875, 0.13791, 0.2286, 0.3211, 0.73451, 0.059522, 0.30613, 0.2557]
Predicted label: 6
Correct prediction
Energy consumption = 194.100733 pJ
sum error= 202
Actual label: 5
Output voltages: [0.27031, 0.060625, 0.1493, 0.37894, 0.15952, 0.70335, 0.259, 0.22382, 0.57198, 0.241]
Predicted label: 5
Correct prediction
Energy consumption = 178.727449 pJ
sum error= 202
Actual label: 7
Output voltages: [0.38406, 0.15189, 0.15953, 0.40823, 0.091494, 0.18601, 0.038766, 0.7341, 0.41085, 0.38928]
Predicted label: 7
Correct prediction
Energy consumption = 190.352393 pJ
sum error= 202
Actual label: 4
Output voltages: [0.19171, 0.15244, 0.30462, 0.10912, 0.74748, 0.15109, 0.34125, 0.17645, 0.29819, 0.27566]
Predicted label: 4
Correct prediction
Energy consumption = 192.133531 pJ
sum error= 202
Actual label: 9
Output voltages: [0.40473, 0.11763, 0.14946, 0.28351, 0.35391, 0.24796, 0.097708, 0.29735, 0.31297, 0.66791]
Predicted label: 9
Correct prediction
Energy consumption = 190.441591 pJ
sum error= 202
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 477 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 477 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 477 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.27198, 0.18579, 0.30434, 0.75534, 0.16483, 0.19058, 0.14068, 0.16388, 0.43312, 0.27651]
Predicted label: 3
Correct prediction
Energy consumption = 181.677837 pJ
sum error= 202
Actual label: 5
Output voltages: [0.25373, 0.1377, 0.16088, 0.27083, 0.18307, 0.67271, 0.25418, 0.048702, 0.54404, 0.23896]
Predicted label: 5
Correct prediction
Energy consumption = 197.337419 pJ
sum error= 202
Actual label: 4
Output voltages: [0.1246, 0.20644, 0.23179, 0.086824, 0.66509, 0.080954, 0.1817, 0.26875, 0.38562, 0.28256]
Predicted label: 4
Correct prediction
Energy consumption = 201.719482 pJ
sum error= 202
Actual label: 7
Output voltages: [0.33441, 0.33006, 0.23561, 0.45944, 0.056147, 0.054295, 0.045765, 0.677, 0.36857, 0.33482]
Predicted label: 7
Correct prediction
Energy consumption = 201.003795 pJ
sum error= 202
Actual label: 1
Output voltages: [0.099903, 0.75843, 0.2198, 0.31797, 0.255, 0.11369, 0.38423, 0.13911, 0.35807, 0.26667]
Predicted label: 1
Correct prediction
Energy consumption = 209.199547 pJ
sum error= 202
Actual label: 2
Output voltages: [0.33846, 0.38888, 0.64565, 0.31942, 0.21575, 0.030154, 0.42033, 0.19896, 0.39424, 0.15286]
Predicted label: 2
Correct prediction
Energy consumption = 190.153604 pJ
sum error= 202
Actual label: 0
Output voltages: [0.69259, 0.1807, 0.22611, 0.13828, 0.15988, 0.15059, 0.46076, 0.20222, 0.30885, 0.31122]
Predicted label: 0
Correct prediction
Energy consumption = 190.086287 pJ
sum error= 202
Actual label: 8
Output voltages: [0.26723, 0.28768, 0.1475, 0.37203, 0.1076, 0.30029, 0.40234, 0.099614, 0.68858, 0.16653]
Predicted label: 8
Correct prediction
Energy consumption = 202.172599 pJ
sum error= 202
Actual label: 1
Output voltages: [0.1798, 0.76268, 0.23204, 0.35658, 0.22831, 0.19194, 0.24661, 0.20804, 0.19716, 0.3115]
Predicted label: 1
Correct prediction
Energy consumption = 214.608384 pJ
sum error= 202
Actual label: 6
Output voltages: [0.28023, 0.19943, 0.36131, 0.074775, 0.29378, 0.33732, 0.74281, 0.078624, 0.36967, 0.17244]
Predicted label: 6
Correct prediction
Energy consumption = 188.388504 pJ
sum error= 202
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 478 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 478 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 478 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.66916, 0.25732, 0.23857, 0.17727, 0.20722, 0.17204, 0.46757, 0.14912, 0.36435, 0.22012]
Predicted label: 0
Correct prediction
Energy consumption = 206.148234 pJ
sum error= 202
Actual label: 7
Output voltages: [0.29654, 0.25759, 0.36423, 0.29724, 0.08338, 0.063867, 0.035489, 0.73718, 0.44566, 0.35317]
Predicted label: 7
Correct prediction
Energy consumption = 195.573477 pJ
sum error= 202
Actual label: 3
Output voltages: [0.28956, 0.22938, 0.22832, 0.75793, 0.14014, 0.17414, 0.1211, 0.26387, 0.39245, 0.32344]
Predicted label: 3
Correct prediction
Energy consumption = 182.713376 pJ
sum error= 202
Actual label: 4
Output voltages: [0.16967, 0.16166, 0.21573, 0.28996, 0.70163, 0.13358, 0.23996, 0.16046, 0.19916, 0.41418]
Predicted label: 4
Correct prediction
Energy consumption = 192.852206 pJ
sum error= 202
Actual label: 7
Output voltages: [0.27197, 0.22162, 0.15416, 0.31102, 0.17562, 0.15495, 0.039448, 0.74311, 0.32184, 0.41482]
Predicted label: 7
Correct prediction
Energy consumption = 196.308140 pJ
sum error= 202
Actual label: 3
Output voltages: [0.16388, 0.17862, 0.26864, 0.61761, 0.085624, 0.15893, 0.065635, 0.26163, 0.6375, 0.26075]
Predicted label: 8
Wrong prediction!
Energy consumption = 185.718651 pJ
sum error= 203
Actual label: 9
Output voltages: [0.39906, 0.14707, 0.1855, 0.2763, 0.37971, 0.17902, 0.13086, 0.15457, 0.33341, 0.69853]
Predicted label: 9
Correct prediction
Energy consumption = 176.520830 pJ
sum error= 203
Actual label: 6
Output voltages: [0.28985, 0.22115, 0.27999, 0.15398, 0.33329, 0.41172, 0.73732, 0.10922, 0.38644, 0.10498]
Predicted label: 6
Correct prediction
Energy consumption = 197.190884 pJ
sum error= 203
Actual label: 0
Output voltages: [0.66832, 0.22116, 0.14716, 0.17798, 0.2263, 0.32443, 0.48293, 0.1875, 0.2115, 0.34347]
Predicted label: 0
Correct prediction
Energy consumption = 198.567720 pJ
sum error= 203
Actual label: 8
Output voltages: [0.32466, 0.13759, 0.31755, 0.241, 0.10371, 0.42431, 0.34027, 0.12208, 0.70206, 0.15314]
Predicted label: 8
Correct prediction
Energy consumption = 188.911008 pJ
sum error= 203
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 479 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 479 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 479 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29507, 0.20566, 0.2814, 0.073946, 0.31094, 0.35616, 0.73569, 0.092987, 0.43193, 0.12537]
Predicted label: 6
Correct prediction
Energy consumption = 188.302082 pJ
sum error= 203
Actual label: 4
Output voltages: [0.15765, 0.29445, 0.12145, 0.29868, 0.72491, 0.16746, 0.23669, 0.19233, 0.18167, 0.30896]
Predicted label: 4
Correct prediction
Energy consumption = 199.592646 pJ
sum error= 203
Actual label: 8
Output voltages: [0.18931, 0.19714, 0.29505, 0.24815, 0.12976, 0.23061, 0.19215, 0.15442, 0.74428, 0.35352]
Predicted label: 8
Correct prediction
Energy consumption = 198.100026 pJ
sum error= 203
Actual label: 7
Output voltages: [0.3118, 0.25282, 0.36623, 0.16688, 0.086517, 0.11625, 0.052941, 0.73975, 0.48324, 0.3262]
Predicted label: 7
Correct prediction
Energy consumption = 191.766700 pJ
sum error= 203
Actual label: 7
Output voltages: [0.32139, 0.14465, 0.078758, 0.17915, 0.38483, 0.19406, 0.048273, 0.73349, 0.30357, 0.32185]
Predicted label: 7
Correct prediction
Energy consumption = 205.154339 pJ
sum error= 203
Actual label: 9
Output voltages: [0.33556, 0.15661, 0.15552, 0.30952, 0.24679, 0.18385, 0.11428, 0.26645, 0.41544, 0.66318]
Predicted label: 9
Correct prediction
Energy consumption = 186.364086 pJ
sum error= 203
Actual label: 3
Output voltages: [0.3477, 0.28801, 0.33134, 0.76082, 0.14023, 0.19064, 0.090958, 0.2356, 0.43471, 0.23426]
Predicted label: 3
Correct prediction
Energy consumption = 192.575531 pJ
sum error= 203
Actual label: 8
Output voltages: [0.23364, 0.23316, 0.32978, 0.2124, 0.17724, 0.16736, 0.17781, 0.13995, 0.74969, 0.31474]
Predicted label: 8
Correct prediction
Energy consumption = 190.093662 pJ
sum error= 203
Actual label: 6
Output voltages: [0.31786, 0.197, 0.17867, 0.2425, 0.30044, 0.30648, 0.59643, 0.072741, 0.54531, 0.089182]
Predicted label: 6
Correct prediction
Energy consumption = 202.640345 pJ
sum error= 203
Actual label: 9
Output voltages: [0.31372, 0.17052, 0.23884, 0.38455, 0.32877, 0.14447, 0.18915, 0.2651, 0.2764, 0.63092]
Predicted label: 9
Correct prediction
Energy consumption = 193.891416 pJ
sum error= 203
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 480 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 480 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 480 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35916, 0.14518, 0.20166, 0.28683, 0.11333, 0.15956, 0.039423, 0.75231, 0.44074, 0.39097]
Predicted label: 7
Correct prediction
Energy consumption = 196.934900 pJ
sum error= 203
Actual label: 2
Output voltages: [0.30564, 0.35782, 0.67933, 0.31334, 0.29595, 0.040389, 0.28233, 0.23434, 0.31259, 0.16599]
Predicted label: 2
Correct prediction
Energy consumption = 188.530314 pJ
sum error= 203
Actual label: 3
Output voltages: [0.25409, 0.21125, 0.17314, 0.72188, 0.18745, 0.38299, 0.16676, 0.17647, 0.32739, 0.23422]
Predicted label: 3
Correct prediction
Energy consumption = 192.373546 pJ
sum error= 203
Actual label: 4
Output voltages: [0.13525, 0.18248, 0.27892, 0.18201, 0.75866, 0.052041, 0.21229, 0.31297, 0.23194, 0.20033]
Predicted label: 4
Correct prediction
Energy consumption = 191.810724 pJ
sum error= 203
Actual label: 0
Output voltages: [0.73061, 0.23741, 0.28914, 0.198, 0.15481, 0.17115, 0.4029, 0.19153, 0.34489, 0.18237]
Predicted label: 0
Correct prediction
Energy consumption = 195.240662 pJ
sum error= 203
Actual label: 2
Output voltages: [0.38288, 0.35336, 0.72533, 0.25066, 0.17765, 0.021021, 0.30481, 0.32154, 0.35552, 0.22368]
Predicted label: 2
Correct prediction
Energy consumption = 183.827260 pJ
sum error= 203
Actual label: 1
Output voltages: [0.29801, 0.76111, 0.36662, 0.23848, 0.18716, 0.057283, 0.41892, 0.057449, 0.23177, 0.30631]
Predicted label: 1
Correct prediction
Energy consumption = 204.996457 pJ
sum error= 203
Actual label: 8
Output voltages: [0.61663, 0.20805, 0.17726, 0.42943, 0.17971, 0.15579, 0.35875, 0.057862, 0.49276, 0.24075]
Predicted label: 0
Wrong prediction!
Energy consumption = 204.507858 pJ
sum error= 204
Actual label: 3
Output voltages: [0.19661, 0.13468, 0.14712, 0.6125, 0.14036, 0.49159, 0.16434, 0.22848, 0.46152, 0.22675]
Predicted label: 3
Correct prediction
Energy consumption = 194.689550 pJ
sum error= 204
Actual label: 5
Output voltages: [0.25391, 0.096591, 0.043991, 0.28304, 0.29855, 0.68211, 0.28697, 0.1405, 0.47844, 0.23353]
Predicted label: 5
Correct prediction
Energy consumption = 184.714929 pJ
sum error= 204
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 481 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 481 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 481 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.21256, 0.11995, 0.064966, 0.3562, 0.17125, 0.73663, 0.24474, 0.16671, 0.47469, 0.26529]
Predicted label: 5
Correct prediction
Energy consumption = 191.928260 pJ
sum error= 204
Actual label: 7
Output voltages: [0.30673, 0.26224, 0.29615, 0.27592, 0.11264, 0.055758, 0.056093, 0.75697, 0.3664, 0.33039]
Predicted label: 7
Correct prediction
Energy consumption = 199.346973 pJ
sum error= 204
Actual label: 2
Output voltages: [0.36868, 0.34096, 0.73067, 0.33, 0.15827, 0.026331, 0.35549, 0.17991, 0.42076, 0.21304]
Predicted label: 2
Correct prediction
Energy consumption = 194.698295 pJ
sum error= 204
Actual label: 4
Output voltages: [0.21287, 0.1489, 0.28794, 0.12102, 0.73077, 0.09322, 0.30362, 0.17004, 0.28841, 0.28216]
Predicted label: 4
Correct prediction
Energy consumption = 193.375805 pJ
sum error= 204
Actual label: 6
Output voltages: [0.53581, 0.14245, 0.29304, 0.087791, 0.28122, 0.13123, 0.54609, 0.09497, 0.38477, 0.20134]
Predicted label: 6
Correct prediction
Energy consumption = 208.830139 pJ
sum error= 204
Actual label: 7
Output voltages: [0.3203, 0.28193, 0.1851, 0.3545, 0.15215, 0.1118, 0.034201, 0.72038, 0.31862, 0.38419]
Predicted label: 7
Correct prediction
Energy consumption = 199.981752 pJ
sum error= 204
Actual label: 2
Output voltages: [0.43862, 0.18138, 0.55605, 0.52755, 0.2274, 0.12751, 0.3832, 0.20605, 0.2705, 0.094231]
Predicted label: 2
Correct prediction
Energy consumption = 193.683110 pJ
sum error= 204
Actual label: 8
Output voltages: [0.24744, 0.17058, 0.31665, 0.29757, 0.13038, 0.25106, 0.22602, 0.14648, 0.74357, 0.32294]
Predicted label: 8
Correct prediction
Energy consumption = 196.929090 pJ
sum error= 204
Actual label: 3
Output voltages: [0.28527, 0.18954, 0.29917, 0.75322, 0.18104, 0.14796, 0.10485, 0.18116, 0.47788, 0.28292]
Predicted label: 3
Correct prediction
Energy consumption = 179.290719 pJ
sum error= 204
Actual label: 0
Output voltages: [0.70748, 0.20381, 0.28395, 0.1877, 0.1933, 0.12948, 0.32458, 0.22307, 0.38815, 0.25401]
Predicted label: 0
Correct prediction
Energy consumption = 198.627509 pJ
sum error= 204
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 482 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 482 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 482 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.15938, 0.18027, 0.16957, 0.28265, 0.14707, 0.35162, 0.094138, 0.21237, 0.73331, 0.31856]
Predicted label: 8
Correct prediction
Energy consumption = 195.396601 pJ
sum error= 204
Actual label: 7
Output voltages: [0.35842, 0.18754, 0.13705, 0.23622, 0.21341, 0.18662, 0.048295, 0.76088, 0.3613, 0.3786]
Predicted label: 7
Correct prediction
Energy consumption = 197.266634 pJ
sum error= 204
Actual label: 8
Output voltages: [0.247, 0.18193, 0.29253, 0.39394, 0.12049, 0.21386, 0.21564, 0.073486, 0.7304, 0.30148]
Predicted label: 8
Correct prediction
Energy consumption = 196.937705 pJ
sum error= 204
Actual label: 9
Output voltages: [0.1858, 0.11413, 0.19855, 0.20223, 0.57744, 0.24154, 0.50667, 0.12704, 0.29464, 0.33965]
Predicted label: 4
Wrong prediction!
Energy consumption = 198.274542 pJ
sum error= 205
Actual label: 0
Output voltages: [0.61344, 0.22893, 0.28623, 0.22781, 0.26518, 0.061156, 0.41401, 0.15811, 0.40674, 0.23787]
Predicted label: 0
Correct prediction
Energy consumption = 206.759491 pJ
sum error= 205
Actual label: 8
Output voltages: [0.24471, 0.14755, 0.31542, 0.33089, 0.18369, 0.062597, 0.11349, 0.12112, 0.61635, 0.37417]
Predicted label: 8
Correct prediction
Energy consumption = 199.141594 pJ
sum error= 205
Actual label: 4
Output voltages: [0.13685, 0.26314, 0.32483, 0.20289, 0.73357, 0.065643, 0.2026, 0.17689, 0.1929, 0.47392]
Predicted label: 4
Correct prediction
Energy consumption = 199.850572 pJ
sum error= 205
Actual label: 4
Output voltages: [0.067024, 0.19382, 0.24205, 0.090196, 0.68, 0.1255, 0.21631, 0.28831, 0.41557, 0.29858]
Predicted label: 4
Correct prediction
Energy consumption = 193.974246 pJ
sum error= 205
Actual label: 5
Output voltages: [0.23695, 0.047635, 0.10315, 0.2964, 0.28511, 0.65882, 0.29142, 0.17055, 0.54239, 0.32884]
Predicted label: 5
Correct prediction
Energy consumption = 195.164024 pJ
sum error= 205
Actual label: 8
Output voltages: [0.28602, 0.20946, 0.24661, 0.23847, 0.12919, 0.35963, 0.16562, 0.28774, 0.73233, 0.1995]
Predicted label: 8
Correct prediction
Energy consumption = 194.296440 pJ
sum error= 205
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 483 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 483 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 483 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.32535, 0.042417, 0.11922, 0.39176, 0.19257, 0.63107, 0.25034, 0.173, 0.52791, 0.32752]
Predicted label: 5
Correct prediction
Energy consumption = 191.019339 pJ
sum error= 205
Actual label: 6
Output voltages: [0.34779, 0.1841, 0.25631, 0.1292, 0.30685, 0.37531, 0.70027, 0.067883, 0.45404, 0.1402]
Predicted label: 6
Correct prediction
Energy consumption = 187.048711 pJ
sum error= 205
Actual label: 6
Output voltages: [0.30886, 0.29914, 0.26897, 0.15743, 0.29603, 0.42304, 0.73654, 0.13916, 0.3973, 0.12303]
Predicted label: 6
Correct prediction
Energy consumption = 197.023562 pJ
sum error= 205
Actual label: 3
Output voltages: [0.25218, 0.1168, 0.41419, 0.71818, 0.19657, 0.13559, 0.12684, 0.18679, 0.52222, 0.2103]
Predicted label: 3
Correct prediction
Energy consumption = 188.421499 pJ
sum error= 205
Actual label: 0
Output voltages: [0.69125, 0.072667, 0.26081, 0.27476, 0.095417, 0.31868, 0.39745, 0.15393, 0.31926, 0.30747]
Predicted label: 0
Correct prediction
Energy consumption = 192.032338 pJ
sum error= 205
Actual label: 9
Output voltages: [0.36892, 0.10528, 0.19321, 0.25792, 0.23374, 0.20912, 0.094148, 0.27028, 0.44257, 0.638]
Predicted label: 9
Correct prediction
Energy consumption = 190.389900 pJ
sum error= 205
Actual label: 3
Output voltages: [0.32082, 0.14061, 0.30461, 0.75285, 0.18662, 0.26623, 0.15974, 0.18852, 0.44059, 0.23836]
Predicted label: 3
Correct prediction
Energy consumption = 183.726364 pJ
sum error= 205
Actual label: 7
Output voltages: [0.30797, 0.28622, 0.53242, 0.36748, 0.16054, 0.02577, 0.073776, 0.50163, 0.45822, 0.33423]
Predicted label: 2
Wrong prediction!
Energy consumption = 195.915140 pJ
sum error= 206
Actual label: 6
Output voltages: [0.3684, 0.22068, 0.074817, 0.39039, 0.16141, 0.54008, 0.57616, 0.10822, 0.48745, 0.094013]
Predicted label: 6
Correct prediction
Energy consumption = 194.048775 pJ
sum error= 206
Actual label: 8
Output voltages: [0.303, 0.19206, 0.37928, 0.38629, 0.086071, 0.1504, 0.24822, 0.17691, 0.7304, 0.21313]
Predicted label: 8
Correct prediction
Energy consumption = 188.016285 pJ
sum error= 206
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 484 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 484 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 484 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3827, 0.15661, 0.22438, 0.21445, 0.3008, 0.14909, 0.11205, 0.29391, 0.31389, 0.69026]
Predicted label: 9
Correct prediction
Energy consumption = 198.017479 pJ
sum error= 206
Actual label: 3
Output voltages: [0.32452, 0.22504, 0.36694, 0.72403, 0.12235, 0.087617, 0.13193, 0.13792, 0.54232, 0.3004]
Predicted label: 3
Correct prediction
Energy consumption = 193.764256 pJ
sum error= 206
Actual label: 4
Output voltages: [0.21334, 0.12705, 0.26738, 0.19248, 0.73764, 0.21406, 0.22172, 0.18892, 0.25022, 0.45593]
Predicted label: 4
Correct prediction
Energy consumption = 196.423385 pJ
sum error= 206
Actual label: 9
Output voltages: [0.38351, 0.14087, 0.20079, 0.23174, 0.29414, 0.18672, 0.10236, 0.24622, 0.34802, 0.68406]
Predicted label: 9
Correct prediction
Energy consumption = 187.650388 pJ
sum error= 206
Actual label: 5
Output voltages: [0.35878, 0.11139, 0.1077, 0.40299, 0.12911, 0.73693, 0.29648, 0.20933, 0.42037, 0.19739]
Predicted label: 5
Correct prediction
Energy consumption = 188.244056 pJ
sum error= 206
Actual label: 8
Output voltages: [0.20281, 0.25749, 0.30478, 0.3705, 0.075156, 0.14552, 0.15859, 0.21752, 0.7389, 0.29707]
Predicted label: 8
Correct prediction
Energy consumption = 194.436566 pJ
sum error= 206
Actual label: 9
Output voltages: [0.35661, 0.075057, 0.26801, 0.28516, 0.44998, 0.13451, 0.082794, 0.31689, 0.30435, 0.59916]
Predicted label: 9
Correct prediction
Energy consumption = 204.054060 pJ
sum error= 206
Actual label: 1
Output voltages: [0.22211, 0.75611, 0.2606, 0.26465, 0.20074, 0.12959, 0.3874, 0.082976, 0.29069, 0.23758]
Predicted label: 1
Correct prediction
Energy consumption = 208.316811 pJ
sum error= 206
Actual label: 2
Output voltages: [0.31785, 0.31273, 0.72619, 0.38336, 0.15323, 0.034607, 0.29257, 0.16795, 0.48321, 0.21623]
Predicted label: 2
Correct prediction
Energy consumption = 186.107589 pJ
sum error= 206
Actual label: 8
Output voltages: [0.23376, 0.2591, 0.29236, 0.31124, 0.14462, 0.10979, 0.26625, 0.12154, 0.72551, 0.3026]
Predicted label: 8
Correct prediction
Energy consumption = 195.026382 pJ
sum error= 206
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 485 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 485 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 485 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18732, 0.23661, 0.30874, 0.27122, 0.16815, 0.11881, 0.19671, 0.13477, 0.73422, 0.31362]
Predicted label: 8
Correct prediction
Energy consumption = 200.617958 pJ
sum error= 206
Actual label: 6
Output voltages: [0.41279, 0.21338, 0.2105, 0.16114, 0.36352, 0.27042, 0.69841, 0.097754, 0.39438, 0.1431]
Predicted label: 6
Correct prediction
Energy consumption = 196.661216 pJ
sum error= 206
Actual label: 8
Output voltages: [0.2592, 0.11102, 0.32001, 0.25838, 0.13954, 0.34426, 0.38934, 0.10572, 0.69231, 0.20425]
Predicted label: 8
Correct prediction
Energy consumption = 190.843255 pJ
sum error= 206
Actual label: 1
Output voltages: [0.21204, 0.74616, 0.11453, 0.24051, 0.19902, 0.092266, 0.38982, 0.091806, 0.41654, 0.24356]
Predicted label: 1
Correct prediction
Energy consumption = 208.114208 pJ
sum error= 206
Actual label: 3
Output voltages: [0.30527, 0.10911, 0.20389, 0.73989, 0.23206, 0.36542, 0.1239, 0.26949, 0.39885, 0.17292]
Predicted label: 3
Correct prediction
Energy consumption = 194.234375 pJ
sum error= 206
Actual label: 7
Output voltages: [0.35369, 0.10959, 0.23183, 0.38409, 0.14784, 0.16336, 0.030247, 0.6997, 0.44093, 0.41412]
Predicted label: 7
Correct prediction
Energy consumption = 188.969441 pJ
sum error= 206
Actual label: 9
Output voltages: [0.35094, 0.071436, 0.20589, 0.29805, 0.27153, 0.19297, 0.060476, 0.36627, 0.37418, 0.59988]
Predicted label: 9
Correct prediction
Energy consumption = 185.539542 pJ
sum error= 206
Actual label: 0
Output voltages: [0.69416, 0.18608, 0.25887, 0.31013, 0.11662, 0.15251, 0.29635, 0.1309, 0.4575, 0.33375]
Predicted label: 0
Correct prediction
Energy consumption = 200.659444 pJ
sum error= 206
Actual label: 1
Output voltages: [0.13011, 0.7624, 0.21321, 0.30624, 0.26966, 0.069995, 0.27763, 0.18626, 0.32559, 0.23663]
Predicted label: 1
Correct prediction
Energy consumption = 215.906380 pJ
sum error= 206
Actual label: 1
Output voltages: [0.14125, 0.7657, 0.16217, 0.22429, 0.24113, 0.10061, 0.32213, 0.13243, 0.40356, 0.26516]
Predicted label: 1
Correct prediction
Energy consumption = 198.626239 pJ
sum error= 206
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 486 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 486 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 486 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.32098, 0.08018, 0.24243, 0.26914, 0.46182, 0.11974, 0.10557, 0.15343, 0.38075, 0.4907]
Predicted label: 9
Wrong prediction!
Energy consumption = 191.897261 pJ
sum error= 207
Actual label: 7
Output voltages: [0.37623, 0.33559, 0.31108, 0.53828, 0.057978, 0.041828, 0.096266, 0.55531, 0.45419, 0.20189]
Predicted label: 7
Correct prediction
Energy consumption = 203.354228 pJ
sum error= 207
Actual label: 0
Output voltages: [0.71037, 0.27264, 0.31592, 0.18883, 0.12738, 0.14495, 0.36253, 0.16369, 0.27676, 0.31261]
Predicted label: 0
Correct prediction
Energy consumption = 196.475919 pJ
sum error= 207
Actual label: 8
Output voltages: [0.20891, 0.24205, 0.24236, 0.29997, 0.17492, 0.14831, 0.1883, 0.10491, 0.70019, 0.36271]
Predicted label: 8
Correct prediction
Energy consumption = 202.492065 pJ
sum error= 207
Actual label: 1
Output voltages: [0.2633, 0.76983, 0.18907, 0.27658, 0.235, 0.1096, 0.2968, 0.20887, 0.28654, 0.25193]
Predicted label: 1
Correct prediction
Energy consumption = 216.717856 pJ
sum error= 207
Actual label: 7
Output voltages: [0.34018, 0.24822, 0.36718, 0.17091, 0.10065, 0.053029, 0.053316, 0.74816, 0.47739, 0.23285]
Predicted label: 7
Correct prediction
Energy consumption = 193.346079 pJ
sum error= 207
Actual label: 4
Output voltages: [0.22075, 0.16167, 0.2646, 0.19255, 0.73928, 0.17493, 0.18313, 0.2711, 0.24138, 0.4437]
Predicted label: 4
Correct prediction
Energy consumption = 198.531992 pJ
sum error= 207
Actual label: 5
Output voltages: [0.2311, 0.066278, 0.13918, 0.41911, 0.21552, 0.70474, 0.37675, 0.15902, 0.4517, 0.22289]
Predicted label: 5
Correct prediction
Energy consumption = 186.858066 pJ
sum error= 207
Actual label: 7
Output voltages: [0.32464, 0.23292, 0.40687, 0.2736, 0.10657, 0.081512, 0.04022, 0.66704, 0.45778, 0.4146]
Predicted label: 7
Correct prediction
Energy consumption = 191.398634 pJ
sum error= 207
Actual label: 1
Output voltages: [0.1889, 0.76964, 0.24566, 0.26546, 0.23338, 0.10792, 0.38224, 0.12981, 0.29466, 0.21492]
Predicted label: 1
Correct prediction
Energy consumption = 204.716363 pJ
sum error= 207
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 487 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 487 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 487 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.38691, 0.28221, 0.75054, 0.25214, 0.22274, 0.031219, 0.3102, 0.26665, 0.37834, 0.18913]
Predicted label: 2
Correct prediction
Energy consumption = 184.663533 pJ
sum error= 207
Actual label: 1
Output voltages: [0.2073, 0.76524, 0.21187, 0.2782, 0.11052, 0.17276, 0.30609, 0.14624, 0.38624, 0.28119]
Predicted label: 1
Correct prediction
Energy consumption = 215.066900 pJ
sum error= 207
Actual label: 1
Output voltages: [0.20198, 0.75406, 0.11839, 0.1852, 0.3653, 0.21835, 0.45174, 0.12487, 0.23757, 0.19153]
Predicted label: 1
Correct prediction
Energy consumption = 203.967731 pJ
sum error= 207
Actual label: 3
Output voltages: [0.27182, 0.19904, 0.34625, 0.74478, 0.1086, 0.083494, 0.13301, 0.25227, 0.41044, 0.26506]
Predicted label: 3
Correct prediction
Energy consumption = 191.452716 pJ
sum error= 207
Actual label: 9
Output voltages: [0.56444, 0.095511, 0.32192, 0.18956, 0.15316, 0.22789, 0.46114, 0.10496, 0.1815, 0.45482]
Predicted label: 0
Wrong prediction!
Energy consumption = 201.011046 pJ
sum error= 208
Actual label: 6
Output voltages: [0.3142, 0.25679, 0.2812, 0.10684, 0.33859, 0.31486, 0.74369, 0.073769, 0.4027, 0.12364]
Predicted label: 6
Correct prediction
Energy consumption = 189.400760 pJ
sum error= 208
Actual label: 2
Output voltages: [0.33464, 0.18125, 0.58137, 0.27427, 0.49716, 0.054765, 0.35879, 0.36545, 0.14681, 0.09182]
Predicted label: 2
Correct prediction
Energy consumption = 194.452040 pJ
sum error= 208
Actual label: 1
Output voltages: [0.24701, 0.76368, 0.17942, 0.2206, 0.30811, 0.18607, 0.40123, 0.076876, 0.27575, 0.26817]
Predicted label: 1
Correct prediction
Energy consumption = 209.045858 pJ
sum error= 208
Actual label: 2
Output voltages: [0.35993, 0.13272, 0.66525, 0.39383, 0.11307, 0.044793, 0.26528, 0.22224, 0.54653, 0.15977]
Predicted label: 2
Correct prediction
Energy consumption = 187.914953 pJ
sum error= 208
Actual label: 8
Output voltages: [0.18224, 0.18297, 0.20569, 0.24426, 0.32327, 0.27353, 0.48866, 0.06512, 0.61146, 0.20912]
Predicted label: 8
Correct prediction
Energy consumption = 198.993224 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 488 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 488 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 488 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.56224, 0.14867, 0.24935, 0.21455, 0.18662, 0.16505, 0.35793, 0.07255, 0.49931, 0.28929]
Predicted label: 0
Correct prediction
Energy consumption = 199.582764 pJ
sum error= 208
Actual label: 7
Output voltages: [0.38224, 0.10532, 0.30849, 0.22549, 0.15669, 0.085861, 0.041712, 0.72068, 0.47403, 0.36974]
Predicted label: 7
Correct prediction
Energy consumption = 187.336553 pJ
sum error= 208
Actual label: 6
Output voltages: [0.2733, 0.20967, 0.3343, 0.20077, 0.17162, 0.32319, 0.67996, 0.053289, 0.50141, 0.21531]
Predicted label: 6
Correct prediction
Energy consumption = 194.403058 pJ
sum error= 208
Actual label: 6
Output voltages: [0.33031, 0.22556, 0.24772, 0.11741, 0.32178, 0.38785, 0.74235, 0.10654, 0.38664, 0.14285]
Predicted label: 6
Correct prediction
Energy consumption = 184.408909 pJ
sum error= 208
Actual label: 9
Output voltages: [0.33311, 0.16995, 0.24709, 0.21901, 0.27671, 0.15162, 0.094337, 0.15423, 0.42864, 0.64911]
Predicted label: 9
Correct prediction
Energy consumption = 194.475567 pJ
sum error= 208
Actual label: 3
Output voltages: [0.22384, 0.28273, 0.25135, 0.73616, 0.099284, 0.23337, 0.096131, 0.12188, 0.45665, 0.28386]
Predicted label: 3
Correct prediction
Energy consumption = 186.287231 pJ
sum error= 208
Actual label: 7
Output voltages: [0.3204, 0.41702, 0.38646, 0.39108, 0.077015, 0.041778, 0.10167, 0.54019, 0.50163, 0.24313]
Predicted label: 7
Correct prediction
Energy consumption = 200.998613 pJ
sum error= 208
Actual label: 0
Output voltages: [0.71791, 0.20973, 0.33059, 0.17482, 0.13692, 0.17713, 0.3005, 0.19563, 0.44456, 0.29983]
Predicted label: 0
Correct prediction
Energy consumption = 200.629737 pJ
sum error= 208
Actual label: 5
Output voltages: [0.40147, 0.061135, 0.14141, 0.27243, 0.13943, 0.67985, 0.31325, 0.29798, 0.50797, 0.14931]
Predicted label: 5
Correct prediction
Energy consumption = 198.804085 pJ
sum error= 208
Actual label: 2
Output voltages: [0.37351, 0.32049, 0.7181, 0.38645, 0.1439, 0.029226, 0.27463, 0.1412, 0.38722, 0.16993]
Predicted label: 2
Correct prediction
Energy consumption = 181.818320 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 489 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 489 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 489 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.30046, 0.064756, 0.32176, 0.39958, 0.14775, 0.2336, 0.33813, 0.10735, 0.66953, 0.11538]
Predicted label: 8
Correct prediction
Energy consumption = 198.330541 pJ
sum error= 208
Actual label: 0
Output voltages: [0.7327, 0.21731, 0.25567, 0.12561, 0.18232, 0.17101, 0.3821, 0.14922, 0.26576, 0.3067]
Predicted label: 0
Correct prediction
Energy consumption = 192.098832 pJ
sum error= 208
Actual label: 5
Output voltages: [0.20962, 0.04667, 0.084747, 0.31362, 0.32488, 0.67429, 0.27974, 0.12045, 0.51964, 0.26043]
Predicted label: 5
Correct prediction
Energy consumption = 185.149196 pJ
sum error= 208
Actual label: 4
Output voltages: [0.28992, 0.19175, 0.30223, 0.22435, 0.67339, 0.080692, 0.17068, 0.32498, 0.18672, 0.52738]
Predicted label: 4
Correct prediction
Energy consumption = 204.163873 pJ
sum error= 208
Actual label: 3
Output voltages: [0.27891, 0.17423, 0.2456, 0.75131, 0.19818, 0.3753, 0.12438, 0.23317, 0.43566, 0.22088]
Predicted label: 3
Correct prediction
Energy consumption = 188.623133 pJ
sum error= 208
Actual label: 8
Output voltages: [0.2938, 0.17819, 0.37376, 0.25432, 0.18921, 0.14197, 0.19163, 0.090202, 0.73697, 0.34387]
Predicted label: 8
Correct prediction
Energy consumption = 192.039942 pJ
sum error= 208
Actual label: 4
Output voltages: [0.23075, 0.18904, 0.26354, 0.18679, 0.75174, 0.10276, 0.31338, 0.24407, 0.17001, 0.32195]
Predicted label: 4
Correct prediction
Energy consumption = 192.528207 pJ
sum error= 208
Actual label: 6
Output voltages: [0.33471, 0.2085, 0.25035, 0.21511, 0.2768, 0.39631, 0.72272, 0.079946, 0.433, 0.21831]
Predicted label: 6
Correct prediction
Energy consumption = 191.900544 pJ
sum error= 208
Actual label: 6
Output voltages: [0.33354, 0.30811, 0.23393, 0.24139, 0.24324, 0.34319, 0.74175, 0.10798, 0.39979, 0.1017]
Predicted label: 6
Correct prediction
Energy consumption = 196.827513 pJ
sum error= 208
Actual label: 2
Output voltages: [0.30311, 0.25887, 0.7383, 0.2752, 0.13039, 0.03465, 0.29184, 0.28512, 0.44337, 0.1662]
Predicted label: 2
Correct prediction
Energy consumption = 186.442942 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 490 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 490 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 490 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.29273, 0.38069, 0.36887, 0.31913, 0.080218, 0.049747, 0.064339, 0.71138, 0.32998, 0.32267]
Predicted label: 7
Correct prediction
Energy consumption = 197.299932 pJ
sum error= 208
Actual label: 9
Output voltages: [0.33236, 0.16642, 0.19362, 0.24759, 0.28473, 0.18898, 0.10126, 0.24129, 0.36498, 0.70071]
Predicted label: 9
Correct prediction
Energy consumption = 181.460321 pJ
sum error= 208
Actual label: 5
Output voltages: [0.22417, 0.092598, 0.072368, 0.44561, 0.14855, 0.66362, 0.19109, 0.16307, 0.44286, 0.26359]
Predicted label: 5
Correct prediction
Energy consumption = 190.638461 pJ
sum error= 208
Actual label: 1
Output voltages: [0.26537, 0.76887, 0.28128, 0.32066, 0.18949, 0.062668, 0.40313, 0.10693, 0.27347, 0.25707]
Predicted label: 1
Correct prediction
Energy consumption = 205.859404 pJ
sum error= 208
Actual label: 3
Output voltages: [0.3002, 0.21534, 0.35787, 0.74133, 0.14733, 0.11645, 0.13849, 0.10992, 0.45114, 0.22887]
Predicted label: 3
Correct prediction
Energy consumption = 190.638666 pJ
sum error= 208
Actual label: 2
Output voltages: [0.33952, 0.32272, 0.74193, 0.32989, 0.13286, 0.030692, 0.27455, 0.18808, 0.38651, 0.23028]
Predicted label: 2
Correct prediction
Energy consumption = 183.241527 pJ
sum error= 208
Actual label: 4
Output voltages: [0.12775, 0.17085, 0.29091, 0.1313, 0.75352, 0.073023, 0.34269, 0.31269, 0.21599, 0.22921]
Predicted label: 4
Correct prediction
Energy consumption = 198.582655 pJ
sum error= 208
Actual label: 3
Output voltages: [0.36138, 0.26994, 0.21273, 0.75077, 0.073191, 0.20371, 0.094286, 0.34812, 0.32414, 0.31388]
Predicted label: 3
Correct prediction
Energy consumption = 193.711196 pJ
sum error= 208
Actual label: 6
Output voltages: [0.30652, 0.19117, 0.2516, 0.15041, 0.32443, 0.40197, 0.72995, 0.065032, 0.41513, 0.1463]
Predicted label: 6
Correct prediction
Energy consumption = 190.934300 pJ
sum error= 208
Actual label: 1
Output voltages: [0.1386, 0.75334, 0.26022, 0.2175, 0.36058, 0.13418, 0.41522, 0.065173, 0.16425, 0.2618]
Predicted label: 1
Correct prediction
Energy consumption = 204.652645 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 491 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 491 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 491 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36028, 0.11118, 0.22769, 0.2482, 0.38117, 0.20372, 0.14423, 0.33269, 0.30814, 0.67241]
Predicted label: 9
Correct prediction
Energy consumption = 194.165606 pJ
sum error= 208
Actual label: 4
Output voltages: [0.31754, 0.22514, 0.29281, 0.19774, 0.52928, 0.064569, 0.26965, 0.061991, 0.3052, 0.56757]
Predicted label: 9
Wrong prediction!
Energy consumption = 200.255303 pJ
sum error= 209
Actual label: 4
Output voltages: [0.15936, 0.18323, 0.27004, 0.10745, 0.75312, 0.089621, 0.28503, 0.29021, 0.29844, 0.24757]
Predicted label: 4
Correct prediction
Energy consumption = 197.007779 pJ
sum error= 209
Actual label: 7
Output voltages: [0.30128, 0.22813, 0.3063, 0.26053, 0.15249, 0.050213, 0.066055, 0.74997, 0.26518, 0.36649]
Predicted label: 7
Correct prediction
Energy consumption = 201.318767 pJ
sum error= 209
Actual label: 6
Output voltages: [0.25004, 0.21043, 0.35186, 0.10987, 0.23988, 0.31739, 0.73954, 0.060064, 0.43049, 0.16573]
Predicted label: 6
Correct prediction
Energy consumption = 195.539903 pJ
sum error= 209
Actual label: 5
Output voltages: [0.20055, 0.049552, 0.14172, 0.30792, 0.2095, 0.54091, 0.38174, 0.11779, 0.51498, 0.33072]
Predicted label: 5
Correct prediction
Energy consumption = 190.599910 pJ
sum error= 209
Actual label: 4
Output voltages: [0.11557, 0.19587, 0.27709, 0.13485, 0.75311, 0.095144, 0.24399, 0.25006, 0.25229, 0.29474]
Predicted label: 4
Correct prediction
Energy consumption = 195.149438 pJ
sum error= 209
Actual label: 1
Output voltages: [0.19135, 0.75891, 0.28428, 0.16614, 0.23776, 0.12475, 0.3911, 0.11537, 0.35974, 0.23715]
Predicted label: 1
Correct prediction
Energy consumption = 210.192566 pJ
sum error= 209
Actual label: 9
Output voltages: [0.48281, 0.16391, 0.23319, 0.14615, 0.34259, 0.087583, 0.18935, 0.265, 0.34058, 0.60245]
Predicted label: 9
Correct prediction
Energy consumption = 204.458546 pJ
sum error= 209
Actual label: 9
Output voltages: [0.35815, 0.11862, 0.20917, 0.25054, 0.34014, 0.22086, 0.15802, 0.2692, 0.3273, 0.67093]
Predicted label: 9
Correct prediction
Energy consumption = 195.010417 pJ
sum error= 209
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 492 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 492 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 492 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36097, 0.16464, 0.73876, 0.33744, 0.16278, 0.034377, 0.22699, 0.31781, 0.42473, 0.1807]
Predicted label: 2
Correct prediction
Energy consumption = 184.705032 pJ
sum error= 209
Actual label: 7
Output voltages: [0.33662, 0.33525, 0.40046, 0.28865, 0.14759, 0.048616, 0.049959, 0.68075, 0.26645, 0.40809]
Predicted label: 7
Correct prediction
Energy consumption = 195.835764 pJ
sum error= 209
Actual label: 8
Output voltages: [0.23879, 0.18765, 0.28459, 0.36515, 0.092284, 0.22179, 0.21419, 0.18135, 0.73693, 0.27266]
Predicted label: 8
Correct prediction
Energy consumption = 201.889284 pJ
sum error= 209
Actual label: 0
Output voltages: [0.67716, 0.18699, 0.29279, 0.18284, 0.10619, 0.19457, 0.49647, 0.15329, 0.29482, 0.27039]
Predicted label: 0
Correct prediction
Energy consumption = 185.855445 pJ
sum error= 209
Actual label: 1
Output voltages: [0.27905, 0.7552, 0.42718, 0.21564, 0.24638, 0.052786, 0.31981, 0.18994, 0.25823, 0.24152]
Predicted label: 1
Correct prediction
Energy consumption = 208.009703 pJ
sum error= 209
Actual label: 3
Output voltages: [0.40321, 0.2208, 0.21099, 0.74719, 0.22562, 0.29365, 0.20615, 0.25147, 0.35598, 0.1809]
Predicted label: 3
Correct prediction
Energy consumption = 196.562797 pJ
sum error= 209
Actual label: 6
Output voltages: [0.33732, 0.1993, 0.20098, 0.18603, 0.34162, 0.36093, 0.72246, 0.065762, 0.40898, 0.17489]
Predicted label: 6
Correct prediction
Energy consumption = 192.014060 pJ
sum error= 209
Actual label: 1
Output voltages: [0.2357, 0.75952, 0.33533, 0.26332, 0.19215, 0.05436, 0.36019, 0.063522, 0.31418, 0.26258]
Predicted label: 1
Correct prediction
Energy consumption = 207.478916 pJ
sum error= 209
Actual label: 3
Output voltages: [0.36222, 0.25114, 0.32389, 0.75679, 0.096184, 0.17199, 0.10768, 0.28642, 0.48604, 0.24771]
Predicted label: 3
Correct prediction
Energy consumption = 194.677615 pJ
sum error= 209
Actual label: 4
Output voltages: [0.22618, 0.24372, 0.28072, 0.18158, 0.73359, 0.052862, 0.33296, 0.14834, 0.20119, 0.26236]
Predicted label: 4
Correct prediction
Energy consumption = 200.109237 pJ
sum error= 209
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 493 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 493 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 493 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16886, 0.76512, 0.30822, 0.31419, 0.2235, 0.13808, 0.41252, 0.1285, 0.20416, 0.23423]
Predicted label: 1
Correct prediction
Energy consumption = 207.409146 pJ
sum error= 209
Actual label: 1
Output voltages: [0.24652, 0.76385, 0.30626, 0.2437, 0.30702, 0.075973, 0.37448, 0.075344, 0.27118, 0.28184]
Predicted label: 1
Correct prediction
Energy consumption = 204.874110 pJ
sum error= 209
Actual label: 1
Output voltages: [0.22146, 0.73479, 0.19004, 0.18937, 0.39031, 0.11934, 0.38945, 0.16011, 0.25095, 0.21399]
Predicted label: 1
Correct prediction
Energy consumption = 203.929410 pJ
sum error= 209
Actual label: 5
Output voltages: [0.20784, 0.07972, 0.15024, 0.32991, 0.22286, 0.68958, 0.31318, 0.1614, 0.47857, 0.27705]
Predicted label: 5
Correct prediction
Energy consumption = 193.683424 pJ
sum error= 209
Actual label: 6
Output voltages: [0.33551, 0.14784, 0.23778, 0.13721, 0.30424, 0.4463, 0.71141, 0.04878, 0.38742, 0.20825]
Predicted label: 6
Correct prediction
Energy consumption = 184.669464 pJ
sum error= 209
Actual label: 0
Output voltages: [0.72285, 0.24753, 0.22197, 0.2052, 0.16746, 0.19707, 0.49872, 0.14354, 0.30666, 0.25049]
Predicted label: 0
Correct prediction
Energy consumption = 196.852365 pJ
sum error= 209
Actual label: 7
Output voltages: [0.37598, 0.24939, 0.41303, 0.17713, 0.14854, 0.056007, 0.057198, 0.73471, 0.35448, 0.3746]
Predicted label: 7
Correct prediction
Energy consumption = 190.537148 pJ
sum error= 209
Actual label: 0
Output voltages: [0.72192, 0.30606, 0.31754, 0.23115, 0.06398, 0.18411, 0.37198, 0.18362, 0.32086, 0.27376]
Predicted label: 0
Correct prediction
Energy consumption = 193.048909 pJ
sum error= 209
Actual label: 7
Output voltages: [0.37988, 0.29195, 0.2704, 0.41752, 0.06247, 0.049844, 0.048778, 0.72785, 0.316, 0.37546]
Predicted label: 7
Correct prediction
Energy consumption = 201.573278 pJ
sum error= 209
Actual label: 2
Output voltages: [0.33101, 0.34222, 0.62212, 0.39609, 0.087825, 0.021772, 0.17981, 0.37411, 0.38922, 0.15926]
Predicted label: 2
Correct prediction
Energy consumption = 185.946957 pJ
sum error= 209
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 494 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 494 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 494 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30985, 0.146, 0.29455, 0.74106, 0.22757, 0.25763, 0.17442, 0.21841, 0.42899, 0.15568]
Predicted label: 3
Correct prediction
Energy consumption = 190.060264 pJ
sum error= 209
Actual label: 2
Output voltages: [0.4793, 0.1244, 0.59853, 0.41621, 0.11161, 0.056769, 0.29511, 0.21174, 0.49154, 0.09188]
Predicted label: 2
Correct prediction
Energy consumption = 185.448332 pJ
sum error= 209
Actual label: 5
Output voltages: [0.20273, 0.11411, 0.13813, 0.49159, 0.19306, 0.62528, 0.24515, 0.17901, 0.40243, 0.22171]
Predicted label: 5
Correct prediction
Energy consumption = 195.149553 pJ
sum error= 209
Actual label: 2
Output voltages: [0.34438, 0.11281, 0.55229, 0.33335, 0.06297, 0.081282, 0.17741, 0.41976, 0.61805, 0.17076]
Predicted label: 8
Wrong prediction!
Energy consumption = 189.373370 pJ
sum error= 210
Actual label: 2
Output voltages: [0.33878, 0.126, 0.679, 0.39664, 0.13956, 0.057113, 0.27869, 0.30893, 0.48384, 0.11539]
Predicted label: 2
Correct prediction
Energy consumption = 185.832580 pJ
sum error= 210
Actual label: 9
Output voltages: [0.36256, 0.13851, 0.20756, 0.32973, 0.30498, 0.2074, 0.1201, 0.27449, 0.34114, 0.70162]
Predicted label: 9
Correct prediction
Energy consumption = 198.311879 pJ
sum error= 210
Actual label: 4
Output voltages: [0.18757, 0.13918, 0.29214, 0.24035, 0.7429, 0.042724, 0.15746, 0.22937, 0.26336, 0.22139]
Predicted label: 4
Correct prediction
Energy consumption = 185.802482 pJ
sum error= 210
Actual label: 9
Output voltages: [0.29126, 0.15356, 0.2001, 0.27821, 0.32115, 0.13161, 0.11233, 0.19884, 0.35767, 0.70103]
Predicted label: 9
Correct prediction
Energy consumption = 185.925011 pJ
sum error= 210
Actual label: 8
Output voltages: [0.16754, 0.19613, 0.28488, 0.32387, 0.17778, 0.11354, 0.24666, 0.10588, 0.69077, 0.26902]
Predicted label: 8
Correct prediction
Energy consumption = 203.327389 pJ
sum error= 210
Actual label: 1
Output voltages: [0.15356, 0.75924, 0.20199, 0.30198, 0.24036, 0.18851, 0.4068, 0.10093, 0.30008, 0.24909]
Predicted label: 1
Correct prediction
Energy consumption = 214.171447 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 495 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 495 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 495 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.4835, 0.17933, 0.68258, 0.4088, 0.14763, 0.036735, 0.25148, 0.2091, 0.45318, 0.2022]
Predicted label: 2
Correct prediction
Energy consumption = 200.131866 pJ
sum error= 210
Actual label: 1
Output voltages: [0.19535, 0.72048, 0.322, 0.26198, 0.38286, 0.047548, 0.21303, 0.2546, 0.21786, 0.27036]
Predicted label: 1
Correct prediction
Energy consumption = 201.680468 pJ
sum error= 210
Actual label: 6
Output voltages: [0.30342, 0.092135, 0.15964, 0.21248, 0.25138, 0.51228, 0.61509, 0.055048, 0.5032, 0.18737]
Predicted label: 6
Correct prediction
Energy consumption = 191.807949 pJ
sum error= 210
Actual label: 1
Output voltages: [0.14069, 0.76395, 0.24773, 0.31499, 0.13608, 0.16585, 0.31941, 0.18033, 0.37656, 0.27044]
Predicted label: 1
Correct prediction
Energy consumption = 210.398788 pJ
sum error= 210
Actual label: 2
Output voltages: [0.34627, 0.28261, 0.69763, 0.39011, 0.11304, 0.026045, 0.237, 0.22914, 0.43035, 0.24485]
Predicted label: 2
Correct prediction
Energy consumption = 187.751998 pJ
sum error= 210
Actual label: 7
Output voltages: [0.40798, 0.25436, 0.20552, 0.31274, 0.16123, 0.11238, 0.054831, 0.75736, 0.28928, 0.40383]
Predicted label: 7
Correct prediction
Energy consumption = 198.603717 pJ
sum error= 210
Actual label: 8
Output voltages: [0.17767, 0.14869, 0.21243, 0.20977, 0.53965, 0.23975, 0.21269, 0.10069, 0.50873, 0.2974]
Predicted label: 4
Wrong prediction!
Energy consumption = 203.840830 pJ
sum error= 211
Actual label: 0
Output voltages: [0.70962, 0.2159, 0.2578, 0.16775, 0.12438, 0.19996, 0.44668, 0.14606, 0.26183, 0.29084]
Predicted label: 0
Correct prediction
Energy consumption = 189.552576 pJ
sum error= 211
Actual label: 0
Output voltages: [0.71517, 0.24839, 0.29669, 0.1737, 0.14932, 0.12604, 0.46479, 0.18549, 0.3236, 0.23232]
Predicted label: 0
Correct prediction
Energy consumption = 187.958405 pJ
sum error= 211
Actual label: 0
Output voltages: [0.73105, 0.20528, 0.24445, 0.21744, 0.14782, 0.21306, 0.2982, 0.21323, 0.42747, 0.31607]
Predicted label: 0
Correct prediction
Energy consumption = 199.962568 pJ
sum error= 211
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 496 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 496 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 496 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.25975, 0.084269, 0.24481, 0.28066, 0.19806, 0.2708, 0.31582, 0.11023, 0.73003, 0.13602]
Predicted label: 8
Correct prediction
Energy consumption = 193.700514 pJ
sum error= 211
Actual label: 2
Output voltages: [0.34472, 0.31006, 0.72312, 0.33385, 0.1549, 0.028539, 0.32092, 0.16074, 0.44863, 0.28515]
Predicted label: 2
Correct prediction
Energy consumption = 185.536116 pJ
sum error= 211
Actual label: 2
Output voltages: [0.38935, 0.35382, 0.67174, 0.34625, 0.18645, 0.037476, 0.35147, 0.20721, 0.39634, 0.16817]
Predicted label: 2
Correct prediction
Energy consumption = 178.317404 pJ
sum error= 211
Actual label: 9
Output voltages: [0.37266, 0.12308, 0.20625, 0.3757, 0.34514, 0.16379, 0.054997, 0.30823, 0.33184, 0.63775]
Predicted label: 9
Correct prediction
Energy consumption = 199.216893 pJ
sum error= 211
Actual label: 2
Output voltages: [0.3488, 0.37478, 0.65665, 0.39811, 0.14594, 0.031523, 0.29828, 0.091064, 0.41952, 0.25612]
Predicted label: 2
Correct prediction
Energy consumption = 195.754571 pJ
sum error= 211
Actual label: 2
Output voltages: [0.34802, 0.3001, 0.72212, 0.36961, 0.15098, 0.026287, 0.31922, 0.17804, 0.39595, 0.19302]
Predicted label: 2
Correct prediction
Energy consumption = 181.004965 pJ
sum error= 211
Actual label: 7
Output voltages: [0.16903, 0.25969, 0.17641, 0.48961, 0.16318, 0.15461, 0.066766, 0.4581, 0.50234, 0.37987]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.904254 pJ
sum error= 212
Actual label: 9
Output voltages: [0.35418, 0.16501, 0.21873, 0.27903, 0.34429, 0.13716, 0.25614, 0.16262, 0.29236, 0.68456]
Predicted label: 9
Correct prediction
Energy consumption = 190.783700 pJ
sum error= 212
Actual label: 9
Output voltages: [0.48952, 0.070448, 0.29755, 0.22575, 0.22864, 0.19591, 0.24314, 0.1666, 0.30057, 0.66992]
Predicted label: 9
Correct prediction
Energy consumption = 188.147712 pJ
sum error= 212
Actual label: 2
Output voltages: [0.36736, 0.36179, 0.73048, 0.27077, 0.13679, 0.021304, 0.27944, 0.31649, 0.34032, 0.26803]
Predicted label: 2
Correct prediction
Energy consumption = 187.190430 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 497 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 497 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 497 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.2748, 0.32006, 0.28154, 0.25938, 0.089662, 0.04792, 0.045378, 0.71757, 0.3199, 0.39567]
Predicted label: 7
Correct prediction
Energy consumption = 204.602492 pJ
sum error= 212
Actual label: 5
Output voltages: [0.17589, 0.052716, 0.15925, 0.54083, 0.21092, 0.5448, 0.23778, 0.23256, 0.4442, 0.26937]
Predicted label: 5
Correct prediction
Energy consumption = 194.775503 pJ
sum error= 212
Actual label: 1
Output voltages: [0.21885, 0.74885, 0.14366, 0.14627, 0.40875, 0.16656, 0.41745, 0.15562, 0.26301, 0.25867]
Predicted label: 1
Correct prediction
Energy consumption = 213.207780 pJ
sum error= 212
Actual label: 3
Output voltages: [0.34111, 0.18853, 0.34121, 0.75286, 0.14222, 0.16032, 0.12728, 0.17001, 0.46077, 0.18638]
Predicted label: 3
Correct prediction
Energy consumption = 183.283486 pJ
sum error= 212
Actual label: 4
Output voltages: [0.23547, 0.14598, 0.40282, 0.16311, 0.74349, 0.043269, 0.28137, 0.33858, 0.19982, 0.20681]
Predicted label: 4
Correct prediction
Energy consumption = 189.969331 pJ
sum error= 212
Actual label: 9
Output voltages: [0.35934, 0.10475, 0.22592, 0.31068, 0.35593, 0.14204, 0.14864, 0.22279, 0.33346, 0.62829]
Predicted label: 9
Correct prediction
Energy consumption = 188.665267 pJ
sum error= 212
Actual label: 4
Output voltages: [0.183, 0.1657, 0.25617, 0.1758, 0.75017, 0.074083, 0.23697, 0.27441, 0.20203, 0.27666]
Predicted label: 4
Correct prediction
Energy consumption = 199.262188 pJ
sum error= 212
Actual label: 1
Output voltages: [0.24255, 0.7733, 0.27722, 0.29981, 0.14776, 0.068507, 0.39197, 0.11909, 0.29175, 0.26729]
Predicted label: 1
Correct prediction
Energy consumption = 210.873118 pJ
sum error= 212
Actual label: 8
Output voltages: [0.2047, 0.28216, 0.26181, 0.29395, 0.16159, 0.068856, 0.094795, 0.25329, 0.69387, 0.33477]
Predicted label: 8
Correct prediction
Energy consumption = 204.775581 pJ
sum error= 212
Actual label: 5
Output voltages: [0.24966, 0.060956, 0.10785, 0.4291, 0.23013, 0.72935, 0.2478, 0.23911, 0.52543, 0.26591]
Predicted label: 5
Correct prediction
Energy consumption = 183.946199 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 498 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 498 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 498 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.2913, 0.27826, 0.2863, 0.075194, 0.31396, 0.32378, 0.73181, 0.14599, 0.39234, 0.089269]
Predicted label: 6
Correct prediction
Energy consumption = 201.500795 pJ
sum error= 212
Actual label: 2
Output voltages: [0.41524, 0.21653, 0.71421, 0.38719, 0.15125, 0.036117, 0.29202, 0.21847, 0.48206, 0.16509]
Predicted label: 2
Correct prediction
Energy consumption = 187.831986 pJ
sum error= 212
Actual label: 8
Output voltages: [0.34869, 0.15169, 0.40281, 0.2587, 0.18784, 0.098075, 0.22984, 0.064396, 0.67727, 0.36562]
Predicted label: 8
Correct prediction
Energy consumption = 196.759276 pJ
sum error= 212
Actual label: 3
Output voltages: [0.37888, 0.13085, 0.31415, 0.74085, 0.1972, 0.15604, 0.091939, 0.21439, 0.49284, 0.2496]
Predicted label: 3
Correct prediction
Energy consumption = 186.681335 pJ
sum error= 212
Actual label: 1
Output voltages: [0.232, 0.76185, 0.22916, 0.25707, 0.34003, 0.12118, 0.33649, 0.096356, 0.18841, 0.32619]
Predicted label: 1
Correct prediction
Energy consumption = 207.920282 pJ
sum error= 212
Actual label: 2
Output voltages: [0.32526, 0.24447, 0.69318, 0.37929, 0.32734, 0.035665, 0.30841, 0.32702, 0.20206, 0.14473]
Predicted label: 2
Correct prediction
Energy consumption = 187.668837 pJ
sum error= 212
Actual label: 8
Output voltages: [0.22458, 0.19595, 0.30233, 0.26905, 0.1807, 0.22861, 0.33267, 0.086794, 0.72949, 0.30176]
Predicted label: 8
Correct prediction
Energy consumption = 195.596617 pJ
sum error= 212
Actual label: 4
Output voltages: [0.15913, 0.1838, 0.22948, 0.14866, 0.73773, 0.066817, 0.38621, 0.29443, 0.18769, 0.14727]
Predicted label: 4
Correct prediction
Energy consumption = 199.201741 pJ
sum error= 212
Actual label: 9
Output voltages: [0.37511, 0.082725, 0.2329, 0.21247, 0.29186, 0.1511, 0.08729, 0.25119, 0.42946, 0.62819]
Predicted label: 9
Correct prediction
Energy consumption = 195.606948 pJ
sum error= 212
Actual label: 9
Output voltages: [0.31645, 0.085666, 0.20112, 0.1981, 0.26754, 0.18382, 0.071848, 0.32921, 0.44388, 0.63725]
Predicted label: 9
Correct prediction
Energy consumption = 186.896559 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 499 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 499 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 499 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30502, 0.24181, 0.35247, 0.70072, 0.10017, 0.094953, 0.16229, 0.085805, 0.49555, 0.2654]
Predicted label: 3
Correct prediction
Energy consumption = 203.257811 pJ
sum error= 212
Actual label: 7
Output voltages: [0.31654, 0.23618, 0.26056, 0.24738, 0.11663, 0.084865, 0.032653, 0.71852, 0.38674, 0.38364]
Predicted label: 7
Correct prediction
Energy consumption = 203.104965 pJ
sum error= 212
Actual label: 0
Output voltages: [0.71634, 0.15834, 0.22999, 0.093067, 0.19265, 0.27444, 0.40879, 0.1385, 0.27365, 0.3111]
Predicted label: 0
Correct prediction
Energy consumption = 196.020499 pJ
sum error= 212
Actual label: 7
Output voltages: [0.24241, 0.25215, 0.20826, 0.24468, 0.18713, 0.129, 0.037021, 0.74611, 0.29423, 0.37874]
Predicted label: 7
Correct prediction
Energy consumption = 196.801467 pJ
sum error= 212
Actual label: 7
Output voltages: [0.23622, 0.29421, 0.20523, 0.26425, 0.13666, 0.074537, 0.041233, 0.68963, 0.3155, 0.38472]
Predicted label: 7
Correct prediction
Energy consumption = 198.508631 pJ
sum error= 212
Actual label: 2
Output voltages: [0.38674, 0.46779, 0.60358, 0.32012, 0.089686, 0.028677, 0.36143, 0.24809, 0.33012, 0.15131]
Predicted label: 2
Correct prediction
Energy consumption = 195.463670 pJ
sum error= 212
Actual label: 3
Output voltages: [0.39789, 0.1133, 0.18673, 0.74434, 0.21292, 0.35413, 0.2194, 0.22516, 0.40874, 0.16112]
Predicted label: 3
Correct prediction
Energy consumption = 189.064643 pJ
sum error= 212
Actual label: 2
Output voltages: [0.40869, 0.21262, 0.56037, 0.50425, 0.13771, 0.046744, 0.31204, 0.10455, 0.47911, 0.14374]
Predicted label: 2
Correct prediction
Energy consumption = 186.700030 pJ
sum error= 212
Actual label: 4
Output voltages: [0.12687, 0.22436, 0.24627, 0.13656, 0.73071, 0.056973, 0.27308, 0.25616, 0.28859, 0.292]
Predicted label: 4
Correct prediction
Energy consumption = 208.251217 pJ
sum error= 212
Actual label: 0
Output voltages: [0.74732, 0.22971, 0.28706, 0.1473, 0.1378, 0.25287, 0.35766, 0.1643, 0.24998, 0.24247]
Predicted label: 0
Correct prediction
Energy consumption = 192.331682 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 500 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 500 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 500 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29661, 0.19671, 0.36164, 0.73608, 0.2534, 0.19829, 0.17235, 0.16982, 0.44051, 0.11511]
Predicted label: 3
Correct prediction
Energy consumption = 184.748478 pJ
sum error= 212
Actual label: 9
Output voltages: [0.26779, 0.10753, 0.25214, 0.22669, 0.30916, 0.17686, 0.16034, 0.19596, 0.44855, 0.57131]
Predicted label: 9
Correct prediction
Energy consumption = 197.853818 pJ
sum error= 212
Actual label: 9
Output voltages: [0.31991, 0.139, 0.16884, 0.28038, 0.33752, 0.17561, 0.10829, 0.21478, 0.35857, 0.67274]
Predicted label: 9
Correct prediction
Energy consumption = 183.614095 pJ
sum error= 212
Actual label: 8
Output voltages: [0.17467, 0.20507, 0.27372, 0.2267, 0.15611, 0.20507, 0.1723, 0.18261, 0.74938, 0.27034]
Predicted label: 8
Correct prediction
Energy consumption = 182.543536 pJ
sum error= 212
Actual label: 4
Output voltages: [0.12176, 0.17113, 0.31077, 0.15035, 0.75223, 0.058117, 0.28544, 0.31023, 0.22202, 0.22052]
Predicted label: 4
Correct prediction
Energy consumption = 190.780431 pJ
sum error= 212
Actual label: 1
Output voltages: [0.24615, 0.7585, 0.22737, 0.18671, 0.37969, 0.13774, 0.37098, 0.1624, 0.25894, 0.23568]
Predicted label: 1
Correct prediction
Energy consumption = 207.231884 pJ
sum error= 212
Actual label: 0
Output voltages: [0.60962, 0.31224, 0.30138, 0.15456, 0.21211, 0.11428, 0.54794, 0.15594, 0.35169, 0.15655]
Predicted label: 0
Correct prediction
Energy consumption = 192.371066 pJ
sum error= 212
Actual label: 6
Output voltages: [0.32332, 0.2487, 0.28258, 0.06376, 0.34261, 0.32094, 0.74871, 0.077279, 0.35364, 0.13206]
Predicted label: 6
Correct prediction
Energy consumption = 180.373760 pJ
sum error= 212
Actual label: 0
Output voltages: [0.70086, 0.19754, 0.2546, 0.092671, 0.18102, 0.16242, 0.48064, 0.23648, 0.33436, 0.20294]
Predicted label: 0
Correct prediction
Energy consumption = 184.697109 pJ
sum error= 212
Actual label: 9
Output voltages: [0.31232, 0.11319, 0.11802, 0.24875, 0.39515, 0.32754, 0.19896, 0.19616, 0.3107, 0.61463]
Predicted label: 9
Correct prediction
Energy consumption = 187.144141 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 501 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 501 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 501 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30923, 0.22904, 0.30422, 0.095609, 0.35924, 0.31549, 0.74581, 0.097668, 0.37584, 0.12431]
Predicted label: 6
Correct prediction
Energy consumption = 193.648393 pJ
sum error= 212
Actual label: 8
Output voltages: [0.25413, 0.20251, 0.21933, 0.34356, 0.12463, 0.27501, 0.11908, 0.1251, 0.73261, 0.30359]
Predicted label: 8
Correct prediction
Energy consumption = 196.633922 pJ
sum error= 212
Actual label: 6
Output voltages: [0.28072, 0.27827, 0.31772, 0.07003, 0.35547, 0.29452, 0.74512, 0.080875, 0.33904, 0.10191]
Predicted label: 6
Correct prediction
Energy consumption = 192.229627 pJ
sum error= 212
Actual label: 1
Output voltages: [0.14207, 0.73484, 0.2955, 0.22568, 0.30145, 0.073846, 0.40338, 0.087649, 0.29714, 0.22375]
Predicted label: 1
Correct prediction
Energy consumption = 206.730195 pJ
sum error= 212
Actual label: 1
Output voltages: [0.14132, 0.75731, 0.23289, 0.18893, 0.30362, 0.081811, 0.37665, 0.097979, 0.37352, 0.26139]
Predicted label: 1
Correct prediction
Energy consumption = 205.136666 pJ
sum error= 212
Actual label: 9
Output voltages: [0.30599, 0.12369, 0.25769, 0.31996, 0.33228, 0.1303, 0.14895, 0.16621, 0.43541, 0.59092]
Predicted label: 9
Correct prediction
Energy consumption = 198.235245 pJ
sum error= 212
Actual label: 8
Output voltages: [0.24695, 0.14418, 0.33123, 0.27707, 0.15331, 0.20448, 0.21969, 0.12783, 0.73966, 0.28841]
Predicted label: 8
Correct prediction
Energy consumption = 186.402484 pJ
sum error= 212
Actual label: 9
Output voltages: [0.32911, 0.10827, 0.16324, 0.28869, 0.29368, 0.27156, 0.1934, 0.32029, 0.32963, 0.62677]
Predicted label: 9
Correct prediction
Energy consumption = 191.205329 pJ
sum error= 212
Actual label: 2
Output voltages: [0.39281, 0.15917, 0.75164, 0.33806, 0.19893, 0.045327, 0.24858, 0.30645, 0.39641, 0.14248]
Predicted label: 2
Correct prediction
Energy consumption = 185.791812 pJ
sum error= 212
Actual label: 3
Output voltages: [0.37083, 0.17751, 0.36915, 0.74322, 0.1549, 0.16991, 0.13683, 0.18739, 0.50537, 0.20811]
Predicted label: 3
Correct prediction
Energy consumption = 184.799649 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 502 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 502 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 502 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25913, 0.090169, 0.05445, 0.37567, 0.23411, 0.75283, 0.33708, 0.14611, 0.47282, 0.25564]
Predicted label: 5
Correct prediction
Energy consumption = 201.075126 pJ
sum error= 212
Actual label: 5
Output voltages: [0.25712, 0.052079, 0.056459, 0.39909, 0.24435, 0.75012, 0.28659, 0.21663, 0.48631, 0.22255]
Predicted label: 5
Correct prediction
Energy consumption = 185.154114 pJ
sum error= 212
Actual label: 9
Output voltages: [0.32716, 0.13451, 0.20034, 0.24977, 0.34504, 0.27826, 0.19068, 0.22231, 0.34881, 0.6761]
Predicted label: 9
Correct prediction
Energy consumption = 188.318659 pJ
sum error= 212
Actual label: 4
Output voltages: [0.14214, 0.16579, 0.18454, 0.13223, 0.75181, 0.10793, 0.31762, 0.30608, 0.26012, 0.18818]
Predicted label: 4
Correct prediction
Energy consumption = 190.158922 pJ
sum error= 212
Actual label: 2
Output voltages: [0.39833, 0.27567, 0.73659, 0.35091, 0.19474, 0.032951, 0.2885, 0.24691, 0.36975, 0.18943]
Predicted label: 2
Correct prediction
Energy consumption = 188.987475 pJ
sum error= 212
Actual label: 1
Output voltages: [0.27332, 0.72876, 0.26137, 0.16132, 0.45856, 0.071985, 0.32804, 0.087601, 0.23383, 0.27573]
Predicted label: 1
Correct prediction
Energy consumption = 204.411794 pJ
sum error= 212
Actual label: 9
Output voltages: [0.33187, 0.12072, 0.18059, 0.28913, 0.34719, 0.13873, 0.060462, 0.17979, 0.38638, 0.64738]
Predicted label: 9
Correct prediction
Energy consumption = 193.905540 pJ
sum error= 212
Actual label: 4
Output voltages: [0.11302, 0.14127, 0.2397, 0.17579, 0.73525, 0.094876, 0.17193, 0.26143, 0.32805, 0.19979]
Predicted label: 4
Correct prediction
Energy consumption = 192.705974 pJ
sum error= 212
Actual label: 3
Output voltages: [0.29697, 0.17877, 0.28157, 0.7623, 0.1916, 0.19472, 0.1318, 0.19993, 0.44118, 0.264]
Predicted label: 3
Correct prediction
Energy consumption = 181.757883 pJ
sum error= 212
Actual label: 9
Output voltages: [0.35079, 0.14241, 0.19502, 0.31402, 0.32442, 0.14515, 0.077112, 0.28482, 0.34908, 0.65045]
Predicted label: 9
Correct prediction
Energy consumption = 186.976576 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 503 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 503 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 503 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30115, 0.16988, 0.30792, 0.062304, 0.39648, 0.3424, 0.74229, 0.066263, 0.36837, 0.095995]
Predicted label: 6
Correct prediction
Energy consumption = 185.330961 pJ
sum error= 212
Actual label: 0
Output voltages: [0.70418, 0.22094, 0.33019, 0.16304, 0.19858, 0.060028, 0.38495, 0.1613, 0.36902, 0.22923]
Predicted label: 0
Correct prediction
Energy consumption = 187.257572 pJ
sum error= 212
Actual label: 4
Output voltages: [0.13877, 0.15137, 0.25845, 0.15893, 0.76063, 0.094583, 0.22116, 0.26945, 0.27852, 0.2124]
Predicted label: 4
Correct prediction
Energy consumption = 190.290158 pJ
sum error= 212
Actual label: 0
Output voltages: [0.72697, 0.24499, 0.2895, 0.20551, 0.19712, 0.095617, 0.34663, 0.21549, 0.33696, 0.19933]
Predicted label: 0
Correct prediction
Energy consumption = 193.611227 pJ
sum error= 212
Actual label: 6
Output voltages: [0.30762, 0.1865, 0.22188, 0.16237, 0.33274, 0.39311, 0.73441, 0.077393, 0.4081, 0.16161]
Predicted label: 6
Correct prediction
Energy consumption = 189.110618 pJ
sum error= 212
Actual label: 0
Output voltages: [0.67762, 0.18771, 0.21709, 0.13222, 0.18187, 0.17735, 0.50329, 0.16282, 0.30724, 0.23448]
Predicted label: 0
Correct prediction
Energy consumption = 186.678894 pJ
sum error= 212
Actual label: 1
Output voltages: [0.2189, 0.75533, 0.24402, 0.19299, 0.3298, 0.095912, 0.41937, 0.096435, 0.27734, 0.2356]
Predicted label: 1
Correct prediction
Energy consumption = 204.525811 pJ
sum error= 212
Actual label: 2
Output voltages: [0.27755, 0.2512, 0.74064, 0.23913, 0.18642, 0.03552, 0.24133, 0.34971, 0.44415, 0.12932]
Predicted label: 2
Correct prediction
Energy consumption = 193.179302 pJ
sum error= 212
Actual label: 3
Output voltages: [0.34659, 0.059594, 0.41537, 0.6596, 0.17685, 0.25197, 0.16336, 0.13508, 0.50318, 0.17131]
Predicted label: 3
Correct prediction
Energy consumption = 191.385736 pJ
sum error= 212
Actual label: 4
Output voltages: [0.16386, 0.16339, 0.27027, 0.21201, 0.75416, 0.10317, 0.23235, 0.22972, 0.21667, 0.20838]
Predicted label: 4
Correct prediction
Energy consumption = 189.617257 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 504 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 504 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 504 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26635, 0.28722, 0.35859, 0.1528, 0.25188, 0.042628, 0.035577, 0.68517, 0.33738, 0.36193]
Predicted label: 7
Correct prediction
Energy consumption = 199.265305 pJ
sum error= 212
Actual label: 8
Output voltages: [0.19886, 0.20945, 0.26176, 0.36929, 0.10185, 0.29291, 0.15949, 0.14743, 0.7497, 0.25023]
Predicted label: 8
Correct prediction
Energy consumption = 189.837469 pJ
sum error= 212
Actual label: 9
Output voltages: [0.33007, 0.11826, 0.19242, 0.35526, 0.25081, 0.17205, 0.05748, 0.33193, 0.4209, 0.65359]
Predicted label: 9
Correct prediction
Energy consumption = 188.768133 pJ
sum error= 212
Actual label: 0
Output voltages: [0.71911, 0.22268, 0.23536, 0.16247, 0.16692, 0.15801, 0.47189, 0.18016, 0.30987, 0.25353]
Predicted label: 0
Correct prediction
Energy consumption = 187.878992 pJ
sum error= 212
Actual label: 1
Output voltages: [0.20858, 0.75745, 0.30405, 0.15552, 0.2856, 0.092698, 0.44509, 0.12896, 0.2949, 0.2064]
Predicted label: 1
Correct prediction
Energy consumption = 204.944356 pJ
sum error= 212
Actual label: 2
Output voltages: [0.33249, 0.30774, 0.73045, 0.32671, 0.18048, 0.023359, 0.25247, 0.29853, 0.36762, 0.19894]
Predicted label: 2
Correct prediction
Energy consumption = 184.476023 pJ
sum error= 212
Actual label: 3
Output voltages: [0.32439, 0.062521, 0.29481, 0.71204, 0.22888, 0.32344, 0.26916, 0.17169, 0.40971, 0.12367]
Predicted label: 3
Correct prediction
Energy consumption = 189.131575 pJ
sum error= 212
Actual label: 4
Output voltages: [0.13982, 0.14423, 0.27095, 0.14588, 0.73892, 0.090516, 0.17999, 0.21287, 0.343, 0.23665]
Predicted label: 4
Correct prediction
Energy consumption = 184.687663 pJ
sum error= 212
Actual label: 7
Output voltages: [0.28911, 0.28736, 0.40691, 0.26478, 0.1493, 0.055784, 0.038682, 0.72026, 0.33349, 0.37481]
Predicted label: 7
Correct prediction
Energy consumption = 190.846020 pJ
sum error= 212
Actual label: 8
Output voltages: [0.23371, 0.13562, 0.24766, 0.34255, 0.082313, 0.37237, 0.28709, 0.10231, 0.71454, 0.24514]
Predicted label: 8
Correct prediction
Energy consumption = 183.418458 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 505 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 505 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 505 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.35731, 0.13948, 0.20336, 0.24227, 0.26804, 0.19579, 0.065004, 0.23356, 0.42521, 0.67469]
Predicted label: 9
Correct prediction
Energy consumption = 190.389470 pJ
sum error= 212
Actual label: 0
Output voltages: [0.71547, 0.17908, 0.25009, 0.15695, 0.18553, 0.14408, 0.44218, 0.17518, 0.36543, 0.18535]
Predicted label: 0
Correct prediction
Energy consumption = 191.351100 pJ
sum error= 212
Actual label: 1
Output voltages: [0.21279, 0.73678, 0.24549, 0.15429, 0.35385, 0.068079, 0.33337, 0.15627, 0.27327, 0.26447]
Predicted label: 1
Correct prediction
Energy consumption = 209.696714 pJ
sum error= 212
Actual label: 2
Output voltages: [0.30102, 0.21004, 0.75259, 0.25659, 0.1933, 0.039305, 0.26615, 0.24133, 0.43971, 0.20553]
Predicted label: 2
Correct prediction
Energy consumption = 182.292355 pJ
sum error= 212
Actual label: 3
Output voltages: [0.40529, 0.059804, 0.32667, 0.72386, 0.20711, 0.28533, 0.11708, 0.10871, 0.47241, 0.18671]
Predicted label: 3
Correct prediction
Energy consumption = 187.338208 pJ
sum error= 212
Actual label: 4
Output voltages: [0.197, 0.11707, 0.33534, 0.22313, 0.7461, 0.058409, 0.3153, 0.26923, 0.20656, 0.18104]
Predicted label: 4
Correct prediction
Energy consumption = 188.402100 pJ
sum error= 212
Actual label: 5
Output voltages: [0.31722, 0.057615, 0.055436, 0.27842, 0.2503, 0.74626, 0.42279, 0.185, 0.48164, 0.16224]
Predicted label: 5
Correct prediction
Energy consumption = 186.624237 pJ
sum error= 212
Actual label: 6
Output voltages: [0.3483, 0.28231, 0.26243, 0.096528, 0.3205, 0.34652, 0.74267, 0.060576, 0.31344, 0.16118]
Predicted label: 6
Correct prediction
Energy consumption = 186.926359 pJ
sum error= 212
Actual label: 7
Output voltages: [0.3082, 0.32621, 0.43874, 0.2586, 0.12145, 0.044411, 0.049745, 0.71681, 0.33142, 0.35435]
Predicted label: 7
Correct prediction
Energy consumption = 193.359231 pJ
sum error= 212
Actual label: 8
Output voltages: [0.19012, 0.1881, 0.31178, 0.31386, 0.12638, 0.29195, 0.19398, 0.14744, 0.74922, 0.25663]
Predicted label: 8
Correct prediction
Energy consumption = 186.320223 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 506 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 506 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 506 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33459, 0.10424, 0.1342, 0.22375, 0.29909, 0.34008, 0.16938, 0.2879, 0.36937, 0.63755]
Predicted label: 9
Correct prediction
Energy consumption = 187.004728 pJ
sum error= 212
Actual label: 8
Output voltages: [0.20889, 0.20758, 0.2818, 0.31647, 0.10441, 0.27518, 0.17421, 0.2738, 0.74561, 0.23408]
Predicted label: 8
Correct prediction
Energy consumption = 198.674764 pJ
sum error= 212
Actual label: 3
Output voltages: [0.2288, 0.23361, 0.28961, 0.67109, 0.15283, 0.26551, 0.12098, 0.08122, 0.52032, 0.29972]
Predicted label: 3
Correct prediction
Energy consumption = 188.598945 pJ
sum error= 212
Actual label: 4
Output voltages: [0.17437, 0.21889, 0.25343, 0.17279, 0.74832, 0.08455, 0.24248, 0.29118, 0.25018, 0.22537]
Predicted label: 4
Correct prediction
Energy consumption = 192.304136 pJ
sum error= 212
Actual label: 7
Output voltages: [0.30998, 0.32072, 0.44666, 0.18465, 0.1494, 0.037951, 0.043166, 0.70571, 0.33814, 0.27828]
Predicted label: 7
Correct prediction
Energy consumption = 194.297495 pJ
sum error= 212
Actual label: 8
Output voltages: [0.25144, 0.1503, 0.29371, 0.21454, 0.1218, 0.33529, 0.31672, 0.098081, 0.69069, 0.26231]
Predicted label: 8
Correct prediction
Energy consumption = 202.585327 pJ
sum error= 212
Actual label: 6
Output voltages: [0.39809, 0.26339, 0.17773, 0.23736, 0.28511, 0.34998, 0.72868, 0.049703, 0.30154, 0.17934]
Predicted label: 6
Correct prediction
Energy consumption = 192.497711 pJ
sum error= 212
Actual label: 3
Output voltages: [0.40158, 0.071242, 0.45124, 0.59537, 0.10213, 0.092639, 0.19084, 0.16842, 0.51965, 0.15901]
Predicted label: 3
Correct prediction
Energy consumption = 194.107203 pJ
sum error= 212
Actual label: 4
Output voltages: [0.20399, 0.36014, 0.10307, 0.3045, 0.6563, 0.084002, 0.23043, 0.2298, 0.25167, 0.30848]
Predicted label: 4
Correct prediction
Energy consumption = 207.886129 pJ
sum error= 212
Actual label: 0
Output voltages: [0.73132, 0.25511, 0.22041, 0.19315, 0.15372, 0.12357, 0.3987, 0.20599, 0.31075, 0.26897]
Predicted label: 0
Correct prediction
Energy consumption = 188.704296 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 507 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 507 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 507 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37989, 0.15205, 0.1582, 0.31193, 0.3557, 0.18742, 0.16459, 0.23089, 0.26754, 0.6202]
Predicted label: 9
Correct prediction
Energy consumption = 193.886250 pJ
sum error= 212
Actual label: 7
Output voltages: [0.29608, 0.20689, 0.28717, 0.27994, 0.16851, 0.080271, 0.041392, 0.75548, 0.29354, 0.31746]
Predicted label: 7
Correct prediction
Energy consumption = 190.116254 pJ
sum error= 212
Actual label: 1
Output voltages: [0.29756, 0.72726, 0.31862, 0.22993, 0.40692, 0.047448, 0.28326, 0.1728, 0.21979, 0.24866]
Predicted label: 1
Correct prediction
Energy consumption = 203.422613 pJ
sum error= 212
Actual label: 9
Output voltages: [0.30184, 0.13013, 0.22596, 0.31451, 0.27879, 0.13834, 0.064577, 0.22797, 0.40553, 0.66028]
Predicted label: 9
Correct prediction
Energy consumption = 189.104801 pJ
sum error= 212
Actual label: 3
Output voltages: [0.28027, 0.15791, 0.19171, 0.70888, 0.22973, 0.3916, 0.15493, 0.14413, 0.49603, 0.30172]
Predicted label: 3
Correct prediction
Energy consumption = 193.098391 pJ
sum error= 212
Actual label: 8
Output voltages: [0.20922, 0.21766, 0.25203, 0.25391, 0.14195, 0.27261, 0.17058, 0.16199, 0.75075, 0.30123]
Predicted label: 8
Correct prediction
Energy consumption = 185.505904 pJ
sum error= 212
Actual label: 4
Output voltages: [0.10854, 0.15731, 0.24376, 0.14517, 0.75547, 0.098811, 0.24133, 0.26215, 0.26886, 0.20149]
Predicted label: 4
Correct prediction
Energy consumption = 188.654442 pJ
sum error= 212
Actual label: 7
Output voltages: [0.28216, 0.3131, 0.42024, 0.1552, 0.17217, 0.041283, 0.043361, 0.73215, 0.34192, 0.33354]
Predicted label: 7
Correct prediction
Energy consumption = 192.544762 pJ
sum error= 212
Actual label: 3
Output voltages: [0.33234, 0.056949, 0.32637, 0.682, 0.1994, 0.31041, 0.12932, 0.090799, 0.50922, 0.15924]
Predicted label: 3
Correct prediction
Energy consumption = 189.828911 pJ
sum error= 212
Actual label: 0
Output voltages: [0.72272, 0.23859, 0.25747, 0.16981, 0.18466, 0.10071, 0.43265, 0.15091, 0.30996, 0.24674]
Predicted label: 0
Correct prediction
Energy consumption = 186.208488 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 508 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 508 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 508 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37865, 0.16139, 0.19834, 0.30568, 0.26676, 0.27619, 0.12971, 0.27144, 0.38396, 0.70758]
Predicted label: 9
Correct prediction
Energy consumption = 189.538648 pJ
sum error= 212
Actual label: 1
Output voltages: [0.18963, 0.75175, 0.18763, 0.28617, 0.33049, 0.061322, 0.35281, 0.11383, 0.27469, 0.26461]
Predicted label: 1
Correct prediction
Energy consumption = 211.070795 pJ
sum error= 212
Actual label: 4
Output voltages: [0.15039, 0.16533, 0.28076, 0.22961, 0.73296, 0.06412, 0.19924, 0.27673, 0.25768, 0.24719]
Predicted label: 4
Correct prediction
Energy consumption = 186.640881 pJ
sum error= 212
Actual label: 5
Output voltages: [0.30053, 0.13431, 0.10412, 0.31273, 0.17853, 0.71479, 0.44541, 0.13179, 0.53808, 0.056778]
Predicted label: 5
Correct prediction
Energy consumption = 187.965187 pJ
sum error= 212
Actual label: 4
Output voltages: [0.11521, 0.16159, 0.26251, 0.20947, 0.74063, 0.084392, 0.17328, 0.20013, 0.30091, 0.29633]
Predicted label: 4
Correct prediction
Energy consumption = 192.083813 pJ
sum error= 212
Actual label: 6
Output voltages: [0.36083, 0.20539, 0.23795, 0.12455, 0.3469, 0.32144, 0.73603, 0.051667, 0.35893, 0.18358]
Predicted label: 6
Correct prediction
Energy consumption = 189.901345 pJ
sum error= 212
Actual label: 2
Output voltages: [0.33258, 0.11608, 0.66559, 0.23858, 0.32264, 0.031101, 0.21771, 0.15677, 0.48912, 0.27417]
Predicted label: 2
Correct prediction
Energy consumption = 189.384401 pJ
sum error= 212
Actual label: 0
Output voltages: [0.72522, 0.23561, 0.23932, 0.1905, 0.15374, 0.14492, 0.399, 0.16728, 0.3829, 0.20619]
Predicted label: 0
Correct prediction
Energy consumption = 185.550527 pJ
sum error= 212
Actual label: 6
Output voltages: [0.37932, 0.20499, 0.27704, 0.16034, 0.28904, 0.20885, 0.65927, 0.054208, 0.46126, 0.18788]
Predicted label: 6
Correct prediction
Energy consumption = 188.934135 pJ
sum error= 212
Actual label: 2
Output voltages: [0.25172, 0.25705, 0.73897, 0.3268, 0.19896, 0.037205, 0.26776, 0.23236, 0.40997, 0.19557]
Predicted label: 2
Correct prediction
Energy consumption = 187.859276 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 509 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 509 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 509 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.19501, 0.70102, 0.17943, 0.20962, 0.44841, 0.10567, 0.38563, 0.052697, 0.297, 0.32482]
Predicted label: 1
Correct prediction
Energy consumption = 207.485346 pJ
sum error= 212
Actual label: 1
Output voltages: [0.27253, 0.6453, 0.18368, 0.1912, 0.4916, 0.096126, 0.35047, 0.05133, 0.34745, 0.25921]
Predicted label: 1
Correct prediction
Energy consumption = 199.336153 pJ
sum error= 212
Actual label: 1
Output voltages: [0.26708, 0.67507, 0.23805, 0.21033, 0.395, 0.057452, 0.34432, 0.056534, 0.31192, 0.29459]
Predicted label: 1
Correct prediction
Energy consumption = 201.157094 pJ
sum error= 212
Actual label: 1
Output voltages: [0.25789, 0.72914, 0.2708, 0.18676, 0.36319, 0.046242, 0.2675, 0.21441, 0.23967, 0.3442]
Predicted label: 1
Correct prediction
Energy consumption = 198.075257 pJ
sum error= 212
Actual label: 7
Output voltages: [0.27551, 0.26232, 0.31783, 0.24205, 0.18621, 0.062227, 0.037463, 0.75841, 0.28984, 0.2922]
Predicted label: 7
Correct prediction
Energy consumption = 193.376928 pJ
sum error= 212
Actual label: 2
Output voltages: [0.36331, 0.17098, 0.75151, 0.29665, 0.12119, 0.042437, 0.20149, 0.30595, 0.42952, 0.14273]
Predicted label: 2
Correct prediction
Energy consumption = 179.740308 pJ
sum error= 212
Actual label: 4
Output voltages: [0.15156, 0.20206, 0.27394, 0.20326, 0.75209, 0.071166, 0.22607, 0.26591, 0.19725, 0.21821]
Predicted label: 4
Correct prediction
Energy consumption = 191.309468 pJ
sum error= 212
Actual label: 7
Output voltages: [0.41337, 0.20338, 0.12459, 0.28577, 0.24394, 0.23315, 0.048145, 0.75125, 0.29756, 0.35333]
Predicted label: 7
Correct prediction
Energy consumption = 190.822088 pJ
sum error= 212
Actual label: 5
Output voltages: [0.32057, 0.17792, 0.065109, 0.39973, 0.17031, 0.74373, 0.26709, 0.090588, 0.48105, 0.11706]
Predicted label: 5
Correct prediction
Energy consumption = 191.591912 pJ
sum error= 212
Actual label: 2
Output voltages: [0.31877, 0.28219, 0.74348, 0.28792, 0.18372, 0.035435, 0.23286, 0.25989, 0.40795, 0.22518]
Predicted label: 2
Correct prediction
Energy consumption = 194.541093 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 510 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 510 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 510 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30898, 0.14551, 0.11926, 0.29366, 0.43548, 0.1571, 0.16686, 0.10564, 0.30809, 0.59995]
Predicted label: 9
Correct prediction
Energy consumption = 198.443684 pJ
sum error= 212
Actual label: 4
Output voltages: [0.15529, 0.19011, 0.25142, 0.19558, 0.73779, 0.047198, 0.20965, 0.21024, 0.25204, 0.22174]
Predicted label: 4
Correct prediction
Energy consumption = 191.762161 pJ
sum error= 212
Actual label: 5
Output voltages: [0.33425, 0.047637, 0.065632, 0.36513, 0.15535, 0.72108, 0.34924, 0.13894, 0.53451, 0.10402]
Predicted label: 5
Correct prediction
Energy consumption = 193.032766 pJ
sum error= 212
Actual label: 8
Output voltages: [0.16814, 0.23492, 0.20335, 0.21598, 0.17267, 0.3398, 0.22215, 0.17454, 0.74295, 0.24091]
Predicted label: 8
Correct prediction
Energy consumption = 182.917698 pJ
sum error= 212
Actual label: 4
Output voltages: [0.13916, 0.21067, 0.27053, 0.20331, 0.75326, 0.11691, 0.30355, 0.30166, 0.17646, 0.21543]
Predicted label: 4
Correct prediction
Energy consumption = 195.003508 pJ
sum error= 212
Actual label: 2
Output voltages: [0.32106, 0.26018, 0.74702, 0.25716, 0.20515, 0.035907, 0.29699, 0.31415, 0.32645, 0.15091]
Predicted label: 2
Correct prediction
Energy consumption = 191.800665 pJ
sum error= 212
Actual label: 9
Output voltages: [0.33852, 0.097058, 0.17152, 0.24988, 0.33371, 0.2088, 0.089232, 0.23698, 0.41739, 0.60079]
Predicted label: 9
Correct prediction
Energy consumption = 192.113018 pJ
sum error= 212
Actual label: 7
Output voltages: [0.30468, 0.31412, 0.39503, 0.21926, 0.20506, 0.049174, 0.04228, 0.75029, 0.24319, 0.29245]
Predicted label: 7
Correct prediction
Energy consumption = 190.238895 pJ
sum error= 212
Actual label: 0
Output voltages: [0.73632, 0.20421, 0.25, 0.17206, 0.16978, 0.18412, 0.43854, 0.21647, 0.3282, 0.16094]
Predicted label: 0
Correct prediction
Energy consumption = 189.842627 pJ
sum error= 212
Actual label: 0
Output voltages: [0.67638, 0.30729, 0.35266, 0.1608, 0.16725, 0.055246, 0.39535, 0.18481, 0.32251, 0.27805]
Predicted label: 0
Correct prediction
Energy consumption = 181.249571 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 511 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 511 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 511 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.2739, 0.33813, 0.37619, 0.20547, 0.21746, 0.054132, 0.035443, 0.73733, 0.2649, 0.32678]
Predicted label: 7
Correct prediction
Energy consumption = 196.162636 pJ
sum error= 212
Actual label: 5
Output voltages: [0.34453, 0.063268, 0.051794, 0.42321, 0.206, 0.74989, 0.35211, 0.15128, 0.46687, 0.14431]
Predicted label: 5
Correct prediction
Energy consumption = 186.031036 pJ
sum error= 212
Actual label: 1
Output voltages: [0.25919, 0.72925, 0.24491, 0.20859, 0.44103, 0.079053, 0.35822, 0.069552, 0.23247, 0.25655]
Predicted label: 1
Correct prediction
Energy consumption = 206.498913 pJ
sum error= 212
Actual label: 1
Output voltages: [0.22778, 0.73607, 0.22443, 0.22849, 0.44209, 0.050632, 0.34291, 0.12048, 0.17725, 0.25806]
Predicted label: 1
Correct prediction
Energy consumption = 198.265518 pJ
sum error= 212
Actual label: 7
Output voltages: [0.36727, 0.22413, 0.27058, 0.22839, 0.20375, 0.074089, 0.041498, 0.70838, 0.30138, 0.37134]
Predicted label: 7
Correct prediction
Energy consumption = 198.727859 pJ
sum error= 212
Actual label: 6
Output voltages: [0.35442, 0.23757, 0.24642, 0.14525, 0.30712, 0.315, 0.73313, 0.061671, 0.36894, 0.18491]
Predicted label: 6
Correct prediction
Energy consumption = 191.036114 pJ
sum error= 212
Actual label: 6
Output voltages: [0.31213, 0.21884, 0.30855, 0.076447, 0.33811, 0.32619, 0.74384, 0.068481, 0.34048, 0.1441]
Predicted label: 6
Correct prediction
Energy consumption = 183.745687 pJ
sum error= 212
Actual label: 6
Output voltages: [0.37231, 0.26659, 0.31561, 0.11736, 0.29506, 0.24402, 0.73166, 0.057475, 0.3934, 0.16097]
Predicted label: 6
Correct prediction
Energy consumption = 182.877630 pJ
sum error= 212
Actual label: 8
Output voltages: [0.25547, 0.15243, 0.21675, 0.39913, 0.080128, 0.34609, 0.23236, 0.098232, 0.72024, 0.23871]
Predicted label: 8
Correct prediction
Energy consumption = 193.984277 pJ
sum error= 212
Actual label: 2
Output voltages: [0.27224, 0.31316, 0.71884, 0.36785, 0.13322, 0.037028, 0.23344, 0.15261, 0.41473, 0.20325]
Predicted label: 2
Correct prediction
Energy consumption = 188.627187 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 512 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 512 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 512 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.26931, 0.24672, 0.71944, 0.34619, 0.17426, 0.040367, 0.27882, 0.22899, 0.43328, 0.17124]
Predicted label: 2
Correct prediction
Energy consumption = 189.244886 pJ
sum error= 212
Actual label: 7
Output voltages: [0.22835, 0.30966, 0.28165, 0.12845, 0.45047, 0.046017, 0.043518, 0.63429, 0.26838, 0.3239]
Predicted label: 7
Correct prediction
Energy consumption = 202.778145 pJ
sum error= 212
Actual label: 7
Output voltages: [0.28912, 0.30349, 0.35598, 0.23144, 0.19379, 0.049892, 0.042485, 0.74981, 0.26615, 0.31608]
Predicted label: 7
Correct prediction
Energy consumption = 189.686794 pJ
sum error= 212
Actual label: 4
Output voltages: [0.12387, 0.16639, 0.25665, 0.17753, 0.75451, 0.15608, 0.34157, 0.29203, 0.21887, 0.17414]
Predicted label: 4
Correct prediction
Energy consumption = 194.176063 pJ
sum error= 212
Actual label: 0
Output voltages: [0.7285, 0.25776, 0.28665, 0.14614, 0.14265, 0.089192, 0.40462, 0.18527, 0.31755, 0.28643]
Predicted label: 0
Correct prediction
Energy consumption = 182.442997 pJ
sum error= 212
Actual label: 2
Output voltages: [0.19895, 0.23116, 0.74994, 0.21854, 0.21188, 0.040563, 0.25788, 0.33997, 0.40573, 0.16344]
Predicted label: 2
Correct prediction
Energy consumption = 190.328925 pJ
sum error= 212
Actual label: 4
Output voltages: [0.23772, 0.21658, 0.36086, 0.23614, 0.72506, 0.04035, 0.26044, 0.24061, 0.1858, 0.23856]
Predicted label: 4
Correct prediction
Energy consumption = 192.110941 pJ
sum error= 212
Actual label: 2
Output voltages: [0.28426, 0.25864, 0.67557, 0.30711, 0.092884, 0.045997, 0.19158, 0.47217, 0.45031, 0.12078]
Predicted label: 2
Correct prediction
Energy consumption = 189.575169 pJ
sum error= 212
Actual label: 1
Output voltages: [0.16718, 0.7438, 0.24392, 0.23532, 0.35784, 0.099947, 0.39497, 0.13269, 0.2634, 0.24155]
Predicted label: 1
Correct prediction
Energy consumption = 206.799685 pJ
sum error= 212
Actual label: 8
Output voltages: [0.16793, 0.17068, 0.23216, 0.2957, 0.11543, 0.32762, 0.21362, 0.08351, 0.74239, 0.25082]
Predicted label: 8
Correct prediction
Energy consumption = 192.131345 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 513 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 513 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 513 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28903, 0.13424, 0.18816, 0.31555, 0.34974, 0.094372, 0.055941, 0.26269, 0.36602, 0.63695]
Predicted label: 9
Correct prediction
Energy consumption = 191.379849 pJ
sum error= 212
Actual label: 6
Output voltages: [0.30571, 0.19007, 0.21014, 0.19992, 0.29535, 0.38142, 0.72915, 0.061548, 0.46882, 0.20121]
Predicted label: 6
Correct prediction
Energy consumption = 189.551969 pJ
sum error= 212
Actual label: 1
Output voltages: [0.24547, 0.71718, 0.32555, 0.14686, 0.35926, 0.064546, 0.39307, 0.056522, 0.35142, 0.30119]
Predicted label: 1
Correct prediction
Energy consumption = 205.051046 pJ
sum error= 212
Actual label: 0
Output voltages: [0.72967, 0.23599, 0.31709, 0.17678, 0.19306, 0.084458, 0.40273, 0.15689, 0.32148, 0.23245]
Predicted label: 0
Correct prediction
Energy consumption = 187.319961 pJ
sum error= 212
Actual label: 5
Output voltages: [0.38352, 0.057006, 0.061513, 0.27413, 0.20583, 0.74278, 0.40189, 0.20895, 0.45186, 0.15887]
Predicted label: 5
Correct prediction
Energy consumption = 187.348243 pJ
sum error= 212
Actual label: 9
Output voltages: [0.28953, 0.089153, 0.14724, 0.29542, 0.40905, 0.26558, 0.10961, 0.30778, 0.32881, 0.55899]
Predicted label: 9
Correct prediction
Energy consumption = 191.998859 pJ
sum error= 212
Actual label: 6
Output voltages: [0.3766, 0.24895, 0.30332, 0.1332, 0.28071, 0.24868, 0.72147, 0.065697, 0.38086, 0.16327]
Predicted label: 6
Correct prediction
Energy consumption = 191.084191 pJ
sum error= 212
Actual label: 9
Output voltages: [0.32944, 0.1437, 0.17959, 0.23624, 0.25782, 0.18448, 0.069803, 0.26807, 0.44074, 0.6495]
Predicted label: 9
Correct prediction
Energy consumption = 191.394241 pJ
sum error= 212
Actual label: 8
Output voltages: [0.30516, 0.15024, 0.19213, 0.27978, 0.1244, 0.47213, 0.28749, 0.091948, 0.71835, 0.16132]
Predicted label: 8
Correct prediction
Energy consumption = 192.890996 pJ
sum error= 212
Actual label: 0
Output voltages: [0.68733, 0.27498, 0.27581, 0.19802, 0.1749, 0.087897, 0.44176, 0.18716, 0.32599, 0.26465]
Predicted label: 0
Correct prediction
Energy consumption = 191.450787 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 514 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 514 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 514 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32121, 0.052026, 0.32004, 0.4647, 0.1413, 0.32324, 0.24607, 0.056898, 0.53077, 0.16602]
Predicted label: 8
Wrong prediction!
Energy consumption = 195.166153 pJ
sum error= 213
Actual label: 0
Output voltages: [0.65422, 0.2277, 0.28934, 0.16233, 0.17928, 0.075449, 0.42284, 0.1722, 0.44719, 0.21169]
Predicted label: 0
Correct prediction
Energy consumption = 195.032412 pJ
sum error= 213
Actual label: 8
Output voltages: [0.13793, 0.25128, 0.30309, 0.33827, 0.11476, 0.20052, 0.12676, 0.2009, 0.7407, 0.24609]
Predicted label: 8
Correct prediction
Energy consumption = 193.119961 pJ
sum error= 213
Actual label: 3
Output voltages: [0.32454, 0.056414, 0.37489, 0.70378, 0.14238, 0.28917, 0.16926, 0.14, 0.48602, 0.1644]
Predicted label: 3
Correct prediction
Energy consumption = 184.152047 pJ
sum error= 213
Actual label: 9
Output voltages: [0.32114, 0.11854, 0.17728, 0.24827, 0.37126, 0.14761, 0.072325, 0.18768, 0.40284, 0.61887]
Predicted label: 9
Correct prediction
Energy consumption = 191.796046 pJ
sum error= 213
Actual label: 6
Output voltages: [0.46075, 0.21424, 0.1941, 0.14346, 0.29312, 0.26345, 0.67345, 0.076393, 0.34009, 0.19155]
Predicted label: 6
Correct prediction
Energy consumption = 189.921914 pJ
sum error= 213
Actual label: 3
Output voltages: [0.27193, 0.11928, 0.256, 0.71088, 0.22407, 0.2985, 0.13783, 0.14351, 0.54736, 0.2701]
Predicted label: 3
Correct prediction
Energy consumption = 189.210597 pJ
sum error= 213
Actual label: 0
Output voltages: [0.74394, 0.21918, 0.24034, 0.19981, 0.13341, 0.24823, 0.38101, 0.1931, 0.31844, 0.20963]
Predicted label: 0
Correct prediction
Energy consumption = 187.511979 pJ
sum error= 213
Actual label: 1
Output voltages: [0.15904, 0.74349, 0.20953, 0.23427, 0.27112, 0.15549, 0.44229, 0.054965, 0.3514, 0.24399]
Predicted label: 1
Correct prediction
Energy consumption = 206.644606 pJ
sum error= 213
Actual label: 2
Output voltages: [0.40301, 0.28613, 0.71936, 0.35076, 0.16835, 0.034627, 0.34218, 0.17698, 0.49078, 0.21344]
Predicted label: 2
Correct prediction
Energy consumption = 181.271113 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 515 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 515 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 515 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35616, 0.12758, 0.35072, 0.75897, 0.21856, 0.22484, 0.1327, 0.22022, 0.45764, 0.25046]
Predicted label: 3
Correct prediction
Energy consumption = 186.609228 pJ
sum error= 213
Actual label: 4
Output voltages: [0.12945, 0.14884, 0.26703, 0.14609, 0.73716, 0.07951, 0.20469, 0.28845, 0.30028, 0.33217]
Predicted label: 4
Correct prediction
Energy consumption = 197.546976 pJ
sum error= 213
Actual label: 5
Output voltages: [0.15925, 0.081365, 0.10268, 0.46865, 0.28445, 0.64088, 0.27442, 0.10585, 0.52202, 0.21791]
Predicted label: 5
Correct prediction
Energy consumption = 184.270078 pJ
sum error= 213
Actual label: 6
Output voltages: [0.25846, 0.27506, 0.35668, 0.078318, 0.32071, 0.31803, 0.74854, 0.083541, 0.36051, 0.14986]
Predicted label: 6
Correct prediction
Energy consumption = 182.298897 pJ
sum error= 213
Actual label: 7
Output voltages: [0.33897, 0.27306, 0.45729, 0.32154, 0.078102, 0.041899, 0.04527, 0.71224, 0.34522, 0.34169]
Predicted label: 7
Correct prediction
Energy consumption = 200.713961 pJ
sum error= 213
Actual label: 0
Output voltages: [0.66307, 0.18462, 0.30125, 0.12144, 0.23384, 0.10108, 0.48972, 0.2151, 0.26968, 0.29489]
Predicted label: 0
Correct prediction
Energy consumption = 189.051070 pJ
sum error= 213
Actual label: 1
Output voltages: [0.14392, 0.7522, 0.22154, 0.27017, 0.24993, 0.075367, 0.43777, 0.12661, 0.33807, 0.21274]
Predicted label: 1
Correct prediction
Energy consumption = 204.180839 pJ
sum error= 213
Actual label: 2
Output voltages: [0.37149, 0.34303, 0.69893, 0.42458, 0.13743, 0.029637, 0.27596, 0.13384, 0.3601, 0.20825]
Predicted label: 2
Correct prediction
Energy consumption = 188.112145 pJ
sum error= 213
Actual label: 3
Output voltages: [0.35635, 0.16481, 0.26869, 0.75118, 0.13971, 0.36757, 0.1716, 0.23066, 0.38548, 0.19025]
Predicted label: 3
Correct prediction
Energy consumption = 182.060665 pJ
sum error= 213
Actual label: 4
Output voltages: [0.14163, 0.17248, 0.27615, 0.16252, 0.63218, 0.066979, 0.12728, 0.25607, 0.33307, 0.40996]
Predicted label: 4
Correct prediction
Energy consumption = 196.329176 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 516 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 516 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 516 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.21444, 0.051813, 0.078232, 0.3572, 0.30589, 0.69723, 0.31895, 0.14747, 0.49837, 0.23325]
Predicted label: 5
Correct prediction
Energy consumption = 181.763693 pJ
sum error= 213
Actual label: 6
Output voltages: [0.26898, 0.21761, 0.33549, 0.058996, 0.39318, 0.28463, 0.74543, 0.061991, 0.32546, 0.16441]
Predicted label: 6
Correct prediction
Energy consumption = 181.836738 pJ
sum error= 213
Actual label: 7
Output voltages: [0.39582, 0.30637, 0.2833, 0.28787, 0.13108, 0.061709, 0.055692, 0.65685, 0.20139, 0.38885]
Predicted label: 7
Correct prediction
Energy consumption = 207.412586 pJ
sum error= 213
Actual label: 8
Output voltages: [0.19996, 0.1098, 0.3232, 0.23166, 0.11916, 0.29212, 0.19513, 0.14048, 0.73851, 0.27163]
Predicted label: 8
Correct prediction
Energy consumption = 183.997016 pJ
sum error= 213
Actual label: 9
Output voltages: [0.34775, 0.11465, 0.1889, 0.30749, 0.32799, 0.14513, 0.084933, 0.1485, 0.44016, 0.61962]
Predicted label: 9
Correct prediction
Energy consumption = 190.736728 pJ
sum error= 213
Actual label: 0
Output voltages: [0.62999, 0.26072, 0.27442, 0.25602, 0.1419, 0.15635, 0.45635, 0.20876, 0.4226, 0.10801]
Predicted label: 0
Correct prediction
Energy consumption = 195.814745 pJ
sum error= 213
Actual label: 1
Output voltages: [0.23271, 0.73646, 0.18641, 0.18331, 0.3904, 0.1156, 0.37253, 0.13439, 0.29502, 0.22707]
Predicted label: 1
Correct prediction
Energy consumption = 201.488662 pJ
sum error= 213
Actual label: 2
Output voltages: [0.41563, 0.23695, 0.7148, 0.41218, 0.0911, 0.045844, 0.25569, 0.16601, 0.45308, 0.15438]
Predicted label: 2
Correct prediction
Energy consumption = 186.870251 pJ
sum error= 213
Actual label: 3
Output voltages: [0.30821, 0.17452, 0.33075, 0.76004, 0.17566, 0.17117, 0.1341, 0.22622, 0.49656, 0.2329]
Predicted label: 3
Correct prediction
Energy consumption = 174.393288 pJ
sum error= 213
Actual label: 4
Output voltages: [0.15746, 0.16283, 0.27839, 0.13004, 0.75485, 0.14402, 0.2855, 0.27955, 0.24311, 0.27594]
Predicted label: 4
Correct prediction
Energy consumption = 194.295913 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 517 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 517 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 517 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27604, 0.041503, 0.095465, 0.44773, 0.22983, 0.66378, 0.30798, 0.16283, 0.47058, 0.22774]
Predicted label: 5
Correct prediction
Energy consumption = 186.919006 pJ
sum error= 213
Actual label: 6
Output voltages: [0.2939, 0.20192, 0.3429, 0.056929, 0.39024, 0.31416, 0.73883, 0.055997, 0.34428, 0.1418]
Predicted label: 6
Correct prediction
Energy consumption = 185.001528 pJ
sum error= 213
Actual label: 7
Output voltages: [0.3905, 0.19786, 0.25168, 0.35203, 0.20378, 0.12346, 0.052346, 0.75565, 0.23045, 0.31695]
Predicted label: 7
Correct prediction
Energy consumption = 203.647820 pJ
sum error= 213
Actual label: 8
Output voltages: [0.21193, 0.15104, 0.29525, 0.22486, 0.12488, 0.33834, 0.33762, 0.15143, 0.71006, 0.19736]
Predicted label: 8
Correct prediction
Energy consumption = 186.099648 pJ
sum error= 213
Actual label: 5
Output voltages: [0.20502, 0.046721, 0.10729, 0.32339, 0.19513, 0.68321, 0.2257, 0.1769, 0.58599, 0.23511]
Predicted label: 5
Correct prediction
Energy consumption = 188.658406 pJ
sum error= 213
Actual label: 4
Output voltages: [0.25563, 0.18337, 0.25151, 0.16444, 0.74115, 0.07437, 0.24769, 0.26982, 0.21645, 0.36974]
Predicted label: 4
Correct prediction
Energy consumption = 205.068536 pJ
sum error= 213
Actual label: 8
Output voltages: [0.10662, 0.1861, 0.31859, 0.086952, 0.46799, 0.1825, 0.30238, 0.087885, 0.60898, 0.16724]
Predicted label: 8
Correct prediction
Energy consumption = 181.937742 pJ
sum error= 213
Actual label: 7
Output voltages: [0.43502, 0.30598, 0.23669, 0.25803, 0.18097, 0.12615, 0.047331, 0.66977, 0.25054, 0.37935]
Predicted label: 7
Correct prediction
Energy consumption = 199.628398 pJ
sum error= 213
Actual label: 4
Output voltages: [0.18741, 0.18439, 0.29091, 0.20723, 0.74839, 0.066648, 0.24247, 0.27424, 0.18754, 0.33104]
Predicted label: 4
Correct prediction
Energy consumption = 200.642033 pJ
sum error= 213
Actual label: 7
Output voltages: [0.31308, 0.17546, 0.17028, 0.33718, 0.17307, 0.13636, 0.039649, 0.75531, 0.35557, 0.37236]
Predicted label: 7
Correct prediction
Energy consumption = 191.754345 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 518 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 518 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 518 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35835, 0.19772, 0.23203, 0.41842, 0.087566, 0.12278, 0.04021, 0.74465, 0.28206, 0.32199]
Predicted label: 7
Correct prediction
Energy consumption = 204.649025 pJ
sum error= 213
Actual label: 3
Output voltages: [0.25344, 0.22253, 0.37408, 0.74405, 0.15565, 0.19703, 0.10389, 0.17119, 0.502, 0.20043]
Predicted label: 3
Correct prediction
Energy consumption = 181.790398 pJ
sum error= 213
Actual label: 9
Output voltages: [0.31893, 0.087182, 0.19967, 0.33594, 0.34145, 0.087344, 0.051559, 0.24765, 0.37763, 0.60325]
Predicted label: 9
Correct prediction
Energy consumption = 190.386139 pJ
sum error= 213
Actual label: 8
Output voltages: [0.1451, 0.15446, 0.24423, 0.18138, 0.35036, 0.24047, 0.22045, 0.090074, 0.69051, 0.20049]
Predicted label: 8
Correct prediction
Energy consumption = 193.777435 pJ
sum error= 213
Actual label: 8
Output voltages: [0.13042, 0.19559, 0.21318, 0.29515, 0.16624, 0.29029, 0.20225, 0.17116, 0.74545, 0.22835]
Predicted label: 8
Correct prediction
Energy consumption = 191.488747 pJ
sum error= 213
Actual label: 3
Output voltages: [0.2462, 0.14548, 0.26553, 0.73141, 0.21247, 0.31728, 0.14827, 0.143, 0.50108, 0.21356]
Predicted label: 3
Correct prediction
Energy consumption = 178.780980 pJ
sum error= 213
Actual label: 1
Output voltages: [0.16532, 0.76583, 0.31807, 0.24004, 0.18686, 0.062985, 0.36708, 0.11971, 0.34186, 0.23648]
Predicted label: 1
Correct prediction
Energy consumption = 205.341179 pJ
sum error= 213
Actual label: 5
Output voltages: [0.24349, 0.052032, 0.1047, 0.44001, 0.29079, 0.66604, 0.28641, 0.15025, 0.51332, 0.20189]
Predicted label: 5
Correct prediction
Energy consumption = 186.825155 pJ
sum error= 213
Actual label: 8
Output voltages: [0.17305, 0.11902, 0.17573, 0.26579, 0.18461, 0.32438, 0.26258, 0.13244, 0.74332, 0.16143]
Predicted label: 8
Correct prediction
Energy consumption = 186.228458 pJ
sum error= 213
Actual label: 2
Output voltages: [0.31728, 0.30058, 0.7132, 0.37644, 0.12047, 0.038637, 0.27898, 0.12478, 0.46637, 0.18366]
Predicted label: 2
Correct prediction
Energy consumption = 182.843906 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 519 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 519 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 519 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34096, 0.25292, 0.45516, 0.24775, 0.17421, 0.05041, 0.053949, 0.72553, 0.29439, 0.38741]
Predicted label: 7
Correct prediction
Energy consumption = 195.041650 pJ
sum error= 213
Actual label: 4
Output voltages: [0.21486, 0.10417, 0.31709, 0.079414, 0.75418, 0.098883, 0.26789, 0.21827, 0.25754, 0.29642]
Predicted label: 4
Correct prediction
Energy consumption = 198.073090 pJ
sum error= 213
Actual label: 2
Output voltages: [0.37521, 0.24946, 0.72454, 0.33204, 0.1871, 0.026206, 0.28235, 0.22458, 0.43759, 0.27162]
Predicted label: 2
Correct prediction
Energy consumption = 184.671175 pJ
sum error= 213
Actual label: 1
Output voltages: [0.16115, 0.758, 0.223, 0.1817, 0.30551, 0.093477, 0.40997, 0.2244, 0.26969, 0.24332]
Predicted label: 1
Correct prediction
Energy consumption = 202.861807 pJ
sum error= 213
Actual label: 5
Output voltages: [0.23309, 0.048032, 0.082408, 0.34768, 0.38835, 0.58995, 0.34883, 0.095453, 0.48247, 0.22029]
Predicted label: 5
Correct prediction
Energy consumption = 197.851093 pJ
sum error= 213
Actual label: 4
Output voltages: [0.23927, 0.14547, 0.34479, 0.19214, 0.74468, 0.084004, 0.3716, 0.26342, 0.13618, 0.30997]
Predicted label: 4
Correct prediction
Energy consumption = 198.313111 pJ
sum error= 213
Actual label: 5
Output voltages: [0.22831, 0.051939, 0.061286, 0.37123, 0.29947, 0.70701, 0.33666, 0.13935, 0.53771, 0.2125]
Predicted label: 5
Correct prediction
Energy consumption = 180.950558 pJ
sum error= 213
Actual label: 5
Output voltages: [0.20077, 0.051521, 0.062151, 0.39728, 0.3097, 0.68332, 0.33219, 0.12457, 0.50119, 0.24956]
Predicted label: 5
Correct prediction
Energy consumption = 173.074335 pJ
sum error= 213
Actual label: 8
Output voltages: [0.14955, 0.2387, 0.24092, 0.20789, 0.25158, 0.21777, 0.19968, 0.13956, 0.74422, 0.22545]
Predicted label: 8
Correct prediction
Energy consumption = 188.781789 pJ
sum error= 213
Actual label: 6
Output voltages: [0.33581, 0.22255, 0.36366, 0.045931, 0.48951, 0.17594, 0.71308, 0.081083, 0.21265, 0.18286]
Predicted label: 6
Correct prediction
Energy consumption = 188.798931 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 520 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 520 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 520 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.208, 0.14527, 0.29262, 0.14853, 0.71658, 0.13766, 0.21515, 0.22846, 0.25993, 0.40377]
Predicted label: 4
Correct prediction
Energy consumption = 199.022271 pJ
sum error= 213
Actual label: 4
Output voltages: [0.34322, 0.1472, 0.25735, 0.15673, 0.56064, 0.090748, 0.41814, 0.090643, 0.18395, 0.47492]
Predicted label: 4
Correct prediction
Energy consumption = 204.520945 pJ
sum error= 213
Actual label: 4
Output voltages: [0.16997, 0.16902, 0.28473, 0.11916, 0.75936, 0.12791, 0.30791, 0.24657, 0.22136, 0.29183]
Predicted label: 4
Correct prediction
Energy consumption = 189.804880 pJ
sum error= 213
Actual label: 1
Output voltages: [0.24774, 0.70558, 0.39403, 0.36534, 0.18184, 0.037244, 0.15422, 0.22774, 0.30144, 0.29059]
Predicted label: 1
Correct prediction
Energy consumption = 213.962638 pJ
sum error= 213
Actual label: 8
Output voltages: [0.166, 0.2512, 0.33749, 0.32061, 0.097022, 0.17483, 0.18614, 0.19939, 0.73276, 0.2879]
Predicted label: 8
Correct prediction
Energy consumption = 196.307266 pJ
sum error= 213
Actual label: 7
Output voltages: [0.26293, 0.22838, 0.48245, 0.2388, 0.1277, 0.049359, 0.045111, 0.74763, 0.40207, 0.35057]
Predicted label: 7
Correct prediction
Energy consumption = 189.465622 pJ
sum error= 213
Actual label: 5
Output voltages: [0.26435, 0.050096, 0.058984, 0.41324, 0.26819, 0.67868, 0.3587, 0.20183, 0.45626, 0.25949]
Predicted label: 5
Correct prediction
Energy consumption = 183.997697 pJ
sum error= 213
Actual label: 5
Output voltages: [0.16065, 0.061041, 0.15474, 0.40984, 0.27669, 0.61734, 0.37168, 0.096157, 0.48508, 0.18247]
Predicted label: 5
Correct prediction
Energy consumption = 183.294525 pJ
sum error= 213
Actual label: 1
Output voltages: [0.1515, 0.75303, 0.22959, 0.17499, 0.30816, 0.16852, 0.48783, 0.15247, 0.29108, 0.23703]
Predicted label: 1
Correct prediction
Energy consumption = 205.078465 pJ
sum error= 213
Actual label: 8
Output voltages: [0.24782, 0.079824, 0.1942, 0.28696, 0.13303, 0.4447, 0.38364, 0.097121, 0.68499, 0.13381]
Predicted label: 8
Correct prediction
Energy consumption = 183.618717 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 521 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 521 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 521 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24513, 0.048636, 0.21223, 0.34517, 0.22164, 0.33193, 0.0714, 0.43845, 0.46705, 0.46887]
Predicted label: 9
Correct prediction
Energy consumption = 194.411176 pJ
sum error= 213
Actual label: 1
Output voltages: [0.21697, 0.76329, 0.14049, 0.28674, 0.2899, 0.092654, 0.37411, 0.13486, 0.27869, 0.27045]
Predicted label: 1
Correct prediction
Energy consumption = 212.719128 pJ
sum error= 213
Actual label: 3
Output voltages: [0.24746, 0.22194, 0.36503, 0.74562, 0.15893, 0.12231, 0.11823, 0.15887, 0.56762, 0.19694]
Predicted label: 3
Correct prediction
Energy consumption = 184.931620 pJ
sum error= 213
Actual label: 6
Output voltages: [0.27089, 0.20171, 0.25955, 0.11859, 0.43354, 0.31621, 0.72064, 0.073255, 0.35098, 0.089578]
Predicted label: 6
Correct prediction
Energy consumption = 190.709831 pJ
sum error= 213
Actual label: 3
Output voltages: [0.24345, 0.17941, 0.34531, 0.74657, 0.16474, 0.19149, 0.091964, 0.15208, 0.49561, 0.2371]
Predicted label: 3
Correct prediction
Energy consumption = 186.045017 pJ
sum error= 213
Actual label: 3
Output voltages: [0.2237, 0.21399, 0.36984, 0.74474, 0.19906, 0.16676, 0.10839, 0.18055, 0.48867, 0.22861]
Predicted label: 3
Correct prediction
Energy consumption = 177.468982 pJ
sum error= 213
Actual label: 2
Output voltages: [0.41951, 0.28445, 0.7285, 0.39548, 0.12567, 0.031733, 0.3076, 0.21213, 0.42198, 0.23146]
Predicted label: 2
Correct prediction
Energy consumption = 177.259548 pJ
sum error= 213
Actual label: 2
Output voltages: [0.31863, 0.28132, 0.64951, 0.4287, 0.079409, 0.039799, 0.25894, 0.14821, 0.51982, 0.26393]
Predicted label: 2
Correct prediction
Energy consumption = 177.413712 pJ
sum error= 213
Actual label: 6
Output voltages: [0.29569, 0.19091, 0.33317, 0.051961, 0.43475, 0.26103, 0.74296, 0.082446, 0.27122, 0.1577]
Predicted label: 6
Correct prediction
Energy consumption = 191.070891 pJ
sum error= 213
Actual label: 9
Output voltages: [0.31719, 0.13184, 0.19037, 0.23139, 0.29255, 0.16139, 0.074727, 0.15173, 0.4418, 0.64966]
Predicted label: 9
Correct prediction
Energy consumption = 185.012032 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 522 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 522 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 522 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39144, 0.11968, 0.19964, 0.25098, 0.34288, 0.17848, 0.088704, 0.14322, 0.3749, 0.66859]
Predicted label: 9
Correct prediction
Energy consumption = 198.614234 pJ
sum error= 213
Actual label: 6
Output voltages: [0.41258, 0.19697, 0.35942, 0.053135, 0.46332, 0.14923, 0.69828, 0.088083, 0.20604, 0.23759]
Predicted label: 6
Correct prediction
Energy consumption = 191.254767 pJ
sum error= 213
Actual label: 5
Output voltages: [0.28415, 0.042122, 0.057202, 0.35248, 0.25885, 0.68977, 0.31582, 0.14593, 0.54741, 0.25587]
Predicted label: 5
Correct prediction
Energy consumption = 184.122108 pJ
sum error= 213
Actual label: 5
Output voltages: [0.27076, 0.047457, 0.055714, 0.38553, 0.31088, 0.68346, 0.40411, 0.11812, 0.50643, 0.15543]
Predicted label: 5
Correct prediction
Energy consumption = 176.330148 pJ
sum error= 213
Actual label: 3
Output voltages: [0.27606, 0.12738, 0.32844, 0.73213, 0.20276, 0.27667, 0.098921, 0.15089, 0.53136, 0.20788]
Predicted label: 3
Correct prediction
Energy consumption = 180.365728 pJ
sum error= 213
Actual label: 3
Output voltages: [0.26667, 0.10516, 0.36707, 0.73427, 0.18592, 0.24397, 0.12929, 0.16427, 0.5484, 0.20369]
Predicted label: 3
Correct prediction
Energy consumption = 175.831288 pJ
sum error= 213
Actual label: 8
Output voltages: [0.15816, 0.15809, 0.27053, 0.23843, 0.15941, 0.30913, 0.30425, 0.1261, 0.73856, 0.24992]
Predicted label: 8
Correct prediction
Energy consumption = 185.903630 pJ
sum error= 213
Actual label: 1
Output voltages: [0.17235, 0.75204, 0.26034, 0.22937, 0.28795, 0.092713, 0.43669, 0.11599, 0.30162, 0.18344]
Predicted label: 1
Correct prediction
Energy consumption = 206.452822 pJ
sum error= 213
Actual label: 6
Output voltages: [0.30831, 0.2606, 0.22434, 0.056987, 0.60597, 0.31633, 0.58945, 0.17932, 0.16563, 0.12124]
Predicted label: 4
Wrong prediction!
Energy consumption = 197.996188 pJ
sum error= 214
Actual label: 5
Output voltages: [0.22219, 0.098724, 0.056503, 0.4678, 0.21393, 0.66978, 0.2567, 0.07871, 0.48858, 0.25812]
Predicted label: 5
Correct prediction
Energy consumption = 192.799771 pJ
sum error= 214
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 523 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 523 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 523 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.25867, 0.19578, 0.32324, 0.11093, 0.34601, 0.35219, 0.74181, 0.059007, 0.42097, 0.16247]
Predicted label: 6
Correct prediction
Energy consumption = 187.847924 pJ
sum error= 214
Actual label: 8
Output voltages: [0.13476, 0.20648, 0.21672, 0.17656, 0.29694, 0.35343, 0.27008, 0.18031, 0.74885, 0.18849]
Predicted label: 8
Correct prediction
Energy consumption = 191.429904 pJ
sum error= 214
Actual label: 1
Output voltages: [0.17402, 0.75879, 0.20259, 0.20183, 0.28461, 0.17767, 0.44108, 0.10249, 0.28889, 0.22347]
Predicted label: 1
Correct prediction
Energy consumption = 203.400913 pJ
sum error= 214
Actual label: 9
Output voltages: [0.34018, 0.14594, 0.20451, 0.30846, 0.30789, 0.1701, 0.13917, 0.23367, 0.33859, 0.67025]
Predicted label: 9
Correct prediction
Energy consumption = 196.220360 pJ
sum error= 214
Actual label: 7
Output voltages: [0.34436, 0.27033, 0.34901, 0.3379, 0.10863, 0.041271, 0.044111, 0.73389, 0.32488, 0.35656]
Predicted label: 7
Correct prediction
Energy consumption = 194.286659 pJ
sum error= 214
Actual label: 6
Output voltages: [0.2811, 0.18807, 0.35728, 0.057286, 0.46633, 0.24971, 0.73136, 0.059045, 0.31478, 0.19107]
Predicted label: 6
Correct prediction
Energy consumption = 186.706388 pJ
sum error= 214
Actual label: 8
Output voltages: [0.15781, 0.22507, 0.23032, 0.23567, 0.21702, 0.32267, 0.35931, 0.18158, 0.73331, 0.16797]
Predicted label: 8
Correct prediction
Energy consumption = 199.966493 pJ
sum error= 214
Actual label: 3
Output voltages: [0.28078, 0.17746, 0.40569, 0.74025, 0.1244, 0.09247, 0.090481, 0.19372, 0.54891, 0.19596]
Predicted label: 3
Correct prediction
Energy consumption = 186.059539 pJ
sum error= 214
Actual label: 7
Output voltages: [0.3972, 0.14183, 0.41068, 0.28872, 0.15173, 0.057491, 0.04438, 0.75194, 0.32076, 0.33734]
Predicted label: 7
Correct prediction
Energy consumption = 194.676533 pJ
sum error= 214
Actual label: 4
Output voltages: [0.17323, 0.14801, 0.26042, 0.13589, 0.71928, 0.073936, 0.19749, 0.31678, 0.27064, 0.28699]
Predicted label: 4
Correct prediction
Energy consumption = 188.090800 pJ
sum error= 214
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 524 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 524 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 524 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35418, 0.24914, 0.23664, 0.36581, 0.10512, 0.086568, 0.048418, 0.70163, 0.2338, 0.3624]
Predicted label: 7
Correct prediction
Energy consumption = 206.166612 pJ
sum error= 214
Actual label: 0
Output voltages: [0.73287, 0.25214, 0.27739, 0.21369, 0.13029, 0.1657, 0.43896, 0.15311, 0.26631, 0.29585]
Predicted label: 0
Correct prediction
Energy consumption = 193.813026 pJ
sum error= 214
Actual label: 9
Output voltages: [0.32059, 0.071682, 0.18463, 0.29593, 0.21324, 0.20618, 0.060738, 0.3777, 0.45377, 0.57264]
Predicted label: 9
Correct prediction
Energy consumption = 188.582360 pJ
sum error= 214
Actual label: 0
Output voltages: [0.67806, 0.17209, 0.24057, 0.16015, 0.16746, 0.18654, 0.43814, 0.19324, 0.2475, 0.34002]
Predicted label: 0
Correct prediction
Energy consumption = 184.953080 pJ
sum error= 214
Actual label: 0
Output voltages: [0.65686, 0.13668, 0.2579, 0.21571, 0.15318, 0.20511, 0.47395, 0.14411, 0.293, 0.3768]
Predicted label: 0
Correct prediction
Energy consumption = 186.975816 pJ
sum error= 214
Actual label: 3
Output voltages: [0.28458, 0.27688, 0.31095, 0.76288, 0.11328, 0.17683, 0.10152, 0.26551, 0.42762, 0.28533]
Predicted label: 3
Correct prediction
Energy consumption = 191.044316 pJ
sum error= 214
Actual label: 7
Output voltages: [0.26814, 0.28577, 0.61208, 0.27277, 0.11369, 0.034987, 0.070657, 0.53936, 0.41458, 0.41543]
Predicted label: 2
Wrong prediction!
Energy consumption = 192.963431 pJ
sum error= 215
Actual label: 9
Output voltages: [0.33591, 0.14696, 0.19028, 0.34528, 0.35612, 0.077428, 0.050329, 0.16117, 0.36661, 0.61776]
Predicted label: 9
Correct prediction
Energy consumption = 189.209288 pJ
sum error= 215
Actual label: 3
Output voltages: [0.31313, 0.18261, 0.29154, 0.7618, 0.18179, 0.22844, 0.11282, 0.18256, 0.48692, 0.21177]
Predicted label: 3
Correct prediction
Energy consumption = 181.540485 pJ
sum error= 215
Actual label: 0
Output voltages: [0.6979, 0.21609, 0.27051, 0.21422, 0.15778, 0.1003, 0.46327, 0.14992, 0.3369, 0.26998]
Predicted label: 0
Correct prediction
Energy consumption = 194.054685 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 525 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 525 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 525 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.29769, 0.12824, 0.70431, 0.40799, 0.14916, 0.05836, 0.24067, 0.15204, 0.51044, 0.17879]
Predicted label: 2
Correct prediction
Energy consumption = 184.404586 pJ
sum error= 215
Actual label: 0
Output voltages: [0.72043, 0.17512, 0.24299, 0.18911, 0.15708, 0.26758, 0.4187, 0.19668, 0.1931, 0.313]
Predicted label: 0
Correct prediction
Energy consumption = 189.945287 pJ
sum error= 215
Actual label: 1
Output voltages: [0.15885, 0.73856, 0.17875, 0.24047, 0.39428, 0.12281, 0.39865, 0.20977, 0.24347, 0.22582]
Predicted label: 1
Correct prediction
Energy consumption = 203.217740 pJ
sum error= 215
Actual label: 0
Output voltages: [0.62286, 0.23603, 0.37598, 0.18868, 0.18612, 0.057198, 0.42212, 0.16719, 0.39848, 0.1754]
Predicted label: 0
Correct prediction
Energy consumption = 193.542674 pJ
sum error= 215
Actual label: 1
Output voltages: [0.25259, 0.73151, 0.26272, 0.1788, 0.36348, 0.16879, 0.49087, 0.040687, 0.26943, 0.21192]
Predicted label: 1
Correct prediction
Energy consumption = 200.395221 pJ
sum error= 215
Actual label: 0
Output voltages: [0.57125, 0.29149, 0.31801, 0.13881, 0.22446, 0.16925, 0.54202, 0.13999, 0.37292, 0.1395]
Predicted label: 0
Correct prediction
Energy consumption = 201.075477 pJ
sum error= 215
Actual label: 4
Output voltages: [0.17887, 0.1313, 0.32488, 0.14425, 0.7504, 0.061706, 0.27863, 0.30355, 0.18699, 0.22362]
Predicted label: 4
Correct prediction
Energy consumption = 190.082885 pJ
sum error= 215
Actual label: 0
Output voltages: [0.65504, 0.18813, 0.34112, 0.18463, 0.20587, 0.081421, 0.35626, 0.21152, 0.42218, 0.14803]
Predicted label: 0
Correct prediction
Energy consumption = 194.786990 pJ
sum error= 215
Actual label: 1
Output voltages: [0.26445, 0.66737, 0.25977, 0.092093, 0.43035, 0.11817, 0.40239, 0.045036, 0.32057, 0.28429]
Predicted label: 1
Correct prediction
Energy consumption = 200.691585 pJ
sum error= 215
Actual label: 0
Output voltages: [0.74929, 0.23688, 0.25509, 0.18533, 0.15066, 0.18186, 0.3988, 0.1895, 0.27626, 0.23474]
Predicted label: 0
Correct prediction
Energy consumption = 185.840949 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 526 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 526 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 526 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19776, 0.17516, 0.3526, 0.10904, 0.65761, 0.042421, 0.2356, 0.19097, 0.40492, 0.17783]
Predicted label: 4
Correct prediction
Energy consumption = 190.152706 pJ
sum error= 215
Actual label: 7
Output voltages: [0.33935, 0.24089, 0.47857, 0.28112, 0.12241, 0.04579, 0.047326, 0.65321, 0.31918, 0.45785]
Predicted label: 7
Correct prediction
Energy consumption = 196.907283 pJ
sum error= 215
Actual label: 9
Output voltages: [0.3198, 0.14711, 0.19342, 0.27274, 0.36667, 0.13862, 0.057273, 0.16473, 0.36762, 0.66319]
Predicted label: 9
Correct prediction
Energy consumption = 192.408346 pJ
sum error= 215
Actual label: 6
Output voltages: [0.28303, 0.15276, 0.35017, 0.044172, 0.41012, 0.2644, 0.72986, 0.063987, 0.31173, 0.15185]
Predicted label: 6
Correct prediction
Energy consumption = 187.153939 pJ
sum error= 215
Actual label: 2
Output voltages: [0.37467, 0.24295, 0.73052, 0.3503, 0.16033, 0.034423, 0.271, 0.22326, 0.47236, 0.23446]
Predicted label: 2
Correct prediction
Energy consumption = 179.784984 pJ
sum error= 215
Actual label: 6
Output voltages: [0.24086, 0.13409, 0.28738, 0.054464, 0.46757, 0.25637, 0.68227, 0.085967, 0.30788, 0.13212]
Predicted label: 6
Correct prediction
Energy consumption = 192.602533 pJ
sum error= 215
Actual label: 2
Output voltages: [0.3594, 0.32438, 0.69143, 0.38726, 0.14616, 0.034478, 0.27287, 0.15731, 0.44713, 0.23449]
Predicted label: 2
Correct prediction
Energy consumption = 189.684157 pJ
sum error= 215
Actual label: 2
Output voltages: [0.42892, 0.21328, 0.69789, 0.42537, 0.082941, 0.050087, 0.22512, 0.18776, 0.49669, 0.16486]
Predicted label: 2
Correct prediction
Energy consumption = 179.566285 pJ
sum error= 215
Actual label: 9
Output voltages: [0.28664, 0.06177, 0.19271, 0.22824, 0.24439, 0.19985, 0.047365, 0.34664, 0.52555, 0.59173]
Predicted label: 9
Correct prediction
Energy consumption = 194.451681 pJ
sum error= 215
Actual label: 9
Output voltages: [0.35419, 0.10971, 0.25199, 0.18471, 0.32154, 0.10189, 0.054938, 0.2201, 0.46674, 0.61734]
Predicted label: 9
Correct prediction
Energy consumption = 190.159884 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 527 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 527 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 527 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73681, 0.20635, 0.20693, 0.183, 0.17819, 0.24834, 0.38647, 0.16759, 0.33371, 0.32154]
Predicted label: 0
Correct prediction
Energy consumption = 198.454610 pJ
sum error= 215
Actual label: 1
Output voltages: [0.18819, 0.75485, 0.27136, 0.27789, 0.25626, 0.055208, 0.3697, 0.14078, 0.32685, 0.19741]
Predicted label: 1
Correct prediction
Energy consumption = 207.300386 pJ
sum error= 215
Actual label: 2
Output voltages: [0.36415, 0.2119, 0.73362, 0.38608, 0.16265, 0.038388, 0.21116, 0.28378, 0.38656, 0.12885]
Predicted label: 2
Correct prediction
Energy consumption = 187.865857 pJ
sum error= 215
Actual label: 3
Output voltages: [0.34561, 0.10309, 0.28307, 0.75108, 0.20605, 0.21973, 0.17827, 0.21535, 0.40656, 0.22774]
Predicted label: 3
Correct prediction
Energy consumption = 188.669483 pJ
sum error= 215
Actual label: 4
Output voltages: [0.13508, 0.15979, 0.24345, 0.087425, 0.75029, 0.13581, 0.28958, 0.28003, 0.32705, 0.17765]
Predicted label: 4
Correct prediction
Energy consumption = 190.606710 pJ
sum error= 215
Actual label: 5
Output voltages: [0.25292, 0.06774, 0.14693, 0.38, 0.20199, 0.69783, 0.21562, 0.19379, 0.54258, 0.31803]
Predicted label: 5
Correct prediction
Energy consumption = 188.498212 pJ
sum error= 215
Actual label: 6
Output voltages: [0.28833, 0.17076, 0.25663, 0.14439, 0.37966, 0.39106, 0.73904, 0.063422, 0.36779, 0.14665]
Predicted label: 6
Correct prediction
Energy consumption = 185.360666 pJ
sum error= 215
Actual label: 7
Output voltages: [0.29468, 0.24422, 0.33899, 0.2802, 0.089176, 0.046874, 0.053769, 0.74923, 0.37473, 0.28863]
Predicted label: 7
Correct prediction
Energy consumption = 199.566406 pJ
sum error= 215
Actual label: 8
Output voltages: [0.3299, 0.2038, 0.3075, 0.12614, 0.17569, 0.089139, 0.1493, 0.21915, 0.64931, 0.45242]
Predicted label: 8
Correct prediction
Energy consumption = 190.638770 pJ
sum error= 215
Actual label: 9
Output voltages: [0.3851, 0.11668, 0.20852, 0.21155, 0.26992, 0.17021, 0.08395, 0.24064, 0.44406, 0.68355]
Predicted label: 9
Correct prediction
Energy consumption = 182.303000 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 528 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 528 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 528 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69418, 0.24982, 0.27015, 0.17244, 0.19557, 0.14533, 0.47709, 0.14923, 0.33515, 0.22048]
Predicted label: 0
Correct prediction
Energy consumption = 198.241675 pJ
sum error= 215
Actual label: 1
Output voltages: [0.22728, 0.70742, 0.2312, 0.16663, 0.47644, 0.10316, 0.3869, 0.053526, 0.27265, 0.27593]
Predicted label: 1
Correct prediction
Energy consumption = 205.356526 pJ
sum error= 215
Actual label: 2
Output voltages: [0.40029, 0.16438, 0.74774, 0.31526, 0.18784, 0.040114, 0.24034, 0.29653, 0.42223, 0.17055]
Predicted label: 2
Correct prediction
Energy consumption = 184.252097 pJ
sum error= 215
Actual label: 3
Output voltages: [0.24682, 0.12645, 0.35103, 0.69875, 0.15783, 0.15097, 0.1639, 0.18064, 0.56851, 0.25847]
Predicted label: 3
Correct prediction
Energy consumption = 186.097078 pJ
sum error= 215
Actual label: 4
Output voltages: [0.22645, 0.18461, 0.26908, 0.12952, 0.74126, 0.065143, 0.30167, 0.25388, 0.24747, 0.21161]
Predicted label: 4
Correct prediction
Energy consumption = 193.542233 pJ
sum error= 215
Actual label: 5
Output voltages: [0.25374, 0.044851, 0.10442, 0.35688, 0.27645, 0.70532, 0.30132, 0.17919, 0.53274, 0.29123]
Predicted label: 5
Correct prediction
Energy consumption = 184.931411 pJ
sum error= 215
Actual label: 6
Output voltages: [0.27789, 0.18469, 0.23547, 0.19308, 0.32122, 0.40384, 0.72249, 0.059439, 0.40984, 0.13916]
Predicted label: 6
Correct prediction
Energy consumption = 190.406648 pJ
sum error= 215
Actual label: 7
Output voltages: [0.41063, 0.27828, 0.21203, 0.28824, 0.10231, 0.18037, 0.054361, 0.73547, 0.3542, 0.30737]
Predicted label: 7
Correct prediction
Energy consumption = 202.028027 pJ
sum error= 215
Actual label: 8
Output voltages: [0.42802, 0.17899, 0.37368, 0.10347, 0.17385, 0.056045, 0.15122, 0.20304, 0.62572, 0.39881]
Predicted label: 8
Correct prediction
Energy consumption = 190.502649 pJ
sum error= 215
Actual label: 9
Output voltages: [0.38133, 0.077828, 0.16546, 0.22762, 0.27937, 0.26646, 0.078551, 0.26722, 0.43451, 0.63196]
Predicted label: 9
Correct prediction
Energy consumption = 189.361819 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 529 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 529 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 529 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.68007, 0.24595, 0.29045, 0.18558, 0.16478, 0.081475, 0.42918, 0.15213, 0.36418, 0.29529]
Predicted label: 0
Correct prediction
Energy consumption = 197.623989 pJ
sum error= 215
Actual label: 1
Output voltages: [0.19116, 0.73848, 0.22823, 0.26515, 0.34111, 0.078262, 0.36665, 0.085747, 0.32792, 0.27445]
Predicted label: 1
Correct prediction
Energy consumption = 206.543630 pJ
sum error= 215
Actual label: 2
Output voltages: [0.38683, 0.12483, 0.74684, 0.36932, 0.16717, 0.05418, 0.24173, 0.31064, 0.40399, 0.14397]
Predicted label: 2
Correct prediction
Energy consumption = 188.829957 pJ
sum error= 215
Actual label: 3
Output voltages: [0.39809, 0.1188, 0.32933, 0.75243, 0.19626, 0.16467, 0.17995, 0.177, 0.4136, 0.22872]
Predicted label: 3
Correct prediction
Energy consumption = 182.083408 pJ
sum error= 215
Actual label: 4
Output voltages: [0.15332, 0.17326, 0.26655, 0.14153, 0.74996, 0.083895, 0.31054, 0.28862, 0.21221, 0.20122]
Predicted label: 4
Correct prediction
Energy consumption = 190.845350 pJ
sum error= 215
Actual label: 5
Output voltages: [0.22596, 0.055515, 0.13981, 0.35675, 0.18435, 0.70622, 0.24834, 0.19342, 0.56932, 0.23571]
Predicted label: 5
Correct prediction
Energy consumption = 190.329708 pJ
sum error= 215
Actual label: 6
Output voltages: [0.2849, 0.22304, 0.27849, 0.11684, 0.28865, 0.35056, 0.74208, 0.099029, 0.44393, 0.13925]
Predicted label: 6
Correct prediction
Energy consumption = 184.664949 pJ
sum error= 215
Actual label: 7
Output voltages: [0.31929, 0.19475, 0.3366, 0.33886, 0.1502, 0.047082, 0.045508, 0.75659, 0.36042, 0.28535]
Predicted label: 7
Correct prediction
Energy consumption = 193.031736 pJ
sum error= 215
Actual label: 8
Output voltages: [0.34727, 0.26031, 0.36226, 0.11646, 0.19208, 0.10829, 0.25047, 0.122, 0.68763, 0.28479]
Predicted label: 8
Correct prediction
Energy consumption = 190.995045 pJ
sum error= 215
Actual label: 9
Output voltages: [0.34922, 0.13155, 0.19559, 0.26521, 0.18796, 0.21837, 0.059287, 0.338, 0.47053, 0.59059]
Predicted label: 9
Correct prediction
Energy consumption = 194.209578 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 530 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 530 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 530 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26102, 0.32723, 0.32123, 0.27537, 0.19497, 0.10646, 0.29386, 0.084879, 0.73064, 0.31798]
Predicted label: 8
Correct prediction
Energy consumption = 207.648293 pJ
sum error= 215
Actual label: 0
Output voltages: [0.69054, 0.27949, 0.33882, 0.21959, 0.16441, 0.068492, 0.39997, 0.18245, 0.38364, 0.27821]
Predicted label: 0
Correct prediction
Energy consumption = 205.933968 pJ
sum error= 215
Actual label: 5
Output voltages: [0.19949, 0.052186, 0.12981, 0.45562, 0.18554, 0.63055, 0.24373, 0.17534, 0.45303, 0.27514]
Predicted label: 5
Correct prediction
Energy consumption = 191.952195 pJ
sum error= 215
Actual label: 6
Output voltages: [0.29113, 0.2449, 0.28084, 0.12683, 0.34535, 0.46443, 0.73868, 0.088561, 0.38865, 0.093865]
Predicted label: 6
Correct prediction
Energy consumption = 190.157630 pJ
sum error= 215
Actual label: 6
Output voltages: [0.32734, 0.2188, 0.2531, 0.18247, 0.30075, 0.41756, 0.72833, 0.082606, 0.43695, 0.13078]
Predicted label: 6
Correct prediction
Energy consumption = 185.201659 pJ
sum error= 215
Actual label: 0
Output voltages: [0.72628, 0.26357, 0.25728, 0.18177, 0.15763, 0.12346, 0.41066, 0.18472, 0.3255, 0.27496]
Predicted label: 0
Correct prediction
Energy consumption = 186.420100 pJ
sum error= 215
Actual label: 8
Output voltages: [0.20766, 0.25731, 0.30925, 0.26034, 0.20358, 0.21524, 0.19714, 0.12533, 0.74298, 0.27066]
Predicted label: 8
Correct prediction
Energy consumption = 196.852421 pJ
sum error= 215
Actual label: 0
Output voltages: [0.72416, 0.2709, 0.26286, 0.1756, 0.23633, 0.12207, 0.36994, 0.15078, 0.36654, 0.26635]
Predicted label: 0
Correct prediction
Energy consumption = 195.553285 pJ
sum error= 215
Actual label: 2
Output voltages: [0.46456, 0.054741, 0.68979, 0.48619, 0.13512, 0.068535, 0.15312, 0.29543, 0.41587, 0.17881]
Predicted label: 2
Correct prediction
Energy consumption = 183.868108 pJ
sum error= 215
Actual label: 3
Output voltages: [0.48514, 0.14314, 0.33523, 0.75473, 0.15209, 0.17177, 0.1204, 0.22381, 0.37415, 0.18844]
Predicted label: 3
Correct prediction
Energy consumption = 181.455638 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 531 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 531 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 531 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.36015, 0.22997, 0.36513, 0.29632, 0.065225, 0.078887, 0.09676, 0.72545, 0.36299, 0.26051]
Predicted label: 7
Correct prediction
Energy consumption = 199.755716 pJ
sum error= 215
Actual label: 9
Output voltages: [0.36538, 0.083921, 0.16765, 0.35732, 0.23556, 0.18106, 0.045076, 0.39649, 0.42262, 0.54241]
Predicted label: 9
Correct prediction
Energy consumption = 198.016101 pJ
sum error= 215
Actual label: 4
Output voltages: [0.17467, 0.15285, 0.29379, 0.22094, 0.74213, 0.054592, 0.21968, 0.2174, 0.21445, 0.23274]
Predicted label: 4
Correct prediction
Energy consumption = 188.930447 pJ
sum error= 215
Actual label: 7
Output voltages: [0.33037, 0.19349, 0.26463, 0.28673, 0.13408, 0.090394, 0.047467, 0.75963, 0.35796, 0.33957]
Predicted label: 7
Correct prediction
Energy consumption = 192.189449 pJ
sum error= 215
Actual label: 1
Output voltages: [0.21992, 0.72623, 0.29078, 0.21554, 0.39522, 0.14024, 0.48125, 0.10462, 0.22487, 0.18683]
Predicted label: 1
Correct prediction
Energy consumption = 208.556844 pJ
sum error= 215
Actual label: 9
Output voltages: [0.40077, 0.073861, 0.17036, 0.25635, 0.30041, 0.23184, 0.07135, 0.29582, 0.40018, 0.64699]
Predicted label: 9
Correct prediction
Energy consumption = 199.352964 pJ
sum error= 215
Actual label: 1
Output voltages: [0.25415, 0.74544, 0.26335, 0.2288, 0.36911, 0.050608, 0.34744, 0.16314, 0.2168, 0.30152]
Predicted label: 1
Correct prediction
Energy consumption = 206.328875 pJ
sum error= 215
Actual label: 7
Output voltages: [0.37909, 0.20616, 0.29119, 0.34561, 0.14225, 0.090845, 0.047695, 0.75947, 0.32286, 0.30503]
Predicted label: 7
Correct prediction
Energy consumption = 192.223668 pJ
sum error= 215
Actual label: 1
Output voltages: [0.12499, 0.75286, 0.2425, 0.24381, 0.25096, 0.085199, 0.4223, 0.14208, 0.30418, 0.22027]
Predicted label: 1
Correct prediction
Energy consumption = 203.863614 pJ
sum error= 215
Actual label: 4
Output voltages: [0.18759, 0.1666, 0.28774, 0.20567, 0.7504, 0.065464, 0.38989, 0.28923, 0.13064, 0.15561]
Predicted label: 4
Correct prediction
Energy consumption = 192.508968 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 532 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 532 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 532 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73211, 0.16983, 0.1826, 0.26588, 0.13772, 0.26886, 0.29131, 0.14579, 0.37647, 0.30882]
Predicted label: 0
Correct prediction
Energy consumption = 202.196864 pJ
sum error= 215
Actual label: 0
Output voltages: [0.7225, 0.23064, 0.19151, 0.18949, 0.1999, 0.16415, 0.43114, 0.17719, 0.31948, 0.25971]
Predicted label: 0
Correct prediction
Energy consumption = 190.926941 pJ
sum error= 215
Actual label: 4
Output voltages: [0.24943, 0.18786, 0.25337, 0.21459, 0.73732, 0.054288, 0.17221, 0.23384, 0.22054, 0.29378]
Predicted label: 4
Correct prediction
Energy consumption = 202.748037 pJ
sum error= 215
Actual label: 1
Output voltages: [0.21245, 0.72606, 0.16771, 0.14758, 0.44438, 0.075595, 0.28408, 0.19567, 0.26579, 0.32003]
Predicted label: 1
Correct prediction
Energy consumption = 202.877913 pJ
sum error= 215
Actual label: 7
Output voltages: [0.40066, 0.19557, 0.31197, 0.37209, 0.11362, 0.051284, 0.042655, 0.73207, 0.31451, 0.29051]
Predicted label: 7
Correct prediction
Energy consumption = 203.449929 pJ
sum error= 215
Actual label: 5
Output voltages: [0.21275, 0.059235, 0.071825, 0.41347, 0.22084, 0.73279, 0.22349, 0.25151, 0.47875, 0.30129]
Predicted label: 5
Correct prediction
Energy consumption = 186.306852 pJ
sum error= 215
Actual label: 7
Output voltages: [0.29171, 0.23372, 0.30389, 0.28046, 0.09175, 0.069656, 0.059015, 0.75363, 0.39146, 0.34171]
Predicted label: 7
Correct prediction
Energy consumption = 194.682088 pJ
sum error= 215
Actual label: 1
Output voltages: [0.24605, 0.71714, 0.26591, 0.22031, 0.38213, 0.053288, 0.30829, 0.084876, 0.34771, 0.29634]
Predicted label: 1
Correct prediction
Energy consumption = 203.834996 pJ
sum error= 215
Actual label: 3
Output voltages: [0.3362, 0.14026, 0.31222, 0.7516, 0.20611, 0.15834, 0.12884, 0.20268, 0.47062, 0.23785]
Predicted label: 3
Correct prediction
Energy consumption = 191.702301 pJ
sum error= 215
Actual label: 3
Output voltages: [0.37271, 0.15411, 0.28025, 0.75574, 0.2024, 0.20683, 0.2073, 0.19395, 0.37623, 0.23862]
Predicted label: 3
Correct prediction
Energy consumption = 178.904236 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 533 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 533 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 533 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.40586, 0.13637, 0.29426, 0.74795, 0.11789, 0.20401, 0.1453, 0.17897, 0.45736, 0.20724]
Predicted label: 3
Correct prediction
Energy consumption = 189.657010 pJ
sum error= 215
Actual label: 1
Output voltages: [0.43654, 0.53405, 0.21637, 0.16277, 0.30251, 0.32773, 0.67704, 0.086061, 0.26906, 0.13863]
Predicted label: 6
Wrong prediction!
Energy consumption = 209.529538 pJ
sum error= 216
Actual label: 6
Output voltages: [0.31816, 0.16364, 0.24728, 0.15197, 0.3154, 0.39871, 0.73184, 0.062141, 0.4397, 0.18817]
Predicted label: 6
Correct prediction
Energy consumption = 182.798365 pJ
sum error= 216
Actual label: 9
Output voltages: [0.3638, 0.075015, 0.18326, 0.30735, 0.28518, 0.1836, 0.074675, 0.28536, 0.43441, 0.63018]
Predicted label: 9
Correct prediction
Energy consumption = 193.941456 pJ
sum error= 216
Actual label: 7
Output voltages: [0.38225, 0.19228, 0.40762, 0.3274, 0.1187, 0.033671, 0.058351, 0.72634, 0.36065, 0.26697]
Predicted label: 7
Correct prediction
Energy consumption = 192.251028 pJ
sum error= 216
Actual label: 4
Output voltages: [0.20991, 0.18496, 0.29811, 0.19489, 0.73889, 0.055544, 0.31281, 0.21111, 0.18756, 0.27987]
Predicted label: 4
Correct prediction
Energy consumption = 194.736887 pJ
sum error= 216
Actual label: 3
Output voltages: [0.32539, 0.15862, 0.34954, 0.74772, 0.13181, 0.2203, 0.13153, 0.16655, 0.50091, 0.24488]
Predicted label: 3
Correct prediction
Energy consumption = 189.073946 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72569, 0.25154, 0.23103, 0.1438, 0.17895, 0.14502, 0.42205, 0.19065, 0.27754, 0.28182]
Predicted label: 0
Correct prediction
Energy consumption = 194.299543 pJ
sum error= 216
Actual label: 2
Output voltages: [0.36603, 0.14038, 0.72047, 0.40138, 0.14683, 0.048331, 0.19803, 0.21576, 0.43505, 0.14258]
Predicted label: 2
Correct prediction
Energy consumption = 193.063077 pJ
sum error= 216
Actual label: 5
Output voltages: [0.25967, 0.065129, 0.14309, 0.48167, 0.14999, 0.69247, 0.14162, 0.21598, 0.50879, 0.21902]
Predicted label: 5
Correct prediction
Energy consumption = 183.368497 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 534 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 534 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 534 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40733, 0.16944, 0.75361, 0.29588, 0.18911, 0.047351, 0.21969, 0.28847, 0.40947, 0.15964]
Predicted label: 2
Correct prediction
Energy consumption = 186.736892 pJ
sum error= 216
Actual label: 6
Output voltages: [0.31572, 0.28963, 0.2211, 0.18703, 0.27075, 0.44065, 0.73819, 0.13231, 0.40679, 0.11643]
Predicted label: 6
Correct prediction
Energy consumption = 199.278818 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72786, 0.21258, 0.27944, 0.19275, 0.17373, 0.12654, 0.44735, 0.18842, 0.33501, 0.24326]
Predicted label: 0
Correct prediction
Energy consumption = 188.585124 pJ
sum error= 216
Actual label: 8
Output voltages: [0.23616, 0.32671, 0.2727, 0.25552, 0.25478, 0.090831, 0.21156, 0.074378, 0.66511, 0.35238]
Predicted label: 8
Correct prediction
Energy consumption = 206.031378 pJ
sum error= 216
Actual label: 9
Output voltages: [0.39781, 0.12675, 0.16124, 0.31697, 0.3235, 0.23534, 0.1047, 0.25471, 0.3448, 0.68856]
Predicted label: 9
Correct prediction
Energy consumption = 195.076512 pJ
sum error= 216
Actual label: 4
Output voltages: [0.19662, 0.17526, 0.29162, 0.21031, 0.74612, 0.11505, 0.29286, 0.15845, 0.20192, 0.31151]
Predicted label: 4
Correct prediction
Energy consumption = 199.104560 pJ
sum error= 216
Actual label: 3
Output voltages: [0.37136, 0.10693, 0.32625, 0.73783, 0.15021, 0.20403, 0.11526, 0.17783, 0.45012, 0.268]
Predicted label: 3
Correct prediction
Energy consumption = 186.158132 pJ
sum error= 216
Actual label: 5
Output voltages: [0.25229, 0.065734, 0.11025, 0.42664, 0.16789, 0.70061, 0.21245, 0.19683, 0.51339, 0.27488]
Predicted label: 5
Correct prediction
Energy consumption = 179.802699 pJ
sum error= 216
Actual label: 4
Output voltages: [0.17033, 0.21296, 0.217, 0.17626, 0.72545, 0.12592, 0.44065, 0.24111, 0.22041, 0.23574]
Predicted label: 4
Correct prediction
Energy consumption = 198.409488 pJ
sum error= 216
Actual label: 8
Output voltages: [0.24813, 0.28652, 0.32027, 0.22633, 0.20609, 0.1261, 0.20585, 0.11504, 0.72825, 0.31413]
Predicted label: 8
Correct prediction
Energy consumption = 196.593371 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 535 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 535 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 535 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23948, 0.7439, 0.31518, 0.24243, 0.33216, 0.044423, 0.27694, 0.16568, 0.26576, 0.28521]
Predicted label: 1
Correct prediction
Energy consumption = 210.268557 pJ
sum error= 216
Actual label: 5
Output voltages: [0.24651, 0.070881, 0.1029, 0.46597, 0.13449, 0.71722, 0.1982, 0.2094, 0.5285, 0.2013]
Predicted label: 5
Correct prediction
Energy consumption = 193.409329 pJ
sum error= 216
Actual label: 9
Output voltages: [0.35, 0.078683, 0.18293, 0.28171, 0.28408, 0.21983, 0.090864, 0.35703, 0.40744, 0.63785]
Predicted label: 9
Correct prediction
Energy consumption = 191.125854 pJ
sum error= 216
Actual label: 0
Output voltages: [0.69945, 0.2098, 0.21114, 0.16676, 0.1822, 0.18208, 0.48594, 0.17409, 0.31286, 0.2119]
Predicted label: 0
Correct prediction
Energy consumption = 190.883893 pJ
sum error= 216
Actual label: 6
Output voltages: [0.29685, 0.18228, 0.24684, 0.1549, 0.31132, 0.42679, 0.73033, 0.085208, 0.42075, 0.12563]
Predicted label: 6
Correct prediction
Energy consumption = 189.233786 pJ
sum error= 216
Actual label: 4
Output voltages: [0.2183, 0.15515, 0.29798, 0.14018, 0.73784, 0.095381, 0.33613, 0.22961, 0.2008, 0.21393]
Predicted label: 4
Correct prediction
Energy consumption = 190.270257 pJ
sum error= 216
Actual label: 3
Output voltages: [0.27992, 0.19269, 0.29585, 0.75379, 0.1657, 0.20156, 0.12194, 0.20214, 0.49408, 0.28594]
Predicted label: 3
Correct prediction
Energy consumption = 183.090585 pJ
sum error= 216
Actual label: 6
Output voltages: [0.35641, 0.27844, 0.20123, 0.20471, 0.31126, 0.35495, 0.72205, 0.096934, 0.38368, 0.10078]
Predicted label: 6
Correct prediction
Energy consumption = 192.241739 pJ
sum error= 216
Actual label: 3
Output voltages: [0.35967, 0.13054, 0.32325, 0.74143, 0.13045, 0.20574, 0.10384, 0.17628, 0.50009, 0.22566]
Predicted label: 3
Correct prediction
Energy consumption = 192.495083 pJ
sum error= 216
Actual label: 3
Output voltages: [0.32453, 0.15561, 0.29968, 0.75242, 0.18584, 0.18693, 0.13664, 0.1616, 0.44509, 0.29903]
Predicted label: 3
Correct prediction
Energy consumption = 182.323688 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 536 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 536 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 536 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.25106, 0.30804, 0.30182, 0.21919, 0.16253, 0.1648, 0.16866, 0.17795, 0.73533, 0.31347]
Predicted label: 8
Correct prediction
Energy consumption = 202.301000 pJ
sum error= 216
Actual label: 1
Output voltages: [0.21287, 0.74868, 0.32554, 0.21405, 0.40158, 0.054394, 0.41107, 0.086622, 0.21345, 0.22649]
Predicted label: 1
Correct prediction
Energy consumption = 208.198041 pJ
sum error= 216
Actual label: 4
Output voltages: [0.16832, 0.14592, 0.30329, 0.21061, 0.73863, 0.055571, 0.20945, 0.26579, 0.22173, 0.21729]
Predicted label: 4
Correct prediction
Energy consumption = 192.631558 pJ
sum error= 216
Actual label: 7
Output voltages: [0.31365, 0.19892, 0.183, 0.38249, 0.17905, 0.17248, 0.036397, 0.74053, 0.30407, 0.42869]
Predicted label: 7
Correct prediction
Energy consumption = 192.028419 pJ
sum error= 216
Actual label: 5
Output voltages: [0.22035, 0.048416, 0.12686, 0.316, 0.27577, 0.73239, 0.29507, 0.22461, 0.55596, 0.27038]
Predicted label: 5
Correct prediction
Energy consumption = 179.531802 pJ
sum error= 216
Actual label: 7
Output voltages: [0.35402, 0.2219, 0.2349, 0.28766, 0.14636, 0.14827, 0.044034, 0.76535, 0.2666, 0.31043]
Predicted label: 7
Correct prediction
Energy consumption = 193.164271 pJ
sum error= 216
Actual label: 2
Output voltages: [0.38076, 0.16426, 0.75405, 0.31005, 0.18485, 0.041347, 0.21402, 0.29171, 0.41048, 0.17484]
Predicted label: 2
Correct prediction
Energy consumption = 178.647200 pJ
sum error= 216
Actual label: 2
Output voltages: [0.41224, 0.1551, 0.75601, 0.2629, 0.13118, 0.045416, 0.22853, 0.34572, 0.38585, 0.14727]
Predicted label: 2
Correct prediction
Energy consumption = 180.235656 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73186, 0.24971, 0.24288, 0.19226, 0.1765, 0.12113, 0.43045, 0.17893, 0.31508, 0.32442]
Predicted label: 0
Correct prediction
Energy consumption = 192.048431 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73111, 0.22767, 0.18813, 0.16706, 0.14648, 0.24788, 0.41037, 0.17844, 0.33729, 0.27824]
Predicted label: 0
Correct prediction
Energy consumption = 181.481118 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 537 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 537 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 537 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16719, 0.76235, 0.28309, 0.19743, 0.2101, 0.10304, 0.42936, 0.096171, 0.33148, 0.23476]
Predicted label: 1
Correct prediction
Energy consumption = 213.768962 pJ
sum error= 216
Actual label: 7
Output voltages: [0.36412, 0.25836, 0.18338, 0.26116, 0.15432, 0.21105, 0.050149, 0.74102, 0.27616, 0.38858]
Predicted label: 7
Correct prediction
Energy consumption = 200.946221 pJ
sum error= 216
Actual label: 7
Output voltages: [0.31505, 0.32349, 0.36616, 0.22856, 0.14163, 0.042299, 0.046516, 0.74082, 0.26559, 0.30443]
Predicted label: 7
Correct prediction
Energy consumption = 192.885123 pJ
sum error= 216
Actual label: 9
Output voltages: [0.36841, 0.096807, 0.21951, 0.27809, 0.34648, 0.17855, 0.078802, 0.30491, 0.34695, 0.65102]
Predicted label: 9
Correct prediction
Energy consumption = 185.410782 pJ
sum error= 216
Actual label: 5
Output voltages: [0.22303, 0.098949, 0.091634, 0.53525, 0.17614, 0.69527, 0.16535, 0.16548, 0.48581, 0.22115]
Predicted label: 5
Correct prediction
Energy consumption = 184.425350 pJ
sum error= 216
Actual label: 9
Output voltages: [0.33518, 0.16765, 0.23048, 0.21602, 0.21915, 0.12637, 0.070578, 0.21161, 0.42683, 0.68569]
Predicted label: 9
Correct prediction
Energy consumption = 189.453361 pJ
sum error= 216
Actual label: 8
Output voltages: [0.25697, 0.29285, 0.29205, 0.2129, 0.19845, 0.17797, 0.25265, 0.10711, 0.7384, 0.2934]
Predicted label: 8
Correct prediction
Energy consumption = 191.521792 pJ
sum error= 216
Actual label: 9
Output voltages: [0.40891, 0.059037, 0.21407, 0.22918, 0.36552, 0.238, 0.10267, 0.25308, 0.37056, 0.64797]
Predicted label: 9
Correct prediction
Energy consumption = 191.911431 pJ
sum error= 216
Actual label: 6
Output voltages: [0.27951, 0.23183, 0.25958, 0.14455, 0.31542, 0.36958, 0.74235, 0.094615, 0.40109, 0.12025]
Predicted label: 6
Correct prediction
Energy consumption = 190.543382 pJ
sum error= 216
Actual label: 8
Output voltages: [0.23636, 0.23354, 0.29057, 0.24561, 0.24254, 0.069295, 0.15801, 0.24989, 0.70804, 0.28693]
Predicted label: 8
Correct prediction
Energy consumption = 202.837095 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 538 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 538 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 538 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.27513, 0.18999, 0.27229, 0.24286, 0.13875, 0.14791, 0.16531, 0.14497, 0.72106, 0.37477]
Predicted label: 8
Correct prediction
Energy consumption = 201.651860 pJ
sum error= 216
Actual label: 2
Output voltages: [0.46438, 0.12567, 0.73873, 0.33598, 0.155, 0.045792, 0.24021, 0.26201, 0.45093, 0.14533]
Predicted label: 2
Correct prediction
Energy consumption = 185.029123 pJ
sum error= 216
Actual label: 3
Output voltages: [0.40128, 0.17292, 0.26107, 0.74629, 0.20536, 0.21717, 0.20596, 0.23341, 0.36145, 0.20681]
Predicted label: 3
Correct prediction
Energy consumption = 190.354362 pJ
sum error= 216
Actual label: 6
Output voltages: [0.29892, 0.2791, 0.2702, 0.14932, 0.25808, 0.44292, 0.74561, 0.12276, 0.39785, 0.11872]
Predicted label: 6
Correct prediction
Energy consumption = 187.942872 pJ
sum error= 216
Actual label: 1
Output voltages: [0.18822, 0.76673, 0.26135, 0.26913, 0.27499, 0.071665, 0.31955, 0.16006, 0.2868, 0.23682]
Predicted label: 1
Correct prediction
Energy consumption = 212.469234 pJ
sum error= 216
Actual label: 2
Output voltages: [0.41004, 0.17562, 0.73766, 0.36729, 0.19959, 0.039564, 0.32136, 0.25613, 0.39148, 0.17001]
Predicted label: 2
Correct prediction
Energy consumption = 189.733125 pJ
sum error= 216
Actual label: 9
Output voltages: [0.37159, 0.12602, 0.18508, 0.25506, 0.33295, 0.21163, 0.1054, 0.24095, 0.37622, 0.68917]
Predicted label: 9
Correct prediction
Energy consumption = 188.345344 pJ
sum error= 216
Actual label: 8
Output voltages: [0.25301, 0.31733, 0.2831, 0.29706, 0.13607, 0.17959, 0.24921, 0.10239, 0.735, 0.28342]
Predicted label: 8
Correct prediction
Energy consumption = 200.949531 pJ
sum error= 216
Actual label: 9
Output voltages: [0.36786, 0.13066, 0.20468, 0.25531, 0.31907, 0.21127, 0.11307, 0.25029, 0.36567, 0.68793]
Predicted label: 9
Correct prediction
Energy consumption = 195.920766 pJ
sum error= 216
Actual label: 5
Output voltages: [0.22994, 0.06139, 0.12468, 0.43935, 0.15994, 0.70549, 0.22817, 0.23639, 0.49938, 0.25743]
Predicted label: 5
Correct prediction
Energy consumption = 186.141221 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 539 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 539 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 539 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.38513, 0.12833, 0.73897, 0.36603, 0.23378, 0.04206, 0.19364, 0.22927, 0.43647, 0.21536]
Predicted label: 2
Correct prediction
Energy consumption = 186.697595 pJ
sum error= 216
Actual label: 6
Output voltages: [0.30375, 0.2125, 0.26741, 0.12901, 0.33596, 0.3617, 0.73203, 0.063215, 0.41108, 0.12836]
Predicted label: 6
Correct prediction
Energy consumption = 191.314999 pJ
sum error= 216
Actual label: 2
Output voltages: [0.49905, 0.19656, 0.72714, 0.34153, 0.15868, 0.041051, 0.26775, 0.30725, 0.35662, 0.20122]
Predicted label: 2
Correct prediction
Energy consumption = 190.194150 pJ
sum error= 216
Actual label: 4
Output voltages: [0.1629, 0.13961, 0.29708, 0.16561, 0.75243, 0.061429, 0.32674, 0.28871, 0.18606, 0.18615]
Predicted label: 4
Correct prediction
Energy consumption = 192.197148 pJ
sum error= 216
Actual label: 8
Output voltages: [0.30999, 0.2971, 0.25024, 0.19045, 0.25787, 0.10153, 0.20585, 0.11066, 0.68444, 0.406]
Predicted label: 8
Correct prediction
Energy consumption = 202.551169 pJ
sum error= 216
Actual label: 4
Output voltages: [0.17595, 0.2102, 0.26709, 0.17319, 0.74486, 0.066151, 0.28001, 0.24262, 0.19677, 0.23753]
Predicted label: 4
Correct prediction
Energy consumption = 197.808672 pJ
sum error= 216
Actual label: 6
Output voltages: [0.28253, 0.19878, 0.22586, 0.17746, 0.29265, 0.38498, 0.71521, 0.11503, 0.45753, 0.10665]
Predicted label: 6
Correct prediction
Energy consumption = 195.709389 pJ
sum error= 216
Actual label: 5
Output voltages: [0.26992, 0.055267, 0.1635, 0.39098, 0.17102, 0.69999, 0.22699, 0.2097, 0.57045, 0.24092]
Predicted label: 5
Correct prediction
Energy consumption = 184.089624 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73316, 0.26079, 0.23313, 0.14205, 0.18096, 0.20583, 0.31649, 0.2072, 0.32157, 0.27275]
Predicted label: 0
Correct prediction
Energy consumption = 202.396798 pJ
sum error= 216
Actual label: 1
Output voltages: [0.24706, 0.754, 0.27603, 0.21305, 0.32992, 0.058415, 0.35549, 0.13113, 0.24219, 0.25887]
Predicted label: 1
Correct prediction
Energy consumption = 203.110720 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 540 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 540 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 540 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.28536, 0.062939, 0.053582, 0.41606, 0.25384, 0.73635, 0.29201, 0.13591, 0.44768, 0.26988]
Predicted label: 5
Correct prediction
Energy consumption = 187.990756 pJ
sum error= 216
Actual label: 6
Output voltages: [0.33956, 0.22024, 0.24892, 0.15709, 0.308, 0.3827, 0.72267, 0.073552, 0.43753, 0.10814]
Predicted label: 6
Correct prediction
Energy consumption = 193.007269 pJ
sum error= 216
Actual label: 7
Output voltages: [0.29734, 0.25656, 0.2604, 0.25057, 0.14827, 0.056307, 0.039288, 0.74779, 0.38192, 0.37244]
Predicted label: 7
Correct prediction
Energy consumption = 200.265454 pJ
sum error= 216
Actual label: 8
Output voltages: [0.27694, 0.13348, 0.28993, 0.28017, 0.26873, 0.096669, 0.18858, 0.092484, 0.66124, 0.31404]
Predicted label: 8
Correct prediction
Energy consumption = 193.988984 pJ
sum error= 216
Actual label: 9
Output voltages: [0.30534, 0.11646, 0.20462, 0.29099, 0.26336, 0.16129, 0.093081, 0.20036, 0.47501, 0.64686]
Predicted label: 9
Correct prediction
Energy consumption = 188.363088 pJ
sum error= 216
Actual label: 0
Output voltages: [0.68598, 0.24473, 0.19609, 0.13586, 0.15401, 0.21269, 0.40879, 0.21853, 0.34945, 0.24807]
Predicted label: 0
Correct prediction
Energy consumption = 186.986996 pJ
sum error= 216
Actual label: 1
Output voltages: [0.21902, 0.72173, 0.31153, 0.14151, 0.41963, 0.077355, 0.3848, 0.17225, 0.23383, 0.26125]
Predicted label: 1
Correct prediction
Energy consumption = 205.260893 pJ
sum error= 216
Actual label: 2
Output voltages: [0.33933, 0.2803, 0.73696, 0.31486, 0.11902, 0.025468, 0.20026, 0.38064, 0.37375, 0.21371]
Predicted label: 2
Correct prediction
Energy consumption = 182.736468 pJ
sum error= 216
Actual label: 3
Output voltages: [0.41482, 0.12691, 0.31718, 0.74796, 0.14951, 0.24314, 0.12809, 0.15999, 0.46386, 0.15466]
Predicted label: 3
Correct prediction
Energy consumption = 191.580725 pJ
sum error= 216
Actual label: 4
Output voltages: [0.25881, 0.16989, 0.34586, 0.094132, 0.72664, 0.12177, 0.48313, 0.16525, 0.25467, 0.13714]
Predicted label: 4
Correct prediction
Energy consumption = 196.127092 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 541 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 541 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 541 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25937, 0.041236, 0.062139, 0.24267, 0.27957, 0.67203, 0.35595, 0.095158, 0.56992, 0.20478]
Predicted label: 5
Correct prediction
Energy consumption = 193.165588 pJ
sum error= 216
Actual label: 6
Output voltages: [0.30236, 0.27374, 0.3251, 0.10623, 0.28924, 0.30951, 0.74652, 0.059907, 0.39392, 0.18888]
Predicted label: 6
Correct prediction
Energy consumption = 185.139220 pJ
sum error= 216
Actual label: 7
Output voltages: [0.32567, 0.21391, 0.2298, 0.21776, 0.17129, 0.077011, 0.037788, 0.75624, 0.38975, 0.32901]
Predicted label: 7
Correct prediction
Energy consumption = 199.586898 pJ
sum error= 216
Actual label: 8
Output voltages: [0.16933, 0.18803, 0.2705, 0.38141, 0.21533, 0.11507, 0.24149, 0.11767, 0.69186, 0.27527]
Predicted label: 8
Correct prediction
Energy consumption = 196.192092 pJ
sum error= 216
Actual label: 9
Output voltages: [0.32672, 0.13264, 0.17637, 0.30397, 0.23983, 0.17566, 0.062749, 0.32893, 0.43191, 0.64161]
Predicted label: 9
Correct prediction
Energy consumption = 181.454434 pJ
sum error= 216
Actual label: 0
Output voltages: [0.74275, 0.27994, 0.26626, 0.18764, 0.11314, 0.21683, 0.36102, 0.20629, 0.25589, 0.24969]
Predicted label: 0
Correct prediction
Energy consumption = 191.380250 pJ
sum error= 216
Actual label: 1
Output voltages: [0.13307, 0.7573, 0.23269, 0.25243, 0.3208, 0.083985, 0.30732, 0.13541, 0.31269, 0.26697]
Predicted label: 1
Correct prediction
Energy consumption = 210.625056 pJ
sum error= 216
Actual label: 2
Output voltages: [0.29597, 0.34324, 0.73165, 0.37718, 0.1809, 0.030984, 0.1948, 0.3412, 0.29378, 0.21528]
Predicted label: 2
Correct prediction
Energy consumption = 185.494306 pJ
sum error= 216
Actual label: 3
Output voltages: [0.32201, 0.15981, 0.44549, 0.72226, 0.095155, 0.078223, 0.14508, 0.14217, 0.51553, 0.19628]
Predicted label: 3
Correct prediction
Energy consumption = 181.643739 pJ
sum error= 216
Actual label: 4
Output voltages: [0.14119, 0.18724, 0.24288, 0.17369, 0.75348, 0.13869, 0.32323, 0.25054, 0.21454, 0.2063]
Predicted label: 4
Correct prediction
Energy consumption = 192.544211 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 542 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 542 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 542 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.3259, 0.0467, 0.065922, 0.3725, 0.24796, 0.69734, 0.33103, 0.11398, 0.51696, 0.17462]
Predicted label: 5
Correct prediction
Energy consumption = 191.949358 pJ
sum error= 216
Actual label: 6
Output voltages: [0.28806, 0.23547, 0.3177, 0.071511, 0.37216, 0.27322, 0.73952, 0.071114, 0.33035, 0.12245]
Predicted label: 6
Correct prediction
Energy consumption = 189.049337 pJ
sum error= 216
Actual label: 7
Output voltages: [0.3585, 0.14543, 0.10867, 0.29244, 0.18631, 0.22441, 0.03758, 0.7496, 0.33929, 0.37165]
Predicted label: 7
Correct prediction
Energy consumption = 197.123184 pJ
sum error= 216
Actual label: 8
Output voltages: [0.1987, 0.18603, 0.28366, 0.33204, 0.17063, 0.18505, 0.18937, 0.097414, 0.69005, 0.34371]
Predicted label: 8
Correct prediction
Energy consumption = 195.971759 pJ
sum error= 216
Actual label: 9
Output voltages: [0.30593, 0.13786, 0.19595, 0.24958, 0.42482, 0.16484, 0.078743, 0.30483, 0.31706, 0.62999]
Predicted label: 9
Correct prediction
Energy consumption = 189.226601 pJ
sum error= 216
Actual label: 7
Output voltages: [0.35246, 0.219, 0.22725, 0.15194, 0.24598, 0.13287, 0.040844, 0.75951, 0.32516, 0.27563]
Predicted label: 7
Correct prediction
Energy consumption = 195.984690 pJ
sum error= 216
Actual label: 4
Output voltages: [0.11975, 0.2088, 0.27607, 0.1246, 0.76257, 0.080457, 0.34395, 0.32348, 0.15784, 0.24787]
Predicted label: 4
Correct prediction
Energy consumption = 191.702285 pJ
sum error= 216
Actual label: 2
Output voltages: [0.2565, 0.33523, 0.7396, 0.28849, 0.12951, 0.040777, 0.23277, 0.25199, 0.41115, 0.24091]
Predicted label: 2
Correct prediction
Energy consumption = 191.853144 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73453, 0.25905, 0.32466, 0.20041, 0.1135, 0.17984, 0.4001, 0.19863, 0.31528, 0.22038]
Predicted label: 0
Correct prediction
Energy consumption = 186.431259 pJ
sum error= 216
Actual label: 9
Output voltages: [0.33557, 0.12958, 0.18893, 0.29351, 0.27717, 0.14651, 0.068826, 0.2818, 0.4286, 0.65066]
Predicted label: 9
Correct prediction
Energy consumption = 185.053019 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 543 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 543 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 543 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73296, 0.23994, 0.31613, 0.13343, 0.10816, 0.1397, 0.39733, 0.19517, 0.28881, 0.23521]
Predicted label: 0
Correct prediction
Energy consumption = 186.868239 pJ
sum error= 216
Actual label: 1
Output voltages: [0.17815, 0.75389, 0.29898, 0.2485, 0.31954, 0.071601, 0.39459, 0.14926, 0.27157, 0.2645]
Predicted label: 1
Correct prediction
Energy consumption = 205.767355 pJ
sum error= 216
Actual label: 5
Output voltages: [0.23725, 0.0425, 0.073851, 0.29949, 0.2968, 0.70736, 0.35894, 0.14253, 0.51379, 0.24375]
Predicted label: 5
Correct prediction
Energy consumption = 187.183951 pJ
sum error= 216
Actual label: 8
Output voltages: [0.23343, 0.22829, 0.26786, 0.34509, 0.11815, 0.21918, 0.20974, 0.18468, 0.74982, 0.24941]
Predicted label: 8
Correct prediction
Energy consumption = 192.448500 pJ
sum error= 216
Actual label: 8
Output voltages: [0.20159, 0.24933, 0.26923, 0.30683, 0.14901, 0.1945, 0.24523, 0.24002, 0.74708, 0.29381]
Predicted label: 8
Correct prediction
Energy consumption = 192.089604 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73484, 0.21732, 0.23269, 0.24818, 0.20719, 0.15247, 0.36867, 0.19498, 0.35916, 0.29166]
Predicted label: 0
Correct prediction
Energy consumption = 202.909076 pJ
sum error= 216
Actual label: 2
Output voltages: [0.36726, 0.22344, 0.75315, 0.31779, 0.17593, 0.039145, 0.25125, 0.30729, 0.40073, 0.17968]
Predicted label: 2
Correct prediction
Energy consumption = 177.534912 pJ
sum error= 216
Actual label: 7
Output voltages: [0.30454, 0.17029, 0.23235, 0.25112, 0.138, 0.10994, 0.044173, 0.7618, 0.38723, 0.34307]
Predicted label: 7
Correct prediction
Energy consumption = 189.727272 pJ
sum error= 216
Actual label: 8
Output voltages: [0.25261, 0.168, 0.23856, 0.3999, 0.13322, 0.17146, 0.18197, 0.086704, 0.70251, 0.32633]
Predicted label: 8
Correct prediction
Energy consumption = 191.985499 pJ
sum error= 216
Actual label: 4
Output voltages: [0.24322, 0.19269, 0.29202, 0.1539, 0.73582, 0.080565, 0.40939, 0.2429, 0.21212, 0.16048]
Predicted label: 4
Correct prediction
Energy consumption = 191.705375 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 544 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 544 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 544 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16066, 0.1739, 0.30405, 0.1996, 0.75566, 0.062792, 0.26128, 0.30802, 0.16442, 0.20084]
Predicted label: 4
Correct prediction
Energy consumption = 195.778289 pJ
sum error= 216
Actual label: 6
Output voltages: [0.32045, 0.26541, 0.32761, 0.11657, 0.29455, 0.28604, 0.74842, 0.11635, 0.25827, 0.25135]
Predicted label: 6
Correct prediction
Energy consumption = 190.139789 pJ
sum error= 216
Actual label: 1
Output voltages: [0.19238, 0.75217, 0.25431, 0.19249, 0.34358, 0.12009, 0.43653, 0.11783, 0.24139, 0.23788]
Predicted label: 1
Correct prediction
Energy consumption = 206.157091 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73878, 0.22805, 0.25236, 0.19082, 0.091264, 0.19396, 0.41625, 0.23365, 0.32354, 0.22147]
Predicted label: 0
Correct prediction
Energy consumption = 192.947437 pJ
sum error= 216
Actual label: 4
Output voltages: [0.19582, 0.1216, 0.23377, 0.1224, 0.74129, 0.15887, 0.44707, 0.20481, 0.29318, 0.13354]
Predicted label: 4
Correct prediction
Energy consumption = 196.728213 pJ
sum error= 216
Actual label: 5
Output voltages: [0.23579, 0.057167, 0.054736, 0.32339, 0.27766, 0.74484, 0.3592, 0.17104, 0.47578, 0.21269]
Predicted label: 5
Correct prediction
Energy consumption = 190.485283 pJ
sum error= 216
Actual label: 3
Output voltages: [0.30376, 0.13209, 0.27248, 0.7463, 0.22193, 0.28584, 0.16163, 0.16945, 0.39934, 0.22591]
Predicted label: 3
Correct prediction
Energy consumption = 187.681449 pJ
sum error= 216
Actual label: 9
Output voltages: [0.33252, 0.13512, 0.15913, 0.23403, 0.35719, 0.13924, 0.087034, 0.30219, 0.36643, 0.65253]
Predicted label: 9
Correct prediction
Energy consumption = 187.654777 pJ
sum error= 216
Actual label: 4
Output voltages: [0.21797, 0.15584, 0.32321, 0.22286, 0.74178, 0.043994, 0.21145, 0.23801, 0.16695, 0.2872]
Predicted label: 4
Correct prediction
Energy consumption = 189.466497 pJ
sum error= 216
Actual label: 2
Output voltages: [0.34363, 0.15773, 0.66992, 0.43203, 0.17283, 0.044425, 0.09797, 0.20259, 0.48239, 0.24012]
Predicted label: 2
Correct prediction
Energy consumption = 188.610116 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 545 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 545 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 545 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.65937, 0.10704, 0.085373, 0.25947, 0.13337, 0.40872, 0.25993, 0.32655, 0.39799, 0.24496]
Predicted label: 0
Correct prediction
Energy consumption = 195.699736 pJ
sum error= 216
Actual label: 5
Output voltages: [0.22952, 0.052329, 0.10056, 0.30897, 0.21263, 0.73516, 0.35301, 0.17021, 0.49962, 0.21682]
Predicted label: 5
Correct prediction
Energy consumption = 183.214214 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73293, 0.23351, 0.22333, 0.16844, 0.12766, 0.21384, 0.4143, 0.21928, 0.30165, 0.23234]
Predicted label: 0
Correct prediction
Energy consumption = 188.071409 pJ
sum error= 216
Actual label: 1
Output voltages: [0.11341, 0.75806, 0.18196, 0.18377, 0.29407, 0.17496, 0.43552, 0.098689, 0.35375, 0.23607]
Predicted label: 1
Correct prediction
Energy consumption = 211.244106 pJ
sum error= 216
Actual label: 3
Output voltages: [0.3015, 0.080619, 0.2169, 0.70545, 0.26315, 0.31087, 0.19061, 0.10148, 0.46543, 0.2366]
Predicted label: 3
Correct prediction
Energy consumption = 195.745231 pJ
sum error= 216
Actual label: 2
Output voltages: [0.35063, 0.21092, 0.72439, 0.35742, 0.16821, 0.027619, 0.29248, 0.28209, 0.44566, 0.17785]
Predicted label: 2
Correct prediction
Energy consumption = 184.997663 pJ
sum error= 216
Actual label: 9
Output voltages: [0.35796, 0.12285, 0.24608, 0.26723, 0.35252, 0.20334, 0.11248, 0.28857, 0.30926, 0.66649]
Predicted label: 9
Correct prediction
Energy consumption = 191.412828 pJ
sum error= 216
Actual label: 1
Output voltages: [0.40388, 0.57328, 0.25181, 0.21604, 0.32399, 0.061296, 0.32368, 0.072755, 0.45744, 0.2546]
Predicted label: 1
Correct prediction
Energy consumption = 205.424495 pJ
sum error= 216
Actual label: 6
Output voltages: [0.33929, 0.26684, 0.34566, 0.076258, 0.26887, 0.2947, 0.74538, 0.088107, 0.30209, 0.1996]
Predicted label: 6
Correct prediction
Energy consumption = 193.311826 pJ
sum error= 216
Actual label: 0
Output voltages: [0.71823, 0.18088, 0.25989, 0.1611, 0.097572, 0.20068, 0.39058, 0.19085, 0.29814, 0.26676]
Predicted label: 0
Correct prediction
Energy consumption = 188.047540 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 546 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 546 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 546 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23136, 0.74959, 0.14509, 0.16817, 0.39129, 0.14319, 0.35586, 0.088513, 0.29645, 0.2769]
Predicted label: 1
Correct prediction
Energy consumption = 208.231121 pJ
sum error= 216
Actual label: 1
Output voltages: [0.24128, 0.75035, 0.29146, 0.19876, 0.35395, 0.072076, 0.37586, 0.11997, 0.26443, 0.24893]
Predicted label: 1
Correct prediction
Energy consumption = 201.507464 pJ
sum error= 216
Actual label: 8
Output voltages: [0.17091, 0.17526, 0.26794, 0.31074, 0.13289, 0.1948, 0.16038, 0.19069, 0.73813, 0.24579]
Predicted label: 8
Correct prediction
Energy consumption = 195.524550 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72879, 0.21952, 0.24119, 0.16734, 0.15019, 0.20797, 0.43587, 0.1705, 0.30588, 0.18889]
Predicted label: 0
Correct prediction
Energy consumption = 191.583111 pJ
sum error= 216
Actual label: 4
Output voltages: [0.21151, 0.11197, 0.26069, 0.094367, 0.69604, 0.13095, 0.29122, 0.17169, 0.34304, 0.2754]
Predicted label: 4
Correct prediction
Energy consumption = 198.777780 pJ
sum error= 216
Actual label: 7
Output voltages: [0.31494, 0.23399, 0.22311, 0.2755, 0.12193, 0.11259, 0.045532, 0.75859, 0.41771, 0.32819]
Predicted label: 7
Correct prediction
Energy consumption = 201.407727 pJ
sum error= 216
Actual label: 7
Output voltages: [0.3407, 0.21061, 0.26629, 0.22703, 0.12777, 0.069292, 0.046412, 0.75634, 0.4142, 0.28261]
Predicted label: 7
Correct prediction
Energy consumption = 188.317938 pJ
sum error= 216
Actual label: 6
Output voltages: [0.31158, 0.26392, 0.32462, 0.07288, 0.3439, 0.32809, 0.74655, 0.062408, 0.34651, 0.13902]
Predicted label: 6
Correct prediction
Energy consumption = 188.376288 pJ
sum error= 216
Actual label: 3
Output voltages: [0.35365, 0.0855, 0.36035, 0.69985, 0.13665, 0.22195, 0.16348, 0.10086, 0.49118, 0.20311]
Predicted label: 3
Correct prediction
Energy consumption = 190.230001 pJ
sum error= 216
Actual label: 6
Output voltages: [0.33426, 0.26598, 0.31673, 0.064977, 0.36775, 0.30746, 0.74, 0.057229, 0.36316, 0.14957]
Predicted label: 6
Correct prediction
Energy consumption = 184.895379 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 547 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 547 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 547 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72688, 0.18147, 0.23092, 0.19834, 0.08571, 0.23483, 0.39811, 0.27688, 0.36172, 0.1535]
Predicted label: 0
Correct prediction
Energy consumption = 194.171790 pJ
sum error= 216
Actual label: 7
Output voltages: [0.26161, 0.26796, 0.3775, 0.30349, 0.13218, 0.059405, 0.032904, 0.75031, 0.35415, 0.36618]
Predicted label: 7
Correct prediction
Energy consumption = 195.051884 pJ
sum error= 216
Actual label: 3
Output voltages: [0.37611, 0.12505, 0.33049, 0.74408, 0.16508, 0.17642, 0.14206, 0.18169, 0.51671, 0.14174]
Predicted label: 3
Correct prediction
Energy consumption = 184.627232 pJ
sum error= 216
Actual label: 5
Output voltages: [0.24595, 0.047867, 0.071136, 0.34058, 0.26343, 0.7247, 0.39383, 0.15851, 0.53257, 0.25806]
Predicted label: 5
Correct prediction
Energy consumption = 182.310961 pJ
sum error= 216
Actual label: 4
Output voltages: [0.21724, 0.13551, 0.28988, 0.08532, 0.75553, 0.10669, 0.41547, 0.25097, 0.25336, 0.16654]
Predicted label: 4
Correct prediction
Energy consumption = 191.914054 pJ
sum error= 216
Actual label: 2
Output voltages: [0.35227, 0.27168, 0.74027, 0.3223, 0.16705, 0.030365, 0.29887, 0.26926, 0.4539, 0.1934]
Predicted label: 2
Correct prediction
Energy consumption = 186.505670 pJ
sum error= 216
Actual label: 4
Output voltages: [0.19393, 0.15533, 0.32919, 0.12169, 0.75433, 0.11033, 0.42776, 0.27699, 0.2102, 0.14358]
Predicted label: 4
Correct prediction
Energy consumption = 188.980181 pJ
sum error= 216
Actual label: 1
Output voltages: [0.18611, 0.75684, 0.19236, 0.19816, 0.32841, 0.11206, 0.37874, 0.14832, 0.28143, 0.2789]
Predicted label: 1
Correct prediction
Energy consumption = 203.476064 pJ
sum error= 216
Actual label: 8
Output voltages: [0.2167, 0.24115, 0.28096, 0.27312, 0.14716, 0.12052, 0.19263, 0.143, 0.73957, 0.3135]
Predicted label: 8
Correct prediction
Energy consumption = 197.532020 pJ
sum error= 216
Actual label: 3
Output voltages: [0.35209, 0.15272, 0.20906, 0.7554, 0.18637, 0.39972, 0.16765, 0.18954, 0.42012, 0.21261]
Predicted label: 3
Correct prediction
Energy consumption = 183.405926 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 548 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 548 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 548 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22616, 0.050824, 0.068898, 0.36044, 0.23199, 0.71155, 0.38082, 0.087631, 0.51894, 0.17253]
Predicted label: 5
Correct prediction
Energy consumption = 183.238114 pJ
sum error= 216
Actual label: 6
Output voltages: [0.3196, 0.27821, 0.26939, 0.11279, 0.35106, 0.38534, 0.74957, 0.061736, 0.3101, 0.15301]
Predicted label: 6
Correct prediction
Energy consumption = 182.244187 pJ
sum error= 216
Actual label: 7
Output voltages: [0.31277, 0.23218, 0.30537, 0.34009, 0.10273, 0.064085, 0.044776, 0.75622, 0.33711, 0.32322]
Predicted label: 7
Correct prediction
Energy consumption = 197.606462 pJ
sum error= 216
Actual label: 0
Output voltages: [0.67338, 0.26525, 0.28542, 0.14794, 0.19098, 0.12452, 0.40788, 0.21222, 0.35045, 0.21769]
Predicted label: 0
Correct prediction
Energy consumption = 193.671575 pJ
sum error= 216
Actual label: 6
Output voltages: [0.29926, 0.28733, 0.31895, 0.078002, 0.32142, 0.34598, 0.74841, 0.07879, 0.36685, 0.11865]
Predicted label: 6
Correct prediction
Energy consumption = 182.969447 pJ
sum error= 216
Actual label: 7
Output voltages: [0.31848, 0.2144, 0.26515, 0.2579, 0.098847, 0.083285, 0.041239, 0.75311, 0.42873, 0.3417]
Predicted label: 7
Correct prediction
Energy consumption = 200.085460 pJ
sum error= 216
Actual label: 1
Output voltages: [0.22889, 0.74253, 0.2053, 0.1805, 0.3685, 0.11103, 0.38939, 0.0572, 0.30761, 0.28326]
Predicted label: 1
Correct prediction
Energy consumption = 201.692844 pJ
sum error= 216
Actual label: 2
Output voltages: [0.32418, 0.2766, 0.75391, 0.28578, 0.14992, 0.033407, 0.25726, 0.29201, 0.37704, 0.2065]
Predicted label: 2
Correct prediction
Energy consumption = 179.512042 pJ
sum error= 216
Actual label: 5
Output voltages: [0.23914, 0.049396, 0.20548, 0.35672, 0.2086, 0.68113, 0.29461, 0.21071, 0.51042, 0.21026]
Predicted label: 5
Correct prediction
Energy consumption = 189.224677 pJ
sum error= 216
Actual label: 8
Output voltages: [0.15338, 0.26296, 0.30607, 0.28077, 0.12504, 0.20934, 0.19702, 0.20652, 0.75773, 0.24955]
Predicted label: 8
Correct prediction
Energy consumption = 184.568572 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 549 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 549 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 549 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.26978, 0.74273, 0.21452, 0.19694, 0.35171, 0.057641, 0.28803, 0.20406, 0.26109, 0.30632]
Predicted label: 1
Correct prediction
Energy consumption = 205.761815 pJ
sum error= 216
Actual label: 9
Output voltages: [0.3255, 0.11541, 0.19007, 0.29548, 0.34981, 0.16265, 0.091661, 0.19831, 0.39112, 0.64375]
Predicted label: 9
Correct prediction
Energy consumption = 193.217686 pJ
sum error= 216
Actual label: 3
Output voltages: [0.34463, 0.082944, 0.40844, 0.69163, 0.13823, 0.17446, 0.13826, 0.12446, 0.58279, 0.17117]
Predicted label: 3
Correct prediction
Energy consumption = 185.988364 pJ
sum error= 216
Actual label: 8
Output voltages: [0.20967, 0.17164, 0.2867, 0.30441, 0.090311, 0.27027, 0.12848, 0.2937, 0.74669, 0.20902]
Predicted label: 8
Correct prediction
Energy consumption = 187.371653 pJ
sum error= 216
Actual label: 2
Output voltages: [0.3685, 0.28705, 0.73545, 0.38228, 0.14328, 0.032381, 0.31829, 0.1739, 0.42514, 0.23686]
Predicted label: 2
Correct prediction
Energy consumption = 182.296430 pJ
sum error= 216
Actual label: 8
Output voltages: [0.19339, 0.17803, 0.24588, 0.29349, 0.15128, 0.22648, 0.1328, 0.23628, 0.74786, 0.29555]
Predicted label: 8
Correct prediction
Energy consumption = 191.650896 pJ
sum error= 216
Actual label: 7
Output voltages: [0.28602, 0.29478, 0.4022, 0.26834, 0.12773, 0.050789, 0.046833, 0.74787, 0.36933, 0.32468]
Predicted label: 7
Correct prediction
Energy consumption = 191.898719 pJ
sum error= 216
Actual label: 6
Output voltages: [0.29088, 0.22415, 0.39369, 0.044007, 0.38855, 0.25869, 0.72909, 0.080714, 0.301, 0.10897]
Predicted label: 6
Correct prediction
Energy consumption = 189.721760 pJ
sum error= 216
Actual label: 7
Output voltages: [0.31586, 0.22013, 0.30418, 0.36147, 0.0921, 0.097577, 0.03406, 0.74653, 0.45477, 0.35245]
Predicted label: 7
Correct prediction
Energy consumption = 200.712271 pJ
sum error= 216
Actual label: 1
Output voltages: [0.23409, 0.70942, 0.19688, 0.20853, 0.46307, 0.058892, 0.12437, 0.28295, 0.24499, 0.31763]
Predicted label: 1
Correct prediction
Energy consumption = 196.801909 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 550 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 550 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 550 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15673, 0.15726, 0.25734, 0.096755, 0.76036, 0.133, 0.35624, 0.33675, 0.22605, 0.17103]
Predicted label: 4
Correct prediction
Energy consumption = 189.212083 pJ
sum error= 216
Actual label: 6
Output voltages: [0.32514, 0.24008, 0.31053, 0.07605, 0.40051, 0.30873, 0.74223, 0.061099, 0.32886, 0.14148]
Predicted label: 6
Correct prediction
Energy consumption = 187.753793 pJ
sum error= 216
Actual label: 2
Output voltages: [0.35397, 0.21673, 0.73711, 0.39989, 0.16741, 0.047214, 0.26258, 0.25599, 0.42762, 0.16464]
Predicted label: 2
Correct prediction
Energy consumption = 191.156882 pJ
sum error= 216
Actual label: 9
Output voltages: [0.36374, 0.13225, 0.18734, 0.32757, 0.2863, 0.211, 0.088517, 0.3082, 0.38605, 0.67388]
Predicted label: 9
Correct prediction
Energy consumption = 185.962791 pJ
sum error= 216
Actual label: 3
Output voltages: [0.41596, 0.14044, 0.28024, 0.74474, 0.11853, 0.25164, 0.12731, 0.18664, 0.50221, 0.17492]
Predicted label: 3
Correct prediction
Energy consumption = 194.549807 pJ
sum error= 216
Actual label: 0
Output voltages: [0.73446, 0.21865, 0.19925, 0.21497, 0.20836, 0.23462, 0.44254, 0.16526, 0.34552, 0.27575]
Predicted label: 0
Correct prediction
Energy consumption = 201.956533 pJ
sum error= 216
Actual label: 1
Output voltages: [0.19201, 0.76671, 0.3044, 0.37685, 0.15838, 0.06125, 0.30056, 0.15686, 0.30316, 0.25039]
Predicted label: 1
Correct prediction
Energy consumption = 204.766151 pJ
sum error= 216
Actual label: 2
Output voltages: [0.33141, 0.40436, 0.64796, 0.31059, 0.15811, 0.029552, 0.37536, 0.13407, 0.38536, 0.15639]
Predicted label: 2
Correct prediction
Energy consumption = 182.828862 pJ
sum error= 216
Actual label: 3
Output voltages: [0.32743, 0.15478, 0.30815, 0.75813, 0.20938, 0.26662, 0.15336, 0.20785, 0.37834, 0.24282]
Predicted label: 3
Correct prediction
Energy consumption = 184.372706 pJ
sum error= 216
Actual label: 4
Output voltages: [0.19719, 0.18811, 0.25143, 0.1863, 0.73842, 0.11135, 0.29437, 0.29962, 0.18463, 0.4542]
Predicted label: 4
Correct prediction
Energy consumption = 196.245386 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 551 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 551 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 551 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.19393, 0.053418, 0.15961, 0.47294, 0.20368, 0.62743, 0.35062, 0.20007, 0.50029, 0.21499]
Predicted label: 5
Correct prediction
Energy consumption = 189.664400 pJ
sum error= 216
Actual label: 6
Output voltages: [0.31082, 0.24412, 0.26898, 0.12943, 0.34596, 0.43762, 0.74863, 0.076614, 0.35665, 0.10343]
Predicted label: 6
Correct prediction
Energy consumption = 191.363980 pJ
sum error= 216
Actual label: 7
Output voltages: [0.29698, 0.2707, 0.14909, 0.12954, 0.24423, 0.2142, 0.057279, 0.74179, 0.32492, 0.39605]
Predicted label: 7
Correct prediction
Energy consumption = 209.150874 pJ
sum error= 216
Actual label: 0
Output voltages: [0.71514, 0.26094, 0.24322, 0.22365, 0.15143, 0.21734, 0.48032, 0.13187, 0.26967, 0.26183]
Predicted label: 0
Correct prediction
Energy consumption = 197.015818 pJ
sum error= 216
Actual label: 1
Output voltages: [0.21633, 0.75997, 0.23529, 0.30247, 0.21998, 0.051275, 0.24026, 0.21581, 0.28342, 0.30501]
Predicted label: 1
Correct prediction
Energy consumption = 215.228370 pJ
sum error= 216
Actual label: 2
Output voltages: [0.35859, 0.38636, 0.6714, 0.41474, 0.13865, 0.029336, 0.31517, 0.13272, 0.34115, 0.16644]
Predicted label: 2
Correct prediction
Energy consumption = 188.726515 pJ
sum error= 216
Actual label: 3
Output voltages: [0.38911, 0.19073, 0.2028, 0.75213, 0.11143, 0.34109, 0.17189, 0.26636, 0.38294, 0.14414]
Predicted label: 3
Correct prediction
Energy consumption = 180.605242 pJ
sum error= 216
Actual label: 4
Output voltages: [0.1851, 0.14763, 0.26188, 0.11081, 0.75191, 0.126, 0.24653, 0.3276, 0.27377, 0.33695]
Predicted label: 4
Correct prediction
Energy consumption = 203.199574 pJ
sum error= 216
Actual label: 5
Output voltages: [0.24634, 0.068778, 0.19831, 0.38504, 0.14802, 0.68117, 0.33577, 0.13779, 0.56275, 0.23817]
Predicted label: 5
Correct prediction
Energy consumption = 184.660006 pJ
sum error= 216
Actual label: 0
Output voltages: [0.60977, 0.24199, 0.16805, 0.15281, 0.24238, 0.28703, 0.58211, 0.13162, 0.33184, 0.20881]
Predicted label: 0
Correct prediction
Energy consumption = 195.333632 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 552 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 552 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 552 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17082, 0.76239, 0.21421, 0.38141, 0.21923, 0.18038, 0.31196, 0.219, 0.22051, 0.27117]
Predicted label: 1
Correct prediction
Energy consumption = 212.872328 pJ
sum error= 216
Actual label: 2
Output voltages: [0.37442, 0.354, 0.70378, 0.33495, 0.13791, 0.03054, 0.34664, 0.1563, 0.39517, 0.20721]
Predicted label: 2
Correct prediction
Energy consumption = 185.498434 pJ
sum error= 216
Actual label: 8
Output voltages: [0.36008, 0.12143, 0.30987, 0.32068, 0.15426, 0.21692, 0.17666, 0.069774, 0.70601, 0.37853]
Predicted label: 8
Correct prediction
Energy consumption = 197.691275 pJ
sum error= 216
Actual label: 9
Output voltages: [0.30716, 0.069826, 0.21756, 0.27326, 0.33241, 0.15353, 0.074214, 0.35342, 0.39416, 0.65569]
Predicted label: 9
Correct prediction
Energy consumption = 198.056603 pJ
sum error= 216
Actual label: 1
Output voltages: [0.28859, 0.76116, 0.3013, 0.32007, 0.29338, 0.056006, 0.24888, 0.15563, 0.25952, 0.28685]
Predicted label: 1
Correct prediction
Energy consumption = 214.985824 pJ
sum error= 216
Actual label: 4
Output voltages: [0.19522, 0.24293, 0.2945, 0.13487, 0.73739, 0.050508, 0.32475, 0.17804, 0.19902, 0.34858]
Predicted label: 4
Correct prediction
Energy consumption = 197.978853 pJ
sum error= 216
Actual label: 0
Output voltages: [0.71348, 0.19907, 0.22103, 0.20179, 0.24483, 0.11743, 0.34174, 0.23399, 0.37712, 0.3059]
Predicted label: 0
Correct prediction
Energy consumption = 209.484784 pJ
sum error= 216
Actual label: 9
Output voltages: [0.44272, 0.096995, 0.23742, 0.23108, 0.39265, 0.16794, 0.20279, 0.20912, 0.26308, 0.7011]
Predicted label: 9
Correct prediction
Energy consumption = 195.264506 pJ
sum error= 216
Actual label: 5
Output voltages: [0.2612, 0.080675, 0.078788, 0.41406, 0.18304, 0.72929, 0.26211, 0.23872, 0.50276, 0.28907]
Predicted label: 5
Correct prediction
Energy consumption = 188.597824 pJ
sum error= 216
Actual label: 0
Output voltages: [0.69702, 0.21349, 0.22471, 0.22282, 0.19152, 0.14918, 0.41606, 0.19283, 0.37827, 0.29969]
Predicted label: 0
Correct prediction
Energy consumption = 197.587196 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 553 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 553 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 553 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.37056, 0.13053, 0.28924, 0.38931, 0.14797, 0.3225, 0.20257, 0.080553, 0.72743, 0.29541]
Predicted label: 8
Correct prediction
Energy consumption = 200.278918 pJ
sum error= 216
Actual label: 0
Output voltages: [0.71473, 0.21188, 0.27412, 0.13667, 0.18359, 0.16677, 0.4521, 0.16321, 0.29683, 0.2483]
Predicted label: 0
Correct prediction
Energy consumption = 193.254309 pJ
sum error= 216
Actual label: 7
Output voltages: [0.28314, 0.26357, 0.081221, 0.20982, 0.27123, 0.10395, 0.053093, 0.6844, 0.37778, 0.38373]
Predicted label: 7
Correct prediction
Energy consumption = 211.755508 pJ
sum error= 216
Actual label: 7
Output voltages: [0.30414, 0.23884, 0.12085, 0.28225, 0.20315, 0.15443, 0.039818, 0.73368, 0.37555, 0.40428]
Predicted label: 7
Correct prediction
Energy consumption = 193.295033 pJ
sum error= 216
Actual label: 1
Output voltages: [0.19492, 0.7579, 0.30073, 0.32775, 0.24498, 0.051832, 0.30399, 0.13615, 0.31999, 0.24936]
Predicted label: 1
Correct prediction
Energy consumption = 209.561885 pJ
sum error= 216
Actual label: 1
Output voltages: [0.21441, 0.74369, 0.28729, 0.33271, 0.26923, 0.045605, 0.23446, 0.23426, 0.25124, 0.30404]
Predicted label: 1
Correct prediction
Energy consumption = 212.872775 pJ
sum error= 216
Actual label: 2
Output voltages: [0.30684, 0.31816, 0.70112, 0.35173, 0.1033, 0.031525, 0.27575, 0.2343, 0.42434, 0.20002]
Predicted label: 2
Correct prediction
Energy consumption = 190.382200 pJ
sum error= 216
Actual label: 9
Output voltages: [0.35676, 0.14298, 0.21176, 0.253, 0.30778, 0.20357, 0.15933, 0.24356, 0.3347, 0.68364]
Predicted label: 9
Correct prediction
Energy consumption = 199.751975 pJ
sum error= 216
Actual label: 3
Output voltages: [0.25041, 0.17153, 0.35944, 0.74921, 0.1476, 0.167, 0.11234, 0.19397, 0.50475, 0.19804]
Predicted label: 3
Correct prediction
Energy consumption = 180.741014 pJ
sum error= 216
Actual label: 6
Output voltages: [0.45055, 0.31592, 0.30415, 0.16143, 0.29542, 0.15736, 0.64502, 0.063757, 0.37657, 0.12259]
Predicted label: 6
Correct prediction
Energy consumption = 198.834637 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 554 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 554 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 554 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33909, 0.21957, 0.29572, 0.31162, 0.091068, 0.043482, 0.041311, 0.73431, 0.39583, 0.28969]
Predicted label: 7
Correct prediction
Energy consumption = 201.539877 pJ
sum error= 216
Actual label: 2
Output voltages: [0.34442, 0.27368, 0.72324, 0.37942, 0.15875, 0.025853, 0.26193, 0.19997, 0.4151, 0.19663]
Predicted label: 2
Correct prediction
Energy consumption = 182.959036 pJ
sum error= 216
Actual label: 3
Output voltages: [0.31869, 0.11553, 0.33258, 0.74798, 0.14972, 0.2128, 0.12052, 0.26459, 0.44954, 0.21218]
Predicted label: 3
Correct prediction
Energy consumption = 181.381753 pJ
sum error= 216
Actual label: 8
Output voltages: [0.35641, 0.12741, 0.35364, 0.35957, 0.193, 0.1946, 0.23227, 0.072676, 0.69698, 0.32884]
Predicted label: 8
Correct prediction
Energy consumption = 195.500737 pJ
sum error= 216
Actual label: 1
Output voltages: [0.20662, 0.75374, 0.3469, 0.34028, 0.22533, 0.049987, 0.31489, 0.13318, 0.30282, 0.20261]
Predicted label: 1
Correct prediction
Energy consumption = 210.312756 pJ
sum error= 216
Actual label: 2
Output voltages: [0.39919, 0.19327, 0.70688, 0.40747, 0.16661, 0.032835, 0.28067, 0.23363, 0.48745, 0.15563]
Predicted label: 2
Correct prediction
Energy consumption = 182.511778 pJ
sum error= 216
Actual label: 9
Output voltages: [0.33001, 0.16043, 0.26625, 0.19834, 0.47118, 0.060407, 0.20429, 0.12497, 0.33656, 0.56367]
Predicted label: 9
Correct prediction
Energy consumption = 192.430946 pJ
sum error= 216
Actual label: 8
Output voltages: [0.47435, 0.12809, 0.3475, 0.44314, 0.10804, 0.22893, 0.31551, 0.066737, 0.59506, 0.30375]
Predicted label: 8
Correct prediction
Energy consumption = 202.938387 pJ
sum error= 216
Actual label: 8
Output voltages: [0.3674, 0.097198, 0.36764, 0.40657, 0.18845, 0.15134, 0.23947, 0.084844, 0.65997, 0.29954]
Predicted label: 8
Correct prediction
Energy consumption = 198.533205 pJ
sum error= 216
Actual label: 7
Output voltages: [0.27919, 0.25728, 0.26614, 0.24728, 0.094373, 0.10941, 0.052024, 0.75318, 0.38246, 0.34046]
Predicted label: 7
Correct prediction
Energy consumption = 200.767966 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 555 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 555 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 555 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23937, 0.77433, 0.21605, 0.30374, 0.18598, 0.17947, 0.42519, 0.11948, 0.25281, 0.24647]
Predicted label: 1
Correct prediction
Energy consumption = 212.566441 pJ
sum error= 216
Actual label: 7
Output voltages: [0.3576, 0.23842, 0.16765, 0.18335, 0.18051, 0.17206, 0.05955, 0.74799, 0.33597, 0.34116]
Predicted label: 7
Correct prediction
Energy consumption = 202.895248 pJ
sum error= 216
Actual label: 1
Output voltages: [0.30068, 0.73344, 0.37819, 0.34859, 0.2377, 0.036404, 0.30993, 0.12452, 0.2898, 0.2353]
Predicted label: 1
Correct prediction
Energy consumption = 207.201263 pJ
sum error= 216
Actual label: 1
Output voltages: [0.2612, 0.76941, 0.26195, 0.27212, 0.23235, 0.10385, 0.39379, 0.12615, 0.25103, 0.23312]
Predicted label: 1
Correct prediction
Energy consumption = 202.387177 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72379, 0.24217, 0.17449, 0.17303, 0.17151, 0.25856, 0.47043, 0.16513, 0.34271, 0.22646]
Predicted label: 0
Correct prediction
Energy consumption = 199.049710 pJ
sum error= 216
Actual label: 3
Output voltages: [0.30917, 0.1303, 0.28289, 0.75452, 0.24454, 0.25371, 0.15675, 0.26181, 0.48491, 0.22222]
Predicted label: 3
Correct prediction
Energy consumption = 186.743624 pJ
sum error= 216
Actual label: 4
Output voltages: [0.32298, 0.13414, 0.35062, 0.095873, 0.70264, 0.042099, 0.32362, 0.18287, 0.24199, 0.33292]
Predicted label: 4
Correct prediction
Energy consumption = 188.672156 pJ
sum error= 216
Actual label: 2
Output voltages: [0.36331, 0.27787, 0.72151, 0.34073, 0.094319, 0.033547, 0.26729, 0.26, 0.46864, 0.16741]
Predicted label: 2
Correct prediction
Energy consumption = 183.977412 pJ
sum error= 216
Actual label: 6
Output voltages: [0.28635, 0.22541, 0.34508, 0.05387, 0.35413, 0.27397, 0.7406, 0.071373, 0.37168, 0.13619]
Predicted label: 6
Correct prediction
Energy consumption = 190.739600 pJ
sum error= 216
Actual label: 4
Output voltages: [0.29342, 0.16616, 0.28697, 0.13043, 0.73805, 0.062309, 0.39628, 0.14953, 0.20723, 0.32218]
Predicted label: 4
Correct prediction
Energy consumption = 188.884518 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 556 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 556 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 556 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34972, 0.21089, 0.1653, 0.23317, 0.17236, 0.20459, 0.050444, 0.71541, 0.39355, 0.42482]
Predicted label: 7
Correct prediction
Energy consumption = 204.523434 pJ
sum error= 216
Actual label: 4
Output voltages: [0.32413, 0.15517, 0.36519, 0.070663, 0.70796, 0.036013, 0.30362, 0.19217, 0.22558, 0.29385]
Predicted label: 4
Correct prediction
Energy consumption = 192.242536 pJ
sum error= 216
Actual label: 2
Output voltages: [0.28362, 0.28048, 0.6187, 0.42557, 0.079182, 0.043877, 0.25253, 0.14209, 0.51171, 0.2184]
Predicted label: 2
Correct prediction
Energy consumption = 193.565201 pJ
sum error= 216
Actual label: 7
Output voltages: [0.29997, 0.25778, 0.3631, 0.29511, 0.10065, 0.038897, 0.043513, 0.73825, 0.41463, 0.32293]
Predicted label: 7
Correct prediction
Energy consumption = 198.560514 pJ
sum error= 216
Actual label: 4
Output voltages: [0.14011, 0.1673, 0.38332, 0.068626, 0.6361, 0.056091, 0.30301, 0.2643, 0.35931, 0.27835]
Predicted label: 4
Correct prediction
Energy consumption = 191.838723 pJ
sum error= 216
Actual label: 9
Output voltages: [0.37438, 0.16559, 0.20291, 0.27495, 0.35026, 0.17549, 0.13185, 0.25077, 0.29929, 0.71139]
Predicted label: 9
Correct prediction
Energy consumption = 195.442405 pJ
sum error= 216
Actual label: 1
Output voltages: [0.3184, 0.75617, 0.22071, 0.28492, 0.18763, 0.12394, 0.42437, 0.11539, 0.3072, 0.20927]
Predicted label: 1
Correct prediction
Energy consumption = 214.011549 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72053, 0.21381, 0.23392, 0.16401, 0.21728, 0.17227, 0.44545, 0.21087, 0.32064, 0.2716]
Predicted label: 0
Correct prediction
Energy consumption = 204.077671 pJ
sum error= 216
Actual label: 6
Output voltages: [0.36209, 0.24766, 0.2872, 0.11783, 0.27357, 0.28165, 0.73682, 0.078979, 0.37603, 0.19266]
Predicted label: 6
Correct prediction
Energy consumption = 186.986470 pJ
sum error= 216
Actual label: 8
Output voltages: [0.36612, 0.13098, 0.40422, 0.28026, 0.11681, 0.20229, 0.15141, 0.078849, 0.72179, 0.31988]
Predicted label: 8
Correct prediction
Energy consumption = 189.009406 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 557 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 557 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 557 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27534, 0.045546, 0.10383, 0.32277, 0.20952, 0.72511, 0.33511, 0.22878, 0.49673, 0.23497]
Predicted label: 5
Correct prediction
Energy consumption = 194.522997 pJ
sum error= 216
Actual label: 5
Output voltages: [0.17104, 0.058349, 0.10401, 0.37837, 0.26325, 0.72895, 0.22705, 0.24922, 0.52604, 0.23832]
Predicted label: 5
Correct prediction
Energy consumption = 179.869383 pJ
sum error= 216
Actual label: 5
Output voltages: [0.26031, 0.04021, 0.075074, 0.34821, 0.29439, 0.72801, 0.31026, 0.21794, 0.5046, 0.25984]
Predicted label: 5
Correct prediction
Energy consumption = 177.826945 pJ
sum error= 216
Actual label: 3
Output voltages: [0.28825, 0.098618, 0.25187, 0.74482, 0.18914, 0.36579, 0.1446, 0.19405, 0.44701, 0.23533]
Predicted label: 3
Correct prediction
Energy consumption = 180.429875 pJ
sum error= 216
Actual label: 5
Output voltages: [0.23056, 0.047667, 0.098238, 0.35897, 0.25256, 0.71699, 0.27304, 0.19884, 0.55082, 0.23809]
Predicted label: 5
Correct prediction
Energy consumption = 184.367211 pJ
sum error= 216
Actual label: 9
Output voltages: [0.31106, 0.15218, 0.22409, 0.29731, 0.29348, 0.19606, 0.12464, 0.28342, 0.36019, 0.69023]
Predicted label: 9
Correct prediction
Energy consumption = 192.375798 pJ
sum error= 216
Actual label: 7
Output voltages: [0.27919, 0.2743, 0.36359, 0.27278, 0.14892, 0.041568, 0.05418, 0.7562, 0.2981, 0.30704]
Predicted label: 7
Correct prediction
Energy consumption = 192.970702 pJ
sum error= 216
Actual label: 4
Output voltages: [0.19417, 0.25082, 0.17802, 0.22258, 0.70562, 0.10497, 0.37255, 0.19144, 0.21259, 0.27573]
Predicted label: 4
Correct prediction
Energy consumption = 198.361457 pJ
sum error= 216
Actual label: 8
Output voltages: [0.31152, 0.20984, 0.22859, 0.37812, 0.16965, 0.20933, 0.2774, 0.055747, 0.65513, 0.39405]
Predicted label: 8
Correct prediction
Energy consumption = 207.906726 pJ
sum error= 216
Actual label: 5
Output voltages: [0.19035, 0.040964, 0.13297, 0.30191, 0.25336, 0.65297, 0.384, 0.17481, 0.56249, 0.23692]
Predicted label: 5
Correct prediction
Energy consumption = 183.685477 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 558 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 558 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 558 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37544, 0.11314, 0.21803, 0.26355, 0.34428, 0.21899, 0.16226, 0.25234, 0.31584, 0.65753]
Predicted label: 9
Correct prediction
Energy consumption = 202.359140 pJ
sum error= 216
Actual label: 6
Output voltages: [0.30489, 0.28963, 0.30542, 0.11172, 0.28356, 0.33109, 0.74693, 0.093327, 0.40127, 0.15745]
Predicted label: 6
Correct prediction
Energy consumption = 192.443656 pJ
sum error= 216
Actual label: 9
Output voltages: [0.37987, 0.12113, 0.1975, 0.25592, 0.32448, 0.18575, 0.11179, 0.26926, 0.335, 0.67645]
Predicted label: 9
Correct prediction
Energy consumption = 200.933944 pJ
sum error= 216
Actual label: 3
Output voltages: [0.23328, 0.1786, 0.23488, 0.7242, 0.11921, 0.30329, 0.084754, 0.2321, 0.49014, 0.23421]
Predicted label: 3
Correct prediction
Energy consumption = 182.910940 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72949, 0.27985, 0.21761, 0.17162, 0.13892, 0.29491, 0.42761, 0.17264, 0.27508, 0.25992]
Predicted label: 0
Correct prediction
Energy consumption = 195.139265 pJ
sum error= 216
Actual label: 3
Output voltages: [0.29995, 0.17357, 0.27501, 0.76401, 0.18788, 0.18039, 0.1541, 0.25366, 0.44669, 0.23264]
Predicted label: 3
Correct prediction
Energy consumption = 181.965358 pJ
sum error= 216
Actual label: 8
Output voltages: [0.38132, 0.11367, 0.34471, 0.43211, 0.12166, 0.12165, 0.19551, 0.090698, 0.62995, 0.31995]
Predicted label: 8
Correct prediction
Energy consumption = 195.007080 pJ
sum error= 216
Actual label: 9
Output voltages: [0.37615, 0.098267, 0.2172, 0.20704, 0.28361, 0.18723, 0.09862, 0.25932, 0.4276, 0.65506]
Predicted label: 9
Correct prediction
Energy consumption = 191.326643 pJ
sum error= 216
Actual label: 1
Output voltages: [0.22013, 0.76582, 0.1521, 0.27134, 0.13269, 0.15477, 0.40561, 0.13267, 0.38326, 0.18261]
Predicted label: 1
Correct prediction
Energy consumption = 212.502373 pJ
sum error= 216
Actual label: 8
Output voltages: [0.24577, 0.25728, 0.37798, 0.24241, 0.15827, 0.098316, 0.22189, 0.11345, 0.73714, 0.3584]
Predicted label: 8
Correct prediction
Energy consumption = 193.759063 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 559 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 559 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 559 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20759, 0.75348, 0.26871, 0.29675, 0.17894, 0.050992, 0.37818, 0.07904, 0.34347, 0.218]
Predicted label: 1
Correct prediction
Energy consumption = 209.555900 pJ
sum error= 216
Actual label: 6
Output voltages: [0.34629, 0.22784, 0.21857, 0.17198, 0.3163, 0.3645, 0.73049, 0.086653, 0.41065, 0.17796]
Predicted label: 6
Correct prediction
Energy consumption = 193.477788 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72144, 0.18916, 0.29957, 0.18748, 0.21108, 0.12636, 0.39823, 0.17158, 0.38711, 0.2597]
Predicted label: 0
Correct prediction
Energy consumption = 197.674418 pJ
sum error= 216
Actual label: 0
Output voltages: [0.60457, 0.22263, 0.39407, 0.18053, 0.16708, 0.078527, 0.45561, 0.068664, 0.42239, 0.26025]
Predicted label: 0
Correct prediction
Energy consumption = 190.171349 pJ
sum error= 216
Actual label: 1
Output voltages: [0.18649, 0.73812, 0.22347, 0.24888, 0.24858, 0.11125, 0.30564, 0.087099, 0.40502, 0.22992]
Predicted label: 1
Correct prediction
Energy consumption = 208.333222 pJ
sum error= 216
Actual label: 2
Output voltages: [0.39447, 0.22955, 0.65312, 0.44098, 0.18819, 0.037356, 0.28642, 0.18534, 0.38646, 0.12026]
Predicted label: 2
Correct prediction
Energy consumption = 192.275879 pJ
sum error= 216
Actual label: 3
Output voltages: [0.28334, 0.10455, 0.26394, 0.72844, 0.23605, 0.28634, 0.15975, 0.18964, 0.43426, 0.25457]
Predicted label: 3
Correct prediction
Energy consumption = 188.615272 pJ
sum error= 216
Actual label: 4
Output voltages: [0.11464, 0.27808, 0.31057, 0.19266, 0.72545, 0.049043, 0.27109, 0.25318, 0.2237, 0.30651]
Predicted label: 4
Correct prediction
Energy consumption = 201.708164 pJ
sum error= 216
Actual label: 5
Output voltages: [0.24442, 0.053965, 0.064084, 0.37635, 0.17741, 0.72246, 0.30331, 0.21369, 0.52594, 0.15031]
Predicted label: 5
Correct prediction
Energy consumption = 188.801892 pJ
sum error= 216
Actual label: 6
Output voltages: [0.25313, 0.14556, 0.27096, 0.20299, 0.33836, 0.36881, 0.73235, 0.054003, 0.39412, 0.20382]
Predicted label: 6
Correct prediction
Energy consumption = 188.096678 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 560 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 560 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 560 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37599, 0.32091, 0.20411, 0.11628, 0.27682, 0.047635, 0.09409, 0.52509, 0.29021, 0.43418]
Predicted label: 7
Correct prediction
Energy consumption = 220.467900 pJ
sum error= 216
Actual label: 8
Output voltages: [0.22178, 0.21951, 0.35304, 0.29425, 0.35664, 0.052899, 0.29739, 0.045927, 0.60912, 0.24691]
Predicted label: 8
Correct prediction
Energy consumption = 198.056809 pJ
sum error= 216
Actual label: 9
Output voltages: [0.34943, 0.10353, 0.24397, 0.15653, 0.25741, 0.19632, 0.094938, 0.26785, 0.46319, 0.63752]
Predicted label: 9
Correct prediction
Energy consumption = 187.492105 pJ
sum error= 216
Actual label: 0
Output voltages: [0.66427, 0.16195, 0.32797, 0.14867, 0.13283, 0.24871, 0.40138, 0.072596, 0.3908, 0.29138]
Predicted label: 0
Correct prediction
Energy consumption = 189.485885 pJ
sum error= 216
Actual label: 1
Output voltages: [0.18331, 0.7468, 0.28705, 0.37935, 0.22926, 0.04455, 0.19825, 0.22143, 0.28375, 0.29502]
Predicted label: 1
Correct prediction
Energy consumption = 214.190430 pJ
sum error= 216
Actual label: 2
Output voltages: [0.36356, 0.10825, 0.65635, 0.48017, 0.14706, 0.045174, 0.21657, 0.16863, 0.47616, 0.16864]
Predicted label: 2
Correct prediction
Energy consumption = 183.193769 pJ
sum error= 216
Actual label: 3
Output voltages: [0.34028, 0.20496, 0.29714, 0.76179, 0.18914, 0.18535, 0.14127, 0.15024, 0.39717, 0.26298]
Predicted label: 3
Correct prediction
Energy consumption = 181.772306 pJ
sum error= 216
Actual label: 4
Output voltages: [0.153, 0.2767, 0.28131, 0.18863, 0.74061, 0.067701, 0.23696, 0.32088, 0.21877, 0.36303]
Predicted label: 4
Correct prediction
Energy consumption = 197.584635 pJ
sum error= 216
Actual label: 5
Output voltages: [0.29284, 0.047138, 0.062733, 0.40749, 0.20206, 0.72852, 0.29605, 0.20318, 0.54786, 0.19307]
Predicted label: 5
Correct prediction
Energy consumption = 189.663156 pJ
sum error= 216
Actual label: 6
Output voltages: [0.31377, 0.22843, 0.34409, 0.079782, 0.31028, 0.35449, 0.74737, 0.069966, 0.3514, 0.19635]
Predicted label: 6
Correct prediction
Energy consumption = 183.128646 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 561 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 561 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 561 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.45518, 0.17562, 0.17176, 0.20882, 0.30788, 0.14694, 0.088181, 0.73495, 0.20698, 0.37874]
Predicted label: 7
Correct prediction
Energy consumption = 204.082057 pJ
sum error= 216
Actual label: 8
Output voltages: [0.20561, 0.17842, 0.2445, 0.3682, 0.17404, 0.30355, 0.34931, 0.07022, 0.72497, 0.206]
Predicted label: 8
Correct prediction
Energy consumption = 202.936731 pJ
sum error= 216
Actual label: 9
Output voltages: [0.35479, 0.1375, 0.22218, 0.24374, 0.28628, 0.19276, 0.088665, 0.24079, 0.40912, 0.69007]
Predicted label: 9
Correct prediction
Energy consumption = 192.169553 pJ
sum error= 216
Actual label: 0
Output voltages: [0.64458, 0.1455, 0.27323, 0.13537, 0.18916, 0.27202, 0.49827, 0.093534, 0.32815, 0.2912]
Predicted label: 0
Correct prediction
Energy consumption = 188.413108 pJ
sum error= 216
Actual label: 1
Output voltages: [0.18307, 0.76677, 0.20491, 0.27646, 0.24476, 0.15259, 0.29426, 0.10239, 0.3076, 0.2882]
Predicted label: 1
Correct prediction
Energy consumption = 208.729791 pJ
sum error= 216
Actual label: 2
Output voltages: [0.32041, 0.22601, 0.68501, 0.41513, 0.19577, 0.027402, 0.28013, 0.18985, 0.48395, 0.21306]
Predicted label: 2
Correct prediction
Energy consumption = 182.686127 pJ
sum error= 216
Actual label: 3
Output voltages: [0.41597, 0.12514, 0.41531, 0.73269, 0.12718, 0.10486, 0.15295, 0.18313, 0.46353, 0.2142]
Predicted label: 3
Correct prediction
Energy consumption = 187.859508 pJ
sum error= 216
Actual label: 4
Output voltages: [0.053874, 0.24796, 0.16472, 0.068155, 0.55515, 0.12342, 0.20762, 0.34696, 0.48486, 0.23221]
Predicted label: 4
Correct prediction
Energy consumption = 204.558351 pJ
sum error= 216
Actual label: 5
Output voltages: [0.28754, 0.090142, 0.15781, 0.40055, 0.12946, 0.65134, 0.24521, 0.085122, 0.57646, 0.26213]
Predicted label: 5
Correct prediction
Energy consumption = 197.531076 pJ
sum error= 216
Actual label: 6
Output voltages: [0.25769, 0.20045, 0.34684, 0.096557, 0.37741, 0.39983, 0.74088, 0.069881, 0.30626, 0.12135]
Predicted label: 6
Correct prediction
Energy consumption = 187.252677 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 562 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 562 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 562 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35726, 0.2298, 0.18002, 0.16093, 0.22437, 0.16032, 0.074949, 0.73207, 0.31999, 0.42631]
Predicted label: 7
Correct prediction
Energy consumption = 200.862778 pJ
sum error= 216
Actual label: 8
Output voltages: [0.095481, 0.24312, 0.20421, 0.21737, 0.3052, 0.25261, 0.28891, 0.18858, 0.69438, 0.21807]
Predicted label: 8
Correct prediction
Energy consumption = 201.805076 pJ
sum error= 216
Actual label: 9
Output voltages: [0.32291, 0.17034, 0.18605, 0.24866, 0.38683, 0.15925, 0.098465, 0.21365, 0.28969, 0.68827]
Predicted label: 9
Correct prediction
Energy consumption = 202.643582 pJ
sum error= 216
Actual label: 3
Output voltages: [0.50325, 0.096015, 0.1587, 0.70434, 0.085664, 0.35973, 0.13103, 0.25042, 0.41249, 0.23493]
Predicted label: 3
Correct prediction
Energy consumption = 197.194356 pJ
sum error= 216
Actual label: 5
Output voltages: [0.22021, 0.089078, 0.082134, 0.46471, 0.19375, 0.65684, 0.2702, 0.12783, 0.48317, 0.25429]
Predicted label: 5
Correct prediction
Energy consumption = 185.147748 pJ
sum error= 216
Actual label: 3
Output voltages: [0.37282, 0.1545, 0.2786, 0.75699, 0.17917, 0.22878, 0.18436, 0.16382, 0.37333, 0.22545]
Predicted label: 3
Correct prediction
Energy consumption = 183.078402 pJ
sum error= 216
Actual label: 2
Output voltages: [0.3412, 0.2213, 0.71117, 0.33206, 0.16282, 0.028051, 0.31357, 0.22757, 0.48116, 0.19046]
Predicted label: 2
Correct prediction
Energy consumption = 181.650561 pJ
sum error= 216
Actual label: 9
Output voltages: [0.36154, 0.16032, 0.21852, 0.29902, 0.34735, 0.1403, 0.11975, 0.2388, 0.31979, 0.70046]
Predicted label: 9
Correct prediction
Energy consumption = 202.271531 pJ
sum error= 216
Actual label: 3
Output voltages: [0.47223, 0.10127, 0.35563, 0.7371, 0.11559, 0.21576, 0.14539, 0.17011, 0.41073, 0.18742]
Predicted label: 3
Correct prediction
Energy consumption = 195.838159 pJ
sum error= 216
Actual label: 2
Output voltages: [0.35795, 0.22013, 0.72938, 0.35558, 0.17262, 0.029691, 0.28044, 0.19384, 0.42386, 0.21666]
Predicted label: 2
Correct prediction
Energy consumption = 177.785697 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 563 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 563 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 563 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20437, 0.71414, 0.22178, 0.43306, 0.23286, 0.058376, 0.14648, 0.24557, 0.33971, 0.28657]
Predicted label: 1
Correct prediction
Energy consumption = 217.662910 pJ
sum error= 216
Actual label: 4
Output voltages: [0.12517, 0.3184, 0.31225, 0.24202, 0.72763, 0.046713, 0.23342, 0.30076, 0.20455, 0.26416]
Predicted label: 4
Correct prediction
Energy consumption = 202.652342 pJ
sum error= 216
Actual label: 5
Output voltages: [0.24361, 0.062689, 0.081165, 0.41981, 0.24447, 0.73729, 0.26123, 0.14184, 0.49655, 0.25933]
Predicted label: 5
Correct prediction
Energy consumption = 194.485478 pJ
sum error= 216
Actual label: 5
Output voltages: [0.26756, 0.080552, 0.080117, 0.31276, 0.16789, 0.73283, 0.30204, 0.10582, 0.50276, 0.16076]
Predicted label: 5
Correct prediction
Energy consumption = 182.813117 pJ
sum error= 216
Actual label: 2
Output voltages: [0.36289, 0.14951, 0.58193, 0.52491, 0.10895, 0.045288, 0.19767, 0.10918, 0.53268, 0.19995]
Predicted label: 2
Correct prediction
Energy consumption = 190.947006 pJ
sum error= 216
Actual label: 3
Output voltages: [0.2271, 0.15693, 0.30864, 0.73092, 0.20415, 0.24759, 0.1169, 0.19854, 0.51244, 0.25049]
Predicted label: 3
Correct prediction
Energy consumption = 183.715272 pJ
sum error= 216
Actual label: 2
Output voltages: [0.36385, 0.21743, 0.66814, 0.49573, 0.21215, 0.034161, 0.25177, 0.20632, 0.40551, 0.16279]
Predicted label: 2
Correct prediction
Energy consumption = 185.116357 pJ
sum error= 216
Actual label: 1
Output voltages: [0.21346, 0.76679, 0.19693, 0.40531, 0.13217, 0.1932, 0.29707, 0.14662, 0.31123, 0.3308]
Predicted label: 1
Correct prediction
Energy consumption = 212.920177 pJ
sum error= 216
Actual label: 3
Output voltages: [0.34554, 0.18564, 0.23843, 0.75023, 0.1199, 0.27168, 0.27972, 0.22321, 0.35929, 0.13463]
Predicted label: 3
Correct prediction
Energy consumption = 189.944415 pJ
sum error= 216
Actual label: 9
Output voltages: [0.28549, 0.080706, 0.1445, 0.29721, 0.19191, 0.28368, 0.089033, 0.34606, 0.4483, 0.56014]
Predicted label: 9
Correct prediction
Energy consumption = 194.318725 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 564 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 564 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 564 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30901, 0.2227, 0.17619, 0.20951, 0.19896, 0.14463, 0.053758, 0.74798, 0.29954, 0.42079]
Predicted label: 7
Correct prediction
Energy consumption = 202.161925 pJ
sum error= 216
Actual label: 2
Output voltages: [0.364, 0.17306, 0.68356, 0.43913, 0.17054, 0.040464, 0.24913, 0.17219, 0.44601, 0.14075]
Predicted label: 2
Correct prediction
Energy consumption = 190.774332 pJ
sum error= 216
Actual label: 1
Output voltages: [0.32881, 0.54738, 0.063809, 0.1535, 0.23146, 0.46129, 0.34731, 0.12075, 0.5264, 0.087504]
Predicted label: 1
Correct prediction
Energy consumption = 212.253788 pJ
sum error= 216
Actual label: 2
Output voltages: [0.3375, 0.13947, 0.59148, 0.50768, 0.16169, 0.05704, 0.23354, 0.15052, 0.56819, 0.1837]
Predicted label: 2
Correct prediction
Energy consumption = 186.662349 pJ
sum error= 216
Actual label: 8
Output voltages: [0.15911, 0.20587, 0.20632, 0.25604, 0.28532, 0.24773, 0.3431, 0.17395, 0.70342, 0.16613]
Predicted label: 8
Correct prediction
Energy consumption = 196.707177 pJ
sum error= 216
Actual label: 9
Output voltages: [0.37298, 0.14554, 0.20287, 0.23626, 0.32841, 0.1345, 0.060946, 0.16741, 0.36888, 0.6801]
Predicted label: 9
Correct prediction
Energy consumption = 189.953418 pJ
sum error= 216
Actual label: 1
Output voltages: [0.15384, 0.7646, 0.22205, 0.25373, 0.15546, 0.086656, 0.43379, 0.11885, 0.37492, 0.22511]
Predicted label: 1
Correct prediction
Energy consumption = 211.663967 pJ
sum error= 216
Actual label: 8
Output voltages: [0.12385, 0.26251, 0.22961, 0.2622, 0.27756, 0.30602, 0.45789, 0.14295, 0.68546, 0.14725]
Predicted label: 8
Correct prediction
Energy consumption = 201.790297 pJ
sum error= 216
Actual label: 8
Output voltages: [0.16947, 0.22678, 0.2627, 0.22213, 0.27711, 0.21659, 0.28093, 0.11238, 0.73322, 0.22868]
Predicted label: 8
Correct prediction
Energy consumption = 200.751037 pJ
sum error= 216
Actual label: 7
Output voltages: [0.39611, 0.19912, 0.16966, 0.09582, 0.25993, 0.13392, 0.09203, 0.54297, 0.37594, 0.46396]
Predicted label: 7
Correct prediction
Energy consumption = 203.349969 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 565 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 565 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 565 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.16401, 0.1703, 0.17427, 0.21279, 0.29311, 0.27991, 0.28681, 0.22535, 0.74692, 0.18769]
Predicted label: 8
Correct prediction
Energy consumption = 198.401412 pJ
sum error= 216
Actual label: 1
Output voltages: [0.26203, 0.74528, 0.21456, 0.19244, 0.29284, 0.072304, 0.25173, 0.12894, 0.40223, 0.33011]
Predicted label: 1
Correct prediction
Energy consumption = 215.333738 pJ
sum error= 216
Actual label: 0
Output voltages: [0.72022, 0.20702, 0.20631, 0.19654, 0.26737, 0.14427, 0.46007, 0.18393, 0.32209, 0.25483]
Predicted label: 0
Correct prediction
Energy consumption = 203.000638 pJ
sum error= 216
Actual label: 0
Output voltages: [0.64884, 0.16138, 0.3251, 0.12467, 0.22922, 0.10875, 0.50083, 0.17052, 0.40657, 0.25919]
Predicted label: 0
Correct prediction
Energy consumption = 190.027250 pJ
sum error= 216
Actual label: 7
Output voltages: [0.42022, 0.34542, 0.40004, 0.21329, 0.22243, 0.027703, 0.14425, 0.34259, 0.32528, 0.44298]
Predicted label: 9
Wrong prediction!
Energy consumption = 210.087030 pJ
sum error= 217
Actual label: 7
Output voltages: [0.3202, 0.35638, 0.49478, 0.1844, 0.094204, 0.036401, 0.11986, 0.59271, 0.38515, 0.28882]
Predicted label: 7
Correct prediction
Energy consumption = 197.229018 pJ
sum error= 217
Actual label: 8
Output voltages: [0.2111, 0.16189, 0.30935, 0.38309, 0.22004, 0.15782, 0.25699, 0.098585, 0.6725, 0.22649]
Predicted label: 8
Correct prediction
Energy consumption = 199.831515 pJ
sum error= 217
Actual label: 7
Output voltages: [0.27576, 0.2395, 0.23874, 0.2639, 0.19682, 0.12487, 0.044521, 0.74912, 0.26023, 0.40326]
Predicted label: 7
Correct prediction
Energy consumption = 197.077266 pJ
sum error= 217
Actual label: 5
Output voltages: [0.31451, 0.053775, 0.063625, 0.45259, 0.20033, 0.73501, 0.293, 0.18452, 0.45952, 0.1862]
Predicted label: 5
Correct prediction
Energy consumption = 184.389135 pJ
sum error= 217
Actual label: 0
Output voltages: [0.73132, 0.23738, 0.22687, 0.18143, 0.17027, 0.20637, 0.42919, 0.15881, 0.28682, 0.26413]
Predicted label: 0
Correct prediction
Energy consumption = 189.483366 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 566 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 566 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 566 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29337, 0.22269, 0.29456, 0.15569, 0.28663, 0.44722, 0.74374, 0.077793, 0.33202, 0.1314]
Predicted label: 6
Correct prediction
Energy consumption = 190.884701 pJ
sum error= 217
Actual label: 1
Output voltages: [0.141, 0.70865, 0.23132, 0.24253, 0.1428, 0.18737, 0.45064, 0.10574, 0.463, 0.12473]
Predicted label: 1
Correct prediction
Energy consumption = 206.982533 pJ
sum error= 217
Actual label: 5
Output voltages: [0.29267, 0.059059, 0.14164, 0.42693, 0.15143, 0.66991, 0.29907, 0.18594, 0.4191, 0.28501]
Predicted label: 5
Correct prediction
Energy consumption = 197.466585 pJ
sum error= 217
Actual label: 7
Output voltages: [0.30635, 0.24971, 0.15785, 0.25818, 0.23459, 0.15947, 0.057089, 0.7549, 0.29028, 0.38659]
Predicted label: 7
Correct prediction
Energy consumption = 201.283944 pJ
sum error= 217
Actual label: 4
Output voltages: [0.10968, 0.2619, 0.23973, 0.13525, 0.71451, 0.044928, 0.22683, 0.27618, 0.32617, 0.22229]
Predicted label: 4
Correct prediction
Energy consumption = 195.698659 pJ
sum error= 217
Actual label: 6
Output voltages: [0.32696, 0.18366, 0.22586, 0.16731, 0.33608, 0.45668, 0.71871, 0.069039, 0.4035, 0.12047]
Predicted label: 6
Correct prediction
Energy consumption = 197.273060 pJ
sum error= 217
Actual label: 1
Output voltages: [0.17807, 0.75501, 0.20388, 0.32931, 0.2548, 0.086516, 0.39113, 0.20264, 0.32363, 0.18007]
Predicted label: 1
Correct prediction
Energy consumption = 211.561762 pJ
sum error= 217
Actual label: 2
Output voltages: [0.36507, 0.16808, 0.68067, 0.44737, 0.1231, 0.03831, 0.25721, 0.20588, 0.48513, 0.14363]
Predicted label: 2
Correct prediction
Energy consumption = 188.485138 pJ
sum error= 217
Actual label: 5
Output voltages: [0.21953, 0.074093, 0.17374, 0.26929, 0.20444, 0.61458, 0.2512, 0.07457, 0.57832, 0.2746]
Predicted label: 5
Correct prediction
Energy consumption = 188.610347 pJ
sum error= 217
Actual label: 0
Output voltages: [0.69898, 0.17572, 0.29582, 0.12491, 0.18977, 0.22792, 0.4084, 0.11455, 0.37202, 0.28554]
Predicted label: 0
Correct prediction
Energy consumption = 192.389849 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 567 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 567 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 567 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34259, 0.22442, 0.17179, 0.20311, 0.19058, 0.24112, 0.052535, 0.74819, 0.37281, 0.38972]
Predicted label: 7
Correct prediction
Energy consumption = 202.517728 pJ
sum error= 217
Actual label: 9
Output voltages: [0.31052, 0.16241, 0.18224, 0.32037, 0.32715, 0.14872, 0.083245, 0.19301, 0.32995, 0.68589]
Predicted label: 9
Correct prediction
Energy consumption = 184.355172 pJ
sum error= 217
Actual label: 9
Output voltages: [0.35845, 0.13185, 0.23266, 0.2465, 0.34958, 0.18263, 0.13299, 0.22515, 0.33926, 0.70566]
Predicted label: 9
Correct prediction
Energy consumption = 188.479371 pJ
sum error= 217
Actual label: 0
Output voltages: [0.70658, 0.22962, 0.21668, 0.22589, 0.11854, 0.26219, 0.31576, 0.077519, 0.39656, 0.35676]
Predicted label: 0
Correct prediction
Energy consumption = 195.026600 pJ
sum error= 217
Actual label: 3
Output voltages: [0.52282, 0.11242, 0.28484, 0.74423, 0.1231, 0.24652, 0.12163, 0.22653, 0.38853, 0.19467]
Predicted label: 3
Correct prediction
Energy consumption = 193.557367 pJ
sum error= 217
Actual label: 8
Output voltages: [0.24143, 0.12139, 0.27851, 0.29588, 0.25726, 0.18956, 0.36605, 0.17096, 0.68162, 0.10179]
Predicted label: 8
Correct prediction
Energy consumption = 204.294207 pJ
sum error= 217
Actual label: 4
Output voltages: [0.20158, 0.29535, 0.35639, 0.084774, 0.57699, 0.033139, 0.33632, 0.36325, 0.26572, 0.25448]
Predicted label: 4
Correct prediction
Energy consumption = 190.694614 pJ
sum error= 217
Actual label: 4
Output voltages: [0.10891, 0.3864, 0.31399, 0.075916, 0.68628, 0.14625, 0.40913, 0.24078, 0.23873, 0.13564]
Predicted label: 4
Correct prediction
Energy consumption = 198.692291 pJ
sum error= 217
Actual label: 8
Output voltages: [0.17326, 0.19263, 0.16367, 0.35695, 0.2058, 0.26742, 0.40764, 0.11265, 0.68272, 0.15382]
Predicted label: 8
Correct prediction
Energy consumption = 205.586371 pJ
sum error= 217
Actual label: 1
Output voltages: [0.18215, 0.75209, 0.30714, 0.37659, 0.21703, 0.0528, 0.26074, 0.16179, 0.33665, 0.27573]
Predicted label: 1
Correct prediction
Energy consumption = 210.806946 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 568 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 568 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 568 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.30042, 0.089318, 0.21257, 0.32081, 0.14893, 0.36283, 0.31419, 0.10774, 0.73026, 0.236]
Predicted label: 8
Correct prediction
Energy consumption = 202.578314 pJ
sum error= 217
Actual label: 6
Output voltages: [0.28761, 0.21641, 0.33146, 0.12197, 0.35387, 0.33871, 0.74625, 0.079457, 0.42403, 0.12781]
Predicted label: 6
Correct prediction
Energy consumption = 193.735507 pJ
sum error= 217
Actual label: 5
Output voltages: [0.29008, 0.069524, 0.12328, 0.392, 0.17011, 0.72325, 0.31619, 0.1777, 0.54404, 0.22951]
Predicted label: 5
Correct prediction
Energy consumption = 188.275217 pJ
sum error= 217
Actual label: 9
Output voltages: [0.32096, 0.081563, 0.18206, 0.3024, 0.2868, 0.26345, 0.083147, 0.26427, 0.36762, 0.67415]
Predicted label: 9
Correct prediction
Energy consumption = 192.534670 pJ
sum error= 217
Actual label: 0
Output voltages: [0.72774, 0.22169, 0.23843, 0.16929, 0.16254, 0.21998, 0.42877, 0.16438, 0.30328, 0.26076]
Predicted label: 0
Correct prediction
Energy consumption = 196.590807 pJ
sum error= 217
Actual label: 0
Output voltages: [0.72424, 0.21891, 0.18132, 0.1522, 0.16064, 0.29585, 0.38462, 0.13732, 0.33715, 0.23736]
Predicted label: 0
Correct prediction
Energy consumption = 192.600461 pJ
sum error= 217
Actual label: 0
Output voltages: [0.70775, 0.23982, 0.24311, 0.11203, 0.13803, 0.26338, 0.39703, 0.17093, 0.30626, 0.28381]
Predicted label: 0
Correct prediction
Energy consumption = 184.783459 pJ
sum error= 217
Actual label: 3
Output voltages: [0.30253, 0.13831, 0.2766, 0.74749, 0.18061, 0.17291, 0.1529, 0.19574, 0.46502, 0.27398]
Predicted label: 3
Correct prediction
Energy consumption = 192.958144 pJ
sum error= 217
Actual label: 7
Output voltages: [0.37188, 0.24454, 0.17544, 0.24302, 0.15558, 0.18323, 0.056118, 0.63912, 0.35316, 0.47022]
Predicted label: 7
Correct prediction
Energy consumption = 205.742891 pJ
sum error= 217
Actual label: 1
Output voltages: [0.34086, 0.75973, 0.1291, 0.34676, 0.1103, 0.20268, 0.3242, 0.15638, 0.29534, 0.26544]
Predicted label: 1
Correct prediction
Energy consumption = 215.010972 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 569 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 569 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 569 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29571, 0.16749, 0.27321, 0.18871, 0.32495, 0.37118, 0.74071, 0.067149, 0.36157, 0.21413]
Predicted label: 6
Correct prediction
Energy consumption = 195.502153 pJ
sum error= 217
Actual label: 4
Output voltages: [0.15555, 0.38013, 0.28666, 0.1999, 0.60616, 0.047764, 0.29947, 0.28691, 0.29055, 0.17185]
Predicted label: 4
Correct prediction
Energy consumption = 202.292240 pJ
sum error= 217
Actual label: 2
Output voltages: [0.36849, 0.2479, 0.73936, 0.33876, 0.17853, 0.033533, 0.30318, 0.22032, 0.43693, 0.20703]
Predicted label: 2
Correct prediction
Energy consumption = 182.588250 pJ
sum error= 217
Actual label: 6
Output voltages: [0.29767, 0.20461, 0.27842, 0.12547, 0.36631, 0.40577, 0.73786, 0.069232, 0.37813, 0.12037]
Predicted label: 6
Correct prediction
Energy consumption = 190.064999 pJ
sum error= 217
Actual label: 6
Output voltages: [0.25854, 0.23001, 0.34118, 0.10122, 0.30529, 0.36121, 0.74597, 0.066126, 0.38464, 0.162]
Predicted label: 6
Correct prediction
Energy consumption = 180.920419 pJ
sum error= 217
Actual label: 0
Output voltages: [0.63425, 0.242, 0.26346, 0.15446, 0.15332, 0.18914, 0.38416, 0.094826, 0.47165, 0.2638]
Predicted label: 0
Correct prediction
Energy consumption = 198.131712 pJ
sum error= 217
Actual label: 4
Output voltages: [0.15011, 0.25673, 0.31276, 0.19252, 0.73722, 0.055315, 0.43781, 0.25273, 0.16335, 0.23356]
Predicted label: 4
Correct prediction
Energy consumption = 198.341000 pJ
sum error= 217
Actual label: 5
Output voltages: [0.27828, 0.064566, 0.061459, 0.45947, 0.21858, 0.69357, 0.26832, 0.18524, 0.42779, 0.32193]
Predicted label: 5
Correct prediction
Energy consumption = 190.219944 pJ
sum error= 217
Actual label: 4
Output voltages: [0.094127, 0.33818, 0.19642, 0.039312, 0.68864, 0.21022, 0.34976, 0.25336, 0.33148, 0.23683]
Predicted label: 4
Correct prediction
Energy consumption = 206.085098 pJ
sum error= 217
Actual label: 1
Output voltages: [0.17631, 0.76169, 0.27492, 0.32958, 0.2732, 0.079895, 0.22568, 0.17818, 0.25554, 0.30247]
Predicted label: 1
Correct prediction
Energy consumption = 206.638365 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 570 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 570 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 570 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33265, 0.23954, 0.26883, 0.7611, 0.16744, 0.17292, 0.17276, 0.13804, 0.40516, 0.27856]
Predicted label: 3
Correct prediction
Energy consumption = 194.696114 pJ
sum error= 217
Actual label: 8
Output voltages: [0.20799, 0.23003, 0.35471, 0.19478, 0.37131, 0.10794, 0.26633, 0.066158, 0.68611, 0.24819]
Predicted label: 8
Correct prediction
Energy consumption = 198.858122 pJ
sum error= 217
Actual label: 6
Output voltages: [0.27671, 0.20004, 0.30543, 0.073613, 0.36373, 0.38647, 0.74189, 0.057638, 0.32048, 0.1177]
Predicted label: 6
Correct prediction
Energy consumption = 186.948492 pJ
sum error= 217
Actual label: 3
Output voltages: [0.29003, 0.16295, 0.28225, 0.73691, 0.20117, 0.20163, 0.12709, 0.20972, 0.51766, 0.25247]
Predicted label: 3
Correct prediction
Energy consumption = 194.155710 pJ
sum error= 217
Actual label: 9
Output voltages: [0.33945, 0.12683, 0.2207, 0.28028, 0.37482, 0.21322, 0.20253, 0.22511, 0.28446, 0.72723]
Predicted label: 9
Correct prediction
Energy consumption = 196.409219 pJ
sum error= 217
Actual label: 9
Output voltages: [0.3496, 0.13116, 0.20343, 0.31511, 0.36803, 0.18499, 0.10825, 0.27119, 0.3135, 0.70008]
Predicted label: 9
Correct prediction
Energy consumption = 191.809187 pJ
sum error= 217
Actual label: 5
Output voltages: [0.29596, 0.065896, 0.20151, 0.28673, 0.13776, 0.64458, 0.27106, 0.068789, 0.62323, 0.22489]
Predicted label: 5
Correct prediction
Energy consumption = 191.266659 pJ
sum error= 217
Actual label: 9
Output voltages: [0.35085, 0.13053, 0.22212, 0.26365, 0.28284, 0.20118, 0.14585, 0.26415, 0.37912, 0.68462]
Predicted label: 9
Correct prediction
Energy consumption = 188.364150 pJ
sum error= 217
Actual label: 3
Output voltages: [0.33323, 0.17021, 0.28513, 0.76133, 0.19052, 0.25591, 0.15557, 0.19121, 0.39451, 0.23567]
Predicted label: 3
Correct prediction
Energy consumption = 188.260907 pJ
sum error= 217
Actual label: 7
Output voltages: [0.33589, 0.29411, 0.15572, 0.15981, 0.15775, 0.092628, 0.063702, 0.71444, 0.31492, 0.42797]
Predicted label: 7
Correct prediction
Energy consumption = 202.377689 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 571 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 571 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 571 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.17993, 0.2163, 0.28992, 0.41496, 0.14302, 0.15295, 0.32299, 0.092795, 0.66763, 0.29888]
Predicted label: 8
Correct prediction
Energy consumption = 203.857349 pJ
sum error= 217
Actual label: 5
Output voltages: [0.25514, 0.061501, 0.11063, 0.34922, 0.19007, 0.72224, 0.28577, 0.15676, 0.52269, 0.25737]
Predicted label: 5
Correct prediction
Energy consumption = 191.277932 pJ
sum error= 217
Actual label: 6
Output voltages: [0.28751, 0.22044, 0.32786, 0.087093, 0.35147, 0.39355, 0.75046, 0.069168, 0.32831, 0.13371]
Predicted label: 6
Correct prediction
Energy consumption = 187.029551 pJ
sum error= 217
Actual label: 4
Output voltages: [0.098316, 0.2479, 0.29996, 0.1671, 0.74789, 0.095916, 0.27597, 0.35829, 0.23794, 0.2696]
Predicted label: 4
Correct prediction
Energy consumption = 199.281911 pJ
sum error= 217
Actual label: 7
Output voltages: [0.36336, 0.26818, 0.22993, 0.16788, 0.20141, 0.1382, 0.071323, 0.75342, 0.32895, 0.35838]
Predicted label: 7
Correct prediction
Energy consumption = 207.795848 pJ
sum error= 217
Actual label: 6
Output voltages: [0.27892, 0.25633, 0.30247, 0.13747, 0.3126, 0.34471, 0.74758, 0.071147, 0.37584, 0.12912]
Predicted label: 6
Correct prediction
Energy consumption = 196.564369 pJ
sum error= 217
Actual label: 2
Output voltages: [0.37235, 0.2067, 0.73387, 0.32626, 0.18557, 0.031107, 0.30025, 0.23234, 0.46088, 0.21341]
Predicted label: 2
Correct prediction
Energy consumption = 182.117495 pJ
sum error= 217
Actual label: 2
Output voltages: [0.33316, 0.22728, 0.70123, 0.30522, 0.13512, 0.036073, 0.23523, 0.17563, 0.50676, 0.24444]
Predicted label: 2
Correct prediction
Energy consumption = 185.284169 pJ
sum error= 217
Actual label: 0
Output voltages: [0.68769, 0.25309, 0.21468, 0.14594, 0.14467, 0.24421, 0.41452, 0.12552, 0.37319, 0.25739]
Predicted label: 0
Correct prediction
Energy consumption = 194.356393 pJ
sum error= 217
Actual label: 9
Output voltages: [0.37236, 0.10989, 0.17908, 0.29947, 0.36427, 0.31945, 0.18395, 0.26708, 0.27338, 0.62869]
Predicted label: 9
Correct prediction
Energy consumption = 193.017917 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 572 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 572 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 572 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.099996, 0.34955, 0.23769, 0.26033, 0.55219, 0.042964, 0.27119, 0.14063, 0.43443, 0.15799]
Predicted label: 4
Correct prediction
Energy consumption = 201.426194 pJ
sum error= 217
Actual label: 0
Output voltages: [0.72606, 0.22567, 0.26699, 0.14922, 0.21209, 0.15664, 0.4352, 0.16808, 0.3146, 0.25903]
Predicted label: 0
Correct prediction
Energy consumption = 199.762691 pJ
sum error= 217
Actual label: 1
Output voltages: [0.12654, 0.75466, 0.24353, 0.26211, 0.20336, 0.089732, 0.4297, 0.15497, 0.38666, 0.1693]
Predicted label: 1
Correct prediction
Energy consumption = 206.727420 pJ
sum error= 217
Actual label: 2
Output voltages: [0.3687, 0.23934, 0.74215, 0.28511, 0.16217, 0.031684, 0.24735, 0.25, 0.41043, 0.16336]
Predicted label: 2
Correct prediction
Energy consumption = 186.083217 pJ
sum error= 217
Actual label: 3
Output voltages: [0.2904, 0.22198, 0.32967, 0.75676, 0.17048, 0.10273, 0.15396, 0.14701, 0.45164, 0.23502]
Predicted label: 3
Correct prediction
Energy consumption = 182.757443 pJ
sum error= 217
Actual label: 4
Output voltages: [0.19008, 0.12764, 0.31508, 0.092761, 0.76081, 0.057302, 0.28767, 0.27898, 0.24714, 0.22155]
Predicted label: 4
Correct prediction
Energy consumption = 191.412130 pJ
sum error= 217
Actual label: 5
Output voltages: [0.26434, 0.062064, 0.14817, 0.32675, 0.19678, 0.66317, 0.20748, 0.14981, 0.58634, 0.28506]
Predicted label: 5
Correct prediction
Energy consumption = 184.880461 pJ
sum error= 217
Actual label: 6
Output voltages: [0.29138, 0.2488, 0.32122, 0.074241, 0.36907, 0.35959, 0.73965, 0.079313, 0.33389, 0.061912]
Predicted label: 6
Correct prediction
Energy consumption = 186.227696 pJ
sum error= 217
Actual label: 7
Output voltages: [0.2887, 0.096263, 0.14688, 0.21916, 0.31503, 0.1596, 0.041461, 0.74701, 0.35404, 0.3364]
Predicted label: 7
Correct prediction
Energy consumption = 200.558293 pJ
sum error= 217
Actual label: 8
Output voltages: [0.18943, 0.26794, 0.29166, 0.20856, 0.15327, 0.16789, 0.23793, 0.1877, 0.74966, 0.29661]
Predicted label: 8
Correct prediction
Energy consumption = 187.441904 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 573 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 573 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 573 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39738, 0.086876, 0.22081, 0.22083, 0.36544, 0.18843, 0.096865, 0.23106, 0.37917, 0.64177]
Predicted label: 9
Correct prediction
Energy consumption = 193.558563 pJ
sum error= 217
Actual label: 0
Output voltages: [0.70707, 0.23984, 0.26927, 0.28955, 0.14751, 0.13394, 0.37358, 0.12655, 0.29644, 0.37085]
Predicted label: 0
Correct prediction
Energy consumption = 202.187756 pJ
sum error= 217
Actual label: 1
Output voltages: [0.1885, 0.74814, 0.36279, 0.2724, 0.1687, 0.055194, 0.29539, 0.17405, 0.34811, 0.19762]
Predicted label: 1
Correct prediction
Energy consumption = 213.763970 pJ
sum error= 217
Actual label: 2
Output voltages: [0.32999, 0.31392, 0.74618, 0.34069, 0.18843, 0.037698, 0.25241, 0.26464, 0.37371, 0.22967]
Predicted label: 2
Correct prediction
Energy consumption = 183.405047 pJ
sum error= 217
Actual label: 3
Output voltages: [0.18376, 0.20261, 0.44991, 0.60158, 0.090141, 0.15417, 0.088457, 0.40466, 0.30711, 0.37198]
Predicted label: 3
Correct prediction
Energy consumption = 190.139915 pJ
sum error= 217
Actual label: 5
Output voltages: [0.19694, 0.11916, 0.17538, 0.41096, 0.20921, 0.59272, 0.41296, 0.09631, 0.41087, 0.18371]
Predicted label: 5
Correct prediction
Energy consumption = 208.497436 pJ
sum error= 217
Actual label: 6
Output voltages: [0.27752, 0.12512, 0.3706, 0.1846, 0.42789, 0.16573, 0.61666, 0.18536, 0.27475, 0.28034]
Predicted label: 6
Correct prediction
Energy consumption = 191.958969 pJ
sum error= 217
Actual label: 0
Output voltages: [0.73665, 0.24915, 0.24697, 0.38902, 0.067121, 0.23833, 0.29761, 0.18292, 0.31204, 0.3202]
Predicted label: 0
Correct prediction
Energy consumption = 197.688370 pJ
sum error= 217
Actual label: 1
Output voltages: [0.17014, 0.76641, 0.22514, 0.24702, 0.24071, 0.088526, 0.44392, 0.11125, 0.28583, 0.22765]
Predicted label: 1
Correct prediction
Energy consumption = 208.890407 pJ
sum error= 217
Actual label: 2
Output voltages: [0.31177, 0.31418, 0.73867, 0.36746, 0.20567, 0.028313, 0.25909, 0.27272, 0.35725, 0.24607]
Predicted label: 2
Correct prediction
Energy consumption = 182.599519 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 574 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 574 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 574 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.27748, 0.14184, 0.22388, 0.74508, 0.25014, 0.34608, 0.19507, 0.26828, 0.37328, 0.20941]
Predicted label: 3
Correct prediction
Energy consumption = 196.837023 pJ
sum error= 217
Actual label: 4
Output voltages: [0.093069, 0.18542, 0.23315, 0.12362, 0.75763, 0.11465, 0.30378, 0.35517, 0.29185, 0.16352]
Predicted label: 4
Correct prediction
Energy consumption = 195.151925 pJ
sum error= 217
Actual label: 5
Output voltages: [0.29512, 0.058619, 0.16988, 0.49382, 0.10316, 0.63056, 0.19226, 0.14567, 0.50288, 0.25768]
Predicted label: 5
Correct prediction
Energy consumption = 199.138819 pJ
sum error= 217
Actual label: 6
Output voltages: [0.27667, 0.25758, 0.33127, 0.16412, 0.29247, 0.3431, 0.72948, 0.13431, 0.33726, 0.054357]
Predicted label: 6
Correct prediction
Energy consumption = 192.835366 pJ
sum error= 217
Actual label: 8
Output voltages: [0.18691, 0.18795, 0.25772, 0.27766, 0.13355, 0.29117, 0.22355, 0.18724, 0.75103, 0.27117]
Predicted label: 8
Correct prediction
Energy consumption = 186.491732 pJ
sum error= 217
Actual label: 7
Output voltages: [0.32445, 0.41523, 0.39485, 0.28101, 0.14747, 0.026778, 0.069067, 0.55935, 0.35743, 0.25978]
Predicted label: 7
Correct prediction
Energy consumption = 198.431974 pJ
sum error= 217
Actual label: 1
Output voltages: [0.22867, 0.69478, 0.23249, 0.12369, 0.30125, 0.13071, 0.34792, 0.059002, 0.41602, 0.30844]
Predicted label: 1
Correct prediction
Energy consumption = 205.472179 pJ
sum error= 217
Actual label: 3
Output voltages: [0.31554, 0.12168, 0.36751, 0.74239, 0.1596, 0.11881, 0.11486, 0.21619, 0.42458, 0.27584]
Predicted label: 3
Correct prediction
Energy consumption = 189.884684 pJ
sum error= 217
Actual label: 2
Output voltages: [0.3218, 0.23578, 0.73436, 0.34673, 0.20841, 0.040985, 0.30971, 0.24098, 0.44414, 0.17443]
Predicted label: 2
Correct prediction
Energy consumption = 177.662362 pJ
sum error= 217
Actual label: 8
Output voltages: [0.15914, 0.12668, 0.26997, 0.10014, 0.24656, 0.41566, 0.46109, 0.19542, 0.63045, 0.099018]
Predicted label: 8
Correct prediction
Energy consumption = 194.882685 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 575 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 575 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 575 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.68314, 0.28179, 0.36793, 0.19459, 0.17807, 0.048351, 0.38454, 0.17785, 0.29875, 0.27225]
Predicted label: 0
Correct prediction
Energy consumption = 196.879621 pJ
sum error= 217
Actual label: 7
Output voltages: [0.32756, 0.19972, 0.31239, 0.29119, 0.13517, 0.067924, 0.038173, 0.75474, 0.40229, 0.30559]
Predicted label: 7
Correct prediction
Energy consumption = 197.883715 pJ
sum error= 217
Actual label: 5
Output voltages: [0.38605, 0.054274, 0.17883, 0.56804, 0.09811, 0.52216, 0.24032, 0.14196, 0.40865, 0.26488]
Predicted label: 3
Wrong prediction!
Energy consumption = 194.042827 pJ
sum error= 218
Actual label: 9
Output voltages: [0.33682, 0.12762, 0.21572, 0.37721, 0.37664, 0.18839, 0.11437, 0.30066, 0.28166, 0.60794]
Predicted label: 9
Correct prediction
Energy consumption = 186.577016 pJ
sum error= 218
Actual label: 9
Output voltages: [0.34758, 0.092818, 0.19479, 0.30396, 0.40916, 0.15014, 0.20347, 0.29797, 0.23123, 0.51915]
Predicted label: 9
Correct prediction
Energy consumption = 196.503227 pJ
sum error= 218
Actual label: 6
Output voltages: [0.29428, 0.22514, 0.35643, 0.055609, 0.42002, 0.30427, 0.73133, 0.055903, 0.36292, 0.099938]
Predicted label: 6
Correct prediction
Energy consumption = 186.686326 pJ
sum error= 218
Actual label: 0
Output voltages: [0.60957, 0.22102, 0.38516, 0.23669, 0.2723, 0.043009, 0.44565, 0.12496, 0.2611, 0.36433]
Predicted label: 0
Correct prediction
Energy consumption = 188.808669 pJ
sum error= 218
Actual label: 9
Output voltages: [0.46508, 0.09236, 0.16112, 0.30084, 0.36487, 0.18645, 0.13024, 0.19475, 0.31129, 0.61267]
Predicted label: 9
Correct prediction
Energy consumption = 195.662902 pJ
sum error= 218
Actual label: 4
Output voltages: [0.11916, 0.12677, 0.24996, 0.1138, 0.76151, 0.084812, 0.26774, 0.29131, 0.30067, 0.18479]
Predicted label: 4
Correct prediction
Energy consumption = 189.728998 pJ
sum error= 218
Actual label: 1
Output voltages: [0.36386, 0.61837, 0.3284, 0.084012, 0.47249, 0.086533, 0.44805, 0.077251, 0.24249, 0.25935]
Predicted label: 1
Correct prediction
Energy consumption = 197.914390 pJ
sum error= 218
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 576 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 576 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 576 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36727, 0.21821, 0.35688, 0.7529, 0.086021, 0.18396, 0.13998, 0.25552, 0.39093, 0.14069]
Predicted label: 3
Correct prediction
Energy consumption = 191.191397 pJ
sum error= 218
Actual label: 2
Output voltages: [0.34811, 0.16224, 0.75062, 0.25562, 0.17005, 0.043164, 0.24867, 0.3142, 0.45795, 0.14768]
Predicted label: 2
Correct prediction
Energy consumption = 175.970380 pJ
sum error= 218
Actual label: 1
Output voltages: [0.21199, 0.73439, 0.36158, 0.26922, 0.41454, 0.03871, 0.31271, 0.15275, 0.16922, 0.28789]
Predicted label: 1
Correct prediction
Energy consumption = 212.345779 pJ
sum error= 218
Actual label: 2
Output voltages: [0.38167, 0.21281, 0.73896, 0.29196, 0.13856, 0.034741, 0.2747, 0.37109, 0.46133, 0.18065]
Predicted label: 2
Correct prediction
Energy consumption = 179.075886 pJ
sum error= 218
Actual label: 3
Output voltages: [0.35251, 0.19507, 0.28205, 0.76353, 0.17648, 0.20088, 0.13231, 0.20346, 0.49651, 0.22983]
Predicted label: 3
Correct prediction
Energy consumption = 184.967682 pJ
sum error= 218
Actual label: 8
Output voltages: [0.22382, 0.18502, 0.31674, 0.32157, 0.17756, 0.12898, 0.16025, 0.19106, 0.74179, 0.23699]
Predicted label: 8
Correct prediction
Energy consumption = 186.273007 pJ
sum error= 218
Actual label: 3
Output voltages: [0.29564, 0.238, 0.29237, 0.75826, 0.13737, 0.13252, 0.10657, 0.19639, 0.49834, 0.26589]
Predicted label: 3
Correct prediction
Energy consumption = 176.061970 pJ
sum error= 218
Actual label: 2
Output voltages: [0.37526, 0.25243, 0.75674, 0.29223, 0.20667, 0.036907, 0.30653, 0.2809, 0.39306, 0.22455]
Predicted label: 2
Correct prediction
Energy consumption = 173.206491 pJ
sum error= 218
Actual label: 6
Output voltages: [0.25767, 0.22556, 0.40551, 0.058722, 0.37618, 0.27337, 0.7479, 0.085083, 0.31725, 0.11913]
Predicted label: 6
Correct prediction
Energy consumption = 186.458225 pJ
sum error= 218
Actual label: 5
Output voltages: [0.29698, 0.07153, 0.17762, 0.31135, 0.22398, 0.49826, 0.50257, 0.049646, 0.50986, 0.21669]
Predicted label: 8
Wrong prediction!
Energy consumption = 185.083482 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 577 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 577 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 577 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27572, 0.26601, 0.35269, 0.066414, 0.34461, 0.36273, 0.73776, 0.074767, 0.3382, 0.071981]
Predicted label: 6
Correct prediction
Energy consumption = 192.396967 pJ
sum error= 219
Actual label: 8
Output voltages: [0.22608, 0.12699, 0.3218, 0.24816, 0.18949, 0.2354, 0.20167, 0.13387, 0.73857, 0.3106]
Predicted label: 8
Correct prediction
Energy consumption = 189.539693 pJ
sum error= 219
Actual label: 2
Output voltages: [0.34415, 0.2633, 0.74459, 0.27628, 0.16373, 0.037511, 0.20029, 0.3976, 0.39856, 0.18941]
Predicted label: 2
Correct prediction
Energy consumption = 185.495679 pJ
sum error= 219
Actual label: 7
Output voltages: [0.34923, 0.21334, 0.091351, 0.31892, 0.11565, 0.15306, 0.034264, 0.59393, 0.39666, 0.53072]
Predicted label: 7
Correct prediction
Energy consumption = 197.879374 pJ
sum error= 219
Actual label: 4
Output voltages: [0.16032, 0.16522, 0.25954, 0.22014, 0.75286, 0.062246, 0.23471, 0.26294, 0.21703, 0.23888]
Predicted label: 4
Correct prediction
Energy consumption = 199.053316 pJ
sum error= 219
Actual label: 8
Output voltages: [0.22623, 0.24106, 0.33013, 0.21697, 0.15448, 0.14566, 0.26814, 0.15705, 0.74684, 0.28608]
Predicted label: 8
Correct prediction
Energy consumption = 187.300422 pJ
sum error= 219
Actual label: 1
Output voltages: [0.18187, 0.76289, 0.26645, 0.2168, 0.29703, 0.088446, 0.42321, 0.14521, 0.26766, 0.24002]
Predicted label: 1
Correct prediction
Energy consumption = 207.510474 pJ
sum error= 219
Actual label: 8
Output voltages: [0.16771, 0.17705, 0.26902, 0.18477, 0.15556, 0.24803, 0.27477, 0.19796, 0.74127, 0.28979]
Predicted label: 8
Correct prediction
Energy consumption = 186.392941 pJ
sum error= 219
Actual label: 0
Output voltages: [0.65724, 0.29857, 0.29517, 0.20642, 0.28125, 0.0801, 0.42694, 0.19938, 0.32953, 0.13828]
Predicted label: 0
Correct prediction
Energy consumption = 201.334785 pJ
sum error= 219
Actual label: 5
Output voltages: [0.25596, 0.062687, 0.069678, 0.45484, 0.15569, 0.72468, 0.26663, 0.20862, 0.45517, 0.2508]
Predicted label: 5
Correct prediction
Energy consumption = 193.822196 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 578 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 578 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 578 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36841, 0.20845, 0.41905, 0.74145, 0.13424, 0.077295, 0.11943, 0.23671, 0.45514, 0.21159]
Predicted label: 3
Correct prediction
Energy consumption = 193.840164 pJ
sum error= 219
Actual label: 9
Output voltages: [0.33956, 0.11102, 0.20314, 0.28287, 0.23444, 0.15931, 0.050084, 0.27895, 0.45708, 0.63893]
Predicted label: 9
Correct prediction
Energy consumption = 191.347659 pJ
sum error= 219
Actual label: 4
Output voltages: [0.098975, 0.18355, 0.34923, 0.10637, 0.75984, 0.0937, 0.29751, 0.28261, 0.24002, 0.31476]
Predicted label: 4
Correct prediction
Energy consumption = 192.472600 pJ
sum error= 219
Actual label: 1
Output voltages: [0.21455, 0.7629, 0.28279, 0.27578, 0.22546, 0.06477, 0.40527, 0.097234, 0.30373, 0.22059]
Predicted label: 1
Correct prediction
Energy consumption = 211.509150 pJ
sum error= 219
Actual label: 9
Output voltages: [0.40212, 0.097154, 0.20465, 0.27254, 0.45025, 0.16964, 0.24652, 0.22321, 0.20247, 0.59799]
Predicted label: 9
Correct prediction
Energy consumption = 195.812979 pJ
sum error= 219
Actual label: 2
Output voltages: [0.36054, 0.20362, 0.75277, 0.32528, 0.18312, 0.041474, 0.28236, 0.24747, 0.41589, 0.1628]
Predicted label: 2
Correct prediction
Energy consumption = 177.983401 pJ
sum error= 219
Actual label: 1
Output voltages: [0.20934, 0.76835, 0.33594, 0.25507, 0.2432, 0.055737, 0.39743, 0.11529, 0.25525, 0.24179]
Predicted label: 1
Correct prediction
Energy consumption = 199.990074 pJ
sum error= 219
Actual label: 9
Output voltages: [0.34482, 0.082399, 0.20357, 0.25883, 0.37037, 0.20764, 0.13232, 0.20389, 0.34021, 0.65648]
Predicted label: 9
Correct prediction
Energy consumption = 191.862101 pJ
sum error= 219
Actual label: 6
Output voltages: [0.30127, 0.23147, 0.30448, 0.098136, 0.34292, 0.34411, 0.74136, 0.070015, 0.40101, 0.10297]
Predicted label: 6
Correct prediction
Energy consumption = 189.603432 pJ
sum error= 219
Actual label: 7
Output voltages: [0.32368, 0.18716, 0.26592, 0.23952, 0.11543, 0.074821, 0.039314, 0.75369, 0.45732, 0.2866]
Predicted label: 7
Correct prediction
Energy consumption = 199.778371 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 579 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 579 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 579 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.41681, 0.070942, 0.23963, 0.16277, 0.30552, 0.15535, 0.11093, 0.25123, 0.45139, 0.62458]
Predicted label: 9
Correct prediction
Energy consumption = 194.100274 pJ
sum error= 219
Actual label: 0
Output voltages: [0.6749, 0.25088, 0.30567, 0.24107, 0.12626, 0.11581, 0.48583, 0.17792, 0.30087, 0.24291]
Predicted label: 0
Correct prediction
Energy consumption = 198.913770 pJ
sum error= 219
Actual label: 4
Output voltages: [0.14801, 0.14727, 0.28292, 0.12749, 0.74915, 0.1338, 0.37962, 0.28416, 0.26082, 0.15504]
Predicted label: 4
Correct prediction
Energy consumption = 194.585292 pJ
sum error= 219
Actual label: 6
Output voltages: [0.27746, 0.28185, 0.32913, 0.084533, 0.35896, 0.34052, 0.74653, 0.081644, 0.30923, 0.091912]
Predicted label: 6
Correct prediction
Energy consumption = 187.797820 pJ
sum error= 219
Actual label: 1
Output voltages: [0.1824, 0.75888, 0.24501, 0.1674, 0.27839, 0.13436, 0.44586, 0.10673, 0.34735, 0.18117]
Predicted label: 1
Correct prediction
Energy consumption = 203.189761 pJ
sum error= 219
Actual label: 7
Output voltages: [0.22377, 0.21201, 0.26662, 0.26209, 0.121, 0.07719, 0.03591, 0.74346, 0.45969, 0.35661]
Predicted label: 7
Correct prediction
Energy consumption = 193.937155 pJ
sum error= 219
Actual label: 3
Output voltages: [0.39363, 0.17383, 0.29442, 0.76104, 0.19241, 0.1886, 0.18171, 0.1673, 0.40664, 0.26275]
Predicted label: 3
Correct prediction
Energy consumption = 183.373551 pJ
sum error= 219
Actual label: 8
Output voltages: [0.18528, 0.20887, 0.28453, 0.36243, 0.13785, 0.25807, 0.22529, 0.13634, 0.7117, 0.19932]
Predicted label: 8
Correct prediction
Energy consumption = 195.765633 pJ
sum error= 219
Actual label: 7
Output voltages: [0.31721, 0.23869, 0.18917, 0.33699, 0.12679, 0.068907, 0.038944, 0.74069, 0.38706, 0.39107]
Predicted label: 7
Correct prediction
Energy consumption = 198.042071 pJ
sum error= 219
Actual label: 2
Output voltages: [0.32927, 0.29608, 0.74333, 0.32084, 0.16339, 0.028313, 0.26358, 0.34379, 0.38852, 0.22741]
Predicted label: 2
Correct prediction
Energy consumption = 182.075325 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 580 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 580 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 580 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.38588, 0.10388, 0.16682, 0.37585, 0.30833, 0.23404, 0.16661, 0.2534, 0.28216, 0.66354]
Predicted label: 9
Correct prediction
Energy consumption = 199.149861 pJ
sum error= 219
Actual label: 6
Output voltages: [0.4586, 0.29894, 0.28065, 0.12742, 0.27617, 0.26414, 0.62218, 0.0736, 0.39712, 0.073419]
Predicted label: 6
Correct prediction
Energy consumption = 191.915649 pJ
sum error= 219
Actual label: 5
Output voltages: [0.22939, 0.075092, 0.16297, 0.44427, 0.12126, 0.60353, 0.16681, 0.13083, 0.56537, 0.27991]
Predicted label: 5
Correct prediction
Energy consumption = 190.208781 pJ
sum error= 219
Actual label: 8
Output voltages: [0.18944, 0.11501, 0.30918, 0.35663, 0.095877, 0.29686, 0.22277, 0.098914, 0.72949, 0.2383]
Predicted label: 8
Correct prediction
Energy consumption = 177.391052 pJ
sum error= 219
Actual label: 3
Output voltages: [0.29665, 0.17712, 0.24887, 0.75745, 0.16289, 0.26012, 0.15088, 0.20507, 0.44494, 0.2344]
Predicted label: 3
Correct prediction
Energy consumption = 185.130059 pJ
sum error= 219
Actual label: 9
Output voltages: [0.38445, 0.12692, 0.16869, 0.30618, 0.25786, 0.19541, 0.06699, 0.21983, 0.43007, 0.66681]
Predicted label: 9
Correct prediction
Energy consumption = 186.885855 pJ
sum error= 219
Actual label: 0
Output voltages: [0.69257, 0.21583, 0.35001, 0.21991, 0.23189, 0.05914, 0.45776, 0.17426, 0.33189, 0.23384]
Predicted label: 0
Correct prediction
Energy consumption = 195.947813 pJ
sum error= 219
Actual label: 5
Output voltages: [0.24891, 0.04708, 0.12948, 0.38492, 0.1458, 0.67616, 0.20707, 0.20914, 0.51951, 0.28377]
Predicted label: 5
Correct prediction
Energy consumption = 188.331051 pJ
sum error= 219
Actual label: 7
Output voltages: [0.33724, 0.2659, 0.28008, 0.32753, 0.1312, 0.085458, 0.030135, 0.74621, 0.38548, 0.31741]
Predicted label: 7
Correct prediction
Energy consumption = 195.830159 pJ
sum error= 219
Actual label: 1
Output voltages: [0.21424, 0.74764, 0.24584, 0.14327, 0.36046, 0.17158, 0.43398, 0.084637, 0.26727, 0.23112]
Predicted label: 1
Correct prediction
Energy consumption = 200.687801 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 581 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 581 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 581 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27167, 0.16475, 0.26368, 0.13302, 0.32761, 0.39767, 0.7431, 0.06786, 0.38403, 0.1705]
Predicted label: 6
Correct prediction
Energy consumption = 191.030235 pJ
sum error= 219
Actual label: 1
Output voltages: [0.18859, 0.75497, 0.30355, 0.21743, 0.36371, 0.10659, 0.43632, 0.17469, 0.24439, 0.19736]
Predicted label: 1
Correct prediction
Energy consumption = 204.664733 pJ
sum error= 219
Actual label: 0
Output voltages: [0.66762, 0.19819, 0.35001, 0.20867, 0.2341, 0.04929, 0.37093, 0.14405, 0.37382, 0.2243]
Predicted label: 0
Correct prediction
Energy consumption = 198.409704 pJ
sum error= 219
Actual label: 9
Output voltages: [0.36325, 0.11115, 0.21391, 0.2141, 0.30909, 0.2002, 0.091558, 0.2882, 0.37097, 0.68275]
Predicted label: 9
Correct prediction
Energy consumption = 188.372109 pJ
sum error= 219
Actual label: 3
Output voltages: [0.40871, 0.18275, 0.26606, 0.73066, 0.1167, 0.29421, 0.3427, 0.22525, 0.28923, 0.12619]
Predicted label: 3
Correct prediction
Energy consumption = 193.271677 pJ
sum error= 219
Actual label: 3
Output voltages: [0.47212, 0.098523, 0.28994, 0.75511, 0.1929, 0.30075, 0.15791, 0.21954, 0.42713, 0.18882]
Predicted label: 3
Correct prediction
Energy consumption = 182.008392 pJ
sum error= 219
Actual label: 4
Output voltages: [0.1709, 0.15056, 0.3414, 0.14609, 0.7465, 0.059964, 0.35843, 0.36607, 0.18312, 0.1738]
Predicted label: 4
Correct prediction
Energy consumption = 185.960847 pJ
sum error= 219
Actual label: 4
Output voltages: [0.1444, 0.1312, 0.3295, 0.14343, 0.75498, 0.055363, 0.31117, 0.2701, 0.22573, 0.20971]
Predicted label: 4
Correct prediction
Energy consumption = 188.298001 pJ
sum error= 219
Actual label: 0
Output voltages: [0.70086, 0.23938, 0.2674, 0.21931, 0.22608, 0.11705, 0.44905, 0.11643, 0.35208, 0.22326]
Predicted label: 0
Correct prediction
Energy consumption = 206.205918 pJ
sum error= 219
Actual label: 6
Output voltages: [0.32888, 0.2342, 0.29374, 0.13926, 0.32391, 0.3752, 0.74629, 0.095281, 0.37732, 0.09677]
Predicted label: 6
Correct prediction
Energy consumption = 190.761559 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 582 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 582 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 582 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.29957, 0.21615, 0.70374, 0.3658, 0.12308, 0.037165, 0.22899, 0.31577, 0.46771, 0.15775]
Predicted label: 2
Correct prediction
Energy consumption = 188.241629 pJ
sum error= 219
Actual label: 5
Output voltages: [0.27066, 0.090301, 0.08653, 0.42306, 0.21484, 0.70421, 0.33947, 0.13015, 0.47954, 0.24304]
Predicted label: 5
Correct prediction
Energy consumption = 194.444489 pJ
sum error= 219
Actual label: 4
Output voltages: [0.17358, 0.14293, 0.29773, 0.13824, 0.7511, 0.056399, 0.32825, 0.2761, 0.25165, 0.22455]
Predicted label: 4
Correct prediction
Energy consumption = 199.197144 pJ
sum error= 219
Actual label: 2
Output voltages: [0.34641, 0.31846, 0.7484, 0.24587, 0.11203, 0.035275, 0.24866, 0.26643, 0.40506, 0.22126]
Predicted label: 2
Correct prediction
Energy consumption = 185.900806 pJ
sum error= 219
Actual label: 3
Output voltages: [0.22675, 0.18775, 0.30479, 0.72898, 0.18797, 0.17489, 0.08873, 0.23821, 0.50211, 0.26787]
Predicted label: 3
Correct prediction
Energy consumption = 184.205626 pJ
sum error= 219
Actual label: 4
Output voltages: [0.14006, 0.12216, 0.34213, 0.056442, 0.74907, 0.1596, 0.34256, 0.24342, 0.29846, 0.27494]
Predicted label: 4
Correct prediction
Energy consumption = 193.803874 pJ
sum error= 219
Actual label: 6
Output voltages: [0.27145, 0.2326, 0.32689, 0.095613, 0.32853, 0.29167, 0.74728, 0.1041, 0.3122, 0.21638]
Predicted label: 6
Correct prediction
Energy consumption = 183.848915 pJ
sum error= 219
Actual label: 0
Output voltages: [0.68248, 0.20917, 0.30177, 0.26063, 0.19107, 0.060504, 0.36665, 0.17627, 0.29307, 0.36024]
Predicted label: 0
Correct prediction
Energy consumption = 202.076225 pJ
sum error= 219
Actual label: 0
Output voltages: [0.64425, 0.19728, 0.27372, 0.20427, 0.16084, 0.27885, 0.49918, 0.10361, 0.19591, 0.32036]
Predicted label: 0
Correct prediction
Energy consumption = 191.860224 pJ
sum error= 219
Actual label: 2
Output voltages: [0.34008, 0.31019, 0.73378, 0.38258, 0.29079, 0.039446, 0.24874, 0.28939, 0.30781, 0.19792]
Predicted label: 2
Correct prediction
Energy consumption = 184.515919 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 583 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 583 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 583 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74415, 0.17856, 0.15645, 0.32761, 0.1717, 0.27331, 0.27528, 0.19893, 0.32265, 0.35977]
Predicted label: 0
Correct prediction
Energy consumption = 200.278350 pJ
sum error= 219
Actual label: 1
Output voltages: [0.22812, 0.75197, 0.13198, 0.24311, 0.17856, 0.274, 0.45408, 0.13601, 0.34369, 0.16694]
Predicted label: 1
Correct prediction
Energy consumption = 213.232350 pJ
sum error= 219
Actual label: 4
Output voltages: [0.14601, 0.13081, 0.33363, 0.11201, 0.75416, 0.079197, 0.3237, 0.23622, 0.25977, 0.24866]
Predicted label: 4
Correct prediction
Energy consumption = 191.209375 pJ
sum error= 219
Actual label: 5
Output voltages: [0.24061, 0.047359, 0.13594, 0.43587, 0.18412, 0.70657, 0.15466, 0.21558, 0.52997, 0.2757]
Predicted label: 5
Correct prediction
Energy consumption = 184.818132 pJ
sum error= 219
Actual label: 6
Output voltages: [0.26023, 0.17571, 0.2917, 0.12076, 0.30236, 0.35381, 0.72704, 0.052258, 0.44786, 0.13892]
Predicted label: 6
Correct prediction
Energy consumption = 179.917062 pJ
sum error= 219
Actual label: 7
Output voltages: [0.39418, 0.073896, 0.3682, 0.25695, 0.32087, 0.075781, 0.18577, 0.58734, 0.25888, 0.33938]
Predicted label: 7
Correct prediction
Energy consumption = 205.667249 pJ
sum error= 219
Actual label: 8
Output voltages: [0.20979, 0.18382, 0.30864, 0.31564, 0.13027, 0.24161, 0.26041, 0.11866, 0.73728, 0.24321]
Predicted label: 8
Correct prediction
Energy consumption = 196.505934 pJ
sum error= 219
Actual label: 9
Output voltages: [0.35871, 0.13329, 0.22406, 0.23379, 0.30723, 0.1797, 0.10032, 0.23237, 0.34809, 0.71518]
Predicted label: 9
Correct prediction
Energy consumption = 193.060859 pJ
sum error= 219
Actual label: 0
Output voltages: [0.71391, 0.24196, 0.17401, 0.26668, 0.20565, 0.26691, 0.34184, 0.20914, 0.27324, 0.21817]
Predicted label: 0
Correct prediction
Energy consumption = 196.733250 pJ
sum error= 219
Actual label: 1
Output voltages: [0.23299, 0.73992, 0.24958, 0.21173, 0.28511, 0.0935, 0.39467, 0.059216, 0.3375, 0.27079]
Predicted label: 1
Correct prediction
Energy consumption = 204.127321 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 584 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 584 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 584 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.26035, 0.14615, 0.72261, 0.36389, 0.15153, 0.045833, 0.30848, 0.24088, 0.47997, 0.14046]
Predicted label: 2
Correct prediction
Energy consumption = 194.108215 pJ
sum error= 219
Actual label: 3
Output voltages: [0.3667, 0.11253, 0.19821, 0.72455, 0.091643, 0.46042, 0.23905, 0.27995, 0.31771, 0.096985]
Predicted label: 3
Correct prediction
Energy consumption = 182.261359 pJ
sum error= 219
Actual label: 4
Output voltages: [0.13423, 0.15037, 0.26479, 0.15604, 0.69029, 0.090007, 0.12187, 0.44473, 0.26732, 0.30599]
Predicted label: 4
Correct prediction
Energy consumption = 189.241852 pJ
sum error= 219
Actual label: 5
Output voltages: [0.31787, 0.063721, 0.15912, 0.33721, 0.15283, 0.69077, 0.35152, 0.16766, 0.49684, 0.20491]
Predicted label: 5
Correct prediction
Energy consumption = 188.211420 pJ
sum error= 219
Actual label: 6
Output voltages: [0.27763, 0.27104, 0.33903, 0.089589, 0.3244, 0.36103, 0.74993, 0.054095, 0.38656, 0.18129]
Predicted label: 6
Correct prediction
Energy consumption = 180.904691 pJ
sum error= 219
Actual label: 7
Output voltages: [0.36512, 0.13997, 0.32307, 0.30744, 0.31945, 0.037917, 0.060791, 0.63624, 0.34141, 0.29829]
Predicted label: 7
Correct prediction
Energy consumption = 196.586434 pJ
sum error= 219
Actual label: 8
Output voltages: [0.17282, 0.17435, 0.25753, 0.27121, 0.13023, 0.32346, 0.2568, 0.16086, 0.75231, 0.23209]
Predicted label: 8
Correct prediction
Energy consumption = 188.652180 pJ
sum error= 219
Actual label: 0
Output voltages: [0.73037, 0.19729, 0.28129, 0.23205, 0.21177, 0.10812, 0.25747, 0.32666, 0.33729, 0.24426]
Predicted label: 0
Correct prediction
Energy consumption = 196.373244 pJ
sum error= 219
Actual label: 1
Output voltages: [0.18526, 0.75109, 0.3006, 0.2484, 0.1883, 0.05178, 0.34937, 0.1351, 0.37398, 0.23252]
Predicted label: 1
Correct prediction
Energy consumption = 209.139890 pJ
sum error= 219
Actual label: 2
Output voltages: [0.36229, 0.23101, 0.68922, 0.38498, 0.13636, 0.033256, 0.32648, 0.18007, 0.48206, 0.16578]
Predicted label: 2
Correct prediction
Energy consumption = 180.311659 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 585 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 585 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 585 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.43147, 0.10006, 0.32467, 0.73698, 0.19407, 0.27164, 0.086805, 0.30347, 0.41494, 0.14676]
Predicted label: 3
Correct prediction
Energy consumption = 184.998844 pJ
sum error= 219
Actual label: 4
Output voltages: [0.2475, 0.20732, 0.31465, 0.18401, 0.74534, 0.049537, 0.36343, 0.21944, 0.19361, 0.28012]
Predicted label: 4
Correct prediction
Energy consumption = 195.168882 pJ
sum error= 219
Actual label: 5
Output voltages: [0.31462, 0.065282, 0.08195, 0.46394, 0.21629, 0.7248, 0.28616, 0.1476, 0.42918, 0.24502]
Predicted label: 5
Correct prediction
Energy consumption = 194.763032 pJ
sum error= 219
Actual label: 6
Output voltages: [0.28673, 0.22011, 0.29784, 0.15335, 0.33022, 0.36599, 0.74205, 0.08402, 0.405, 0.093919]
Predicted label: 6
Correct prediction
Energy consumption = 192.802570 pJ
sum error= 219
Actual label: 7
Output voltages: [0.34589, 0.18773, 0.21144, 0.19967, 0.30068, 0.07923, 0.060319, 0.69706, 0.33589, 0.35067]
Predicted label: 7
Correct prediction
Energy consumption = 199.198464 pJ
sum error= 219
Actual label: 8
Output voltages: [0.29093, 0.20771, 0.29324, 0.3376, 0.12576, 0.24368, 0.26995, 0.10936, 0.73475, 0.20702]
Predicted label: 8
Correct prediction
Energy consumption = 199.122450 pJ
sum error= 219
Actual label: 9
Output voltages: [0.37431, 0.11928, 0.16929, 0.3096, 0.38061, 0.23839, 0.14088, 0.27921, 0.31378, 0.66166]
Predicted label: 9
Correct prediction
Energy consumption = 190.611039 pJ
sum error= 219
Actual label: 8
Output voltages: [0.2676, 0.20416, 0.34626, 0.36457, 0.14633, 0.14884, 0.23196, 0.091189, 0.73341, 0.28001]
Predicted label: 8
Correct prediction
Energy consumption = 191.342510 pJ
sum error= 219
Actual label: 7
Output voltages: [0.29872, 0.14875, 0.24242, 0.41795, 0.32499, 0.037784, 0.05374, 0.53176, 0.38529, 0.36342]
Predicted label: 7
Correct prediction
Energy consumption = 195.834828 pJ
sum error= 219
Actual label: 1
Output voltages: [0.17708, 0.77462, 0.25962, 0.26556, 0.21841, 0.11742, 0.37807, 0.12955, 0.29057, 0.2578]
Predicted label: 1
Correct prediction
Energy consumption = 197.973710 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 586 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 586 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 586 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35943, 0.073493, 0.26732, 0.74589, 0.20592, 0.37628, 0.11203, 0.18677, 0.41107, 0.21194]
Predicted label: 3
Correct prediction
Energy consumption = 185.342701 pJ
sum error= 219
Actual label: 7
Output voltages: [0.24797, 0.20762, 0.36862, 0.2357, 0.25524, 0.031131, 0.055235, 0.74348, 0.33852, 0.20079]
Predicted label: 7
Correct prediction
Energy consumption = 194.123541 pJ
sum error= 219
Actual label: 5
Output voltages: [0.32878, 0.049987, 0.07884, 0.42918, 0.23438, 0.74025, 0.2668, 0.26744, 0.45987, 0.29391]
Predicted label: 5
Correct prediction
Energy consumption = 188.745876 pJ
sum error= 219
Actual label: 2
Output voltages: [0.35813, 0.23737, 0.73583, 0.2877, 0.13776, 0.032321, 0.30971, 0.23021, 0.4758, 0.18669]
Predicted label: 2
Correct prediction
Energy consumption = 190.797519 pJ
sum error= 219
Actual label: 8
Output voltages: [0.20147, 0.18125, 0.28104, 0.21522, 0.20334, 0.1952, 0.1913, 0.13088, 0.74507, 0.32783]
Predicted label: 8
Correct prediction
Energy consumption = 192.720431 pJ
sum error= 219
Actual label: 0
Output voltages: [0.74018, 0.25404, 0.3145, 0.19827, 0.14004, 0.16415, 0.34041, 0.18311, 0.34855, 0.25791]
Predicted label: 0
Correct prediction
Energy consumption = 193.256331 pJ
sum error= 219
Actual label: 7
Output voltages: [0.32117, 0.207, 0.26934, 0.17504, 0.36168, 0.035928, 0.098707, 0.746, 0.25522, 0.22947]
Predicted label: 7
Correct prediction
Energy consumption = 197.404398 pJ
sum error= 219
Actual label: 5
Output voltages: [0.30843, 0.063171, 0.078576, 0.45599, 0.19484, 0.70464, 0.27575, 0.23884, 0.4201, 0.29711]
Predicted label: 5
Correct prediction
Energy consumption = 190.246462 pJ
sum error= 219
Actual label: 9
Output voltages: [0.31024, 0.16453, 0.17696, 0.32533, 0.36948, 0.29571, 0.17984, 0.1994, 0.32033, 0.6815]
Predicted label: 9
Correct prediction
Energy consumption = 187.902474 pJ
sum error= 219
Actual label: 9
Output voltages: [0.35221, 0.14588, 0.20901, 0.32368, 0.34832, 0.24864, 0.1852, 0.21269, 0.29821, 0.68399]
Predicted label: 9
Correct prediction
Energy consumption = 180.357697 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 587 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 587 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 587 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.67973, 0.27296, 0.27402, 0.17694, 0.17653, 0.10548, 0.28457, 0.188, 0.35923, 0.263]
Predicted label: 0
Correct prediction
Energy consumption = 207.392963 pJ
sum error= 219
Actual label: 9
Output voltages: [0.3295, 0.15709, 0.1367, 0.31993, 0.38526, 0.31842, 0.21251, 0.19797, 0.28808, 0.63134]
Predicted label: 9
Correct prediction
Energy consumption = 188.878326 pJ
sum error= 219
Actual label: 1
Output voltages: [0.22087, 0.74291, 0.30587, 0.34541, 0.23652, 0.042638, 0.24227, 0.14466, 0.32314, 0.23967]
Predicted label: 1
Correct prediction
Energy consumption = 214.916312 pJ
sum error= 219
Actual label: 1
Output voltages: [0.2597, 0.76217, 0.24382, 0.29129, 0.15016, 0.16175, 0.39866, 0.082487, 0.32018, 0.26195]
Predicted label: 1
Correct prediction
Energy consumption = 207.122777 pJ
sum error= 219
Actual label: 5
Output voltages: [0.31705, 0.062912, 0.15043, 0.5021, 0.13278, 0.64221, 0.26743, 0.16529, 0.41762, 0.2848]
Predicted label: 5
Correct prediction
Energy consumption = 191.260193 pJ
sum error= 219
Actual label: 8
Output voltages: [0.21864, 0.26653, 0.3117, 0.3116, 0.12708, 0.10183, 0.25107, 0.13726, 0.73248, 0.31835]
Predicted label: 8
Correct prediction
Energy consumption = 189.866727 pJ
sum error= 219
Actual label: 8
Output voltages: [0.17633, 0.17286, 0.35093, 0.33826, 0.12306, 0.14256, 0.17747, 0.18147, 0.72997, 0.28597]
Predicted label: 8
Correct prediction
Energy consumption = 188.029121 pJ
sum error= 219
Actual label: 6
Output voltages: [0.42635, 0.23435, 0.18468, 0.11727, 0.30833, 0.48686, 0.66124, 0.2153, 0.29521, 0.06657]
Predicted label: 6
Correct prediction
Energy consumption = 202.311784 pJ
sum error= 219
Actual label: 3
Output voltages: [0.37714, 0.07399, 0.24855, 0.69916, 0.14282, 0.39167, 0.16284, 0.15014, 0.48942, 0.20491]
Predicted label: 3
Correct prediction
Energy consumption = 186.344605 pJ
sum error= 219
Actual label: 2
Output voltages: [0.37868, 0.32097, 0.71795, 0.33948, 0.20025, 0.03209, 0.35129, 0.19199, 0.39739, 0.18941]
Predicted label: 2
Correct prediction
Energy consumption = 180.003673 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 588 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 588 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 588 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20163, 0.77721, 0.26779, 0.33203, 0.21937, 0.11605, 0.3725, 0.15546, 0.24149, 0.29504]
Predicted label: 1
Correct prediction
Energy consumption = 212.275747 pJ
sum error= 219
Actual label: 8
Output voltages: [0.17233, 0.2187, 0.30189, 0.22866, 0.17301, 0.2348, 0.19736, 0.1827, 0.75874, 0.27654]
Predicted label: 8
Correct prediction
Energy consumption = 198.838420 pJ
sum error= 219
Actual label: 3
Output voltages: [0.28439, 0.18146, 0.36225, 0.67064, 0.15217, 0.25298, 0.06984, 0.070718, 0.53568, 0.26]
Predicted label: 3
Correct prediction
Energy consumption = 187.794864 pJ
sum error= 219
Actual label: 2
Output voltages: [0.41601, 0.23194, 0.73456, 0.33417, 0.15235, 0.031925, 0.34689, 0.22261, 0.4273, 0.19433]
Predicted label: 2
Correct prediction
Energy consumption = 182.413996 pJ
sum error= 219
Actual label: 6
Output voltages: [0.29241, 0.2858, 0.31162, 0.093602, 0.3229, 0.37484, 0.75209, 0.074369, 0.35388, 0.14686]
Predicted label: 6
Correct prediction
Energy consumption = 186.671158 pJ
sum error= 219
Actual label: 5
Output voltages: [0.26658, 0.07341, 0.15747, 0.41833, 0.14243, 0.69246, 0.22077, 0.21499, 0.48565, 0.31852]
Predicted label: 5
Correct prediction
Energy consumption = 190.308731 pJ
sum error= 219
Actual label: 6
Output voltages: [0.29349, 0.30406, 0.2658, 0.19721, 0.29097, 0.29978, 0.74354, 0.089173, 0.3947, 0.081567]
Predicted label: 6
Correct prediction
Energy consumption = 191.753480 pJ
sum error= 219
Actual label: 7
Output voltages: [0.6287, 0.30193, 0.36783, 0.11806, 0.19619, 0.088148, 0.24739, 0.38243, 0.32952, 0.38403]
Predicted label: 0
Wrong prediction!
Energy consumption = 199.540659 pJ
sum error= 220
Actual label: 4
Output voltages: [0.42646, 0.16187, 0.429, 0.15587, 0.39846, 0.051535, 0.50672, 0.10262, 0.36201, 0.24142]
Predicted label: 6
Wrong prediction!
Energy consumption = 197.250021 pJ
sum error= 221
Actual label: 1
Output voltages: [0.099158, 0.74747, 0.36633, 0.37451, 0.23026, 0.14333, 0.37173, 0.22771, 0.25703, 0.22729]
Predicted label: 1
Correct prediction
Energy consumption = 210.095474 pJ
sum error= 221
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 589 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 589 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 589 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.6728, 0.25113, 0.15062, 0.18678, 0.24013, 0.2096, 0.42691, 0.21048, 0.35013, 0.241]
Predicted label: 0
Correct prediction
Energy consumption = 219.581052 pJ
sum error= 221
Actual label: 5
Output voltages: [0.39744, 0.09035, 0.18696, 0.4545, 0.087152, 0.618, 0.4261, 0.12579, 0.39427, 0.18178]
Predicted label: 5
Correct prediction
Energy consumption = 190.717067 pJ
sum error= 221
Actual label: 3
Output voltages: [0.45586, 0.1457, 0.31077, 0.7568, 0.17134, 0.22587, 0.15559, 0.19652, 0.3952, 0.19692]
Predicted label: 3
Correct prediction
Energy consumption = 183.247295 pJ
sum error= 221
Actual label: 1
Output voltages: [0.19372, 0.76657, 0.188, 0.32959, 0.22945, 0.16512, 0.30752, 0.12507, 0.31125, 0.27798]
Predicted label: 1
Correct prediction
Energy consumption = 211.310424 pJ
sum error= 221
Actual label: 9
Output voltages: [0.38983, 0.12874, 0.184, 0.25974, 0.26209, 0.25033, 0.12195, 0.33265, 0.35371, 0.68431]
Predicted label: 9
Correct prediction
Energy consumption = 196.865567 pJ
sum error= 221
Actual label: 2
Output voltages: [0.34005, 0.30844, 0.69896, 0.296, 0.19874, 0.035132, 0.36534, 0.21155, 0.3527, 0.12979]
Predicted label: 2
Correct prediction
Energy consumption = 190.580107 pJ
sum error= 221
Actual label: 1
Output voltages: [0.21345, 0.76738, 0.16925, 0.31058, 0.21009, 0.171, 0.32004, 0.16795, 0.33117, 0.26869]
Predicted label: 1
Correct prediction
Energy consumption = 209.168171 pJ
sum error= 221
Actual label: 9
Output voltages: [0.41692, 0.093682, 0.1776, 0.20286, 0.33382, 0.22986, 0.1462, 0.2894, 0.33616, 0.64936]
Predicted label: 9
Correct prediction
Energy consumption = 193.001665 pJ
sum error= 221
Actual label: 6
Output voltages: [0.33075, 0.2147, 0.24936, 0.17094, 0.35514, 0.43204, 0.73996, 0.074717, 0.36423, 0.1577]
Predicted label: 6
Correct prediction
Energy consumption = 184.185513 pJ
sum error= 221
Actual label: 0
Output voltages: [0.69571, 0.24278, 0.27704, 0.18625, 0.17603, 0.11977, 0.46613, 0.14575, 0.31658, 0.2605]
Predicted label: 0
Correct prediction
Energy consumption = 200.397862 pJ
sum error= 221
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 590 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 590 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 590 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.10636, 0.17196, 0.2659, 0.20252, 0.75782, 0.12508, 0.31813, 0.28611, 0.23551, 0.27036]
Predicted label: 4
Correct prediction
Energy consumption = 191.213503 pJ
sum error= 221
Actual label: 6
Output voltages: [0.31755, 0.27152, 0.27909, 0.15091, 0.34414, 0.33727, 0.74865, 0.086958, 0.36395, 0.091563]
Predicted label: 6
Correct prediction
Energy consumption = 194.198550 pJ
sum error= 221
Actual label: 1
Output voltages: [0.14768, 0.76723, 0.22917, 0.24234, 0.2287, 0.12673, 0.37197, 0.12324, 0.35439, 0.2274]
Predicted label: 1
Correct prediction
Energy consumption = 212.707461 pJ
sum error= 221
Actual label: 7
Output voltages: [0.28423, 0.27156, 0.15156, 0.23637, 0.23725, 0.1148, 0.083156, 0.74426, 0.23707, 0.38948]
Predicted label: 7
Correct prediction
Energy consumption = 204.141641 pJ
sum error= 221
Actual label: 3
Output voltages: [0.23522, 0.21507, 0.32398, 0.73304, 0.16926, 0.29176, 0.096271, 0.11896, 0.47568, 0.28239]
Predicted label: 3
Correct prediction
Energy consumption = 188.733658 pJ
sum error= 221
Actual label: 8
Output voltages: [0.18509, 0.21277, 0.23674, 0.38519, 0.097478, 0.22766, 0.18654, 0.19304, 0.73803, 0.25509]
Predicted label: 8
Correct prediction
Energy consumption = 196.582777 pJ
sum error= 221
Actual label: 7
Output voltages: [0.30537, 0.18186, 0.18196, 0.31422, 0.43209, 0.046129, 0.058206, 0.63919, 0.22686, 0.35002]
Predicted label: 7
Correct prediction
Energy consumption = 197.063778 pJ
sum error= 221
Actual label: 2
Output voltages: [0.2728, 0.35497, 0.63228, 0.40298, 0.065702, 0.036878, 0.28006, 0.0925, 0.46773, 0.1835]
Predicted label: 2
Correct prediction
Energy consumption = 190.285183 pJ
sum error= 221
Actual label: 9
Output voltages: [0.29445, 0.14434, 0.20931, 0.358, 0.28255, 0.2459, 0.10232, 0.28626, 0.35546, 0.66376]
Predicted label: 9
Correct prediction
Energy consumption = 191.485432 pJ
sum error= 221
Actual label: 6
Output voltages: [0.32838, 0.17392, 0.24739, 0.10494, 0.3544, 0.37718, 0.72525, 0.074772, 0.44989, 0.11107]
Predicted label: 6
Correct prediction
Energy consumption = 185.974432 pJ
sum error= 221
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 591 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 591 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 591 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.28417, 0.05063, 0.079352, 0.41166, 0.22048, 0.74711, 0.2523, 0.289, 0.46165, 0.27984]
Predicted label: 5
Correct prediction
Energy consumption = 192.183593 pJ
sum error= 221
Actual label: 8
Output voltages: [0.17438, 0.16684, 0.26964, 0.29316, 0.15555, 0.2147, 0.15875, 0.16642, 0.74821, 0.28932]
Predicted label: 8
Correct prediction
Energy consumption = 189.923697 pJ
sum error= 221
Actual label: 3
Output voltages: [0.52182, 0.13488, 0.18636, 0.68598, 0.1475, 0.44871, 0.21245, 0.24316, 0.33761, 0.11019]
Predicted label: 3
Correct prediction
Energy consumption = 190.867336 pJ
sum error= 221
Actual label: 5
Output voltages: [0.46645, 0.14177, 0.19768, 0.45641, 0.088878, 0.63839, 0.35349, 0.12902, 0.38915, 0.17774]
Predicted label: 5
Correct prediction
Energy consumption = 187.540345 pJ
sum error= 221
Actual label: 7
Output voltages: [0.29946, 0.20129, 0.15027, 0.24024, 0.31251, 0.056934, 0.050756, 0.74553, 0.35571, 0.27227]
Predicted label: 7
Correct prediction
Energy consumption = 200.640302 pJ
sum error= 221
Actual label: 1
Output voltages: [0.16029, 0.76277, 0.18973, 0.25994, 0.17108, 0.21549, 0.51735, 0.14682, 0.31605, 0.18143]
Predicted label: 1
Correct prediction
Energy consumption = 213.775572 pJ
sum error= 221
Actual label: 6
Output voltages: [0.3104, 0.33245, 0.29403, 0.11068, 0.42203, 0.29694, 0.73704, 0.075046, 0.27458, 0.084206]
Predicted label: 6
Correct prediction
Energy consumption = 190.785783 pJ
sum error= 221
Actual label: 1
Output voltages: [0.14746, 0.75674, 0.25465, 0.35148, 0.22948, 0.088896, 0.34592, 0.16138, 0.34611, 0.22073]
Predicted label: 1
Correct prediction
Energy consumption = 214.835549 pJ
sum error= 221
Actual label: 0
Output voltages: [0.60908, 0.28024, 0.33616, 0.15806, 0.18192, 0.12078, 0.46283, 0.13403, 0.45045, 0.20371]
Predicted label: 0
Correct prediction
Energy consumption = 208.047774 pJ
sum error= 221
Actual label: 9
Output voltages: [0.3656, 0.16045, 0.26742, 0.28016, 0.35434, 0.13708, 0.21343, 0.20206, 0.27639, 0.71687]
Predicted label: 9
Correct prediction
Energy consumption = 197.569766 pJ
sum error= 221
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 592 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 592 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 592 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29932, 0.24485, 0.27685, 0.17274, 0.29731, 0.36388, 0.7391, 0.097732, 0.44488, 0.099672]
Predicted label: 6
Correct prediction
Energy consumption = 197.513074 pJ
sum error= 221
Actual label: 2
Output voltages: [0.31608, 0.41077, 0.67951, 0.34036, 0.093995, 0.030143, 0.25813, 0.26405, 0.38012, 0.23185]
Predicted label: 2
Correct prediction
Energy consumption = 199.611234 pJ
sum error= 221
Actual label: 5
Output voltages: [0.42092, 0.06886, 0.15952, 0.38893, 0.092355, 0.69435, 0.28541, 0.20909, 0.43921, 0.22604]
Predicted label: 5
Correct prediction
Energy consumption = 190.568100 pJ
sum error= 221
Actual label: 4
Output voltages: [0.12958, 0.3097, 0.26022, 0.118, 0.74869, 0.096121, 0.33624, 0.33251, 0.18957, 0.25728]
Predicted label: 4
Correct prediction
Energy consumption = 195.890821 pJ
sum error= 221
Actual label: 2
Output voltages: [0.3128, 0.41992, 0.67921, 0.32038, 0.10241, 0.032326, 0.32135, 0.17864, 0.35697, 0.17712]
Predicted label: 2
Correct prediction
Energy consumption = 197.880678 pJ
sum error= 221
Actual label: 3
Output voltages: [0.31786, 0.10812, 0.27868, 0.74018, 0.23028, 0.29597, 0.096336, 0.24358, 0.41227, 0.20387]
Predicted label: 3
Correct prediction
Energy consumption = 191.541901 pJ
sum error= 221
Actual label: 4
Output voltages: [0.18377, 0.12453, 0.21187, 0.20241, 0.65662, 0.11007, 0.16618, 0.33366, 0.27875, 0.4009]
Predicted label: 4
Correct prediction
Energy consumption = 201.513152 pJ
sum error= 221
Actual label: 4
Output voltages: [0.14029, 0.13669, 0.34736, 0.1552, 0.76602, 0.12523, 0.29062, 0.28272, 0.21033, 0.29165]
Predicted label: 4
Correct prediction
Energy consumption = 191.721412 pJ
sum error= 221
Actual label: 6
Output voltages: [0.27752, 0.21226, 0.29575, 0.13273, 0.37979, 0.29964, 0.74527, 0.072617, 0.36739, 0.15871]
Predicted label: 6
Correct prediction
Energy consumption = 190.022104 pJ
sum error= 221
Actual label: 0
Output voltages: [0.72966, 0.22789, 0.28352, 0.18001, 0.20909, 0.13522, 0.41898, 0.15132, 0.34244, 0.28929]
Predicted label: 0
Correct prediction
Energy consumption = 195.538665 pJ
sum error= 221
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 593 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 593 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 593 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69562, 0.25273, 0.26996, 0.15326, 0.17788, 0.15136, 0.48124, 0.14377, 0.31737, 0.24721]
Predicted label: 0
Correct prediction
Energy consumption = 199.915065 pJ
sum error= 221
Actual label: 2
Output voltages: [0.38083, 0.29544, 0.74583, 0.33428, 0.21303, 0.035462, 0.3377, 0.15765, 0.38168, 0.19929]
Predicted label: 2
Correct prediction
Energy consumption = 182.226394 pJ
sum error= 221
Actual label: 0
Output voltages: [0.73685, 0.23153, 0.18198, 0.18564, 0.19354, 0.27661, 0.40717, 0.17135, 0.27462, 0.28808]
Predicted label: 0
Correct prediction
Energy consumption = 199.646718 pJ
sum error= 221
Actual label: 1
Output voltages: [0.18118, 0.75839, 0.2134, 0.30011, 0.2447, 0.18253, 0.3014, 0.084609, 0.2309, 0.32154]
Predicted label: 1
Correct prediction
Energy consumption = 213.351969 pJ
sum error= 221
Actual label: 2
Output voltages: [0.39885, 0.30551, 0.70934, 0.29628, 0.14993, 0.033811, 0.35314, 0.24208, 0.32813, 0.15643]
Predicted label: 2
Correct prediction
Energy consumption = 205.453376 pJ
sum error= 221
Actual label: 3
Output voltages: [0.33796, 0.22098, 0.22121, 0.67388, 0.14659, 0.26012, 0.14617, 0.07717, 0.43577, 0.32454]
Predicted label: 3
Correct prediction
Energy consumption = 198.643359 pJ
sum error= 221
Actual label: 4
Output voltages: [0.2474, 0.16187, 0.24773, 0.212, 0.53084, 0.11576, 0.1235, 0.35851, 0.23885, 0.54631]
Predicted label: 9
Wrong prediction!
Energy consumption = 196.225792 pJ
sum error= 222
Actual label: 5
Output voltages: [0.21103, 0.072855, 0.18403, 0.64704, 0.25259, 0.41611, 0.19175, 0.2124, 0.39039, 0.29826]
Predicted label: 3
Wrong prediction!
Energy consumption = 191.189918 pJ
sum error= 223
Actual label: 6
Output voltages: [0.29613, 0.23862, 0.29708, 0.076535, 0.37966, 0.34931, 0.74654, 0.09523, 0.31698, 0.15507]
Predicted label: 6
Correct prediction
Energy consumption = 192.589526 pJ
sum error= 223
Actual label: 7
Output voltages: [0.26129, 0.31411, 0.22246, 0.25934, 0.10538, 0.076255, 0.044779, 0.71022, 0.31333, 0.42651]
Predicted label: 7
Correct prediction
Energy consumption = 204.001755 pJ
sum error= 223
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 594 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 594 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 594 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.3442, 0.12864, 0.36976, 0.31865, 0.17325, 0.183, 0.20927, 0.072665, 0.70219, 0.35011]
Predicted label: 8
Correct prediction
Energy consumption = 201.605896 pJ
sum error= 223
Actual label: 9
Output voltages: [0.3968, 0.096302, 0.19855, 0.25068, 0.25471, 0.20643, 0.064443, 0.22201, 0.41804, 0.67836]
Predicted label: 9
Correct prediction
Energy consumption = 189.123294 pJ
sum error= 223
Actual label: 0
Output voltages: [0.66232, 0.1525, 0.28723, 0.17351, 0.10449, 0.22403, 0.40865, 0.17754, 0.34691, 0.2423]
Predicted label: 0
Correct prediction
Energy consumption = 192.143336 pJ
sum error= 223
Actual label: 1
Output voltages: [0.21654, 0.73863, 0.25769, 0.2568, 0.126, 0.15779, 0.39282, 0.12761, 0.32944, 0.1808]
Predicted label: 1
Correct prediction
Energy consumption = 208.006447 pJ
sum error= 223
Actual label: 2
Output voltages: [0.31335, 0.28611, 0.73816, 0.21303, 0.16655, 0.033355, 0.26503, 0.25987, 0.38908, 0.23379]
Predicted label: 2
Correct prediction
Energy consumption = 205.364938 pJ
sum error= 223
Actual label: 3
Output voltages: [0.29555, 0.30807, 0.26813, 0.72822, 0.15617, 0.1895, 0.16909, 0.10469, 0.43133, 0.27756]
Predicted label: 3
Correct prediction
Energy consumption = 198.066063 pJ
sum error= 223
Actual label: 4
Output voltages: [0.13568, 0.14953, 0.28523, 0.1845, 0.73698, 0.19853, 0.18293, 0.20232, 0.32281, 0.39864]
Predicted label: 4
Correct prediction
Energy consumption = 199.765476 pJ
sum error= 223
Actual label: 5
Output voltages: [0.26551, 0.049056, 0.17947, 0.37831, 0.15647, 0.63383, 0.20866, 0.18681, 0.57963, 0.28239]
Predicted label: 5
Correct prediction
Energy consumption = 189.024294 pJ
sum error= 223
Actual label: 6
Output voltages: [0.26752, 0.21979, 0.34193, 0.091722, 0.41147, 0.2794, 0.74777, 0.13322, 0.3407, 0.12548]
Predicted label: 6
Correct prediction
Energy consumption = 194.549027 pJ
sum error= 223
Actual label: 7
Output voltages: [0.3127, 0.2822, 0.1449, 0.36473, 0.1171, 0.1894, 0.032259, 0.67319, 0.23558, 0.45836]
Predicted label: 7
Correct prediction
Energy consumption = 203.690092 pJ
sum error= 223
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 595 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 595 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 595 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.31845, 0.2013, 0.43859, 0.37337, 0.12805, 0.09684, 0.27706, 0.11364, 0.64145, 0.28758]
Predicted label: 8
Correct prediction
Energy consumption = 205.951102 pJ
sum error= 223
Actual label: 9
Output voltages: [0.33438, 0.14401, 0.24922, 0.24217, 0.26987, 0.11413, 0.069622, 0.23829, 0.37219, 0.68948]
Predicted label: 9
Correct prediction
Energy consumption = 199.697512 pJ
sum error= 223
Actual label: 0
Output voltages: [0.67703, 0.19195, 0.18224, 0.19051, 0.12853, 0.3, 0.41742, 0.14995, 0.32796, 0.27215]
Predicted label: 0
Correct prediction
Energy consumption = 200.184640 pJ
sum error= 223
Actual label: 1
Output voltages: [0.1386, 0.75519, 0.3145, 0.38061, 0.2945, 0.13261, 0.28239, 0.17721, 0.23077, 0.23424]
Predicted label: 1
Correct prediction
Energy consumption = 208.938636 pJ
sum error= 223
Actual label: 2
Output voltages: [0.26725, 0.25088, 0.73974, 0.3483, 0.16737, 0.043021, 0.23811, 0.32852, 0.32685, 0.16387]
Predicted label: 2
Correct prediction
Energy consumption = 190.879707 pJ
sum error= 223
Actual label: 3
Output voltages: [0.33484, 0.22325, 0.37142, 0.33179, 0.1788, 0.15455, 0.20034, 0.060761, 0.62955, 0.43524]
Predicted label: 8
Wrong prediction!
Energy consumption = 202.898326 pJ
sum error= 224
Actual label: 4
Output voltages: [0.19531, 0.1359, 0.30493, 0.14337, 0.74977, 0.12275, 0.19134, 0.23425, 0.2666, 0.4102]
Predicted label: 4
Correct prediction
Energy consumption = 194.695181 pJ
sum error= 224
Actual label: 5
Output voltages: [0.27902, 0.058931, 0.20895, 0.33845, 0.15956, 0.59505, 0.20827, 0.14849, 0.64042, 0.30367]
Predicted label: 8
Wrong prediction!
Energy consumption = 190.230605 pJ
sum error= 225
Actual label: 6
Output voltages: [0.31947, 0.22177, 0.33594, 0.07963, 0.4296, 0.34692, 0.74241, 0.078743, 0.30094, 0.1414]
Predicted label: 6
Correct prediction
Energy consumption = 190.380593 pJ
sum error= 225
Actual label: 7
Output voltages: [0.29964, 0.22924, 0.19844, 0.21065, 0.15446, 0.11412, 0.055011, 0.66093, 0.34092, 0.5072]
Predicted label: 7
Correct prediction
Energy consumption = 204.173406 pJ
sum error= 225
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 596 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 596 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 596 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.347, 0.082508, 0.43469, 0.33585, 0.12841, 0.17618, 0.23104, 0.072375, 0.67087, 0.31241]
Predicted label: 8
Correct prediction
Energy consumption = 205.002719 pJ
sum error= 225
Actual label: 9
Output voltages: [0.26815, 0.1853, 0.28579, 0.27616, 0.28674, 0.062882, 0.048811, 0.39697, 0.27936, 0.6157]
Predicted label: 9
Correct prediction
Energy consumption = 207.768888 pJ
sum error= 225
Actual label: 8
Output voltages: [0.28069, 0.092251, 0.38875, 0.26775, 0.2301, 0.15802, 0.32912, 0.1209, 0.7119, 0.2882]
Predicted label: 8
Correct prediction
Energy consumption = 194.930737 pJ
sum error= 225
Actual label: 6
Output voltages: [0.26651, 0.27295, 0.25536, 0.17212, 0.34589, 0.33726, 0.74179, 0.10835, 0.42292, 0.11867]
Predicted label: 6
Correct prediction
Energy consumption = 198.235032 pJ
sum error= 225
Actual label: 5
Output voltages: [0.27145, 0.053149, 0.090125, 0.43287, 0.19499, 0.65913, 0.25662, 0.21732, 0.4774, 0.35517]
Predicted label: 5
Correct prediction
Energy consumption = 184.473699 pJ
sum error= 225
Actual label: 0
Output voltages: [0.65178, 0.13429, 0.28851, 0.11855, 0.18498, 0.18116, 0.44893, 0.15297, 0.34714, 0.29456]
Predicted label: 0
Correct prediction
Energy consumption = 196.222817 pJ
sum error= 225
Actual label: 6
Output voltages: [0.3884, 0.22076, 0.26361, 0.18366, 0.28983, 0.37682, 0.73449, 0.077173, 0.35348, 0.17343]
Predicted label: 6
Correct prediction
Energy consumption = 192.161845 pJ
sum error= 225
Actual label: 8
Output voltages: [0.34791, 0.14332, 0.39504, 0.25312, 0.14641, 0.15659, 0.19189, 0.11157, 0.71732, 0.31276]
Predicted label: 8
Correct prediction
Energy consumption = 192.717135 pJ
sum error= 225
Actual label: 9
Output voltages: [0.38031, 0.11577, 0.27932, 0.27621, 0.27799, 0.18097, 0.11787, 0.25405, 0.33054, 0.70362]
Predicted label: 9
Correct prediction
Energy consumption = 200.496708 pJ
sum error= 225
Actual label: 4
Output voltages: [0.13975, 0.2266, 0.29054, 0.25953, 0.68083, 0.21253, 0.24292, 0.10808, 0.2802, 0.48226]
Predicted label: 4
Correct prediction
Energy consumption = 200.532155 pJ
sum error= 225
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 597 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 597 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 597 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20095, 0.74075, 0.25474, 0.23798, 0.27319, 0.10756, 0.38206, 0.04886, 0.31899, 0.24674]
Predicted label: 1
Correct prediction
Energy consumption = 208.762660 pJ
sum error= 225
Actual label: 9
Output voltages: [0.29406, 0.13734, 0.22865, 0.28656, 0.31662, 0.13554, 0.095536, 0.2621, 0.35853, 0.72118]
Predicted label: 9
Correct prediction
Energy consumption = 196.199413 pJ
sum error= 225
Actual label: 5
Output voltages: [0.1976, 0.049971, 0.18532, 0.46028, 0.21446, 0.53875, 0.14215, 0.22829, 0.54562, 0.29028]
Predicted label: 8
Wrong prediction!
Energy consumption = 193.542429 pJ
sum error= 226
Actual label: 3
Output voltages: [0.32911, 0.25043, 0.19699, 0.58315, 0.149, 0.22479, 0.28486, 0.10157, 0.60047, 0.255]
Predicted label: 8
Wrong prediction!
Energy consumption = 205.328676 pJ
sum error= 227
Actual label: 0
Output voltages: [0.71662, 0.20671, 0.25392, 0.19155, 0.20796, 0.1486, 0.43476, 0.19846, 0.33919, 0.29266]
Predicted label: 0
Correct prediction
Energy consumption = 206.533746 pJ
sum error= 227
Actual label: 4
Output voltages: [0.17403, 0.13879, 0.2375, 0.21506, 0.60026, 0.15635, 0.20157, 0.16809, 0.33907, 0.49653]
Predicted label: 4
Correct prediction
Energy consumption = 204.314673 pJ
sum error= 227
Actual label: 8
Output voltages: [0.1823, 0.2031, 0.27095, 0.27787, 0.1439, 0.18196, 0.17051, 0.14412, 0.73818, 0.33099]
Predicted label: 8
Correct prediction
Energy consumption = 198.959254 pJ
sum error= 227
Actual label: 9
Output voltages: [0.37937, 0.08687, 0.23815, 0.20591, 0.32142, 0.1526, 0.053686, 0.20305, 0.37813, 0.65985]
Predicted label: 9
Correct prediction
Energy consumption = 193.037386 pJ
sum error= 227
Actual label: 1
Output voltages: [0.11894, 0.70967, 0.31287, 0.38684, 0.25565, 0.099623, 0.2824, 0.19943, 0.2476, 0.25846]
Predicted label: 1
Correct prediction
Energy consumption = 214.241056 pJ
sum error= 227
Actual label: 4
Output voltages: [0.20043, 0.18228, 0.31355, 0.21324, 0.72221, 0.14002, 0.16083, 0.1518, 0.2294, 0.50058]
Predicted label: 4
Correct prediction
Energy consumption = 196.092383 pJ
sum error= 227
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 598 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 598 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 598 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73659, 0.19577, 0.21793, 0.16801, 0.26632, 0.19153, 0.4439, 0.19335, 0.24048, 0.26492]
Predicted label: 0
Correct prediction
Energy consumption = 204.865914 pJ
sum error= 227
Actual label: 5
Output voltages: [0.32705, 0.061418, 0.14708, 0.40048, 0.26561, 0.30441, 0.12863, 0.14676, 0.47837, 0.51527]
Predicted label: 9
Wrong prediction!
Energy consumption = 199.837855 pJ
sum error= 228
Actual label: 5
Output voltages: [0.25878, 0.051105, 0.22287, 0.54514, 0.15258, 0.48718, 0.21605, 0.18012, 0.50661, 0.22357]
Predicted label: 3
Wrong prediction!
Energy consumption = 194.594250 pJ
sum error= 229
Actual label: 2
Output voltages: [0.40874, 0.22657, 0.73075, 0.29733, 0.15665, 0.036398, 0.27516, 0.28938, 0.33749, 0.20373]
Predicted label: 2
Correct prediction
Energy consumption = 191.730555 pJ
sum error= 229
Actual label: 1
Output voltages: [0.14611, 0.755, 0.33749, 0.38103, 0.3138, 0.11212, 0.24071, 0.26695, 0.19106, 0.21467]
Predicted label: 1
Correct prediction
Energy consumption = 206.840201 pJ
sum error= 229
Actual label: 5
Output voltages: [0.15878, 0.060991, 0.20124, 0.48236, 0.22846, 0.51449, 0.29715, 0.13644, 0.59018, 0.28154]
Predicted label: 8
Wrong prediction!
Energy consumption = 196.433189 pJ
sum error= 230
Actual label: 4
Output voltages: [0.19902, 0.18327, 0.28711, 0.25955, 0.64885, 0.19687, 0.18437, 0.1703, 0.28539, 0.4722]
Predicted label: 4
Correct prediction
Energy consumption = 204.353127 pJ
sum error= 230
Actual label: 0
Output voltages: [0.67442, 0.11609, 0.29286, 0.20078, 0.19685, 0.16384, 0.38735, 0.16497, 0.32296, 0.31841]
Predicted label: 0
Correct prediction
Energy consumption = 206.372670 pJ
sum error= 230
Actual label: 7
Output voltages: [0.24722, 0.31915, 0.31095, 0.51722, 0.079533, 0.11392, 0.049937, 0.58214, 0.21816, 0.46727]
Predicted label: 7
Correct prediction
Energy consumption = 204.263111 pJ
sum error= 230
Actual label: 6
Output voltages: [0.3071, 0.25909, 0.15492, 0.27108, 0.3499, 0.48988, 0.68897, 0.077008, 0.34381, 0.079848]
Predicted label: 6
Correct prediction
Energy consumption = 202.445858 pJ
sum error= 230
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 599 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 599 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 599 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.71228, 0.20983, 0.19855, 0.133, 0.25514, 0.2128, 0.48782, 0.21714, 0.25306, 0.27055]
Predicted label: 0
Correct prediction
Energy consumption = 198.759999 pJ
sum error= 230
Actual label: 1
Output voltages: [0.20966, 0.75811, 0.25025, 0.34281, 0.30907, 0.10965, 0.30125, 0.11325, 0.20884, 0.30442]
Predicted label: 1
Correct prediction
Energy consumption = 214.460426 pJ
sum error= 230
Actual label: 7
Output voltages: [0.27818, 0.26457, 0.14833, 0.36427, 0.10066, 0.19352, 0.03269, 0.68021, 0.25012, 0.48543]
Predicted label: 7
Correct prediction
Energy consumption = 201.913022 pJ
sum error= 230
Actual label: 0
Output voltages: [0.71381, 0.18585, 0.22292, 0.12005, 0.18786, 0.23454, 0.44496, 0.14011, 0.24587, 0.3017]
Predicted label: 0
Correct prediction
Energy consumption = 194.025726 pJ
sum error= 230
Actual label: 6
Output voltages: [0.28248, 0.21544, 0.26401, 0.13295, 0.3066, 0.40547, 0.73782, 0.10819, 0.37725, 0.095567]
Predicted label: 6
Correct prediction
Energy consumption = 193.167707 pJ
sum error= 230
Actual label: 8
Output voltages: [0.28851, 0.18287, 0.35197, 0.26382, 0.1191, 0.14873, 0.17738, 0.098428, 0.72261, 0.40074]
Predicted label: 8
Correct prediction
Energy consumption = 191.992922 pJ
sum error= 230
Actual label: 9
Output voltages: [0.49065, 0.0711, 0.29914, 0.19681, 0.34079, 0.13084, 0.24984, 0.15629, 0.28708, 0.56439]
Predicted label: 9
Correct prediction
Energy consumption = 193.701508 pJ
sum error= 230
Actual label: 5
Output voltages: [0.26652, 0.072529, 0.15486, 0.37939, 0.15314, 0.52537, 0.17518, 0.16912, 0.55627, 0.37009]
Predicted label: 8
Wrong prediction!
Energy consumption = 198.566817 pJ
sum error= 231
Actual label: 1
Output voltages: [0.14724, 0.75308, 0.22785, 0.32238, 0.22282, 0.1522, 0.29481, 0.075749, 0.28809, 0.30432]
Predicted label: 1
Correct prediction
Energy consumption = 213.802591 pJ
sum error= 231
Actual label: 7
Output voltages: [0.34237, 0.28725, 0.20263, 0.31899, 0.11584, 0.097491, 0.038731, 0.74408, 0.28715, 0.39339]
Predicted label: 7
Correct prediction
Energy consumption = 202.344396 pJ
sum error= 231
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 600 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 600 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 600 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.38432, 0.073051, 0.21575, 0.26035, 0.27768, 0.1948, 0.066387, 0.43415, 0.36979, 0.63798]
Predicted label: 9
Correct prediction
Energy consumption = 195.411895 pJ
sum error= 231
Actual label: 8
Output voltages: [0.31667, 0.16809, 0.29569, 0.39444, 0.14652, 0.17336, 0.27933, 0.076657, 0.69682, 0.27968]
Predicted label: 8
Correct prediction
Energy consumption = 200.853928 pJ
sum error= 231
Actual label: 6
Output voltages: [0.30929, 0.36883, 0.28374, 0.12886, 0.28929, 0.29268, 0.7382, 0.089653, 0.34643, 0.13406]
Predicted label: 6
Correct prediction
Energy consumption = 203.274750 pJ
sum error= 231
Actual label: 0
Output voltages: [0.7136, 0.15531, 0.20342, 0.18084, 0.23606, 0.24009, 0.42126, 0.1824, 0.30463, 0.33007]
Predicted label: 0
Correct prediction
Energy consumption = 199.583018 pJ
sum error= 231
Actual label: 8
Output voltages: [0.32285, 0.11892, 0.28932, 0.20915, 0.22567, 0.16427, 0.23, 0.12229, 0.52837, 0.54083]
Predicted label: 9
Wrong prediction!
Energy consumption = 207.389393 pJ
sum error= 232
Actual label: 1
Output voltages: [0.15011, 0.73579, 0.36446, 0.31548, 0.32172, 0.09766, 0.21237, 0.16201, 0.20742, 0.29155]
Predicted label: 1
Correct prediction
Energy consumption = 213.910770 pJ
sum error= 232
Actual label: 7
Output voltages: [0.27264, 0.40182, 0.18238, 0.28248, 0.093168, 0.17211, 0.049338, 0.58013, 0.29323, 0.50885]
Predicted label: 7
Correct prediction
Energy consumption = 210.766852 pJ
sum error= 232
Actual label: 7
Output voltages: [0.27766, 0.25911, 0.15666, 0.27141, 0.071329, 0.13873, 0.040067, 0.72435, 0.36391, 0.45326]
Predicted label: 7
Correct prediction
Energy consumption = 199.131371 pJ
sum error= 232
Actual label: 1
Output voltages: [0.080422, 0.71544, 0.2379, 0.31413, 0.34364, 0.13455, 0.29221, 0.20535, 0.24458, 0.2307]
Predicted label: 1
Correct prediction
Energy consumption = 211.200604 pJ
sum error= 232
Actual label: 3
Output voltages: [0.27588, 0.20218, 0.26713, 0.74168, 0.19525, 0.22187, 0.24271, 0.17722, 0.39722, 0.26951]
Predicted label: 3
Correct prediction
Energy consumption = 199.966481 pJ
sum error= 232
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 601 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 601 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 601 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31224, 0.2193, 0.74185, 0.34395, 0.122, 0.046702, 0.29673, 0.32396, 0.38703, 0.19212]
Predicted label: 2
Correct prediction
Energy consumption = 200.566667 pJ
sum error= 232
Actual label: 3
Output voltages: [0.46423, 0.12239, 0.28135, 0.52009, 0.098627, 0.38418, 0.26824, 0.11449, 0.41313, 0.31816]
Predicted label: 3
Correct prediction
Energy consumption = 208.333428 pJ
sum error= 232
Actual label: 1
Output voltages: [0.24267, 0.76482, 0.29544, 0.31015, 0.20378, 0.10615, 0.37202, 0.099416, 0.2736, 0.2389]
Predicted label: 1
Correct prediction
Energy consumption = 209.181374 pJ
sum error= 232
Actual label: 4
Output voltages: [0.18616, 0.10058, 0.35848, 0.20695, 0.74627, 0.16464, 0.24289, 0.21117, 0.21732, 0.39371]
Predicted label: 4
Correct prediction
Energy consumption = 201.499417 pJ
sum error= 232
Actual label: 2
Output voltages: [0.35409, 0.37796, 0.72709, 0.38487, 0.17145, 0.0309, 0.23761, 0.3063, 0.22137, 0.1635]
Predicted label: 2
Correct prediction
Energy consumption = 196.307966 pJ
sum error= 232
Actual label: 0
Output voltages: [0.69147, 0.1718, 0.1938, 0.16633, 0.15325, 0.29741, 0.42396, 0.15404, 0.30659, 0.26666]
Predicted label: 0
Correct prediction
Energy consumption = 202.395576 pJ
sum error= 232
Actual label: 0
Output voltages: [0.70865, 0.19763, 0.21843, 0.13282, 0.20616, 0.24966, 0.4387, 0.17417, 0.3038, 0.2464]
Predicted label: 0
Correct prediction
Energy consumption = 188.957697 pJ
sum error= 232
Actual label: 7
Output voltages: [0.34657, 0.26102, 0.43042, 0.29757, 0.086518, 0.034961, 0.064549, 0.72916, 0.3367, 0.32408]
Predicted label: 7
Correct prediction
Energy consumption = 207.679298 pJ
sum error= 232
Actual label: 8
Output voltages: [0.31952, 0.1417, 0.37756, 0.22712, 0.13877, 0.15965, 0.18181, 0.096445, 0.72405, 0.3852]
Predicted label: 8
Correct prediction
Energy consumption = 185.973151 pJ
sum error= 232
Actual label: 4
Output voltages: [0.12117, 0.18304, 0.22593, 0.15763, 0.65194, 0.2114, 0.17003, 0.20453, 0.37995, 0.39003]
Predicted label: 4
Correct prediction
Energy consumption = 199.951450 pJ
sum error= 232
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 602 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 602 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 602 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31108, 0.22837, 0.22512, 0.17986, 0.37086, 0.33721, 0.71213, 0.06965, 0.38709, 0.097976]
Predicted label: 6
Correct prediction
Energy consumption = 200.823045 pJ
sum error= 232
Actual label: 4
Output voltages: [0.14219, 0.21519, 0.21781, 0.2958, 0.7017, 0.19905, 0.21801, 0.19963, 0.28846, 0.38846]
Predicted label: 4
Correct prediction
Energy consumption = 203.501063 pJ
sum error= 232
Actual label: 9
Output voltages: [0.3256, 0.16466, 0.2644, 0.38943, 0.28537, 0.15345, 0.13607, 0.2511, 0.29518, 0.69371]
Predicted label: 9
Correct prediction
Energy consumption = 199.301792 pJ
sum error= 232
Actual label: 3
Output voltages: [0.21326, 0.23699, 0.19679, 0.67212, 0.2447, 0.30624, 0.23707, 0.063856, 0.42562, 0.32036]
Predicted label: 3
Correct prediction
Energy consumption = 194.749703 pJ
sum error= 232
Actual label: 8
Output voltages: [0.22888, 0.12845, 0.24215, 0.42034, 0.076194, 0.27128, 0.13167, 0.11453, 0.73276, 0.36918]
Predicted label: 8
Correct prediction
Energy consumption = 192.156366 pJ
sum error= 232
Actual label: 4
Output voltages: [0.13513, 0.16574, 0.38502, 0.17866, 0.74681, 0.12701, 0.23876, 0.13972, 0.22652, 0.4036]
Predicted label: 4
Correct prediction
Energy consumption = 199.692936 pJ
sum error= 232
Actual label: 7
Output voltages: [0.26347, 0.4108, 0.2928, 0.41203, 0.090525, 0.15598, 0.047917, 0.59633, 0.17466, 0.50505]
Predicted label: 7
Correct prediction
Energy consumption = 205.651990 pJ
sum error= 232
Actual label: 2
Output voltages: [0.25728, 0.27987, 0.68667, 0.21999, 0.16313, 0.031488, 0.4135, 0.24373, 0.38881, 0.21099]
Predicted label: 2
Correct prediction
Energy consumption = 202.996113 pJ
sum error= 232
Actual label: 5
Output voltages: [0.25492, 0.048934, 0.1227, 0.51499, 0.18927, 0.59922, 0.26804, 0.20612, 0.47655, 0.29725]
Predicted label: 5
Correct prediction
Energy consumption = 191.987814 pJ
sum error= 232
Actual label: 6
Output voltages: [0.32925, 0.23666, 0.18153, 0.28241, 0.26216, 0.5028, 0.71246, 0.071664, 0.34781, 0.093865]
Predicted label: 6
Correct prediction
Energy consumption = 192.050239 pJ
sum error= 232
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 603 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 603 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 603 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.28582, 0.24436, 0.25341, 0.72974, 0.093061, 0.23962, 0.25677, 0.16673, 0.41684, 0.19208]
Predicted label: 3
Correct prediction
Energy consumption = 196.991540 pJ
sum error= 232
Actual label: 6
Output voltages: [0.29027, 0.27132, 0.25708, 0.22365, 0.25943, 0.30371, 0.69269, 0.13941, 0.41245, 0.074204]
Predicted label: 6
Correct prediction
Energy consumption = 197.428794 pJ
sum error= 232
Actual label: 9
Output voltages: [0.32181, 0.09762, 0.25954, 0.29311, 0.2586, 0.14657, 0.071061, 0.22702, 0.37876, 0.64894]
Predicted label: 9
Correct prediction
Energy consumption = 199.221528 pJ
sum error= 232
Actual label: 6
Output voltages: [0.27629, 0.26471, 0.15689, 0.24176, 0.36437, 0.38983, 0.69133, 0.078484, 0.38602, 0.10432]
Predicted label: 6
Correct prediction
Energy consumption = 205.795835 pJ
sum error= 232
Actual label: 3
Output voltages: [0.29644, 0.16468, 0.20821, 0.72521, 0.19735, 0.21605, 0.16879, 0.096678, 0.45063, 0.34056]
Predicted label: 3
Correct prediction
Energy consumption = 199.479934 pJ
sum error= 232
Actual label: 2
Output voltages: [0.55971, 0.205, 0.46629, 0.22234, 0.27301, 0.088653, 0.18388, 0.27386, 0.22655, 0.30684]
Predicted label: 0
Wrong prediction!
Energy consumption = 207.116298 pJ
sum error= 233
Actual label: 2
Output voltages: [0.36635, 0.15662, 0.71309, 0.37859, 0.17536, 0.03317, 0.26123, 0.30417, 0.41218, 0.18831]
Predicted label: 2
Correct prediction
Energy consumption = 191.448983 pJ
sum error= 233
Actual label: 4
Output voltages: [0.15735, 0.1848, 0.26257, 0.21246, 0.65862, 0.19243, 0.21399, 0.17482, 0.33658, 0.44958]
Predicted label: 4
Correct prediction
Energy consumption = 204.114075 pJ
sum error= 233
Actual label: 6
Output voltages: [0.31609, 0.16619, 0.31032, 0.093854, 0.36584, 0.3584, 0.73514, 0.063969, 0.38081, 0.16002]
Predicted label: 6
Correct prediction
Energy consumption = 189.798941 pJ
sum error= 233
Actual label: 9
Output voltages: [0.34748, 0.1729, 0.23088, 0.33748, 0.30164, 0.18866, 0.062728, 0.30097, 0.28804, 0.71147]
Predicted label: 9
Correct prediction
Energy consumption = 194.985959 pJ
sum error= 233
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 604 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 604 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 604 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.68792, 0.1437, 0.20133, 0.1652, 0.23191, 0.23419, 0.43961, 0.2042, 0.29383, 0.30403]
Predicted label: 0
Correct prediction
Energy consumption = 208.265147 pJ
sum error= 233
Actual label: 2
Output voltages: [0.38351, 0.37024, 0.7024, 0.3425, 0.10544, 0.028766, 0.35722, 0.20275, 0.3262, 0.15601]
Predicted label: 2
Correct prediction
Energy consumption = 204.084200 pJ
sum error= 233
Actual label: 5
Output voltages: [0.30271, 0.058602, 0.20832, 0.27983, 0.17582, 0.47908, 0.13618, 0.1301, 0.64815, 0.40516]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.415336 pJ
sum error= 234
Actual label: 5
Output voltages: [0.22465, 0.044147, 0.092374, 0.40757, 0.21841, 0.63761, 0.27191, 0.21286, 0.54056, 0.25476]
Predicted label: 5
Correct prediction
Energy consumption = 184.848156 pJ
sum error= 234
Actual label: 1
Output voltages: [0.2022, 0.73322, 0.26007, 0.20752, 0.3514, 0.13568, 0.40176, 0.057364, 0.28107, 0.25465]
Predicted label: 1
Correct prediction
Energy consumption = 211.236263 pJ
sum error= 234
Actual label: 3
Output voltages: [0.24585, 0.27177, 0.28383, 0.73304, 0.14202, 0.13297, 0.214, 0.15165, 0.43107, 0.22808]
Predicted label: 3
Correct prediction
Energy consumption = 196.096047 pJ
sum error= 234
Actual label: 3
Output voltages: [0.25896, 0.24004, 0.36506, 0.7326, 0.15864, 0.061244, 0.27624, 0.16622, 0.48669, 0.20597]
Predicted label: 3
Correct prediction
Energy consumption = 184.567188 pJ
sum error= 234
Actual label: 9
Output voltages: [0.32769, 0.066452, 0.24008, 0.2533, 0.29822, 0.15739, 0.069144, 0.26658, 0.38739, 0.65994]
Predicted label: 9
Correct prediction
Energy consumption = 193.445586 pJ
sum error= 234
Actual label: 7
Output voltages: [0.33764, 0.36958, 0.4138, 0.23274, 0.1195, 0.036584, 0.061325, 0.6644, 0.25213, 0.39949]
Predicted label: 7
Correct prediction
Energy consumption = 207.952831 pJ
sum error= 234
Actual label: 8
Output voltages: [0.32212, 0.14859, 0.42689, 0.32332, 0.12461, 0.099575, 0.26584, 0.091368, 0.68841, 0.32541]
Predicted label: 8
Correct prediction
Energy consumption = 196.508893 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 605 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 605 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 605 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28681, 0.35362, 0.24332, 0.20208, 0.11931, 0.12891, 0.043065, 0.74491, 0.30522, 0.40238]
Predicted label: 7
Correct prediction
Energy consumption = 210.322169 pJ
sum error= 234
Actual label: 2
Output voltages: [0.31217, 0.29029, 0.71658, 0.31244, 0.18824, 0.025507, 0.29303, 0.30899, 0.36382, 0.22829]
Predicted label: 2
Correct prediction
Energy consumption = 205.744898 pJ
sum error= 234
Actual label: 2
Output voltages: [0.33679, 0.37362, 0.71375, 0.27416, 0.18088, 0.030054, 0.32984, 0.23635, 0.32749, 0.16947]
Predicted label: 2
Correct prediction
Energy consumption = 195.133941 pJ
sum error= 234
Actual label: 5
Output voltages: [0.21453, 0.07134, 0.18649, 0.41126, 0.25606, 0.34675, 0.12818, 0.12111, 0.5796, 0.43124]
Predicted label: 8
Wrong prediction!
Energy consumption = 194.914684 pJ
sum error= 235
Actual label: 7
Output voltages: [0.30268, 0.32115, 0.38487, 0.3115, 0.097109, 0.04713, 0.065026, 0.71719, 0.24944, 0.45201]
Predicted label: 7
Correct prediction
Energy consumption = 207.025969 pJ
sum error= 235
Actual label: 9
Output voltages: [0.34023, 0.092217, 0.24514, 0.27257, 0.24471, 0.16412, 0.080062, 0.25646, 0.44156, 0.66668]
Predicted label: 9
Correct prediction
Energy consumption = 193.793237 pJ
sum error= 235
Actual label: 8
Output voltages: [0.30613, 0.12398, 0.30509, 0.42325, 0.14666, 0.26439, 0.18699, 0.091235, 0.72284, 0.29579]
Predicted label: 8
Correct prediction
Energy consumption = 191.156869 pJ
sum error= 235
Actual label: 2
Output voltages: [0.31526, 0.30116, 0.73924, 0.21698, 0.2243, 0.027131, 0.384, 0.20809, 0.33739, 0.19739]
Predicted label: 2
Correct prediction
Energy consumption = 202.027371 pJ
sum error= 235
Actual label: 1
Output voltages: [0.25852, 0.76099, 0.26221, 0.27744, 0.2113, 0.094861, 0.3185, 0.057614, 0.32042, 0.22725]
Predicted label: 1
Correct prediction
Energy consumption = 210.016514 pJ
sum error= 235
Actual label: 3
Output voltages: [0.32598, 0.28708, 0.19972, 0.70097, 0.083935, 0.30176, 0.25988, 0.1388, 0.42385, 0.2154]
Predicted label: 3
Correct prediction
Energy consumption = 204.529111 pJ
sum error= 235
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 606 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 606 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 606 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17828, 0.75548, 0.18374, 0.2989, 0.15404, 0.22127, 0.33896, 0.13035, 0.34519, 0.22254]
Predicted label: 1
Correct prediction
Energy consumption = 209.319206 pJ
sum error= 235
Actual label: 3
Output voltages: [0.31916, 0.14512, 0.30264, 0.7517, 0.17651, 0.19218, 0.22268, 0.1911, 0.38475, 0.19957]
Predicted label: 3
Correct prediction
Energy consumption = 191.129267 pJ
sum error= 235
Actual label: 0
Output voltages: [0.72274, 0.22557, 0.24082, 0.17244, 0.18284, 0.14036, 0.38378, 0.19791, 0.37364, 0.22945]
Predicted label: 0
Correct prediction
Energy consumption = 192.784635 pJ
sum error= 235
Actual label: 1
Output voltages: [0.22399, 0.75091, 0.2147, 0.3162, 0.18885, 0.13122, 0.45953, 0.063712, 0.33944, 0.17128]
Predicted label: 1
Correct prediction
Energy consumption = 211.859119 pJ
sum error= 235
Actual label: 2
Output voltages: [0.35659, 0.22682, 0.70514, 0.37876, 0.16018, 0.031546, 0.29829, 0.16603, 0.46103, 0.19057]
Predicted label: 2
Correct prediction
Energy consumption = 186.441941 pJ
sum error= 235
Actual label: 3
Output voltages: [0.23542, 0.17624, 0.32475, 0.57613, 0.091945, 0.093526, 0.086076, 0.34231, 0.65082, 0.1583]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.775596 pJ
sum error= 236
Actual label: 4
Output voltages: [0.11845, 0.17353, 0.27369, 0.12495, 0.76098, 0.10314, 0.30619, 0.32004, 0.25601, 0.23827]
Predicted label: 4
Correct prediction
Energy consumption = 189.892126 pJ
sum error= 236
Actual label: 5
Output voltages: [0.26232, 0.046192, 0.084994, 0.32515, 0.2677, 0.68631, 0.29498, 0.17977, 0.5743, 0.28017]
Predicted label: 5
Correct prediction
Energy consumption = 185.756744 pJ
sum error= 236
Actual label: 6
Output voltages: [0.27044, 0.21615, 0.36676, 0.056147, 0.33356, 0.32245, 0.74489, 0.065818, 0.36318, 0.16047]
Predicted label: 6
Correct prediction
Energy consumption = 185.135224 pJ
sum error= 236
Actual label: 7
Output voltages: [0.24883, 0.21162, 0.21061, 0.25873, 0.1929, 0.10458, 0.040181, 0.74834, 0.4552, 0.29651]
Predicted label: 7
Correct prediction
Energy consumption = 194.985496 pJ
sum error= 236
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 607 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 607 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 607 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.40075, 0.12948, 0.36523, 0.35009, 0.15876, 0.12282, 0.30024, 0.05663, 0.66396, 0.31916]
Predicted label: 8
Correct prediction
Energy consumption = 196.293182 pJ
sum error= 236
Actual label: 9
Output voltages: [0.34664, 0.049642, 0.26453, 0.37414, 0.21188, 0.25346, 0.094015, 0.10088, 0.5454, 0.41913]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.716773 pJ
sum error= 237
Actual label: 0
Output voltages: [0.66089, 0.17976, 0.28428, 0.15152, 0.23458, 0.15286, 0.50966, 0.15941, 0.27219, 0.26703]
Predicted label: 0
Correct prediction
Energy consumption = 190.144244 pJ
sum error= 237
Actual label: 1
Output voltages: [0.21791, 0.74728, 0.22864, 0.32184, 0.14125, 0.068579, 0.44735, 0.090559, 0.34242, 0.18144]
Predicted label: 1
Correct prediction
Energy consumption = 207.212787 pJ
sum error= 237
Actual label: 2
Output voltages: [0.32714, 0.23842, 0.71021, 0.39419, 0.17595, 0.030548, 0.30359, 0.21628, 0.46591, 0.20252]
Predicted label: 2
Correct prediction
Energy consumption = 183.017584 pJ
sum error= 237
Actual label: 3
Output voltages: [0.29553, 0.06801, 0.18919, 0.67989, 0.25856, 0.35143, 0.17298, 0.22329, 0.50355, 0.22241]
Predicted label: 3
Correct prediction
Energy consumption = 190.631202 pJ
sum error= 237
Actual label: 4
Output voltages: [0.21605, 0.18753, 0.29577, 0.14808, 0.7502, 0.081118, 0.29149, 0.2241, 0.20349, 0.37253]
Predicted label: 4
Correct prediction
Energy consumption = 192.857341 pJ
sum error= 237
Actual label: 5
Output voltages: [0.26978, 0.056726, 0.12894, 0.32078, 0.1957, 0.70391, 0.34653, 0.13992, 0.58587, 0.16728]
Predicted label: 5
Correct prediction
Energy consumption = 185.348374 pJ
sum error= 237
Actual label: 6
Output voltages: [0.27974, 0.1868, 0.33689, 0.061849, 0.42951, 0.35821, 0.7347, 0.059774, 0.36272, 0.10712]
Predicted label: 6
Correct prediction
Energy consumption = 182.809765 pJ
sum error= 237
Actual label: 7
Output voltages: [0.28591, 0.27332, 0.21468, 0.27346, 0.17183, 0.087111, 0.04405, 0.75951, 0.33319, 0.31764]
Predicted label: 7
Correct prediction
Energy consumption = 200.549895 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 608 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 608 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 608 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.30902, 0.12508, 0.42531, 0.18901, 0.19911, 0.1705, 0.38872, 0.069895, 0.69902, 0.25085]
Predicted label: 8
Correct prediction
Energy consumption = 196.814746 pJ
sum error= 237
Actual label: 9
Output voltages: [0.44712, 0.055638, 0.28158, 0.30795, 0.18372, 0.24929, 0.14526, 0.08209, 0.55827, 0.46052]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.036670 pJ
sum error= 238
Actual label: 0
Output voltages: [0.71728, 0.19493, 0.24722, 0.17294, 0.17477, 0.20532, 0.4509, 0.17463, 0.28104, 0.28653]
Predicted label: 0
Correct prediction
Energy consumption = 188.123585 pJ
sum error= 238
Actual label: 1
Output voltages: [0.24122, 0.73144, 0.20425, 0.2434, 0.23169, 0.11254, 0.38506, 0.063197, 0.4637, 0.19049]
Predicted label: 1
Correct prediction
Energy consumption = 210.894813 pJ
sum error= 238
Actual label: 2
Output voltages: [0.33214, 0.21639, 0.72856, 0.34274, 0.16034, 0.029922, 0.23105, 0.25816, 0.43478, 0.15806]
Predicted label: 2
Correct prediction
Energy consumption = 183.003135 pJ
sum error= 238
Actual label: 3
Output voltages: [0.23979, 0.12201, 0.29541, 0.62966, 0.102, 0.20953, 0.067904, 0.27799, 0.65526, 0.16797]
Predicted label: 8
Wrong prediction!
Energy consumption = 185.061124 pJ
sum error= 239
Actual label: 4
Output voltages: [0.18716, 0.15653, 0.271, 0.14174, 0.76172, 0.094835, 0.32035, 0.29607, 0.24091, 0.23606]
Predicted label: 4
Correct prediction
Energy consumption = 185.905270 pJ
sum error= 239
Actual label: 5
Output voltages: [0.35679, 0.04703, 0.15211, 0.32859, 0.13503, 0.6376, 0.29969, 0.16709, 0.62118, 0.097189]
Predicted label: 5
Correct prediction
Energy consumption = 193.050544 pJ
sum error= 239
Actual label: 6
Output voltages: [0.26561, 0.18767, 0.31057, 0.12528, 0.32195, 0.3569, 0.73298, 0.05587, 0.43138, 0.16286]
Predicted label: 6
Correct prediction
Energy consumption = 183.164803 pJ
sum error= 239
Actual label: 7
Output voltages: [0.28682, 0.25337, 0.24924, 0.25659, 0.11674, 0.10267, 0.043954, 0.75027, 0.42079, 0.30736]
Predicted label: 7
Correct prediction
Energy consumption = 196.681022 pJ
sum error= 239
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 609 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 609 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 609 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.38698, 0.13261, 0.29256, 0.30833, 0.1338, 0.25561, 0.23025, 0.063872, 0.70788, 0.3056]
Predicted label: 8
Correct prediction
Energy consumption = 199.049924 pJ
sum error= 239
Actual label: 9
Output voltages: [0.40173, 0.046945, 0.23335, 0.31482, 0.11532, 0.40127, 0.19186, 0.08071, 0.60308, 0.32923]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.786908 pJ
sum error= 240
Actual label: 1
Output voltages: [0.2231, 0.75244, 0.29206, 0.27124, 0.22567, 0.074366, 0.36708, 0.10697, 0.36185, 0.17716]
Predicted label: 1
Correct prediction
Energy consumption = 208.202457 pJ
sum error= 240
Actual label: 2
Output voltages: [0.28135, 0.2502, 0.6553, 0.28877, 0.10058, 0.037939, 0.27644, 0.18452, 0.54369, 0.21468]
Predicted label: 2
Correct prediction
Energy consumption = 189.960055 pJ
sum error= 240
Actual label: 6
Output voltages: [0.32826, 0.26387, 0.26944, 0.085958, 0.33329, 0.35674, 0.74507, 0.091609, 0.38779, 0.10736]
Predicted label: 6
Correct prediction
Energy consumption = 190.698116 pJ
sum error= 240
Actual label: 5
Output voltages: [0.26425, 0.056809, 0.084892, 0.311, 0.24323, 0.73232, 0.3744, 0.13535, 0.48774, 0.17594]
Predicted label: 5
Correct prediction
Energy consumption = 189.784111 pJ
sum error= 240
Actual label: 3
Output voltages: [0.2782, 0.17372, 0.25176, 0.75393, 0.18509, 0.22308, 0.13832, 0.22848, 0.47432, 0.24224]
Predicted label: 3
Correct prediction
Energy consumption = 183.038739 pJ
sum error= 240
Actual label: 0
Output voltages: [0.74428, 0.24505, 0.24736, 0.19572, 0.13392, 0.21108, 0.40515, 0.20699, 0.34265, 0.18493]
Predicted label: 0
Correct prediction
Energy consumption = 189.707488 pJ
sum error= 240
Actual label: 7
Output voltages: [0.24727, 0.24326, 0.23389, 0.29763, 0.10091, 0.075426, 0.037185, 0.69353, 0.48933, 0.38863]
Predicted label: 7
Correct prediction
Energy consumption = 204.994276 pJ
sum error= 240
Actual label: 0
Output voltages: [0.71529, 0.19581, 0.28275, 0.17113, 0.17043, 0.16247, 0.36203, 0.1843, 0.37787, 0.25279]
Predicted label: 0
Correct prediction
Energy consumption = 189.649644 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 610 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 610 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 610 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.17548, 0.18921, 0.2993, 0.09627, 0.75705, 0.11444, 0.30513, 0.27441, 0.24726, 0.21744]
Predicted label: 4
Correct prediction
Energy consumption = 188.711884 pJ
sum error= 240
Actual label: 1
Output voltages: [0.28563, 0.55876, 0.20467, 0.38331, 0.078714, 0.22337, 0.36525, 0.075996, 0.5939, 0.16977]
Predicted label: 8
Wrong prediction!
Energy consumption = 208.683831 pJ
sum error= 241
Actual label: 4
Output voltages: [0.1864, 0.13874, 0.29539, 0.11725, 0.75418, 0.060748, 0.36701, 0.28153, 0.18819, 0.22994]
Predicted label: 4
Correct prediction
Energy consumption = 193.416132 pJ
sum error= 241
Actual label: 3
Output voltages: [0.22464, 0.12409, 0.22533, 0.72315, 0.26632, 0.32708, 0.21128, 0.17326, 0.47493, 0.25175]
Predicted label: 3
Correct prediction
Energy consumption = 186.606598 pJ
sum error= 241
Actual label: 6
Output voltages: [0.32747, 0.21427, 0.33773, 0.08273, 0.31365, 0.29891, 0.74253, 0.06725, 0.42681, 0.18014]
Predicted label: 6
Correct prediction
Energy consumption = 184.827582 pJ
sum error= 241
Actual label: 7
Output voltages: [0.25347, 0.22723, 0.23205, 0.24972, 0.12451, 0.094666, 0.038385, 0.71386, 0.54799, 0.31302]
Predicted label: 7
Correct prediction
Energy consumption = 197.124271 pJ
sum error= 241
Actual label: 2
Output voltages: [0.3688, 0.20907, 0.72527, 0.32046, 0.17871, 0.035026, 0.33241, 0.24553, 0.49202, 0.20335]
Predicted label: 2
Correct prediction
Energy consumption = 179.538944 pJ
sum error= 241
Actual label: 3
Output voltages: [0.26484, 0.13893, 0.27647, 0.74091, 0.17388, 0.22925, 0.11844, 0.21338, 0.53323, 0.23522]
Predicted label: 3
Correct prediction
Energy consumption = 179.781903 pJ
sum error= 241
Actual label: 1
Output voltages: [0.19145, 0.75779, 0.23251, 0.23815, 0.22112, 0.13085, 0.4799, 0.1035, 0.3086, 0.1574]
Predicted label: 1
Correct prediction
Energy consumption = 204.366435 pJ
sum error= 241
Actual label: 2
Output voltages: [0.3596, 0.2423, 0.73352, 0.297, 0.098924, 0.027315, 0.20882, 0.46904, 0.41392, 0.15564]
Predicted label: 2
Correct prediction
Energy consumption = 180.711660 pJ
sum error= 241
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 611 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 611 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 611 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.24134, 0.69962, 0.19, 0.36179, 0.14146, 0.099948, 0.37275, 0.07634, 0.48935, 0.22738]
Predicted label: 1
Correct prediction
Energy consumption = 216.196317 pJ
sum error= 241
Actual label: 2
Output voltages: [0.30978, 0.29266, 0.71764, 0.31583, 0.13161, 0.031242, 0.23194, 0.26944, 0.45541, 0.19448]
Predicted label: 2
Correct prediction
Energy consumption = 187.362307 pJ
sum error= 241
Actual label: 9
Output voltages: [0.44014, 0.087854, 0.26771, 0.25114, 0.20429, 0.23015, 0.22016, 0.080077, 0.53021, 0.46841]
Predicted label: 8
Wrong prediction!
Energy consumption = 193.523029 pJ
sum error= 242
Actual label: 6
Output voltages: [0.38699, 0.22891, 0.32, 0.10748, 0.32872, 0.26593, 0.728, 0.075269, 0.40736, 0.16893]
Predicted label: 6
Correct prediction
Energy consumption = 187.261683 pJ
sum error= 242
Actual label: 0
Output voltages: [0.73125, 0.22146, 0.24708, 0.16807, 0.15496, 0.16503, 0.45346, 0.17549, 0.31098, 0.22879]
Predicted label: 0
Correct prediction
Energy consumption = 185.843415 pJ
sum error= 242
Actual label: 1
Output voltages: [0.2493, 0.68098, 0.18499, 0.27552, 0.34903, 0.058666, 0.27283, 0.067949, 0.43079, 0.28125]
Predicted label: 1
Correct prediction
Energy consumption = 212.028570 pJ
sum error= 242
Actual label: 3
Output voltages: [0.31063, 0.2053, 0.2371, 0.75071, 0.13142, 0.1752, 0.15003, 0.19289, 0.51642, 0.22773]
Predicted label: 3
Correct prediction
Energy consumption = 184.977694 pJ
sum error= 242
Actual label: 0
Output voltages: [0.69231, 0.20337, 0.22423, 0.19757, 0.18189, 0.12537, 0.4204, 0.13816, 0.38235, 0.24165]
Predicted label: 0
Correct prediction
Energy consumption = 194.540583 pJ
sum error= 242
Actual label: 2
Output voltages: [0.37024, 0.26407, 0.73606, 0.32891, 0.14001, 0.027642, 0.27035, 0.26617, 0.39897, 0.18989]
Predicted label: 2
Correct prediction
Energy consumption = 189.789956 pJ
sum error= 242
Actual label: 7
Output voltages: [0.28992, 0.25101, 0.29547, 0.19685, 0.17515, 0.059055, 0.042097, 0.75411, 0.42805, 0.23844]
Predicted label: 7
Correct prediction
Energy consumption = 191.840675 pJ
sum error= 242
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 612 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 612 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 612 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27334, 0.06057, 0.084979, 0.23185, 0.24621, 0.704, 0.48113, 0.09874, 0.47857, 0.12778]
Predicted label: 5
Correct prediction
Energy consumption = 188.225971 pJ
sum error= 242
Actual label: 7
Output voltages: [0.385, 0.25748, 0.26945, 0.11316, 0.1666, 0.095206, 0.044835, 0.74589, 0.37029, 0.14888]
Predicted label: 7
Correct prediction
Energy consumption = 197.110305 pJ
sum error= 242
Actual label: 6
Output voltages: [0.30389, 0.14937, 0.24666, 0.16718, 0.32132, 0.40267, 0.70281, 0.053339, 0.44781, 0.1883]
Predicted label: 6
Correct prediction
Energy consumption = 188.327077 pJ
sum error= 242
Actual label: 2
Output voltages: [0.38446, 0.2667, 0.73307, 0.32396, 0.17732, 0.030446, 0.30537, 0.19828, 0.44303, 0.22311]
Predicted label: 2
Correct prediction
Energy consumption = 177.200079 pJ
sum error= 242
Actual label: 9
Output voltages: [0.37121, 0.048201, 0.23735, 0.21289, 0.27471, 0.30882, 0.1864, 0.077065, 0.54327, 0.44856]
Predicted label: 8
Wrong prediction!
Energy consumption = 195.455007 pJ
sum error= 243
Actual label: 1
Output voltages: [0.21189, 0.7749, 0.25309, 0.334, 0.14334, 0.1555, 0.4278, 0.15107, 0.28817, 0.23144]
Predicted label: 1
Correct prediction
Energy consumption = 212.025155 pJ
sum error= 243
Actual label: 9
Output voltages: [0.40884, 0.060034, 0.20389, 0.27169, 0.23409, 0.29918, 0.16571, 0.071172, 0.51485, 0.50566]
Predicted label: 8
Wrong prediction!
Energy consumption = 193.122381 pJ
sum error= 244
Actual label: 0
Output voltages: [0.75503, 0.23687, 0.24032, 0.16552, 0.13546, 0.23898, 0.35817, 0.19311, 0.28161, 0.17564]
Predicted label: 0
Correct prediction
Energy consumption = 184.089615 pJ
sum error= 244
Actual label: 6
Output voltages: [0.30233, 0.22842, 0.30878, 0.073661, 0.33894, 0.35881, 0.75144, 0.094335, 0.37732, 0.15347]
Predicted label: 6
Correct prediction
Energy consumption = 185.406842 pJ
sum error= 244
Actual label: 0
Output voltages: [0.73455, 0.27817, 0.29335, 0.17351, 0.12236, 0.20825, 0.39816, 0.15579, 0.30823, 0.2344]
Predicted label: 0
Correct prediction
Energy consumption = 185.389724 pJ
sum error= 244
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 613 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 613 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 613 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29072, 0.20563, 0.3343, 0.051072, 0.36434, 0.2974, 0.74087, 0.061496, 0.34831, 0.14214]
Predicted label: 6
Correct prediction
Energy consumption = 188.656297 pJ
sum error= 244
Actual label: 0
Output voltages: [0.73859, 0.23594, 0.29717, 0.14878, 0.12524, 0.16344, 0.40976, 0.19176, 0.29737, 0.22324]
Predicted label: 0
Correct prediction
Energy consumption = 186.798126 pJ
sum error= 244
Actual label: 2
Output voltages: [0.32137, 0.28297, 0.73919, 0.2837, 0.1672, 0.027592, 0.33898, 0.23612, 0.43507, 0.22312]
Predicted label: 2
Correct prediction
Energy consumption = 181.024170 pJ
sum error= 244
Actual label: 0
Output voltages: [0.73291, 0.24133, 0.21458, 0.17989, 0.16399, 0.24437, 0.4119, 0.16435, 0.25603, 0.2385]
Predicted label: 0
Correct prediction
Energy consumption = 190.182984 pJ
sum error= 244
Actual label: 6
Output voltages: [0.2824, 0.15748, 0.22352, 0.15951, 0.31545, 0.41843, 0.7261, 0.050185, 0.39267, 0.18056]
Predicted label: 6
Correct prediction
Energy consumption = 186.966391 pJ
sum error= 244
Actual label: 1
Output voltages: [0.19971, 0.75907, 0.29979, 0.30361, 0.22899, 0.060515, 0.41104, 0.12169, 0.31827, 0.19763]
Predicted label: 1
Correct prediction
Energy consumption = 212.621864 pJ
sum error= 244
Actual label: 5
Output voltages: [0.29307, 0.055918, 0.04915, 0.36637, 0.16222, 0.72894, 0.30556, 0.16508, 0.52754, 0.14073]
Predicted label: 5
Correct prediction
Energy consumption = 184.734895 pJ
sum error= 244
Actual label: 8
Output voltages: [0.33599, 0.16368, 0.37465, 0.29803, 0.20107, 0.11308, 0.29289, 0.055026, 0.70328, 0.31254]
Predicted label: 8
Correct prediction
Energy consumption = 184.994028 pJ
sum error= 244
Actual label: 4
Output voltages: [0.1495, 0.11465, 0.26534, 0.13253, 0.75789, 0.1207, 0.32305, 0.27642, 0.24602, 0.21588]
Predicted label: 4
Correct prediction
Energy consumption = 194.395533 pJ
sum error= 244
Actual label: 3
Output voltages: [0.30914, 0.14427, 0.39561, 0.73155, 0.14925, 0.078757, 0.14097, 0.1196, 0.52321, 0.18706]
Predicted label: 3
Correct prediction
Energy consumption = 181.691985 pJ
sum error= 244
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 614 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 614 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 614 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.71967, 0.19005, 0.176, 0.21388, 0.095463, 0.30269, 0.41658, 0.22938, 0.34945, 0.20933]
Predicted label: 0
Correct prediction
Energy consumption = 193.006638 pJ
sum error= 244
Actual label: 1
Output voltages: [0.28482, 0.73828, 0.29442, 0.29472, 0.26382, 0.0409, 0.36628, 0.058075, 0.32646, 0.23301]
Predicted label: 1
Correct prediction
Energy consumption = 202.503861 pJ
sum error= 244
Actual label: 5
Output voltages: [0.32579, 0.043876, 0.056694, 0.29877, 0.21076, 0.71827, 0.30449, 0.14543, 0.54474, 0.11125]
Predicted label: 5
Correct prediction
Energy consumption = 192.018828 pJ
sum error= 244
Actual label: 4
Output voltages: [0.1343, 0.15066, 0.19097, 0.064419, 0.74424, 0.1438, 0.3624, 0.26314, 0.33324, 0.17073]
Predicted label: 4
Correct prediction
Energy consumption = 190.220015 pJ
sum error= 244
Actual label: 4
Output voltages: [0.24804, 0.14439, 0.33967, 0.097976, 0.74579, 0.057832, 0.36594, 0.27386, 0.19686, 0.18955]
Predicted label: 4
Correct prediction
Energy consumption = 182.367922 pJ
sum error= 244
Actual label: 8
Output voltages: [0.30893, 0.21285, 0.27755, 0.3411, 0.13343, 0.17965, 0.21768, 0.095377, 0.71337, 0.3108]
Predicted label: 8
Correct prediction
Energy consumption = 198.278819 pJ
sum error= 244
Actual label: 5
Output voltages: [0.25111, 0.059697, 0.13337, 0.26838, 0.21794, 0.6351, 0.36483, 0.08105, 0.54638, 0.25327]
Predicted label: 5
Correct prediction
Energy consumption = 180.545938 pJ
sum error= 244
Actual label: 7
Output voltages: [0.28544, 0.23145, 0.14742, 0.19233, 0.20214, 0.098185, 0.03804, 0.6791, 0.41661, 0.41055]
Predicted label: 7
Correct prediction
Energy consumption = 199.867554 pJ
sum error= 244
Actual label: 5
Output voltages: [0.25904, 0.057493, 0.056804, 0.31519, 0.21443, 0.74745, 0.34636, 0.16313, 0.51002, 0.16112]
Predicted label: 5
Correct prediction
Energy consumption = 185.422332 pJ
sum error= 244
Actual label: 7
Output voltages: [0.2563, 0.23563, 0.28662, 0.24078, 0.15897, 0.053715, 0.033798, 0.74703, 0.4458, 0.25676]
Predicted label: 7
Correct prediction
Energy consumption = 194.060500 pJ
sum error= 244
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 615 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 615 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 615 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.29241, 0.15487, 0.37785, 0.2562, 0.14562, 0.18943, 0.18932, 0.077826, 0.73665, 0.32626]
Predicted label: 8
Correct prediction
Energy consumption = 192.586497 pJ
sum error= 244
Actual label: 3
Output voltages: [0.32408, 0.12577, 0.27325, 0.75525, 0.23829, 0.23968, 0.18575, 0.19339, 0.45531, 0.22872]
Predicted label: 3
Correct prediction
Energy consumption = 184.755721 pJ
sum error= 244
Actual label: 4
Output voltages: [0.14112, 0.20665, 0.25278, 0.098576, 0.74582, 0.074547, 0.29192, 0.25239, 0.28313, 0.24307]
Predicted label: 4
Correct prediction
Energy consumption = 195.827608 pJ
sum error= 244
Actual label: 8
Output voltages: [0.25822, 0.11474, 0.37351, 0.27095, 0.1734, 0.23838, 0.20277, 0.072941, 0.73645, 0.35264]
Predicted label: 8
Correct prediction
Energy consumption = 193.690626 pJ
sum error= 244
Actual label: 8
Output voltages: [0.31836, 0.12611, 0.31213, 0.2977, 0.10821, 0.30365, 0.18868, 0.059657, 0.72433, 0.30475]
Predicted label: 8
Correct prediction
Energy consumption = 192.634919 pJ
sum error= 244
Actual label: 5
Output voltages: [0.25507, 0.039918, 0.069715, 0.31138, 0.30146, 0.72875, 0.43149, 0.14848, 0.52815, 0.20376]
Predicted label: 5
Correct prediction
Energy consumption = 188.502969 pJ
sum error= 244
Actual label: 2
Output voltages: [0.38813, 0.315, 0.73302, 0.3175, 0.17882, 0.036827, 0.33573, 0.21751, 0.41627, 0.18007]
Predicted label: 2
Correct prediction
Energy consumption = 191.082914 pJ
sum error= 244
Actual label: 9
Output voltages: [0.49612, 0.10236, 0.29116, 0.25127, 0.22491, 0.18011, 0.25672, 0.097238, 0.52046, 0.38363]
Predicted label: 8
Wrong prediction!
Energy consumption = 196.362787 pJ
sum error= 245
Actual label: 7
Output voltages: [0.23998, 0.24618, 0.24746, 0.24453, 0.12985, 0.08203, 0.044202, 0.74622, 0.47553, 0.31833]
Predicted label: 7
Correct prediction
Energy consumption = 199.301774 pJ
sum error= 245
Actual label: 1
Output voltages: [0.20511, 0.75903, 0.35696, 0.25239, 0.18173, 0.049339, 0.34779, 0.16719, 0.35644, 0.20375]
Predicted label: 1
Correct prediction
Energy consumption = 201.022827 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 616 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 616 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 616 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26884, 0.17141, 0.36469, 0.73924, 0.13867, 0.1477, 0.12745, 0.2325, 0.54182, 0.20179]
Predicted label: 3
Correct prediction
Energy consumption = 180.527648 pJ
sum error= 245
Actual label: 8
Output voltages: [0.29402, 0.12988, 0.37387, 0.22071, 0.20435, 0.1855, 0.30081, 0.064263, 0.72875, 0.31951]
Predicted label: 8
Correct prediction
Energy consumption = 190.607935 pJ
sum error= 245
Actual label: 1
Output voltages: [0.23849, 0.76168, 0.27609, 0.30237, 0.24354, 0.12852, 0.38669, 0.13224, 0.27305, 0.21283]
Predicted label: 1
Correct prediction
Energy consumption = 212.515800 pJ
sum error= 245
Actual label: 0
Output voltages: [0.72965, 0.21434, 0.27438, 0.18474, 0.1562, 0.20857, 0.44611, 0.20195, 0.29213, 0.20117]
Predicted label: 0
Correct prediction
Energy consumption = 194.456458 pJ
sum error= 245
Actual label: 7
Output voltages: [0.2321, 0.24876, 0.18009, 0.25614, 0.17492, 0.11866, 0.038939, 0.72867, 0.42447, 0.34707]
Predicted label: 7
Correct prediction
Energy consumption = 201.501937 pJ
sum error= 245
Actual label: 5
Output voltages: [0.25789, 0.047442, 0.16007, 0.38639, 0.16756, 0.57881, 0.24314, 0.15239, 0.59985, 0.25605]
Predicted label: 8
Wrong prediction!
Energy consumption = 185.692504 pJ
sum error= 246
Actual label: 9
Output voltages: [0.3854, 0.080934, 0.18637, 0.34721, 0.15661, 0.24467, 0.24426, 0.062575, 0.57661, 0.3352]
Predicted label: 8
Wrong prediction!
Energy consumption = 198.204233 pJ
sum error= 247
Actual label: 6
Output voltages: [0.29183, 0.17494, 0.32139, 0.071404, 0.38806, 0.32589, 0.74155, 0.052206, 0.37519, 0.16084]
Predicted label: 6
Correct prediction
Energy consumption = 184.104188 pJ
sum error= 247
Actual label: 9
Output voltages: [0.32875, 0.083357, 0.24723, 0.34484, 0.30435, 0.12302, 0.14194, 0.10516, 0.48979, 0.46953]
Predicted label: 8
Wrong prediction!
Energy consumption = 199.400011 pJ
sum error= 248
Actual label: 4
Output voltages: [0.15118, 0.17654, 0.3104, 0.085492, 0.74542, 0.057015, 0.37739, 0.27287, 0.22038, 0.25365]
Predicted label: 4
Correct prediction
Energy consumption = 183.035840 pJ
sum error= 248
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 617 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 617 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 617 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28985, 0.28655, 0.30332, 0.28428, 0.12214, 0.060557, 0.03441, 0.74732, 0.41181, 0.31934]
Predicted label: 7
Correct prediction
Energy consumption = 200.189912 pJ
sum error= 248
Actual label: 7
Output voltages: [0.31468, 0.25284, 0.33659, 0.26801, 0.16124, 0.061882, 0.038528, 0.75529, 0.41817, 0.30843]
Predicted label: 7
Correct prediction
Energy consumption = 187.714759 pJ
sum error= 248
Actual label: 9
Output voltages: [0.47826, 0.070541, 0.27106, 0.33616, 0.18531, 0.27102, 0.30182, 0.055355, 0.49592, 0.35861]
Predicted label: 8
Wrong prediction!
Energy consumption = 195.148385 pJ
sum error= 249
Actual label: 9
Output voltages: [0.49245, 0.077076, 0.37025, 0.27682, 0.29946, 0.049804, 0.20147, 0.20001, 0.45706, 0.36551]
Predicted label: 0
Wrong prediction!
Energy consumption = 188.989323 pJ
sum error= 250
Actual label: 3
Output voltages: [0.28959, 0.13739, 0.30582, 0.74288, 0.24686, 0.25247, 0.27961, 0.17827, 0.50039, 0.19415]
Predicted label: 3
Correct prediction
Energy consumption = 182.880213 pJ
sum error= 250
Actual label: 4
Output voltages: [0.12741, 0.13278, 0.1942, 0.11724, 0.71914, 0.065876, 0.2896, 0.3021, 0.36812, 0.18399]
Predicted label: 4
Correct prediction
Energy consumption = 198.402142 pJ
sum error= 250
Actual label: 4
Output voltages: [0.19693, 0.15358, 0.27198, 0.08234, 0.75446, 0.10111, 0.30988, 0.2544, 0.30007, 0.19263]
Predicted label: 4
Correct prediction
Energy consumption = 180.714289 pJ
sum error= 250
Actual label: 3
Output voltages: [0.30113, 0.1141, 0.25869, 0.75128, 0.18026, 0.29699, 0.15024, 0.24837, 0.45265, 0.18167]
Predicted label: 3
Correct prediction
Energy consumption = 181.359030 pJ
sum error= 250
Actual label: 8
Output voltages: [0.27747, 0.11647, 0.37551, 0.26768, 0.16082, 0.24678, 0.18414, 0.061287, 0.72403, 0.31297]
Predicted label: 8
Correct prediction
Energy consumption = 191.444962 pJ
sum error= 250
Actual label: 6
Output voltages: [0.31322, 0.14585, 0.2484, 0.1453, 0.31415, 0.41459, 0.70604, 0.048487, 0.45211, 0.22135]
Predicted label: 6
Correct prediction
Energy consumption = 184.285233 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 618 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 618 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 618 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33884, 0.22561, 0.73124, 0.34689, 0.11685, 0.03405, 0.33275, 0.29665, 0.43007, 0.2174]
Predicted label: 2
Correct prediction
Energy consumption = 191.342656 pJ
sum error= 250
Actual label: 0
Output voltages: [0.70293, 0.25135, 0.22076, 0.22065, 0.1755, 0.11182, 0.3004, 0.21677, 0.40273, 0.31352]
Predicted label: 0
Correct prediction
Energy consumption = 197.708860 pJ
sum error= 250
Actual label: 1
Output voltages: [0.15404, 0.76144, 0.24974, 0.27939, 0.21415, 0.076765, 0.38543, 0.15152, 0.35029, 0.24024]
Predicted label: 1
Correct prediction
Energy consumption = 210.560848 pJ
sum error= 250
Actual label: 2
Output voltages: [0.38148, 0.22293, 0.72238, 0.40078, 0.13371, 0.040761, 0.32349, 0.22043, 0.38531, 0.15689]
Predicted label: 2
Correct prediction
Energy consumption = 193.730496 pJ
sum error= 250
Actual label: 3
Output voltages: [0.2967, 0.17939, 0.30076, 0.72883, 0.10942, 0.16753, 0.11307, 0.16091, 0.57021, 0.21533]
Predicted label: 3
Correct prediction
Energy consumption = 180.725496 pJ
sum error= 250
Actual label: 4
Output voltages: [0.12619, 0.16397, 0.27056, 0.13122, 0.73721, 0.099414, 0.21266, 0.20285, 0.32571, 0.24566]
Predicted label: 4
Correct prediction
Energy consumption = 190.144023 pJ
sum error= 250
Actual label: 5
Output voltages: [0.21534, 0.050385, 0.076565, 0.40555, 0.23641, 0.71021, 0.2757, 0.18314, 0.52174, 0.25339]
Predicted label: 5
Correct prediction
Energy consumption = 187.606611 pJ
sum error= 250
Actual label: 6
Output voltages: [0.26695, 0.22729, 0.36108, 0.053961, 0.40906, 0.28641, 0.74027, 0.060604, 0.34267, 0.092191]
Predicted label: 6
Correct prediction
Energy consumption = 189.874328 pJ
sum error= 250
Actual label: 7
Output voltages: [0.35581, 0.28955, 0.22908, 0.29127, 0.20423, 0.10367, 0.039482, 0.68424, 0.27914, 0.39675]
Predicted label: 7
Correct prediction
Energy consumption = 204.195684 pJ
sum error= 250
Actual label: 8
Output voltages: [0.19852, 0.28819, 0.25358, 0.38462, 0.099429, 0.17775, 0.22213, 0.1198, 0.73794, 0.27488]
Predicted label: 8
Correct prediction
Energy consumption = 191.643455 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 619 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 619 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 619 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32912, 0.10255, 0.19533, 0.24751, 0.22856, 0.1838, 0.068709, 0.24619, 0.50344, 0.63474]
Predicted label: 9
Correct prediction
Energy consumption = 189.431771 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73502, 0.26418, 0.31255, 0.20223, 0.13041, 0.11606, 0.37166, 0.20894, 0.30623, 0.25043]
Predicted label: 0
Correct prediction
Energy consumption = 187.883769 pJ
sum error= 250
Actual label: 1
Output voltages: [0.19983, 0.74686, 0.30154, 0.21626, 0.29598, 0.070632, 0.46139, 0.10644, 0.31498, 0.18786]
Predicted label: 1
Correct prediction
Energy consumption = 207.742115 pJ
sum error= 250
Actual label: 2
Output voltages: [0.39377, 0.26468, 0.70776, 0.44415, 0.16679, 0.046373, 0.241, 0.24548, 0.35931, 0.11249]
Predicted label: 2
Correct prediction
Energy consumption = 192.159988 pJ
sum error= 250
Actual label: 3
Output voltages: [0.41068, 0.10589, 0.34861, 0.73991, 0.17305, 0.16079, 0.079666, 0.2302, 0.45544, 0.22554]
Predicted label: 3
Correct prediction
Energy consumption = 185.235754 pJ
sum error= 250
Actual label: 4
Output voltages: [0.15794, 0.12561, 0.33518, 0.1072, 0.75303, 0.080013, 0.25399, 0.23975, 0.26932, 0.21823]
Predicted label: 4
Correct prediction
Energy consumption = 192.759183 pJ
sum error= 250
Actual label: 5
Output voltages: [0.26079, 0.052047, 0.084538, 0.36138, 0.20614, 0.72162, 0.29775, 0.17668, 0.53646, 0.23893]
Predicted label: 5
Correct prediction
Energy consumption = 190.908073 pJ
sum error= 250
Actual label: 6
Output voltages: [0.2763, 0.16723, 0.28778, 0.14714, 0.31944, 0.35738, 0.73322, 0.05894, 0.41614, 0.17119]
Predicted label: 6
Correct prediction
Energy consumption = 181.440915 pJ
sum error= 250
Actual label: 7
Output voltages: [0.35281, 0.17767, 0.17076, 0.31278, 0.21901, 0.20145, 0.043404, 0.75386, 0.31893, 0.39616]
Predicted label: 7
Correct prediction
Energy consumption = 201.693144 pJ
sum error= 250
Actual label: 8
Output voltages: [0.20274, 0.16511, 0.27571, 0.26761, 0.11559, 0.32213, 0.21554, 0.13066, 0.74684, 0.26056]
Predicted label: 8
Correct prediction
Energy consumption = 183.855930 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 620 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 620 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 620 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.35357, 0.089793, 0.21169, 0.23575, 0.28572, 0.24953, 0.13852, 0.3076, 0.39957, 0.65087]
Predicted label: 9
Correct prediction
Energy consumption = 196.735025 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73409, 0.28107, 0.30934, 0.17689, 0.12863, 0.12262, 0.41757, 0.17873, 0.2836, 0.26012]
Predicted label: 0
Correct prediction
Energy consumption = 192.281798 pJ
sum error= 250
Actual label: 1
Output voltages: [0.16578, 0.76209, 0.29306, 0.19511, 0.26518, 0.1095, 0.43284, 0.13091, 0.32401, 0.20216]
Predicted label: 1
Correct prediction
Energy consumption = 206.212390 pJ
sum error= 250
Actual label: 2
Output voltages: [0.36772, 0.22093, 0.7436, 0.32758, 0.13943, 0.04207, 0.23805, 0.24628, 0.41298, 0.15498]
Predicted label: 2
Correct prediction
Energy consumption = 188.535550 pJ
sum error= 250
Actual label: 3
Output voltages: [0.38028, 0.18165, 0.29217, 0.75293, 0.093256, 0.20458, 0.10651, 0.23588, 0.49353, 0.26207]
Predicted label: 3
Correct prediction
Energy consumption = 184.008231 pJ
sum error= 250
Actual label: 4
Output voltages: [0.13796, 0.14609, 0.2515, 0.14289, 0.75021, 0.1356, 0.28891, 0.20871, 0.31893, 0.14505]
Predicted label: 4
Correct prediction
Energy consumption = 193.570434 pJ
sum error= 250
Actual label: 5
Output voltages: [0.28253, 0.054837, 0.080512, 0.45069, 0.2004, 0.66346, 0.27303, 0.12765, 0.49815, 0.29357]
Predicted label: 5
Correct prediction
Energy consumption = 191.400548 pJ
sum error= 250
Actual label: 6
Output voltages: [0.29422, 0.16746, 0.32447, 0.086735, 0.35225, 0.29218, 0.73495, 0.04873, 0.39751, 0.16868]
Predicted label: 6
Correct prediction
Energy consumption = 181.083806 pJ
sum error= 250
Actual label: 7
Output voltages: [0.33465, 0.27011, 0.26861, 0.35962, 0.15685, 0.086686, 0.037603, 0.70157, 0.33589, 0.42443]
Predicted label: 7
Correct prediction
Energy consumption = 202.559162 pJ
sum error= 250
Actual label: 8
Output voltages: [0.19618, 0.20486, 0.28652, 0.30688, 0.13124, 0.23972, 0.22387, 0.13946, 0.75623, 0.27433]
Predicted label: 8
Correct prediction
Energy consumption = 189.303414 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 621 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 621 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 621 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39, 0.073851, 0.20692, 0.19857, 0.32915, 0.19598, 0.077717, 0.27959, 0.45571, 0.62477]
Predicted label: 9
Correct prediction
Energy consumption = 193.098663 pJ
sum error= 250
Actual label: 0
Output voltages: [0.72824, 0.24761, 0.21105, 0.16819, 0.19401, 0.17426, 0.44246, 0.15061, 0.29604, 0.23363]
Predicted label: 0
Correct prediction
Energy consumption = 195.340760 pJ
sum error= 250
Actual label: 8
Output voltages: [0.23508, 0.23557, 0.2569, 0.37768, 0.11083, 0.21084, 0.19296, 0.12854, 0.74844, 0.34707]
Predicted label: 8
Correct prediction
Energy consumption = 193.572695 pJ
sum error= 250
Actual label: 3
Output voltages: [0.29287, 0.12999, 0.26642, 0.74294, 0.19584, 0.39391, 0.17776, 0.22599, 0.43145, 0.20521]
Predicted label: 3
Correct prediction
Energy consumption = 184.926373 pJ
sum error= 250
Actual label: 9
Output voltages: [0.29101, 0.1425, 0.19119, 0.26767, 0.2765, 0.16947, 0.060322, 0.20768, 0.42217, 0.66698]
Predicted label: 9
Correct prediction
Energy consumption = 187.974978 pJ
sum error= 250
Actual label: 5
Output voltages: [0.33113, 0.051344, 0.088806, 0.43958, 0.18975, 0.66657, 0.32998, 0.10787, 0.47058, 0.25912]
Predicted label: 5
Correct prediction
Energy consumption = 192.502460 pJ
sum error= 250
Actual label: 5
Output voltages: [0.25894, 0.049264, 0.10085, 0.35291, 0.18823, 0.68929, 0.32024, 0.14213, 0.52233, 0.27021]
Predicted label: 5
Correct prediction
Energy consumption = 183.613059 pJ
sum error= 250
Actual label: 2
Output voltages: [0.36902, 0.17864, 0.73972, 0.31578, 0.15665, 0.040923, 0.24802, 0.27104, 0.46224, 0.1504]
Predicted label: 2
Correct prediction
Energy consumption = 180.009696 pJ
sum error= 250
Actual label: 6
Output voltages: [0.26833, 0.21291, 0.33153, 0.05894, 0.37938, 0.26413, 0.74197, 0.051566, 0.35432, 0.15985]
Predicted label: 6
Correct prediction
Energy consumption = 186.860773 pJ
sum error= 250
Actual label: 8
Output voltages: [0.21246, 0.24355, 0.28745, 0.3737, 0.098239, 0.14854, 0.2889, 0.1099, 0.72447, 0.31495]
Predicted label: 8
Correct prediction
Energy consumption = 194.986866 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 622 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 622 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 622 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15638, 0.1408, 0.29509, 0.13105, 0.75694, 0.070984, 0.33387, 0.29341, 0.21765, 0.22014]
Predicted label: 4
Correct prediction
Energy consumption = 196.241964 pJ
sum error= 250
Actual label: 9
Output voltages: [0.33401, 0.14508, 0.18587, 0.2642, 0.34322, 0.20119, 0.096648, 0.22164, 0.38096, 0.69798]
Predicted label: 9
Correct prediction
Energy consumption = 182.392427 pJ
sum error= 250
Actual label: 1
Output voltages: [0.24648, 0.75589, 0.31409, 0.21279, 0.28876, 0.053172, 0.3645, 0.11413, 0.24467, 0.22059]
Predicted label: 1
Correct prediction
Energy consumption = 215.054324 pJ
sum error= 250
Actual label: 7
Output voltages: [0.31416, 0.26907, 0.20971, 0.29475, 0.18348, 0.16496, 0.052002, 0.7461, 0.24853, 0.41996]
Predicted label: 7
Correct prediction
Energy consumption = 197.206198 pJ
sum error= 250
Actual label: 1
Output voltages: [0.1716, 0.76043, 0.21278, 0.28569, 0.30508, 0.062908, 0.35033, 0.1625, 0.3272, 0.24657]
Predicted label: 1
Correct prediction
Energy consumption = 205.688063 pJ
sum error= 250
Actual label: 2
Output voltages: [0.36238, 0.18769, 0.73493, 0.37324, 0.15042, 0.047888, 0.20388, 0.24734, 0.44813, 0.10458]
Predicted label: 2
Correct prediction
Energy consumption = 189.838028 pJ
sum error= 250
Actual label: 3
Output voltages: [0.42288, 0.097325, 0.32529, 0.74275, 0.18815, 0.21237, 0.098819, 0.20971, 0.40116, 0.1726]
Predicted label: 3
Correct prediction
Energy consumption = 187.461065 pJ
sum error= 250
Actual label: 5
Output voltages: [0.27894, 0.06139, 0.070217, 0.50022, 0.23543, 0.68949, 0.17307, 0.12736, 0.45912, 0.1894]
Predicted label: 5
Correct prediction
Energy consumption = 184.676620 pJ
sum error= 250
Actual label: 9
Output voltages: [0.34645, 0.093217, 0.19797, 0.20777, 0.24051, 0.21214, 0.07415, 0.2743, 0.4938, 0.62078]
Predicted label: 9
Correct prediction
Energy consumption = 192.776971 pJ
sum error= 250
Actual label: 6
Output voltages: [0.27847, 0.19665, 0.32293, 0.095851, 0.35599, 0.28976, 0.73697, 0.087757, 0.38539, 0.10225]
Predicted label: 6
Correct prediction
Energy consumption = 188.920216 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 623 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 623 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 623 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36122, 0.14649, 0.22229, 0.24739, 0.23131, 0.19667, 0.1021, 0.25091, 0.44433, 0.67054]
Predicted label: 9
Correct prediction
Energy consumption = 191.456906 pJ
sum error= 250
Actual label: 1
Output voltages: [0.20611, 0.7562, 0.22364, 0.21871, 0.25388, 0.077524, 0.38248, 0.076344, 0.35042, 0.23343]
Predicted label: 1
Correct prediction
Energy consumption = 213.357153 pJ
sum error= 250
Actual label: 1
Output voltages: [0.18179, 0.73706, 0.21454, 0.26548, 0.22212, 0.063352, 0.28337, 0.097784, 0.43772, 0.31577]
Predicted label: 1
Correct prediction
Energy consumption = 205.643308 pJ
sum error= 250
Actual label: 1
Output voltages: [0.19029, 0.75611, 0.21442, 0.22644, 0.26085, 0.083382, 0.3291, 0.14591, 0.33487, 0.25628]
Predicted label: 1
Correct prediction
Energy consumption = 203.172646 pJ
sum error= 250
Actual label: 2
Output voltages: [0.24607, 0.20639, 0.71231, 0.37813, 0.15627, 0.049149, 0.16782, 0.28377, 0.43307, 0.18795]
Predicted label: 2
Correct prediction
Energy consumption = 198.168841 pJ
sum error= 250
Actual label: 9
Output voltages: [0.3369, 0.13162, 0.19901, 0.26814, 0.24226, 0.18869, 0.080931, 0.31583, 0.42419, 0.64689]
Predicted label: 9
Correct prediction
Energy consumption = 187.964311 pJ
sum error= 250
Actual label: 5
Output voltages: [0.27433, 0.050098, 0.12706, 0.34771, 0.19351, 0.70875, 0.26883, 0.15183, 0.52899, 0.25763]
Predicted label: 5
Correct prediction
Energy consumption = 191.600795 pJ
sum error= 250
Actual label: 6
Output voltages: [0.2444, 0.1591, 0.27454, 0.058506, 0.40976, 0.27687, 0.71144, 0.10485, 0.33695, 0.16508]
Predicted label: 6
Correct prediction
Energy consumption = 190.375270 pJ
sum error= 250
Actual label: 8
Output voltages: [0.33347, 0.1965, 0.34032, 0.29767, 0.09701, 0.30255, 0.26268, 0.12742, 0.72806, 0.1509]
Predicted label: 8
Correct prediction
Energy consumption = 195.718891 pJ
sum error= 250
Actual label: 1
Output voltages: [0.18524, 0.73662, 0.17773, 0.16328, 0.2998, 0.11905, 0.2716, 0.1674, 0.37206, 0.26431]
Predicted label: 1
Correct prediction
Energy consumption = 203.864682 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 624 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 624 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 624 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31754, 0.24106, 0.73387, 0.35435, 0.15214, 0.040396, 0.24251, 0.28312, 0.4236, 0.13875]
Predicted label: 2
Correct prediction
Energy consumption = 189.890230 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73433, 0.22872, 0.21931, 0.19979, 0.27843, 0.15032, 0.42217, 0.15868, 0.29594, 0.25757]
Predicted label: 0
Correct prediction
Energy consumption = 206.748167 pJ
sum error= 250
Actual label: 7
Output voltages: [0.35444, 0.22569, 0.15026, 0.21762, 0.21525, 0.14991, 0.045346, 0.74473, 0.29058, 0.41205]
Predicted label: 7
Correct prediction
Energy consumption = 200.220899 pJ
sum error= 250
Actual label: 7
Output voltages: [0.33724, 0.13667, 0.090894, 0.14214, 0.28863, 0.28818, 0.072524, 0.76123, 0.34633, 0.22957]
Predicted label: 7
Correct prediction
Energy consumption = 192.952605 pJ
sum error= 250
Actual label: 5
Output voltages: [0.2498, 0.079443, 0.051136, 0.40563, 0.25648, 0.74697, 0.28721, 0.13443, 0.47904, 0.20927]
Predicted label: 5
Correct prediction
Energy consumption = 189.900691 pJ
sum error= 250
Actual label: 8
Output voltages: [0.23541, 0.1983, 0.30463, 0.34372, 0.13442, 0.26886, 0.23557, 0.16312, 0.74829, 0.2052]
Predicted label: 8
Correct prediction
Energy consumption = 197.367674 pJ
sum error= 250
Actual label: 2
Output voltages: [0.34263, 0.18062, 0.74752, 0.28393, 0.15925, 0.042331, 0.2532, 0.29017, 0.46354, 0.18792]
Predicted label: 2
Correct prediction
Energy consumption = 181.090599 pJ
sum error= 250
Actual label: 9
Output voltages: [0.36066, 0.11424, 0.19236, 0.25875, 0.30381, 0.18218, 0.080602, 0.27189, 0.40348, 0.65497]
Predicted label: 9
Correct prediction
Energy consumption = 188.150995 pJ
sum error= 250
Actual label: 8
Output voltages: [0.17441, 0.24215, 0.31048, 0.31588, 0.12433, 0.20564, 0.19201, 0.17755, 0.75224, 0.28557]
Predicted label: 8
Correct prediction
Energy consumption = 191.572223 pJ
sum error= 250
Actual label: 9
Output voltages: [0.33586, 0.15474, 0.20721, 0.24677, 0.25691, 0.17252, 0.10359, 0.23328, 0.42131, 0.66918]
Predicted label: 9
Correct prediction
Energy consumption = 187.016561 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 625 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 625 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 625 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69434, 0.18912, 0.1785, 0.2061, 0.19244, 0.19774, 0.50123, 0.16103, 0.32294, 0.27219]
Predicted label: 0
Correct prediction
Energy consumption = 195.852006 pJ
sum error= 250
Actual label: 4
Output voltages: [0.15994, 0.17559, 0.32718, 0.17472, 0.75267, 0.060519, 0.25757, 0.27823, 0.21035, 0.28348]
Predicted label: 4
Correct prediction
Energy consumption = 196.247161 pJ
sum error= 250
Actual label: 6
Output voltages: [0.27927, 0.19265, 0.28901, 0.10639, 0.40511, 0.2776, 0.73023, 0.082141, 0.28394, 0.17894]
Predicted label: 6
Correct prediction
Energy consumption = 190.972413 pJ
sum error= 250
Actual label: 7
Output voltages: [0.29133, 0.26299, 0.21963, 0.22739, 0.16736, 0.14049, 0.040612, 0.75296, 0.28643, 0.36281]
Predicted label: 7
Correct prediction
Energy consumption = 199.274643 pJ
sum error= 250
Actual label: 1
Output voltages: [0.18674, 0.76771, 0.21436, 0.24432, 0.2625, 0.093593, 0.43078, 0.13028, 0.26087, 0.21271]
Predicted label: 1
Correct prediction
Energy consumption = 204.257702 pJ
sum error= 250
Actual label: 3
Output voltages: [0.40107, 0.1625, 0.27371, 0.7484, 0.1053, 0.19702, 0.11727, 0.17766, 0.47926, 0.3319]
Predicted label: 3
Correct prediction
Energy consumption = 189.780016 pJ
sum error= 250
Actual label: 4
Output voltages: [0.17406, 0.16855, 0.26762, 0.1668, 0.7343, 0.1009, 0.25063, 0.1859, 0.26671, 0.25157]
Predicted label: 4
Correct prediction
Energy consumption = 194.345550 pJ
sum error= 250
Actual label: 5
Output voltages: [0.23608, 0.045246, 0.075821, 0.31138, 0.23313, 0.73376, 0.30711, 0.19076, 0.58182, 0.23042]
Predicted label: 5
Correct prediction
Energy consumption = 184.171503 pJ
sum error= 250
Actual label: 6
Output voltages: [0.29584, 0.15836, 0.20026, 0.18732, 0.3544, 0.44252, 0.72205, 0.052328, 0.39054, 0.14802]
Predicted label: 6
Correct prediction
Energy consumption = 185.695763 pJ
sum error= 250
Actual label: 0
Output voltages: [0.72647, 0.22511, 0.21343, 0.18577, 0.17607, 0.31487, 0.42967, 0.11253, 0.26292, 0.30647]
Predicted label: 0
Correct prediction
Energy consumption = 191.608738 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 626 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 626 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 626 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36509, 0.213, 0.27079, 0.74633, 0.11653, 0.21655, 0.083111, 0.14109, 0.4991, 0.30152]
Predicted label: 3
Correct prediction
Energy consumption = 189.227030 pJ
sum error= 250
Actual label: 6
Output voltages: [0.26491, 0.24851, 0.3171, 0.09216, 0.32277, 0.31753, 0.74628, 0.079448, 0.40365, 0.09024]
Predicted label: 6
Correct prediction
Energy consumption = 193.359560 pJ
sum error= 250
Actual label: 8
Output voltages: [0.25882, 0.18428, 0.29373, 0.37978, 0.1024, 0.12253, 0.10995, 0.13187, 0.7044, 0.30758]
Predicted label: 8
Correct prediction
Energy consumption = 194.477511 pJ
sum error= 250
Actual label: 7
Output voltages: [0.32995, 0.16374, 0.17664, 0.33702, 0.14732, 0.22367, 0.041991, 0.75353, 0.29491, 0.34334]
Predicted label: 7
Correct prediction
Energy consumption = 195.166791 pJ
sum error= 250
Actual label: 0
Output voltages: [0.70385, 0.24934, 0.2811, 0.15686, 0.15133, 0.1211, 0.43178, 0.1937, 0.27766, 0.2519]
Predicted label: 0
Correct prediction
Energy consumption = 195.304696 pJ
sum error= 250
Actual label: 4
Output voltages: [0.18275, 0.19008, 0.27617, 0.17117, 0.74537, 0.057507, 0.19303, 0.25589, 0.24676, 0.25101]
Predicted label: 4
Correct prediction
Energy consumption = 193.188956 pJ
sum error= 250
Actual label: 2
Output voltages: [0.23579, 0.24694, 0.71534, 0.32952, 0.16707, 0.054196, 0.2378, 0.20959, 0.4522, 0.18396]
Predicted label: 2
Correct prediction
Energy consumption = 195.660133 pJ
sum error= 250
Actual label: 7
Output voltages: [0.30887, 0.23304, 0.20755, 0.27504, 0.1938, 0.11058, 0.037463, 0.73763, 0.30693, 0.44324]
Predicted label: 7
Correct prediction
Energy consumption = 199.002644 pJ
sum error= 250
Actual label: 4
Output voltages: [0.16886, 0.13319, 0.27907, 0.11436, 0.75639, 0.073987, 0.32188, 0.26423, 0.23666, 0.22849]
Predicted label: 4
Correct prediction
Energy consumption = 193.422179 pJ
sum error= 250
Actual label: 7
Output voltages: [0.3916, 0.22578, 0.14889, 0.18034, 0.22477, 0.18298, 0.050041, 0.75815, 0.33678, 0.31213]
Predicted label: 7
Correct prediction
Energy consumption = 188.849128 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 627 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 627 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 627 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.26295, 0.049, 0.054713, 0.35334, 0.23772, 0.74597, 0.29105, 0.23497, 0.50727, 0.26503]
Predicted label: 5
Correct prediction
Energy consumption = 185.936929 pJ
sum error= 250
Actual label: 4
Output voltages: [0.12951, 0.16718, 0.2946, 0.21234, 0.73492, 0.05733, 0.20853, 0.18757, 0.25046, 0.27623]
Predicted label: 4
Correct prediction
Energy consumption = 191.766202 pJ
sum error= 250
Actual label: 3
Output voltages: [0.2664, 0.15379, 0.33817, 0.74386, 0.19361, 0.10944, 0.18003, 0.16447, 0.48294, 0.28331]
Predicted label: 3
Correct prediction
Energy consumption = 183.446771 pJ
sum error= 250
Actual label: 4
Output voltages: [0.3813, 0.133, 0.27582, 0.1443, 0.65334, 0.053643, 0.25936, 0.15022, 0.21305, 0.32289]
Predicted label: 4
Correct prediction
Energy consumption = 197.412246 pJ
sum error= 250
Actual label: 2
Output voltages: [0.39673, 0.22337, 0.74013, 0.32175, 0.1526, 0.033277, 0.2458, 0.28208, 0.38741, 0.16848]
Predicted label: 2
Correct prediction
Energy consumption = 188.387706 pJ
sum error= 250
Actual label: 8
Output voltages: [0.1716, 0.28448, 0.31179, 0.32322, 0.13275, 0.15837, 0.19226, 0.13257, 0.75082, 0.31466]
Predicted label: 8
Correct prediction
Energy consumption = 190.052144 pJ
sum error= 250
Actual label: 1
Output voltages: [0.17958, 0.7558, 0.2244, 0.20773, 0.28843, 0.15969, 0.47302, 0.13929, 0.28918, 0.19678]
Predicted label: 1
Correct prediction
Energy consumption = 202.477367 pJ
sum error= 250
Actual label: 5
Output voltages: [0.327, 0.059811, 0.060908, 0.41831, 0.20878, 0.68386, 0.41712, 0.11432, 0.42096, 0.26099]
Predicted label: 5
Correct prediction
Energy consumption = 197.256049 pJ
sum error= 250
Actual label: 1
Output voltages: [0.18591, 0.75081, 0.24139, 0.18826, 0.33609, 0.15999, 0.43945, 0.19389, 0.2512, 0.22355]
Predicted label: 1
Correct prediction
Energy consumption = 210.831355 pJ
sum error= 250
Actual label: 2
Output voltages: [0.29476, 0.18664, 0.75442, 0.27705, 0.23624, 0.034286, 0.21109, 0.32421, 0.37489, 0.20491]
Predicted label: 2
Correct prediction
Energy consumption = 177.657476 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 628 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 628 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 628 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72003, 0.23866, 0.23325, 0.17607, 0.19127, 0.12704, 0.47565, 0.16625, 0.28614, 0.25627]
Predicted label: 0
Correct prediction
Energy consumption = 196.200362 pJ
sum error= 250
Actual label: 2
Output voltages: [0.30711, 0.16831, 0.74649, 0.38711, 0.30085, 0.057034, 0.20213, 0.21182, 0.36557, 0.23176]
Predicted label: 2
Correct prediction
Energy consumption = 187.534438 pJ
sum error= 250
Actual label: 5
Output voltages: [0.2294, 0.051293, 0.12917, 0.3965, 0.17723, 0.67947, 0.27714, 0.15845, 0.5015, 0.27559]
Predicted label: 5
Correct prediction
Energy consumption = 192.639597 pJ
sum error= 250
Actual label: 6
Output voltages: [0.28866, 0.20859, 0.28982, 0.11797, 0.36111, 0.34259, 0.74185, 0.11701, 0.35192, 0.087211]
Predicted label: 6
Correct prediction
Energy consumption = 194.388217 pJ
sum error= 250
Actual label: 4
Output voltages: [0.11413, 0.18096, 0.28191, 0.1732, 0.74615, 0.065163, 0.23914, 0.29269, 0.20941, 0.23154]
Predicted label: 4
Correct prediction
Energy consumption = 195.013408 pJ
sum error= 250
Actual label: 3
Output voltages: [0.40494, 0.12638, 0.34041, 0.74472, 0.16538, 0.23877, 0.1573, 0.16528, 0.50449, 0.15381]
Predicted label: 3
Correct prediction
Energy consumption = 187.410168 pJ
sum error= 250
Actual label: 0
Output voltages: [0.71332, 0.28588, 0.31992, 0.1743, 0.12831, 0.07123, 0.3974, 0.1865, 0.32001, 0.29217]
Predicted label: 0
Correct prediction
Energy consumption = 183.834852 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73401, 0.29706, 0.27088, 0.1697, 0.15093, 0.098531, 0.33601, 0.22732, 0.3226, 0.31142]
Predicted label: 0
Correct prediction
Energy consumption = 183.477987 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73801, 0.28887, 0.30458, 0.18573, 0.14463, 0.13131, 0.37765, 0.18737, 0.30459, 0.2691]
Predicted label: 0
Correct prediction
Energy consumption = 185.641441 pJ
sum error= 250
Actual label: 3
Output voltages: [0.32797, 0.096725, 0.27657, 0.73505, 0.19696, 0.25528, 0.090661, 0.27642, 0.50677, 0.20726]
Predicted label: 3
Correct prediction
Energy consumption = 184.989969 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 629 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 629 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 629 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.46393, 0.077355, 0.38865, 0.70328, 0.13938, 0.16022, 0.14665, 0.1953, 0.53226, 0.22567]
Predicted label: 3
Correct prediction
Energy consumption = 192.819815 pJ
sum error= 250
Actual label: 5
Output voltages: [0.31657, 0.060213, 0.068731, 0.34789, 0.25309, 0.71488, 0.42042, 0.11881, 0.4498, 0.2582]
Predicted label: 5
Correct prediction
Energy consumption = 188.343465 pJ
sum error= 250
Actual label: 7
Output voltages: [0.29664, 0.23564, 0.23011, 0.28394, 0.15379, 0.14194, 0.047554, 0.7626, 0.27392, 0.33803]
Predicted label: 7
Correct prediction
Energy consumption = 194.793721 pJ
sum error= 250
Actual label: 0
Output voltages: [0.74126, 0.24943, 0.25947, 0.21284, 0.15697, 0.12503, 0.40108, 0.17408, 0.32418, 0.25546]
Predicted label: 0
Correct prediction
Energy consumption = 189.570826 pJ
sum error= 250
Actual label: 6
Output voltages: [0.22488, 0.18467, 0.33518, 0.070488, 0.44162, 0.29544, 0.71747, 0.060354, 0.39206, 0.17184]
Predicted label: 6
Correct prediction
Energy consumption = 189.506844 pJ
sum error= 250
Actual label: 4
Output voltages: [0.12655, 0.18845, 0.29756, 0.1634, 0.75215, 0.069344, 0.30163, 0.2768, 0.21894, 0.21463]
Predicted label: 4
Correct prediction
Energy consumption = 190.442485 pJ
sum error= 250
Actual label: 8
Output voltages: [0.19869, 0.20425, 0.28058, 0.34839, 0.11807, 0.29288, 0.20198, 0.1777, 0.75596, 0.24004]
Predicted label: 8
Correct prediction
Energy consumption = 195.221241 pJ
sum error= 250
Actual label: 8
Output voltages: [0.20227, 0.09046, 0.20944, 0.30121, 0.20345, 0.35035, 0.19744, 0.11223, 0.73221, 0.26305]
Predicted label: 8
Correct prediction
Energy consumption = 192.126772 pJ
sum error= 250
Actual label: 6
Output voltages: [0.34586, 0.32998, 0.18662, 0.26574, 0.26318, 0.44218, 0.7468, 0.065967, 0.34821, 0.10401]
Predicted label: 6
Correct prediction
Energy consumption = 198.223132 pJ
sum error= 250
Actual label: 3
Output voltages: [0.39526, 0.14761, 0.32565, 0.75234, 0.18223, 0.20834, 0.12361, 0.19277, 0.37382, 0.22313]
Predicted label: 3
Correct prediction
Energy consumption = 188.465290 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 630 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 630 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 630 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16693, 0.12639, 0.30518, 0.15732, 0.74403, 0.12085, 0.24367, 0.20882, 0.29257, 0.22896]
Predicted label: 4
Correct prediction
Energy consumption = 195.080895 pJ
sum error= 250
Actual label: 6
Output voltages: [0.33278, 0.27861, 0.33435, 0.11879, 0.30035, 0.25739, 0.74687, 0.059783, 0.34387, 0.1948]
Predicted label: 6
Correct prediction
Energy consumption = 191.285114 pJ
sum error= 250
Actual label: 9
Output voltages: [0.32959, 0.10339, 0.2317, 0.2226, 0.25248, 0.16086, 0.083021, 0.21882, 0.505, 0.60816]
Predicted label: 9
Correct prediction
Energy consumption = 195.344471 pJ
sum error= 250
Actual label: 9
Output voltages: [0.32354, 0.056573, 0.18696, 0.18015, 0.29768, 0.26267, 0.097453, 0.36178, 0.46436, 0.59293]
Predicted label: 9
Correct prediction
Energy consumption = 181.077929 pJ
sum error= 250
Actual label: 8
Output voltages: [0.19306, 0.23869, 0.23813, 0.35595, 0.12577, 0.26537, 0.18623, 0.19597, 0.74336, 0.18236]
Predicted label: 8
Correct prediction
Energy consumption = 203.049327 pJ
sum error= 250
Actual label: 2
Output voltages: [0.36315, 0.06568, 0.67355, 0.40714, 0.12481, 0.12503, 0.16259, 0.19025, 0.53622, 0.16689]
Predicted label: 2
Correct prediction
Energy consumption = 185.258527 pJ
sum error= 250
Actual label: 7
Output voltages: [0.27887, 0.26648, 0.4202, 0.25652, 0.11591, 0.043949, 0.039819, 0.7101, 0.39184, 0.3058]
Predicted label: 7
Correct prediction
Energy consumption = 188.180435 pJ
sum error= 250
Actual label: 7
Output voltages: [0.33038, 0.25964, 0.31519, 0.27296, 0.13611, 0.058489, 0.04577, 0.75733, 0.35156, 0.30768]
Predicted label: 7
Correct prediction
Energy consumption = 183.947805 pJ
sum error= 250
Actual label: 1
Output voltages: [0.18878, 0.76177, 0.17627, 0.24093, 0.30021, 0.11631, 0.37191, 0.1077, 0.30415, 0.25646]
Predicted label: 1
Correct prediction
Energy consumption = 207.627404 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73356, 0.22294, 0.25407, 0.17234, 0.17341, 0.18159, 0.4618, 0.18625, 0.31159, 0.24057]
Predicted label: 0
Correct prediction
Energy consumption = 193.673826 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 631 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 631 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 631 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.27747, 0.74252, 0.3664, 0.20275, 0.2673, 0.052695, 0.34714, 0.10797, 0.31648, 0.21813]
Predicted label: 1
Correct prediction
Energy consumption = 209.904474 pJ
sum error= 250
Actual label: 2
Output voltages: [0.39415, 0.2015, 0.75084, 0.31567, 0.22158, 0.045053, 0.28513, 0.2443, 0.3392, 0.18684]
Predicted label: 2
Correct prediction
Energy consumption = 185.046694 pJ
sum error= 250
Actual label: 3
Output voltages: [0.16588, 0.17164, 0.33077, 0.71667, 0.15963, 0.15685, 0.063944, 0.29033, 0.49244, 0.31906]
Predicted label: 3
Correct prediction
Energy consumption = 182.988862 pJ
sum error= 250
Actual label: 4
Output voltages: [0.17468, 0.16479, 0.23411, 0.07419, 0.74893, 0.10945, 0.30053, 0.23221, 0.31333, 0.24208]
Predicted label: 4
Correct prediction
Energy consumption = 194.437904 pJ
sum error= 250
Actual label: 5
Output voltages: [0.28214, 0.072533, 0.13779, 0.41691, 0.16103, 0.68535, 0.34906, 0.13135, 0.47782, 0.24589]
Predicted label: 5
Correct prediction
Energy consumption = 188.610136 pJ
sum error= 250
Actual label: 6
Output voltages: [0.31827, 0.27722, 0.30618, 0.1043, 0.33691, 0.32152, 0.74269, 0.087775, 0.33813, 0.12605]
Predicted label: 6
Correct prediction
Energy consumption = 192.474221 pJ
sum error= 250
Actual label: 7
Output voltages: [0.326, 0.23764, 0.24404, 0.33422, 0.085076, 0.070974, 0.048384, 0.74349, 0.32739, 0.35275]
Predicted label: 7
Correct prediction
Energy consumption = 206.875030 pJ
sum error= 250
Actual label: 8
Output voltages: [0.24315, 0.16501, 0.3774, 0.30134, 0.14644, 0.2034, 0.19094, 0.13805, 0.7482, 0.27514]
Predicted label: 8
Correct prediction
Energy consumption = 188.426458 pJ
sum error= 250
Actual label: 9
Output voltages: [0.30514, 0.14027, 0.19238, 0.32694, 0.2821, 0.15193, 0.091605, 0.24387, 0.37995, 0.67231]
Predicted label: 9
Correct prediction
Energy consumption = 187.370687 pJ
sum error= 250
Actual label: 0
Output voltages: [0.7292, 0.19673, 0.27971, 0.15541, 0.19061, 0.19048, 0.46012, 0.1512, 0.29377, 0.21036]
Predicted label: 0
Correct prediction
Energy consumption = 189.660298 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 632 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 632 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 632 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23977, 0.7546, 0.34944, 0.19335, 0.34155, 0.050757, 0.35708, 0.14116, 0.26366, 0.24808]
Predicted label: 1
Correct prediction
Energy consumption = 208.257643 pJ
sum error= 250
Actual label: 2
Output voltages: [0.43162, 0.13287, 0.72383, 0.37522, 0.18631, 0.040874, 0.25608, 0.27531, 0.43275, 0.16889]
Predicted label: 2
Correct prediction
Energy consumption = 184.392751 pJ
sum error= 250
Actual label: 3
Output voltages: [0.37018, 0.18229, 0.33559, 0.75332, 0.15482, 0.20166, 0.18015, 0.20654, 0.4036, 0.16933]
Predicted label: 3
Correct prediction
Energy consumption = 182.882081 pJ
sum error= 250
Actual label: 4
Output voltages: [0.17639, 0.10706, 0.31101, 0.16148, 0.75456, 0.086034, 0.23752, 0.25031, 0.26906, 0.27582]
Predicted label: 4
Correct prediction
Energy consumption = 189.895631 pJ
sum error= 250
Actual label: 5
Output voltages: [0.25519, 0.095985, 0.11411, 0.29734, 0.24075, 0.75155, 0.36795, 0.19702, 0.43579, 0.21253]
Predicted label: 5
Correct prediction
Energy consumption = 192.445544 pJ
sum error= 250
Actual label: 6
Output voltages: [0.28584, 0.25084, 0.32779, 0.071072, 0.35927, 0.29407, 0.74929, 0.063996, 0.36581, 0.13512]
Predicted label: 6
Correct prediction
Energy consumption = 188.551485 pJ
sum error= 250
Actual label: 7
Output voltages: [0.413, 0.21293, 0.1728, 0.26625, 0.15672, 0.14618, 0.061309, 0.75366, 0.33305, 0.36095]
Predicted label: 7
Correct prediction
Energy consumption = 207.552527 pJ
sum error= 250
Actual label: 8
Output voltages: [0.26045, 0.16741, 0.33091, 0.31232, 0.14255, 0.20355, 0.25225, 0.11276, 0.7391, 0.28756]
Predicted label: 8
Correct prediction
Energy consumption = 192.325142 pJ
sum error= 250
Actual label: 0
Output voltages: [0.6986, 0.23984, 0.23629, 0.1372, 0.26143, 0.18363, 0.50709, 0.1691, 0.27873, 0.18841]
Predicted label: 0
Correct prediction
Energy consumption = 197.200334 pJ
sum error= 250
Actual label: 1
Output voltages: [0.14907, 0.76297, 0.27752, 0.24146, 0.2907, 0.070451, 0.36815, 0.14591, 0.30922, 0.24249]
Predicted label: 1
Correct prediction
Energy consumption = 205.368472 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 633 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 633 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 633 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40163, 0.15429, 0.75274, 0.32545, 0.18331, 0.050013, 0.27126, 0.27835, 0.38169, 0.20028]
Predicted label: 2
Correct prediction
Energy consumption = 183.867710 pJ
sum error= 250
Actual label: 3
Output voltages: [0.47824, 0.14921, 0.3071, 0.73975, 0.14754, 0.27722, 0.22392, 0.22108, 0.32928, 0.077972]
Predicted label: 3
Correct prediction
Energy consumption = 192.532917 pJ
sum error= 250
Actual label: 4
Output voltages: [0.19817, 0.10983, 0.29723, 0.14172, 0.74462, 0.052682, 0.22631, 0.21691, 0.27225, 0.26721]
Predicted label: 4
Correct prediction
Energy consumption = 190.727418 pJ
sum error= 250
Actual label: 5
Output voltages: [0.26076, 0.083508, 0.13028, 0.35506, 0.2218, 0.74361, 0.33703, 0.15436, 0.43801, 0.24935]
Predicted label: 5
Correct prediction
Energy consumption = 190.274415 pJ
sum error= 250
Actual label: 6
Output voltages: [0.27003, 0.23424, 0.33847, 0.07729, 0.28822, 0.29218, 0.74578, 0.064672, 0.40009, 0.15162]
Predicted label: 6
Correct prediction
Energy consumption = 187.336916 pJ
sum error= 250
Actual label: 7
Output voltages: [0.34797, 0.24752, 0.20158, 0.28697, 0.19235, 0.1203, 0.051349, 0.76457, 0.30318, 0.35351]
Predicted label: 7
Correct prediction
Energy consumption = 199.795746 pJ
sum error= 250
Actual label: 8
Output voltages: [0.29123, 0.22193, 0.38321, 0.25284, 0.20884, 0.10452, 0.25029, 0.081387, 0.72262, 0.34674]
Predicted label: 8
Correct prediction
Energy consumption = 192.043156 pJ
sum error= 250
Actual label: 2
Output voltages: [0.36445, 0.18885, 0.75008, 0.30788, 0.20926, 0.042769, 0.26301, 0.31263, 0.38084, 0.17889]
Predicted label: 2
Correct prediction
Energy consumption = 185.925729 pJ
sum error= 250
Actual label: 1
Output voltages: [0.22452, 0.72634, 0.22302, 0.3113, 0.2445, 0.11701, 0.18971, 0.12903, 0.50044, 0.27618]
Predicted label: 1
Correct prediction
Energy consumption = 217.544944 pJ
sum error= 250
Actual label: 7
Output voltages: [0.28047, 0.1859, 0.18816, 0.32928, 0.13994, 0.13364, 0.045484, 0.75483, 0.34328, 0.37895]
Predicted label: 7
Correct prediction
Energy consumption = 201.365064 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 634 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 634 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 634 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.38421, 0.15932, 0.74795, 0.31367, 0.20968, 0.055088, 0.25077, 0.27002, 0.38134, 0.17967]
Predicted label: 2
Correct prediction
Energy consumption = 193.842556 pJ
sum error= 250
Actual label: 5
Output voltages: [0.22595, 0.040992, 0.11562, 0.33811, 0.25673, 0.66286, 0.38033, 0.20905, 0.51592, 0.21369]
Predicted label: 5
Correct prediction
Energy consumption = 185.243627 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73661, 0.21508, 0.2739, 0.17614, 0.20581, 0.14221, 0.42973, 0.18168, 0.28554, 0.25695]
Predicted label: 0
Correct prediction
Energy consumption = 195.566557 pJ
sum error= 250
Actual label: 8
Output voltages: [0.24846, 0.2188, 0.3505, 0.23457, 0.21482, 0.13818, 0.27255, 0.095552, 0.73117, 0.3101]
Predicted label: 8
Correct prediction
Energy consumption = 197.886268 pJ
sum error= 250
Actual label: 0
Output voltages: [0.70262, 0.23687, 0.27489, 0.15692, 0.15403, 0.10647, 0.45959, 0.19853, 0.32761, 0.23122]
Predicted label: 0
Correct prediction
Energy consumption = 190.835046 pJ
sum error= 250
Actual label: 2
Output voltages: [0.43485, 0.23347, 0.75401, 0.28026, 0.17679, 0.039788, 0.30225, 0.28662, 0.34055, 0.19087]
Predicted label: 2
Correct prediction
Energy consumption = 178.342513 pJ
sum error= 250
Actual label: 7
Output voltages: [0.33577, 0.17844, 0.16252, 0.38182, 0.14459, 0.18312, 0.041712, 0.74475, 0.32566, 0.40843]
Predicted label: 7
Correct prediction
Energy consumption = 199.512393 pJ
sum error= 250
Actual label: 8
Output voltages: [0.29925, 0.23173, 0.2546, 0.5018, 0.14343, 0.10867, 0.41871, 0.049927, 0.56378, 0.22056]
Predicted label: 8
Correct prediction
Energy consumption = 205.766362 pJ
sum error= 250
Actual label: 8
Output voltages: [0.26512, 0.14226, 0.42881, 0.20056, 0.18581, 0.15325, 0.24481, 0.13309, 0.73752, 0.31345]
Predicted label: 8
Correct prediction
Energy consumption = 193.024432 pJ
sum error= 250
Actual label: 3
Output voltages: [0.38103, 0.18662, 0.38944, 0.75048, 0.14978, 0.12446, 0.16464, 0.11711, 0.44008, 0.19136]
Predicted label: 3
Correct prediction
Energy consumption = 180.267060 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 635 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 635 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 635 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30464, 0.26469, 0.31107, 0.13053, 0.30276, 0.3445, 0.75144, 0.093725, 0.39085, 0.14496]
Predicted label: 6
Correct prediction
Energy consumption = 190.371502 pJ
sum error= 250
Actual label: 0
Output voltages: [0.68818, 0.24717, 0.34705, 0.16223, 0.13865, 0.086267, 0.44702, 0.15455, 0.30881, 0.24061]
Predicted label: 0
Correct prediction
Energy consumption = 191.372241 pJ
sum error= 250
Actual label: 2
Output voltages: [0.45193, 0.18045, 0.73057, 0.35633, 0.12554, 0.083489, 0.32205, 0.23684, 0.37927, 0.18426]
Predicted label: 2
Correct prediction
Energy consumption = 190.741708 pJ
sum error= 250
Actual label: 7
Output voltages: [0.31619, 0.20336, 0.11293, 0.22835, 0.25268, 0.2045, 0.049452, 0.74729, 0.26727, 0.36035]
Predicted label: 7
Correct prediction
Energy consumption = 203.502280 pJ
sum error= 250
Actual label: 6
Output voltages: [0.32317, 0.24946, 0.31699, 0.11512, 0.30555, 0.33205, 0.75029, 0.082025, 0.40815, 0.18732]
Predicted label: 6
Correct prediction
Energy consumption = 191.936023 pJ
sum error= 250
Actual label: 6
Output voltages: [0.27722, 0.20202, 0.31674, 0.11744, 0.34328, 0.36807, 0.74399, 0.058136, 0.43053, 0.14362]
Predicted label: 6
Correct prediction
Energy consumption = 177.805192 pJ
sum error= 250
Actual label: 1
Output voltages: [0.22761, 0.71135, 0.29647, 0.23878, 0.29885, 0.052224, 0.26648, 0.12493, 0.37625, 0.2987]
Predicted label: 1
Correct prediction
Energy consumption = 206.934969 pJ
sum error= 250
Actual label: 2
Output voltages: [0.39077, 0.14449, 0.74716, 0.32004, 0.20944, 0.057105, 0.29562, 0.27478, 0.40118, 0.19276]
Predicted label: 2
Correct prediction
Energy consumption = 190.134231 pJ
sum error= 250
Actual label: 8
Output voltages: [0.26332, 0.1679, 0.27343, 0.4059, 0.095635, 0.26726, 0.22819, 0.081542, 0.73691, 0.2473]
Predicted label: 8
Correct prediction
Energy consumption = 192.713703 pJ
sum error= 250
Actual label: 8
Output voltages: [0.26129, 0.20408, 0.45598, 0.33964, 0.11686, 0.084603, 0.23558, 0.12004, 0.70048, 0.3197]
Predicted label: 8
Correct prediction
Energy consumption = 187.224457 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 636 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 636 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 636 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37313, 0.22938, 0.12763, 0.36103, 0.17845, 0.21488, 0.041261, 0.75642, 0.2471, 0.37584]
Predicted label: 7
Correct prediction
Energy consumption = 194.089360 pJ
sum error= 250
Actual label: 7
Output voltages: [0.26626, 0.29412, 0.24024, 0.29108, 0.089489, 0.084762, 0.044348, 0.74888, 0.35404, 0.3344]
Predicted label: 7
Correct prediction
Energy consumption = 198.350609 pJ
sum error= 250
Actual label: 4
Output voltages: [0.20371, 0.16471, 0.23113, 0.17113, 0.74932, 0.076637, 0.32991, 0.26926, 0.22439, 0.19736]
Predicted label: 4
Correct prediction
Energy consumption = 198.639526 pJ
sum error= 250
Actual label: 7
Output voltages: [0.36449, 0.20661, 0.15314, 0.2441, 0.24202, 0.20188, 0.065036, 0.76659, 0.24608, 0.33239]
Predicted label: 7
Correct prediction
Energy consumption = 196.129126 pJ
sum error= 250
Actual label: 7
Output voltages: [0.35086, 0.22669, 0.14252, 0.33499, 0.13436, 0.13642, 0.042424, 0.74763, 0.30711, 0.36846]
Predicted label: 7
Correct prediction
Energy consumption = 189.745785 pJ
sum error= 250
Actual label: 3
Output voltages: [0.35885, 0.18329, 0.33717, 0.75862, 0.17963, 0.17613, 0.16488, 0.18924, 0.42899, 0.22919]
Predicted label: 3
Correct prediction
Energy consumption = 177.800061 pJ
sum error= 250
Actual label: 7
Output voltages: [0.33318, 0.15504, 0.14768, 0.26609, 0.18655, 0.14695, 0.041915, 0.75553, 0.37121, 0.3415]
Predicted label: 7
Correct prediction
Energy consumption = 193.510306 pJ
sum error= 250
Actual label: 4
Output voltages: [0.13782, 0.11065, 0.31238, 0.15556, 0.75341, 0.065674, 0.28459, 0.28882, 0.21705, 0.23909]
Predicted label: 4
Correct prediction
Energy consumption = 191.534447 pJ
sum error= 250
Actual label: 5
Output voltages: [0.31526, 0.088013, 0.079442, 0.40697, 0.15728, 0.72183, 0.29671, 0.098213, 0.46765, 0.23216]
Predicted label: 5
Correct prediction
Energy consumption = 191.587381 pJ
sum error= 250
Actual label: 4
Output voltages: [0.14206, 0.20963, 0.25802, 0.22688, 0.74706, 0.054303, 0.29913, 0.29699, 0.18041, 0.22289]
Predicted label: 4
Correct prediction
Energy consumption = 196.416974 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 637 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 637 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 637 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36813, 0.18666, 0.40769, 0.74354, 0.13235, 0.084947, 0.20869, 0.11255, 0.41854, 0.20152]
Predicted label: 3
Correct prediction
Energy consumption = 185.959054 pJ
sum error= 250
Actual label: 3
Output voltages: [0.24593, 0.17068, 0.33617, 0.73861, 0.16507, 0.11459, 0.12185, 0.17796, 0.51884, 0.28408]
Predicted label: 3
Correct prediction
Energy consumption = 175.268008 pJ
sum error= 250
Actual label: 8
Output voltages: [0.25414, 0.20142, 0.32618, 0.3338, 0.11847, 0.14898, 0.30591, 0.086068, 0.73195, 0.29022]
Predicted label: 8
Correct prediction
Energy consumption = 188.960080 pJ
sum error= 250
Actual label: 4
Output voltages: [0.08084, 0.18872, 0.27313, 0.12447, 0.76062, 0.14503, 0.3884, 0.31692, 0.22471, 0.21187]
Predicted label: 4
Correct prediction
Energy consumption = 193.506747 pJ
sum error= 250
Actual label: 1
Output voltages: [0.22811, 0.76214, 0.23689, 0.28308, 0.2719, 0.081162, 0.33273, 0.12691, 0.30822, 0.26877]
Predicted label: 1
Correct prediction
Energy consumption = 211.260437 pJ
sum error= 250
Actual label: 1
Output voltages: [0.26915, 0.77211, 0.28919, 0.28213, 0.18254, 0.069937, 0.41462, 0.11051, 0.25838, 0.23401]
Predicted label: 1
Correct prediction
Energy consumption = 204.005154 pJ
sum error= 250
Actual label: 9
Output voltages: [0.34376, 0.17581, 0.11965, 0.25233, 0.36604, 0.18733, 0.15997, 0.1347, 0.32392, 0.65948]
Predicted label: 9
Correct prediction
Energy consumption = 201.341200 pJ
sum error= 250
Actual label: 7
Output voltages: [0.33862, 0.25796, 0.18842, 0.25372, 0.22055, 0.094268, 0.056738, 0.75922, 0.23637, 0.31944]
Predicted label: 7
Correct prediction
Energy consumption = 199.474887 pJ
sum error= 250
Actual label: 4
Output voltages: [0.12743, 0.17876, 0.24096, 0.07284, 0.75427, 0.1091, 0.24744, 0.34377, 0.30509, 0.282]
Predicted label: 4
Correct prediction
Energy consumption = 195.234146 pJ
sum error= 250
Actual label: 3
Output voltages: [0.28518, 0.23824, 0.31978, 0.75306, 0.15599, 0.074663, 0.12429, 0.17949, 0.406, 0.28775]
Predicted label: 3
Correct prediction
Energy consumption = 184.979949 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 638 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 638 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 638 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30936, 0.21318, 0.1709, 0.3289, 0.15475, 0.20817, 0.04181, 0.75864, 0.30617, 0.40492]
Predicted label: 7
Correct prediction
Energy consumption = 201.181683 pJ
sum error= 250
Actual label: 3
Output voltages: [0.37297, 0.20447, 0.3586, 0.75186, 0.14717, 0.080721, 0.1899, 0.17478, 0.41653, 0.18841]
Predicted label: 3
Correct prediction
Energy consumption = 183.742211 pJ
sum error= 250
Actual label: 3
Output voltages: [0.33692, 0.22046, 0.31474, 0.7623, 0.15523, 0.10275, 0.15981, 0.21503, 0.41189, 0.21563]
Predicted label: 3
Correct prediction
Energy consumption = 171.637725 pJ
sum error= 250
Actual label: 0
Output voltages: [0.72299, 0.18728, 0.24153, 0.22228, 0.25, 0.15781, 0.4167, 0.17044, 0.36899, 0.24385]
Predicted label: 0
Correct prediction
Energy consumption = 200.371925 pJ
sum error= 250
Actual label: 2
Output voltages: [0.42762, 0.18862, 0.74111, 0.34994, 0.17055, 0.042301, 0.29538, 0.23611, 0.3664, 0.20352]
Predicted label: 2
Correct prediction
Energy consumption = 184.834126 pJ
sum error= 250
Actual label: 5
Output voltages: [0.3126, 0.050412, 0.14205, 0.38799, 0.16225, 0.69931, 0.4156, 0.19532, 0.42835, 0.13411]
Predicted label: 5
Correct prediction
Energy consumption = 188.500775 pJ
sum error= 250
Actual label: 5
Output voltages: [0.23486, 0.052309, 0.12887, 0.3159, 0.20812, 0.65201, 0.36804, 0.15184, 0.52418, 0.23693]
Predicted label: 5
Correct prediction
Energy consumption = 178.462827 pJ
sum error= 250
Actual label: 6
Output voltages: [0.29256, 0.30658, 0.28454, 0.093996, 0.3204, 0.37932, 0.74434, 0.065393, 0.34439, 0.17588]
Predicted label: 6
Correct prediction
Energy consumption = 186.612895 pJ
sum error= 250
Actual label: 6
Output voltages: [0.37761, 0.16088, 0.23822, 0.11236, 0.35275, 0.39019, 0.71721, 0.080787, 0.34788, 0.17976]
Predicted label: 6
Correct prediction
Energy consumption = 181.140501 pJ
sum error= 250
Actual label: 3
Output voltages: [0.36101, 0.081616, 0.31563, 0.72986, 0.26016, 0.21821, 0.14637, 0.1829, 0.40987, 0.22897]
Predicted label: 3
Correct prediction
Energy consumption = 187.960877 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 639 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 639 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 639 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.32254, 0.046591, 0.18166, 0.27781, 0.14534, 0.67476, 0.37028, 0.1667, 0.55933, 0.22403]
Predicted label: 5
Correct prediction
Energy consumption = 186.837340 pJ
sum error= 250
Actual label: 2
Output voltages: [0.53756, 0.099297, 0.58933, 0.35427, 0.23507, 0.055826, 0.31705, 0.27308, 0.38034, 0.20305]
Predicted label: 2
Correct prediction
Energy consumption = 196.388566 pJ
sum error= 250
Actual label: 5
Output voltages: [0.33897, 0.047749, 0.20565, 0.28081, 0.15545, 0.58762, 0.41669, 0.07754, 0.49723, 0.16634]
Predicted label: 5
Correct prediction
Energy consumption = 192.518704 pJ
sum error= 250
Actual label: 9
Output voltages: [0.36944, 0.22861, 0.16279, 0.23673, 0.50151, 0.18739, 0.18354, 0.19484, 0.24763, 0.68443]
Predicted label: 9
Correct prediction
Energy consumption = 196.348395 pJ
sum error= 250
Actual label: 9
Output voltages: [0.40139, 0.13302, 0.19294, 0.28641, 0.30225, 0.22167, 0.1401, 0.24169, 0.34212, 0.69494]
Predicted label: 9
Correct prediction
Energy consumption = 189.654824 pJ
sum error= 250
Actual label: 8
Output voltages: [0.26345, 0.20621, 0.36009, 0.22657, 0.16286, 0.1645, 0.2467, 0.10794, 0.74046, 0.35895]
Predicted label: 8
Correct prediction
Energy consumption = 194.652233 pJ
sum error= 250
Actual label: 4
Output voltages: [0.13047, 0.16101, 0.2277, 0.17016, 0.73191, 0.073829, 0.26605, 0.2309, 0.32471, 0.21284]
Predicted label: 4
Correct prediction
Energy consumption = 194.407735 pJ
sum error= 250
Actual label: 1
Output voltages: [0.22811, 0.7259, 0.30324, 0.34247, 0.32854, 0.042484, 0.18557, 0.15903, 0.26319, 0.2761]
Predicted label: 1
Correct prediction
Energy consumption = 217.083886 pJ
sum error= 250
Actual label: 0
Output voltages: [0.7258, 0.21353, 0.31729, 0.18551, 0.14709, 0.2018, 0.36619, 0.171, 0.34627, 0.25898]
Predicted label: 0
Correct prediction
Energy consumption = 204.640845 pJ
sum error= 250
Actual label: 6
Output voltages: [0.34006, 0.27555, 0.30194, 0.097984, 0.40766, 0.26089, 0.75012, 0.11965, 0.284, 0.15499]
Predicted label: 6
Correct prediction
Energy consumption = 191.153603 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 640 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 640 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 640 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.59164, 0.23744, 0.2561, 0.16612, 0.29088, 0.10738, 0.5351, 0.13282, 0.31639, 0.18034]
Predicted label: 0
Correct prediction
Energy consumption = 206.431352 pJ
sum error= 250
Actual label: 9
Output voltages: [0.31978, 0.15747, 0.18757, 0.30585, 0.35405, 0.1126, 0.064678, 0.20234, 0.31625, 0.68142]
Predicted label: 9
Correct prediction
Energy consumption = 198.593171 pJ
sum error= 250
Actual label: 6
Output voltages: [0.32042, 0.27636, 0.32424, 0.098685, 0.45032, 0.25012, 0.73082, 0.13455, 0.27949, 0.10374]
Predicted label: 6
Correct prediction
Energy consumption = 201.364466 pJ
sum error= 250
Actual label: 8
Output voltages: [0.33042, 0.26569, 0.42969, 0.27182, 0.1019, 0.18016, 0.38025, 0.098184, 0.69266, 0.21347]
Predicted label: 8
Correct prediction
Energy consumption = 201.747270 pJ
sum error= 250
Actual label: 8
Output voltages: [0.29304, 0.15544, 0.43498, 0.29466, 0.18666, 0.11748, 0.27013, 0.085254, 0.72231, 0.3202]
Predicted label: 8
Correct prediction
Energy consumption = 189.158238 pJ
sum error= 250
Actual label: 5
Output voltages: [0.22218, 0.051749, 0.12788, 0.36969, 0.2337, 0.69689, 0.36734, 0.13155, 0.50556, 0.2145]
Predicted label: 5
Correct prediction
Energy consumption = 187.391765 pJ
sum error= 250
Actual label: 6
Output voltages: [0.35873, 0.24745, 0.32102, 0.097555, 0.28886, 0.27842, 0.73842, 0.068694, 0.39238, 0.17321]
Predicted label: 6
Correct prediction
Energy consumption = 182.289919 pJ
sum error= 250
Actual label: 1
Output voltages: [0.19968, 0.76184, 0.25494, 0.30511, 0.23795, 0.058466, 0.34888, 0.19031, 0.28378, 0.21925]
Predicted label: 1
Correct prediction
Energy consumption = 212.198856 pJ
sum error= 250
Actual label: 1
Output voltages: [0.14896, 0.75865, 0.22733, 0.39445, 0.26541, 0.14476, 0.22506, 0.16365, 0.25013, 0.32492]
Predicted label: 1
Correct prediction
Energy consumption = 210.241111 pJ
sum error= 250
Actual label: 9
Output voltages: [0.36133, 0.098253, 0.27746, 0.27871, 0.36911, 0.20303, 0.2436, 0.20148, 0.25925, 0.69684]
Predicted label: 9
Correct prediction
Energy consumption = 202.321162 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 641 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 641 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 641 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.30282, 0.17139, 0.3444, 0.30766, 0.16759, 0.15699, 0.35477, 0.051573, 0.66686, 0.31539]
Predicted label: 8
Correct prediction
Energy consumption = 199.763353 pJ
sum error= 250
Actual label: 9
Output voltages: [0.29285, 0.18392, 0.25172, 0.28496, 0.40181, 0.090235, 0.12003, 0.17339, 0.31337, 0.67131]
Predicted label: 9
Correct prediction
Energy consumption = 200.545485 pJ
sum error= 250
Actual label: 2
Output voltages: [0.50769, 0.22105, 0.733, 0.32015, 0.081935, 0.059945, 0.32099, 0.21588, 0.37003, 0.17471]
Predicted label: 2
Correct prediction
Energy consumption = 193.379246 pJ
sum error= 250
Actual label: 3
Output voltages: [0.44298, 0.17184, 0.29552, 0.75883, 0.15397, 0.19243, 0.15507, 0.18196, 0.36148, 0.19315]
Predicted label: 3
Correct prediction
Energy consumption = 186.175296 pJ
sum error= 250
Actual label: 5
Output voltages: [0.26701, 0.055433, 0.11629, 0.3651, 0.15951, 0.67706, 0.33126, 0.15158, 0.54595, 0.13626]
Predicted label: 5
Correct prediction
Energy consumption = 184.966875 pJ
sum error= 250
Actual label: 5
Output voltages: [0.22587, 0.055229, 0.11119, 0.38055, 0.19838, 0.65987, 0.28482, 0.062767, 0.5207, 0.2255]
Predicted label: 5
Correct prediction
Energy consumption = 181.556786 pJ
sum error= 250
Actual label: 9
Output voltages: [0.46009, 0.093357, 0.17818, 0.27434, 0.27989, 0.22544, 0.14733, 0.30972, 0.28188, 0.63984]
Predicted label: 9
Correct prediction
Energy consumption = 192.234560 pJ
sum error= 250
Actual label: 4
Output voltages: [0.095308, 0.19048, 0.14962, 0.14436, 0.70083, 0.11911, 0.40304, 0.26049, 0.3216, 0.16217]
Predicted label: 4
Correct prediction
Energy consumption = 199.648746 pJ
sum error= 250
Actual label: 2
Output voltages: [0.27018, 0.21295, 0.64601, 0.51817, 0.21081, 0.054148, 0.19449, 0.3646, 0.2918, 0.21546]
Predicted label: 2
Correct prediction
Energy consumption = 185.846884 pJ
sum error= 250
Actual label: 1
Output voltages: [0.23767, 0.76159, 0.36336, 0.33617, 0.24871, 0.04631, 0.26794, 0.17119, 0.25034, 0.27664]
Predicted label: 1
Correct prediction
Energy consumption = 204.482563 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 642 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 642 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 642 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.25353, 0.18337, 0.19072, 0.34978, 0.51172, 0.22196, 0.17437, 0.13983, 0.3048, 0.51976]
Predicted label: 9
Correct prediction
Energy consumption = 203.679120 pJ
sum error= 250
Actual label: 3
Output voltages: [0.35073, 0.14371, 0.43464, 0.71894, 0.13778, 0.052601, 0.23969, 0.13867, 0.48732, 0.21497]
Predicted label: 3
Correct prediction
Energy consumption = 197.747479 pJ
sum error= 250
Actual label: 9
Output voltages: [0.3801, 0.11871, 0.1945, 0.25295, 0.30763, 0.1692, 0.10925, 0.3566, 0.31302, 0.63675]
Predicted label: 9
Correct prediction
Energy consumption = 199.062413 pJ
sum error= 250
Actual label: 2
Output voltages: [0.39912, 0.19657, 0.75092, 0.30409, 0.20373, 0.04785, 0.29828, 0.27815, 0.3556, 0.1736]
Predicted label: 2
Correct prediction
Energy consumption = 183.861588 pJ
sum error= 250
Actual label: 0
Output voltages: [0.70295, 0.21261, 0.29787, 0.14033, 0.1681, 0.092547, 0.46275, 0.18508, 0.32852, 0.25971]
Predicted label: 0
Correct prediction
Energy consumption = 188.300317 pJ
sum error= 250
Actual label: 6
Output voltages: [0.39563, 0.31182, 0.32271, 0.092879, 0.28342, 0.21, 0.70713, 0.052677, 0.409, 0.20807]
Predicted label: 6
Correct prediction
Energy consumption = 189.615206 pJ
sum error= 250
Actual label: 0
Output voltages: [0.65216, 0.21399, 0.29288, 0.083331, 0.22636, 0.17435, 0.57337, 0.1739, 0.28216, 0.20276]
Predicted label: 0
Correct prediction
Energy consumption = 196.527092 pJ
sum error= 250
Actual label: 4
Output voltages: [0.13607, 0.16324, 0.20241, 0.098229, 0.73909, 0.093017, 0.26686, 0.31749, 0.30077, 0.20473]
Predicted label: 4
Correct prediction
Energy consumption = 193.553545 pJ
sum error= 250
Actual label: 0
Output voltages: [0.71078, 0.19867, 0.32936, 0.16698, 0.16516, 0.091235, 0.43898, 0.24673, 0.2998, 0.23223]
Predicted label: 0
Correct prediction
Energy consumption = 198.619590 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73282, 0.28481, 0.37307, 0.22567, 0.098894, 0.16871, 0.37693, 0.18256, 0.30479, 0.20951]
Predicted label: 0
Correct prediction
Energy consumption = 183.735173 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 643 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 643 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 643 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.24678, 0.74907, 0.2961, 0.28922, 0.20704, 0.067982, 0.45189, 0.057542, 0.2748, 0.24327]
Predicted label: 1
Correct prediction
Energy consumption = 208.474044 pJ
sum error= 250
Actual label: 2
Output voltages: [0.34975, 0.21816, 0.74867, 0.32533, 0.13116, 0.057552, 0.25943, 0.23492, 0.41183, 0.1896]
Predicted label: 2
Correct prediction
Energy consumption = 189.063575 pJ
sum error= 250
Actual label: 3
Output voltages: [0.21236, 0.19559, 0.34802, 0.72948, 0.12398, 0.11049, 0.12074, 0.15014, 0.51445, 0.23597]
Predicted label: 3
Correct prediction
Energy consumption = 181.720552 pJ
sum error= 250
Actual label: 4
Output voltages: [0.15896, 0.12, 0.30114, 0.19272, 0.74568, 0.05072, 0.23726, 0.29477, 0.23797, 0.16649]
Predicted label: 4
Correct prediction
Energy consumption = 188.979514 pJ
sum error= 250
Actual label: 7
Output voltages: [0.29396, 0.27879, 0.21589, 0.19513, 0.35876, 0.06217, 0.036606, 0.66645, 0.31613, 0.32479]
Predicted label: 7
Correct prediction
Energy consumption = 201.578817 pJ
sum error= 250
Actual label: 8
Output voltages: [0.21917, 0.25151, 0.34303, 0.16754, 0.21095, 0.15759, 0.21916, 0.13305, 0.74372, 0.29584]
Predicted label: 8
Correct prediction
Energy consumption = 190.639928 pJ
sum error= 250
Actual label: 9
Output voltages: [0.35068, 0.1437, 0.21766, 0.27537, 0.32783, 0.1553, 0.077295, 0.20721, 0.36648, 0.68478]
Predicted label: 9
Correct prediction
Energy consumption = 188.856250 pJ
sum error= 250
Actual label: 0
Output voltages: [0.74681, 0.32099, 0.31268, 0.22608, 0.14525, 0.1527, 0.30631, 0.19142, 0.29415, 0.26034]
Predicted label: 0
Correct prediction
Energy consumption = 190.834117 pJ
sum error= 250
Actual label: 1
Output voltages: [0.23893, 0.74928, 0.22272, 0.20692, 0.39123, 0.12055, 0.37598, 0.10923, 0.25278, 0.23587]
Predicted label: 1
Correct prediction
Energy consumption = 200.951574 pJ
sum error= 250
Actual label: 2
Output voltages: [0.25872, 0.2869, 0.7393, 0.29524, 0.18711, 0.040014, 0.22166, 0.21279, 0.42956, 0.20732]
Predicted label: 2
Correct prediction
Energy consumption = 187.058627 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 644 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 644 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 644 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32769, 0.16731, 0.31218, 0.75562, 0.1772, 0.19455, 0.12785, 0.19206, 0.42785, 0.2532]
Predicted label: 3
Correct prediction
Energy consumption = 184.924855 pJ
sum error= 250
Actual label: 7
Output voltages: [0.31056, 0.21686, 0.15072, 0.19766, 0.29432, 0.13594, 0.047287, 0.75484, 0.37358, 0.32391]
Predicted label: 7
Correct prediction
Energy consumption = 196.624165 pJ
sum error= 250
Actual label: 8
Output voltages: [0.21346, 0.24832, 0.31826, 0.21121, 0.17513, 0.20335, 0.17125, 0.16467, 0.75194, 0.2706]
Predicted label: 8
Correct prediction
Energy consumption = 189.971149 pJ
sum error= 250
Actual label: 9
Output voltages: [0.34981, 0.13696, 0.22039, 0.3272, 0.36998, 0.13136, 0.10784, 0.22706, 0.28053, 0.65874]
Predicted label: 9
Correct prediction
Energy consumption = 191.429856 pJ
sum error= 250
Actual label: 0
Output voltages: [0.69355, 0.22022, 0.30851, 0.18374, 0.18398, 0.075647, 0.43897, 0.16313, 0.34098, 0.24738]
Predicted label: 0
Correct prediction
Energy consumption = 194.986350 pJ
sum error= 250
Actual label: 1
Output voltages: [0.26738, 0.6501, 0.2932, 0.12756, 0.33742, 0.1199, 0.44088, 0.048245, 0.3935, 0.30236]
Predicted label: 1
Correct prediction
Energy consumption = 202.974553 pJ
sum error= 250
Actual label: 2
Output voltages: [0.2608, 0.24623, 0.73343, 0.24235, 0.16053, 0.037943, 0.30053, 0.20818, 0.45323, 0.1998]
Predicted label: 2
Correct prediction
Energy consumption = 190.615029 pJ
sum error= 250
Actual label: 3
Output voltages: [0.33182, 0.12721, 0.2605, 0.755, 0.21342, 0.30314, 0.13821, 0.16523, 0.3977, 0.22841]
Predicted label: 3
Correct prediction
Energy consumption = 186.937301 pJ
sum error= 250
Actual label: 4
Output voltages: [0.1608, 0.15181, 0.30358, 0.17783, 0.74767, 0.054179, 0.22083, 0.2628, 0.2339, 0.21276]
Predicted label: 4
Correct prediction
Energy consumption = 194.815388 pJ
sum error= 250
Actual label: 7
Output voltages: [0.30844, 0.23142, 0.21038, 0.25999, 0.22216, 0.14402, 0.03884, 0.73682, 0.31878, 0.38818]
Predicted label: 7
Correct prediction
Energy consumption = 192.078941 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 645 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 645 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 645 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.27526, 0.1626, 0.30575, 0.31938, 0.15721, 0.27051, 0.1899, 0.11259, 0.74558, 0.20589]
Predicted label: 8
Correct prediction
Energy consumption = 195.018329 pJ
sum error= 250
Actual label: 9
Output voltages: [0.32807, 0.14124, 0.20388, 0.27718, 0.295, 0.26495, 0.14312, 0.31998, 0.3592, 0.65429]
Predicted label: 9
Correct prediction
Energy consumption = 190.009425 pJ
sum error= 250
Actual label: 7
Output voltages: [0.35008, 0.10685, 0.13162, 0.3152, 0.2855, 0.19278, 0.037286, 0.73563, 0.38659, 0.25639]
Predicted label: 7
Correct prediction
Energy consumption = 194.994415 pJ
sum error= 250
Actual label: 3
Output voltages: [0.30755, 0.13493, 0.25958, 0.74733, 0.20843, 0.26955, 0.21904, 0.15873, 0.43746, 0.25019]
Predicted label: 3
Correct prediction
Energy consumption = 188.063562 pJ
sum error= 250
Actual label: 0
Output voltages: [0.70592, 0.24456, 0.32694, 0.18767, 0.18759, 0.066179, 0.38665, 0.15646, 0.36781, 0.22187]
Predicted label: 0
Correct prediction
Energy consumption = 194.167863 pJ
sum error= 250
Actual label: 3
Output voltages: [0.34254, 0.10457, 0.31601, 0.74376, 0.17243, 0.29329, 0.11903, 0.21769, 0.45186, 0.19887]
Predicted label: 3
Correct prediction
Energy consumption = 195.202122 pJ
sum error= 250
Actual label: 1
Output voltages: [0.19908, 0.75845, 0.18375, 0.25732, 0.28035, 0.084969, 0.35435, 0.15279, 0.25992, 0.24083]
Predicted label: 1
Correct prediction
Energy consumption = 202.560660 pJ
sum error= 250
Actual label: 8
Output voltages: [0.19776, 0.21355, 0.36558, 0.17976, 0.18685, 0.15827, 0.23665, 0.1381, 0.74781, 0.27691]
Predicted label: 8
Correct prediction
Energy consumption = 190.442381 pJ
sum error= 250
Actual label: 7
Output voltages: [0.27315, 0.29867, 0.19089, 0.25854, 0.3036, 0.12855, 0.039418, 0.65681, 0.37464, 0.2725]
Predicted label: 7
Correct prediction
Energy consumption = 204.687325 pJ
sum error= 250
Actual label: 6
Output voltages: [0.30691, 0.16631, 0.27718, 0.11936, 0.34925, 0.31477, 0.73303, 0.054307, 0.46439, 0.16686]
Predicted label: 6
Correct prediction
Energy consumption = 180.982931 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 646 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 646 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 646 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.17797, 0.24406, 0.29716, 0.20294, 0.72387, 0.1221, 0.34238, 0.20494, 0.37083, 0.10781]
Predicted label: 4
Correct prediction
Energy consumption = 194.441270 pJ
sum error= 250
Actual label: 0
Output voltages: [0.69498, 0.20472, 0.23913, 0.14312, 0.23523, 0.13664, 0.51469, 0.15694, 0.29958, 0.19896]
Predicted label: 0
Correct prediction
Energy consumption = 194.788815 pJ
sum error= 250
Actual label: 2
Output voltages: [0.31125, 0.25038, 0.75281, 0.25157, 0.15112, 0.040297, 0.24624, 0.24151, 0.42779, 0.15471]
Predicted label: 2
Correct prediction
Energy consumption = 186.205196 pJ
sum error= 250
Actual label: 6
Output voltages: [0.29903, 0.20091, 0.30321, 0.070818, 0.32125, 0.31857, 0.74218, 0.053594, 0.39223, 0.12977]
Predicted label: 6
Correct prediction
Energy consumption = 182.725204 pJ
sum error= 250
Actual label: 8
Output voltages: [0.1925, 0.22465, 0.39564, 0.17808, 0.18713, 0.11487, 0.18818, 0.13667, 0.74711, 0.27665]
Predicted label: 8
Correct prediction
Energy consumption = 187.570288 pJ
sum error= 250
Actual label: 3
Output voltages: [0.46254, 0.13402, 0.24386, 0.75115, 0.15229, 0.27911, 0.16082, 0.21829, 0.32629, 0.14874]
Predicted label: 3
Correct prediction
Energy consumption = 187.642761 pJ
sum error= 250
Actual label: 2
Output voltages: [0.31394, 0.28283, 0.73292, 0.29438, 0.11752, 0.03474, 0.27336, 0.28186, 0.42426, 0.13516]
Predicted label: 2
Correct prediction
Energy consumption = 183.429739 pJ
sum error= 250
Actual label: 8
Output voltages: [0.24315, 0.19688, 0.29796, 0.29107, 0.15201, 0.23723, 0.23198, 0.11395, 0.74579, 0.24296]
Predicted label: 8
Correct prediction
Energy consumption = 193.086860 pJ
sum error= 250
Actual label: 1
Output voltages: [0.12284, 0.67209, 0.28767, 0.18192, 0.40278, 0.064179, 0.37097, 0.10093, 0.32937, 0.31512]
Predicted label: 1
Correct prediction
Energy consumption = 206.938291 pJ
sum error= 250
Actual label: 2
Output voltages: [0.21856, 0.35184, 0.7392, 0.27771, 0.15376, 0.041773, 0.22686, 0.282, 0.38137, 0.19205]
Predicted label: 2
Correct prediction
Energy consumption = 182.939940 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 647 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 647 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 647 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.68148, 0.27899, 0.29803, 0.18579, 0.14256, 0.082874, 0.39601, 0.16526, 0.34938, 0.20808]
Predicted label: 0
Correct prediction
Energy consumption = 196.104243 pJ
sum error= 250
Actual label: 7
Output voltages: [0.24235, 0.29526, 0.23936, 0.19237, 0.42496, 0.050964, 0.033908, 0.6821, 0.27975, 0.21243]
Predicted label: 7
Correct prediction
Energy consumption = 203.471940 pJ
sum error= 250
Actual label: 1
Output voltages: [0.19813, 0.71614, 0.25783, 0.13888, 0.38823, 0.10219, 0.40579, 0.043403, 0.30601, 0.30993]
Predicted label: 1
Correct prediction
Energy consumption = 203.994881 pJ
sum error= 250
Actual label: 0
Output voltages: [0.70982, 0.20371, 0.31542, 0.17598, 0.24181, 0.071172, 0.34119, 0.21678, 0.34429, 0.1754]
Predicted label: 0
Correct prediction
Energy consumption = 200.824847 pJ
sum error= 250
Actual label: 4
Output voltages: [0.17269, 0.1613, 0.33818, 0.22048, 0.74561, 0.055767, 0.27191, 0.27548, 0.25606, 0.14874]
Predicted label: 4
Correct prediction
Energy consumption = 192.013582 pJ
sum error= 250
Actual label: 4
Output voltages: [0.17263, 0.17974, 0.36562, 0.19143, 0.75458, 0.065681, 0.31735, 0.32608, 0.14312, 0.17137]
Predicted label: 4
Correct prediction
Energy consumption = 182.545695 pJ
sum error= 250
Actual label: 5
Output voltages: [0.2383, 0.057715, 0.058304, 0.39987, 0.24353, 0.70825, 0.33613, 0.086774, 0.50679, 0.18862]
Predicted label: 5
Correct prediction
Energy consumption = 182.562540 pJ
sum error= 250
Actual label: 8
Output voltages: [0.17713, 0.23141, 0.28966, 0.22637, 0.2137, 0.14005, 0.20763, 0.10586, 0.73741, 0.33191]
Predicted label: 8
Correct prediction
Energy consumption = 186.777469 pJ
sum error= 250
Actual label: 0
Output voltages: [0.72318, 0.23629, 0.26659, 0.24941, 0.19003, 0.11284, 0.39084, 0.1873, 0.3188, 0.21978]
Predicted label: 0
Correct prediction
Energy consumption = 198.527948 pJ
sum error= 250
Actual label: 6
Output voltages: [0.30569, 0.20125, 0.19927, 0.21924, 0.29485, 0.35772, 0.72071, 0.07716, 0.48612, 0.13976]
Predicted label: 6
Correct prediction
Energy consumption = 183.043594 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 648 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 648 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 648 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33598, 0.18954, 0.69441, 0.35204, 0.23854, 0.027023, 0.29912, 0.30363, 0.33262, 0.13034]
Predicted label: 2
Correct prediction
Energy consumption = 192.021971 pJ
sum error= 250
Actual label: 3
Output voltages: [0.32614, 0.088038, 0.31021, 0.73059, 0.22947, 0.25666, 0.11969, 0.19884, 0.54212, 0.19883]
Predicted label: 3
Correct prediction
Energy consumption = 189.340656 pJ
sum error= 250
Actual label: 1
Output voltages: [0.16142, 0.75841, 0.21386, 0.25282, 0.25379, 0.10435, 0.39352, 0.13162, 0.29307, 0.23494]
Predicted label: 1
Correct prediction
Energy consumption = 207.970406 pJ
sum error= 250
Actual label: 5
Output voltages: [0.24328, 0.053029, 0.060183, 0.33728, 0.26999, 0.73516, 0.41071, 0.12562, 0.49688, 0.23143]
Predicted label: 5
Correct prediction
Energy consumption = 190.681568 pJ
sum error= 250
Actual label: 1
Output voltages: [0.15217, 0.74459, 0.32799, 0.30051, 0.28788, 0.045061, 0.29425, 0.17681, 0.26231, 0.2289]
Predicted label: 1
Correct prediction
Energy consumption = 208.463814 pJ
sum error= 250
Actual label: 8
Output voltages: [0.19622, 0.25877, 0.36434, 0.21229, 0.25261, 0.17777, 0.2407, 0.089907, 0.73027, 0.27356]
Predicted label: 8
Correct prediction
Energy consumption = 201.041588 pJ
sum error= 250
Actual label: 5
Output voltages: [0.30089, 0.086195, 0.054921, 0.38108, 0.29824, 0.75334, 0.38621, 0.10478, 0.42883, 0.18616]
Predicted label: 5
Correct prediction
Energy consumption = 185.695236 pJ
sum error= 250
Actual label: 9
Output voltages: [0.38257, 0.15551, 0.18912, 0.31652, 0.34978, 0.17931, 0.13406, 0.16829, 0.30771, 0.67962]
Predicted label: 9
Correct prediction
Energy consumption = 188.283295 pJ
sum error= 250
Actual label: 4
Output voltages: [0.19133, 0.16627, 0.29728, 0.23416, 0.74647, 0.056746, 0.25624, 0.27879, 0.17012, 0.17683]
Predicted label: 4
Correct prediction
Energy consumption = 190.524340 pJ
sum error= 250
Actual label: 0
Output voltages: [0.73443, 0.22183, 0.29606, 0.22971, 0.19029, 0.08801, 0.36127, 0.17223, 0.32613, 0.28597]
Predicted label: 0
Correct prediction
Energy consumption = 190.881942 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 649 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 649 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 649 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35907, 0.23473, 0.20072, 0.21558, 0.32811, 0.099403, 0.035992, 0.72753, 0.30958, 0.22672]
Predicted label: 7
Correct prediction
Energy consumption = 198.048850 pJ
sum error= 250
Actual label: 5
Output voltages: [0.26296, 0.067024, 0.051547, 0.36144, 0.32948, 0.75093, 0.31268, 0.11754, 0.41448, 0.24391]
Predicted label: 5
Correct prediction
Energy consumption = 188.296483 pJ
sum error= 250
Actual label: 8
Output voltages: [0.20048, 0.27311, 0.35084, 0.17753, 0.19821, 0.087594, 0.21637, 0.12806, 0.72126, 0.31605]
Predicted label: 8
Correct prediction
Energy consumption = 192.614854 pJ
sum error= 250
Actual label: 8
Output voltages: [0.21389, 0.22291, 0.29442, 0.25976, 0.19797, 0.1646, 0.2686, 0.072017, 0.73441, 0.30956]
Predicted label: 8
Correct prediction
Energy consumption = 188.974357 pJ
sum error= 250
Actual label: 3
Output voltages: [0.34631, 0.093783, 0.28179, 0.74775, 0.20679, 0.26672, 0.18479, 0.17516, 0.43369, 0.21121]
Predicted label: 3
Correct prediction
Energy consumption = 188.865731 pJ
sum error= 250
Actual label: 8
Output voltages: [0.27361, 0.17704, 0.31478, 0.094602, 0.32507, 0.10992, 0.19676, 0.15797, 0.66275, 0.28942]
Predicted label: 8
Correct prediction
Energy consumption = 194.615664 pJ
sum error= 250
Actual label: 9
Output voltages: [0.36775, 0.17195, 0.20572, 0.27461, 0.32721, 0.13054, 0.078704, 0.16001, 0.34228, 0.67575]
Predicted label: 9
Correct prediction
Energy consumption = 188.357518 pJ
sum error= 250
Actual label: 2
Output voltages: [0.3046, 0.28635, 0.74327, 0.25967, 0.16644, 0.036132, 0.24943, 0.27196, 0.41741, 0.16719]
Predicted label: 2
Correct prediction
Energy consumption = 188.927474 pJ
sum error= 250
Actual label: 6
Output voltages: [0.27357, 0.15111, 0.24696, 0.19978, 0.31911, 0.36327, 0.71629, 0.044653, 0.41923, 0.12806]
Predicted label: 6
Correct prediction
Energy consumption = 184.214848 pJ
sum error= 250
Actual label: 2
Output voltages: [0.31274, 0.18525, 0.72332, 0.33387, 0.17387, 0.041847, 0.19493, 0.23611, 0.48662, 0.15114]
Predicted label: 2
Correct prediction
Energy consumption = 178.018790 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 650 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 650 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 650 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22695, 0.04878, 0.095155, 0.32516, 0.27919, 0.70033, 0.34137, 0.076866, 0.54134, 0.16141]
Predicted label: 5
Correct prediction
Energy consumption = 191.350573 pJ
sum error= 250
Actual label: 3
Output voltages: [0.35163, 0.073266, 0.31235, 0.72196, 0.18808, 0.3054, 0.14807, 0.17938, 0.45449, 0.21724]
Predicted label: 3
Correct prediction
Energy consumption = 191.310801 pJ
sum error= 250
Actual label: 1
Output voltages: [0.24429, 0.68935, 0.29216, 0.19274, 0.43708, 0.047611, 0.37398, 0.054135, 0.22797, 0.34716]
Predicted label: 1
Correct prediction
Energy consumption = 206.028353 pJ
sum error= 250
Actual label: 7
Output voltages: [0.28155, 0.28479, 0.18932, 0.23767, 0.2992, 0.13955, 0.038138, 0.74394, 0.24837, 0.3049]
Predicted label: 7
Correct prediction
Energy consumption = 200.639247 pJ
sum error= 250
Actual label: 3
Output voltages: [0.28442, 0.16048, 0.34047, 0.75686, 0.21155, 0.13891, 0.16486, 0.14929, 0.42592, 0.23132]
Predicted label: 3
Correct prediction
Energy consumption = 187.931567 pJ
sum error= 250
Actual label: 9
Output voltages: [0.54977, 0.15745, 0.37106, 0.23676, 0.25077, 0.05094, 0.34116, 0.21949, 0.3242, 0.45076]
Predicted label: 0
Wrong prediction!
Energy consumption = 196.405572 pJ
sum error= 251
Actual label: 1
Output voltages: [0.25389, 0.69077, 0.30499, 0.17323, 0.42444, 0.075982, 0.38291, 0.077651, 0.25747, 0.25446]
Predicted label: 1
Correct prediction
Energy consumption = 200.186632 pJ
sum error= 251
Actual label: 9
Output voltages: [0.40213, 0.13337, 0.20934, 0.27618, 0.34869, 0.093835, 0.25987, 0.13265, 0.31062, 0.62839]
Predicted label: 9
Correct prediction
Energy consumption = 193.076860 pJ
sum error= 251
Actual label: 9
Output voltages: [0.35303, 0.11597, 0.20448, 0.25112, 0.2913, 0.2176, 0.09102, 0.28499, 0.39223, 0.66104]
Predicted label: 9
Correct prediction
Energy consumption = 182.026404 pJ
sum error= 251
Actual label: 6
Output voltages: [0.28588, 0.17396, 0.32252, 0.089443, 0.33485, 0.30894, 0.7403, 0.048362, 0.40089, 0.15976]
Predicted label: 6
Correct prediction
Energy consumption = 179.212196 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 651 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 651 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 651 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74306, 0.22615, 0.26139, 0.16354, 0.1777, 0.14754, 0.43561, 0.20371, 0.26551, 0.22793]
Predicted label: 0
Correct prediction
Energy consumption = 190.887048 pJ
sum error= 251
Actual label: 3
Output voltages: [0.34869, 0.052196, 0.11912, 0.63363, 0.16511, 0.4812, 0.14557, 0.17042, 0.455, 0.25883]
Predicted label: 3
Correct prediction
Energy consumption = 192.463676 pJ
sum error= 251
Actual label: 9
Output voltages: [0.40299, 0.13809, 0.17475, 0.19106, 0.37737, 0.17693, 0.22729, 0.18473, 0.34224, 0.59935]
Predicted label: 9
Correct prediction
Energy consumption = 194.721326 pJ
sum error= 251
Actual label: 2
Output voltages: [0.32207, 0.29846, 0.73744, 0.32513, 0.18873, 0.034222, 0.24673, 0.24037, 0.38525, 0.25212]
Predicted label: 2
Correct prediction
Energy consumption = 198.923154 pJ
sum error= 251
Actual label: 8
Output voltages: [0.21593, 0.20202, 0.36702, 0.22925, 0.18048, 0.1385, 0.27163, 0.096763, 0.72956, 0.27061]
Predicted label: 8
Correct prediction
Energy consumption = 188.900455 pJ
sum error= 251
Actual label: 1
Output voltages: [0.29017, 0.72605, 0.3183, 0.14757, 0.345, 0.12536, 0.40912, 0.054477, 0.31698, 0.25803]
Predicted label: 1
Correct prediction
Energy consumption = 204.187163 pJ
sum error= 251
Actual label: 4
Output voltages: [0.12155, 0.16157, 0.24008, 0.16707, 0.76304, 0.14195, 0.25561, 0.31068, 0.25066, 0.17786]
Predicted label: 4
Correct prediction
Energy consumption = 188.529739 pJ
sum error= 251
Actual label: 3
Output voltages: [0.49389, 0.077048, 0.36426, 0.61226, 0.069211, 0.31411, 0.21934, 0.21442, 0.28962, 0.12145]
Predicted label: 3
Correct prediction
Energy consumption = 194.638654 pJ
sum error= 251
Actual label: 5
Output voltages: [0.2514, 0.065269, 0.080318, 0.39494, 0.26531, 0.72661, 0.35342, 0.090363, 0.47952, 0.17711]
Predicted label: 5
Correct prediction
Energy consumption = 184.359665 pJ
sum error= 251
Actual label: 2
Output voltages: [0.33754, 0.25361, 0.75172, 0.2876, 0.14741, 0.040348, 0.21575, 0.23131, 0.41446, 0.14711]
Predicted label: 2
Correct prediction
Energy consumption = 187.024482 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 652 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 652 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 652 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30567, 0.1703, 0.19953, 0.32958, 0.3512, 0.11486, 0.075401, 0.1731, 0.33503, 0.66543]
Predicted label: 9
Correct prediction
Energy consumption = 191.633682 pJ
sum error= 251
Actual label: 2
Output voltages: [0.28615, 0.21815, 0.75445, 0.26444, 0.14724, 0.038819, 0.23449, 0.27393, 0.43638, 0.18291]
Predicted label: 2
Correct prediction
Energy consumption = 189.028205 pJ
sum error= 251
Actual label: 5
Output voltages: [0.23668, 0.045633, 0.053198, 0.35225, 0.27836, 0.68648, 0.34863, 0.090529, 0.51884, 0.17709]
Predicted label: 5
Correct prediction
Energy consumption = 190.585716 pJ
sum error= 251
Actual label: 8
Output voltages: [0.27116, 0.31697, 0.31101, 0.17336, 0.25774, 0.070516, 0.23188, 0.15811, 0.64826, 0.31161]
Predicted label: 8
Correct prediction
Energy consumption = 203.395308 pJ
sum error= 251
Actual label: 9
Output voltages: [0.35313, 0.096567, 0.20001, 0.31228, 0.26679, 0.19796, 0.069374, 0.28768, 0.43932, 0.6513]
Predicted label: 9
Correct prediction
Energy consumption = 190.237523 pJ
sum error= 251
Actual label: 5
Output voltages: [0.22723, 0.052602, 0.07529, 0.36225, 0.28119, 0.72104, 0.32011, 0.095907, 0.49259, 0.19086]
Predicted label: 5
Correct prediction
Energy consumption = 188.663332 pJ
sum error= 251
Actual label: 0
Output voltages: [0.73218, 0.17453, 0.17822, 0.16664, 0.14857, 0.23047, 0.41228, 0.23185, 0.32992, 0.21951]
Predicted label: 0
Correct prediction
Energy consumption = 187.161816 pJ
sum error= 251
Actual label: 1
Output voltages: [0.28932, 0.70023, 0.30874, 0.19633, 0.40987, 0.061476, 0.27442, 0.1814, 0.25855, 0.24646]
Predicted label: 1
Correct prediction
Energy consumption = 208.666075 pJ
sum error= 251
Actual label: 2
Output voltages: [0.18805, 0.18318, 0.66508, 0.3463, 0.30954, 0.060009, 0.18661, 0.245, 0.43203, 0.12895]
Predicted label: 2
Correct prediction
Energy consumption = 190.285018 pJ
sum error= 251
Actual label: 4
Output voltages: [0.2294, 0.1385, 0.28549, 0.15486, 0.7192, 0.049823, 0.25527, 0.20918, 0.28153, 0.25701]
Predicted label: 4
Correct prediction
Energy consumption = 181.053721 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 653 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 653 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 653 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2796, 0.061475, 0.072412, 0.42216, 0.22444, 0.72632, 0.28651, 0.1008, 0.47962, 0.18365]
Predicted label: 5
Correct prediction
Energy consumption = 187.832123 pJ
sum error= 251
Actual label: 6
Output voltages: [0.29086, 0.19796, 0.33655, 0.10365, 0.36397, 0.32381, 0.73439, 0.08191, 0.31744, 0.21377]
Predicted label: 6
Correct prediction
Energy consumption = 189.432087 pJ
sum error= 251
Actual label: 0
Output voltages: [0.73808, 0.21255, 0.097768, 0.33458, 0.086616, 0.46861, 0.21615, 0.21846, 0.29233, 0.18191]
Predicted label: 0
Correct prediction
Energy consumption = 199.342691 pJ
sum error= 251
Actual label: 1
Output voltages: [0.16081, 0.76392, 0.30498, 0.20425, 0.19825, 0.066618, 0.3686, 0.15058, 0.3652, 0.2088]
Predicted label: 1
Correct prediction
Energy consumption = 207.039363 pJ
sum error= 251
Actual label: 2
Output voltages: [0.33555, 0.24424, 0.74592, 0.3006, 0.11845, 0.036715, 0.21535, 0.37115, 0.42239, 0.18074]
Predicted label: 2
Correct prediction
Energy consumption = 181.287100 pJ
sum error= 251
Actual label: 3
Output voltages: [0.25878, 0.20808, 0.27738, 0.74539, 0.16466, 0.27639, 0.11094, 0.23514, 0.44052, 0.3658]
Predicted label: 3
Correct prediction
Energy consumption = 184.850247 pJ
sum error= 251
Actual label: 4
Output voltages: [0.20623, 0.11089, 0.28484, 0.22346, 0.72541, 0.045005, 0.19875, 0.25304, 0.32654, 0.22147]
Predicted label: 4
Correct prediction
Energy consumption = 192.135732 pJ
sum error= 251
Actual label: 5
Output voltages: [0.27344, 0.080544, 0.12884, 0.30156, 0.27462, 0.66406, 0.36649, 0.07996, 0.40834, 0.29571]
Predicted label: 5
Correct prediction
Energy consumption = 190.741496 pJ
sum error= 251
Actual label: 6
Output voltages: [0.23157, 0.20502, 0.31268, 0.14438, 0.34812, 0.14909, 0.69647, 0.13554, 0.32367, 0.33361]
Predicted label: 6
Correct prediction
Energy consumption = 191.168983 pJ
sum error= 251
Actual label: 7
Output voltages: [0.35241, 0.17139, 0.17504, 0.32354, 0.17253, 0.17361, 0.034722, 0.75512, 0.31666, 0.41221]
Predicted label: 7
Correct prediction
Energy consumption = 189.512433 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 654 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 654 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 654 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.19816, 0.7598, 0.18113, 0.29619, 0.25842, 0.087439, 0.29269, 0.18958, 0.24261, 0.33431]
Predicted label: 1
Correct prediction
Energy consumption = 219.484091 pJ
sum error= 251
Actual label: 2
Output voltages: [0.37052, 0.37889, 0.70731, 0.36756, 0.17836, 0.031328, 0.26737, 0.2893, 0.33844, 0.19485]
Predicted label: 2
Correct prediction
Energy consumption = 187.707622 pJ
sum error= 251
Actual label: 3
Output voltages: [0.38546, 0.18188, 0.28506, 0.70372, 0.23117, 0.10509, 0.071631, 0.47328, 0.30983, 0.17478]
Predicted label: 3
Correct prediction
Energy consumption = 188.265625 pJ
sum error= 251
Actual label: 4
Output voltages: [0.10501, 0.10551, 0.3389, 0.21283, 0.74421, 0.1074, 0.21846, 0.2803, 0.23204, 0.27576]
Predicted label: 4
Correct prediction
Energy consumption = 190.497742 pJ
sum error= 251
Actual label: 5
Output voltages: [0.21299, 0.071317, 0.053731, 0.42818, 0.25451, 0.69205, 0.35501, 0.10933, 0.44977, 0.26337]
Predicted label: 5
Correct prediction
Energy consumption = 196.943055 pJ
sum error= 251
Actual label: 1
Output voltages: [0.22859, 0.74897, 0.2764, 0.29187, 0.33933, 0.052684, 0.34307, 0.1865, 0.28405, 0.19648]
Predicted label: 1
Correct prediction
Energy consumption = 214.348420 pJ
sum error= 251
Actual label: 0
Output voltages: [0.68535, 0.16493, 0.22897, 0.18406, 0.098374, 0.2087, 0.40442, 0.16471, 0.27784, 0.39673]
Predicted label: 0
Correct prediction
Energy consumption = 190.269957 pJ
sum error= 251
Actual label: 4
Output voltages: [0.11085, 0.16131, 0.28252, 0.12814, 0.74312, 0.077952, 0.38409, 0.29028, 0.19841, 0.20335]
Predicted label: 4
Correct prediction
Energy consumption = 189.556691 pJ
sum error= 251
Actual label: 5
Output voltages: [0.23497, 0.063582, 0.084957, 0.41749, 0.25963, 0.69742, 0.34212, 0.14384, 0.48041, 0.20399]
Predicted label: 5
Correct prediction
Energy consumption = 188.777034 pJ
sum error= 251
Actual label: 6
Output voltages: [0.31671, 0.17831, 0.31793, 0.064413, 0.3931, 0.25333, 0.72454, 0.095307, 0.27924, 0.22595]
Predicted label: 6
Correct prediction
Energy consumption = 182.193231 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 655 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 655 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 655 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29309, 0.22197, 0.25084, 0.14701, 0.31771, 0.40864, 0.74175, 0.083809, 0.35661, 0.16315]
Predicted label: 6
Correct prediction
Energy consumption = 189.417520 pJ
sum error= 251
Actual label: 3
Output voltages: [0.36223, 0.17888, 0.32198, 0.75986, 0.24504, 0.22273, 0.13827, 0.21082, 0.40433, 0.26919]
Predicted label: 3
Correct prediction
Energy consumption = 190.828136 pJ
sum error= 251
Actual label: 4
Output voltages: [0.17839, 0.17297, 0.35126, 0.20552, 0.74253, 0.073211, 0.34635, 0.27162, 0.19666, 0.19956]
Predicted label: 4
Correct prediction
Energy consumption = 194.664507 pJ
sum error= 251
Actual label: 4
Output voltages: [0.14443, 0.15377, 0.27911, 0.36451, 0.6095, 0.10644, 0.26338, 0.17105, 0.31709, 0.23692]
Predicted label: 4
Correct prediction
Energy consumption = 191.272892 pJ
sum error= 251
Actual label: 2
Output voltages: [0.22083, 0.13401, 0.68601, 0.33254, 0.16635, 0.050043, 0.17296, 0.31566, 0.52479, 0.28744]
Predicted label: 2
Correct prediction
Energy consumption = 188.331940 pJ
sum error= 251
Actual label: 8
Output voltages: [0.27141, 0.13001, 0.2556, 0.2967, 0.14012, 0.17233, 0.043935, 0.43309, 0.57223, 0.51103]
Predicted label: 8
Correct prediction
Energy consumption = 194.247862 pJ
sum error= 251
Actual label: 1
Output voltages: [0.20721, 0.75438, 0.22742, 0.21741, 0.3406, 0.061781, 0.32109, 0.23443, 0.23359, 0.25315]
Predicted label: 1
Correct prediction
Energy consumption = 204.272605 pJ
sum error= 251
Actual label: 0
Output voltages: [0.57791, 0.19244, 0.53592, 0.26838, 0.051302, 0.059573, 0.33457, 0.34536, 0.44435, 0.143]
Predicted label: 0
Correct prediction
Energy consumption = 191.030947 pJ
sum error= 251
Actual label: 6
Output voltages: [0.24254, 0.28294, 0.49648, 0.23455, 0.15597, 0.22558, 0.56573, 0.21359, 0.43461, 0.062966]
Predicted label: 6
Correct prediction
Energy consumption = 193.651963 pJ
sum error= 251
Actual label: 4
Output voltages: [0.076331, 0.11236, 0.40044, 0.31422, 0.60249, 0.14966, 0.089453, 0.28685, 0.32623, 0.24113]
Predicted label: 4
Correct prediction
Energy consumption = 197.724924 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 656 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 656 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 656 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31225, 0.16238, 0.087492, 0.43315, 0.45258, 0.43957, 0.26594, 0.10208, 0.27358, 0.45777]
Predicted label: 9
Correct prediction
Energy consumption = 203.067634 pJ
sum error= 251
Actual label: 7
Output voltages: [0.26874, 0.4369, 0.39692, 0.36375, 0.054627, 0.069776, 0.056636, 0.67543, 0.31537, 0.39292]
Predicted label: 7
Correct prediction
Energy consumption = 201.835665 pJ
sum error= 251
Actual label: 2
Output voltages: [0.32966, 0.29705, 0.72175, 0.33997, 0.15489, 0.036972, 0.15296, 0.40595, 0.38705, 0.17115]
Predicted label: 2
Correct prediction
Energy consumption = 182.239429 pJ
sum error= 251
Actual label: 3
Output voltages: [0.29855, 0.24009, 0.33342, 0.75811, 0.14571, 0.24236, 0.092156, 0.29869, 0.32231, 0.19761]
Predicted label: 3
Correct prediction
Energy consumption = 191.151613 pJ
sum error= 251
Actual label: 3
Output voltages: [0.27959, 0.16764, 0.24529, 0.74341, 0.28508, 0.24354, 0.10305, 0.31182, 0.3367, 0.38318]
Predicted label: 3
Correct prediction
Energy consumption = 192.423314 pJ
sum error= 251
Actual label: 9
Output voltages: [0.34436, 0.12614, 0.18193, 0.25391, 0.21756, 0.18959, 0.08632, 0.18769, 0.46718, 0.64596]
Predicted label: 9
Correct prediction
Energy consumption = 189.459611 pJ
sum error= 251
Actual label: 2
Output voltages: [0.35391, 0.23271, 0.6862, 0.28768, 0.33313, 0.038137, 0.22522, 0.19338, 0.34983, 0.17545]
Predicted label: 2
Correct prediction
Energy consumption = 193.820389 pJ
sum error= 251
Actual label: 0
Output voltages: [0.7304, 0.20251, 0.31743, 0.15542, 0.095702, 0.16627, 0.41812, 0.26166, 0.25802, 0.23852]
Predicted label: 0
Correct prediction
Energy consumption = 184.311692 pJ
sum error= 251
Actual label: 9
Output voltages: [0.20169, 0.18451, 0.29796, 0.2979, 0.23956, 0.14947, 0.12239, 0.14292, 0.4809, 0.61873]
Predicted label: 9
Correct prediction
Energy consumption = 195.680491 pJ
sum error= 251
Actual label: 3
Output voltages: [0.29938, 0.29309, 0.31601, 0.71776, 0.11081, 0.17963, 0.068829, 0.25167, 0.37659, 0.3681]
Predicted label: 3
Correct prediction
Energy consumption = 198.429236 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 657 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 657 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 657 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26068, 0.20092, 0.29495, 0.75582, 0.20421, 0.1643, 0.13395, 0.21025, 0.38277, 0.26852]
Predicted label: 3
Correct prediction
Energy consumption = 192.951626 pJ
sum error= 251
Actual label: 9
Output voltages: [0.32704, 0.13885, 0.20755, 0.44373, 0.24516, 0.27558, 0.074011, 0.51377, 0.31889, 0.55803]
Predicted label: 9
Correct prediction
Energy consumption = 188.726081 pJ
sum error= 251
Actual label: 1
Output voltages: [0.21619, 0.69589, 0.33265, 0.36036, 0.047189, 0.24453, 0.30493, 0.18018, 0.38368, 0.28452]
Predicted label: 1
Correct prediction
Energy consumption = 205.632790 pJ
sum error= 251
Actual label: 5
Output voltages: [0.27961, 0.10114, 0.17396, 0.56118, 0.16632, 0.61208, 0.2712, 0.12084, 0.39287, 0.1881]
Predicted label: 5
Correct prediction
Energy consumption = 193.671701 pJ
sum error= 251
Actual label: 2
Output voltages: [0.40637, 0.088894, 0.66938, 0.26958, 0.22843, 0.033374, 0.30937, 0.37898, 0.40024, 0.18821]
Predicted label: 2
Correct prediction
Energy consumption = 177.751646 pJ
sum error= 251
Actual label: 3
Output voltages: [0.29406, 0.11476, 0.34146, 0.7443, 0.28216, 0.21484, 0.12682, 0.19439, 0.37024, 0.2877]
Predicted label: 3
Correct prediction
Energy consumption = 193.373365 pJ
sum error= 251
Actual label: 7
Output voltages: [0.2965, 0.61121, 0.43671, 0.37229, 0.16606, 0.033026, 0.10951, 0.50114, 0.34025, 0.151]
Predicted label: 1
Wrong prediction!
Energy consumption = 196.202953 pJ
sum error= 252
Actual label: 7
Output voltages: [0.26097, 0.34621, 0.42536, 0.37138, 0.086224, 0.053473, 0.052181, 0.703, 0.38975, 0.33512]
Predicted label: 7
Correct prediction
Energy consumption = 191.464394 pJ
sum error= 252
Actual label: 8
Output voltages: [0.21524, 0.1906, 0.25517, 0.30671, 0.05708, 0.46612, 0.24924, 0.14973, 0.67739, 0.22072]
Predicted label: 8
Correct prediction
Energy consumption = 195.808273 pJ
sum error= 252
Actual label: 4
Output voltages: [0.17262, 0.1397, 0.30832, 0.18739, 0.743, 0.046627, 0.21342, 0.26124, 0.25338, 0.23716]
Predicted label: 4
Correct prediction
Energy consumption = 186.273188 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 658 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 658 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 658 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7413, 0.27503, 0.31145, 0.25343, 0.070877, 0.20041, 0.30656, 0.20078, 0.32303, 0.27636]
Predicted label: 0
Correct prediction
Energy consumption = 199.898242 pJ
sum error= 252
Actual label: 2
Output voltages: [0.37618, 0.33289, 0.69345, 0.34285, 0.30023, 0.033789, 0.23186, 0.3952, 0.3339, 0.18394]
Predicted label: 2
Correct prediction
Energy consumption = 190.842266 pJ
sum error= 252
Actual label: 4
Output voltages: [0.085835, 0.26652, 0.27508, 0.10065, 0.75506, 0.10473, 0.37836, 0.34682, 0.14508, 0.2154]
Predicted label: 4
Correct prediction
Energy consumption = 194.818517 pJ
sum error= 252
Actual label: 0
Output voltages: [0.74087, 0.27708, 0.18733, 0.22977, 0.13594, 0.29457, 0.37183, 0.17205, 0.2914, 0.2528]
Predicted label: 0
Correct prediction
Energy consumption = 199.582494 pJ
sum error= 252
Actual label: 2
Output voltages: [0.35674, 0.27524, 0.70928, 0.34521, 0.099789, 0.033869, 0.15746, 0.35676, 0.35202, 0.24106]
Predicted label: 2
Correct prediction
Energy consumption = 195.107148 pJ
sum error= 252
Actual label: 4
Output voltages: [0.12385, 0.13544, 0.29533, 0.16815, 0.74655, 0.075728, 0.25124, 0.32013, 0.26669, 0.193]
Predicted label: 4
Correct prediction
Energy consumption = 195.854515 pJ
sum error= 252
Actual label: 7
Output voltages: [0.31934, 0.24359, 0.24394, 0.32072, 0.13767, 0.056881, 0.040728, 0.74671, 0.33512, 0.3508]
Predicted label: 7
Correct prediction
Energy consumption = 197.692554 pJ
sum error= 252
Actual label: 8
Output voltages: [0.22385, 0.27391, 0.26413, 0.22299, 0.18789, 0.21534, 0.21197, 0.20973, 0.74043, 0.24401]
Predicted label: 8
Correct prediction
Energy consumption = 199.397671 pJ
sum error= 252
Actual label: 0
Output voltages: [0.71961, 0.2124, 0.29621, 0.28692, 0.15576, 0.11296, 0.28125, 0.22808, 0.3494, 0.26413]
Predicted label: 0
Correct prediction
Energy consumption = 205.264822 pJ
sum error= 252
Actual label: 7
Output voltages: [0.36901, 0.22113, 0.41803, 0.35806, 0.12918, 0.044772, 0.044558, 0.73601, 0.30314, 0.32679]
Predicted label: 7
Correct prediction
Energy consumption = 192.864768 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 659 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 659 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 659 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73465, 0.22605, 0.17491, 0.27136, 0.054734, 0.38808, 0.32679, 0.13753, 0.31717, 0.20856]
Predicted label: 0
Correct prediction
Energy consumption = 193.192523 pJ
sum error= 252
Actual label: 6
Output voltages: [0.33438, 0.16748, 0.29161, 0.17238, 0.28101, 0.3993, 0.73078, 0.057809, 0.29606, 0.26285]
Predicted label: 6
Correct prediction
Energy consumption = 187.568516 pJ
sum error= 252
Actual label: 9
Output voltages: [0.30309, 0.18488, 0.071588, 0.31101, 0.39026, 0.29794, 0.35341, 0.21435, 0.25631, 0.59081]
Predicted label: 9
Correct prediction
Energy consumption = 198.524522 pJ
sum error= 252
Actual label: 3
Output voltages: [0.27611, 0.2179, 0.28675, 0.7612, 0.16896, 0.17535, 0.13543, 0.29024, 0.36997, 0.30667]
Predicted label: 3
Correct prediction
Energy consumption = 187.260311 pJ
sum error= 252
Actual label: 2
Output voltages: [0.34743, 0.14357, 0.72878, 0.39052, 0.21745, 0.038846, 0.22827, 0.31716, 0.3984, 0.21162]
Predicted label: 2
Correct prediction
Energy consumption = 178.436139 pJ
sum error= 252
Actual label: 8
Output voltages: [0.13375, 0.24298, 0.27499, 0.23122, 0.17173, 0.24895, 0.14449, 0.2012, 0.75131, 0.23879]
Predicted label: 8
Correct prediction
Energy consumption = 196.627851 pJ
sum error= 252
Actual label: 6
Output voltages: [0.29138, 0.2123, 0.34466, 0.11247, 0.32851, 0.29937, 0.74452, 0.076505, 0.39284, 0.11593]
Predicted label: 6
Correct prediction
Energy consumption = 188.383825 pJ
sum error= 252
Actual label: 0
Output voltages: [0.50397, 0.27456, 0.23555, 0.3673, 0.18059, 0.080417, 0.06931, 0.71708, 0.20262, 0.2727]
Predicted label: 7
Wrong prediction!
Energy consumption = 197.501344 pJ
sum error= 253
Actual label: 5
Output voltages: [0.34951, 0.11383, 0.22769, 0.31645, 0.066545, 0.59797, 0.49363, 0.1825, 0.37274, 0.13216]
Predicted label: 5
Correct prediction
Energy consumption = 192.360151 pJ
sum error= 253
Actual label: 7
Output voltages: [0.22784, 0.35361, 0.37212, 0.16564, 0.22978, 0.042928, 0.048541, 0.67093, 0.34336, 0.36104]
Predicted label: 7
Correct prediction
Energy consumption = 195.264024 pJ
sum error= 253
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 660 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 660 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 660 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24694, 0.036587, 0.06101, 0.28002, 0.30771, 0.69482, 0.36338, 0.1534, 0.47135, 0.24412]
Predicted label: 5
Correct prediction
Energy consumption = 189.911518 pJ
sum error= 253
Actual label: 1
Output voltages: [0.27518, 0.75454, 0.35894, 0.25859, 0.26925, 0.05327, 0.30926, 0.19263, 0.24001, 0.23784]
Predicted label: 1
Correct prediction
Energy consumption = 209.265090 pJ
sum error= 253
Actual label: 0
Output voltages: [0.73874, 0.27237, 0.24774, 0.20118, 0.090927, 0.22576, 0.31714, 0.23072, 0.42073, 0.28083]
Predicted label: 0
Correct prediction
Energy consumption = 200.420395 pJ
sum error= 253
Actual label: 8
Output voltages: [0.39213, 0.14528, 0.26062, 0.1092, 0.1758, 0.18813, 0.11434, 0.32538, 0.61625, 0.41755]
Predicted label: 8
Correct prediction
Energy consumption = 195.921040 pJ
sum error= 253
Actual label: 1
Output voltages: [0.21391, 0.76461, 0.30707, 0.25054, 0.20149, 0.084024, 0.40534, 0.15557, 0.32976, 0.2041]
Predicted label: 1
Correct prediction
Energy consumption = 206.137580 pJ
sum error= 253
Actual label: 6
Output voltages: [0.2865, 0.21074, 0.30865, 0.085036, 0.38679, 0.35809, 0.738, 0.073912, 0.34962, 0.083606]
Predicted label: 6
Correct prediction
Energy consumption = 191.599505 pJ
sum error= 253
Actual label: 7
Output voltages: [0.24722, 0.14303, 0.26879, 0.27271, 0.21075, 0.11043, 0.04172, 0.76293, 0.36457, 0.29595]
Predicted label: 7
Correct prediction
Energy consumption = 195.239129 pJ
sum error= 253
Actual label: 2
Output voltages: [0.3865, 0.16823, 0.70497, 0.31466, 0.21957, 0.034018, 0.17098, 0.26437, 0.39225, 0.17309]
Predicted label: 2
Correct prediction
Energy consumption = 192.588890 pJ
sum error= 253
Actual label: 9
Output voltages: [0.36431, 0.18206, 0.045495, 0.38865, 0.29952, 0.4321, 0.27983, 0.18885, 0.26896, 0.53253]
Predicted label: 9
Correct prediction
Energy consumption = 199.982156 pJ
sum error= 253
Actual label: 7
Output voltages: [0.27546, 0.33453, 0.46527, 0.19486, 0.17606, 0.041255, 0.051528, 0.72519, 0.30702, 0.28847]
Predicted label: 7
Correct prediction
Energy consumption = 198.314116 pJ
sum error= 253
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 661 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 661 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 661 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.26642, 0.12172, 0.11282, 0.36969, 0.334, 0.41605, 0.19045, 0.21314, 0.35059, 0.53445]
Predicted label: 9
Correct prediction
Energy consumption = 194.881510 pJ
sum error= 253
Actual label: 5
Output voltages: [0.36725, 0.074353, 0.047564, 0.38792, 0.2566, 0.74169, 0.26692, 0.20799, 0.38758, 0.17212]
Predicted label: 5
Correct prediction
Energy consumption = 187.895389 pJ
sum error= 253
Actual label: 8
Output voltages: [0.21829, 0.19467, 0.33203, 0.30359, 0.11749, 0.17499, 0.17979, 0.19093, 0.74923, 0.28313]
Predicted label: 8
Correct prediction
Energy consumption = 190.797421 pJ
sum error= 253
Actual label: 6
Output voltages: [0.35871, 0.19362, 0.28948, 0.18399, 0.19556, 0.2586, 0.63398, 0.41151, 0.30955, 0.17777]
Predicted label: 6
Correct prediction
Energy consumption = 187.837586 pJ
sum error= 253
Actual label: 2
Output voltages: [0.4706, 0.15226, 0.73582, 0.28677, 0.078343, 0.051814, 0.21488, 0.40261, 0.37959, 0.17258]
Predicted label: 2
Correct prediction
Energy consumption = 191.275109 pJ
sum error= 253
Actual label: 6
Output voltages: [0.29787, 0.2149, 0.32621, 0.12642, 0.33208, 0.27168, 0.70608, 0.1478, 0.35278, 0.062467]
Predicted label: 6
Correct prediction
Energy consumption = 197.587947 pJ
sum error= 253
Actual label: 2
Output voltages: [0.39546, 0.14775, 0.74773, 0.30185, 0.13972, 0.044039, 0.23397, 0.33034, 0.45155, 0.16456]
Predicted label: 2
Correct prediction
Energy consumption = 184.625916 pJ
sum error= 253
Actual label: 8
Output voltages: [0.24884, 0.20342, 0.40453, 0.19646, 0.15775, 0.10868, 0.17842, 0.17162, 0.73365, 0.32064]
Predicted label: 8
Correct prediction
Energy consumption = 184.973065 pJ
sum error= 253
Actual label: 1
Output voltages: [0.16577, 0.76735, 0.27109, 0.2273, 0.25743, 0.080175, 0.40104, 0.15121, 0.29742, 0.24841]
Predicted label: 1
Correct prediction
Energy consumption = 204.768908 pJ
sum error= 253
Actual label: 7
Output voltages: [0.46216, 0.20805, 0.12371, 0.14986, 0.28926, 0.2214, 0.10475, 0.72521, 0.26616, 0.3454]
Predicted label: 7
Correct prediction
Energy consumption = 191.370568 pJ
sum error= 253
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 662 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 662 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 662 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.28213, 0.056218, 0.063559, 0.30491, 0.22765, 0.73497, 0.30988, 0.19357, 0.51755, 0.20777]
Predicted label: 5
Correct prediction
Energy consumption = 194.184612 pJ
sum error= 253
Actual label: 0
Output voltages: [0.73862, 0.17602, 0.25789, 0.30226, 0.086178, 0.17563, 0.22739, 0.24375, 0.35236, 0.31204]
Predicted label: 0
Correct prediction
Energy consumption = 204.973198 pJ
sum error= 253
Actual label: 1
Output voltages: [0.17411, 0.75298, 0.15123, 0.22306, 0.34301, 0.066185, 0.33456, 0.15277, 0.33107, 0.27246]
Predicted label: 1
Correct prediction
Energy consumption = 207.960919 pJ
sum error= 253
Actual label: 1
Output voltages: [0.14791, 0.76805, 0.18524, 0.17057, 0.29477, 0.21244, 0.4144, 0.16071, 0.28193, 0.2262]
Predicted label: 1
Correct prediction
Energy consumption = 200.492694 pJ
sum error= 253
Actual label: 3
Output voltages: [0.29165, 0.12786, 0.30306, 0.74967, 0.24732, 0.30828, 0.15567, 0.19331, 0.39554, 0.24239]
Predicted label: 3
Correct prediction
Energy consumption = 195.489662 pJ
sum error= 253
Actual label: 8
Output voltages: [0.14517, 0.31469, 0.53838, 0.19681, 0.1829, 0.041886, 0.26276, 0.40666, 0.52906, 0.20734]
Predicted label: 2
Wrong prediction!
Energy consumption = 199.274972 pJ
sum error= 254
Actual label: 4
Output voltages: [0.15731, 0.15895, 0.25736, 0.18345, 0.74552, 0.078248, 0.21623, 0.26919, 0.27844, 0.20937]
Predicted label: 4
Correct prediction
Energy consumption = 193.956500 pJ
sum error= 254
Actual label: 9
Output voltages: [0.28452, 0.11973, 0.1076, 0.26597, 0.44039, 0.2527, 0.17481, 0.16582, 0.32736, 0.62096]
Predicted label: 9
Correct prediction
Energy consumption = 188.956670 pJ
sum error= 254
Actual label: 1
Output voltages: [0.20602, 0.72051, 0.23941, 0.33462, 0.39652, 0.045281, 0.14657, 0.15805, 0.27933, 0.33165]
Predicted label: 1
Correct prediction
Energy consumption = 212.377179 pJ
sum error= 254
Actual label: 8
Output voltages: [0.32088, 0.1157, 0.31138, 0.32877, 0.09878, 0.35341, 0.17125, 0.14953, 0.7475, 0.23497]
Predicted label: 8
Correct prediction
Energy consumption = 188.774112 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 663 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 663 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 663 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29046, 0.2171, 0.32688, 0.059548, 0.35004, 0.30403, 0.74702, 0.065937, 0.36441, 0.12211]
Predicted label: 6
Correct prediction
Energy consumption = 189.958060 pJ
sum error= 254
Actual label: 8
Output voltages: [0.3094, 0.25749, 0.36479, 0.14504, 0.21533, 0.07378, 0.25884, 0.079655, 0.66692, 0.37379]
Predicted label: 8
Correct prediction
Energy consumption = 193.684704 pJ
sum error= 254
Actual label: 9
Output voltages: [0.29408, 0.14972, 0.11425, 0.21764, 0.24091, 0.34707, 0.11355, 0.27443, 0.36203, 0.5987]
Predicted label: 9
Correct prediction
Energy consumption = 202.794495 pJ
sum error= 254
Actual label: 0
Output voltages: [0.71497, 0.21735, 0.30886, 0.15961, 0.149, 0.098473, 0.34958, 0.19961, 0.37827, 0.18918]
Predicted label: 0
Correct prediction
Energy consumption = 193.930450 pJ
sum error= 254
Actual label: 1
Output voltages: [0.20244, 0.75503, 0.25689, 0.22754, 0.34207, 0.086814, 0.39985, 0.15044, 0.28787, 0.18704]
Predicted label: 1
Correct prediction
Energy consumption = 205.821788 pJ
sum error= 254
Actual label: 2
Output voltages: [0.22071, 0.24872, 0.71075, 0.36527, 0.092437, 0.049533, 0.26762, 0.33566, 0.48423, 0.16098]
Predicted label: 2
Correct prediction
Energy consumption = 193.413877 pJ
sum error= 254
Actual label: 3
Output voltages: [0.40143, 0.16736, 0.25196, 0.74858, 0.075322, 0.24449, 0.14912, 0.23457, 0.50389, 0.14293]
Predicted label: 3
Correct prediction
Energy consumption = 187.401723 pJ
sum error= 254
Actual label: 4
Output voltages: [0.21821, 0.17601, 0.31523, 0.21319, 0.73012, 0.047094, 0.27561, 0.32405, 0.24695, 0.20343]
Predicted label: 4
Correct prediction
Energy consumption = 202.211937 pJ
sum error= 254
Actual label: 5
Output voltages: [0.24857, 0.049673, 0.063116, 0.37566, 0.21356, 0.73894, 0.34895, 0.22557, 0.48753, 0.25599]
Predicted label: 5
Correct prediction
Energy consumption = 191.876203 pJ
sum error= 254
Actual label: 6
Output voltages: [0.32361, 0.19575, 0.25227, 0.14792, 0.32152, 0.37162, 0.73242, 0.093986, 0.44275, 0.14505]
Predicted label: 6
Correct prediction
Energy consumption = 182.448438 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 664 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 664 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 664 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3236, 0.23353, 0.32441, 0.25845, 0.17927, 0.066156, 0.045496, 0.76256, 0.30641, 0.30703]
Predicted label: 7
Correct prediction
Energy consumption = 191.535014 pJ
sum error= 254
Actual label: 8
Output voltages: [0.22162, 0.12775, 0.23117, 0.27465, 0.15053, 0.42371, 0.28971, 0.062059, 0.7118, 0.20971]
Predicted label: 8
Correct prediction
Energy consumption = 191.368730 pJ
sum error= 254
Actual label: 9
Output voltages: [0.23587, 0.14898, 0.10036, 0.22199, 0.42858, 0.35, 0.090801, 0.20339, 0.31972, 0.60011]
Predicted label: 9
Correct prediction
Energy consumption = 194.673687 pJ
sum error= 254
Actual label: 0
Output voltages: [0.66727, 0.29256, 0.29052, 0.13504, 0.18028, 0.1109, 0.3379, 0.32765, 0.29973, 0.18194]
Predicted label: 0
Correct prediction
Energy consumption = 204.399965 pJ
sum error= 254
Actual label: 1
Output voltages: [0.22552, 0.7307, 0.28877, 0.18573, 0.34998, 0.065498, 0.36172, 0.16708, 0.27058, 0.19073]
Predicted label: 1
Correct prediction
Energy consumption = 203.831472 pJ
sum error= 254
Actual label: 2
Output voltages: [0.24239, 0.2273, 0.73922, 0.29654, 0.20014, 0.042374, 0.2169, 0.21481, 0.45025, 0.20721]
Predicted label: 2
Correct prediction
Energy consumption = 189.920264 pJ
sum error= 254
Actual label: 3
Output voltages: [0.31491, 0.15711, 0.26847, 0.75052, 0.13461, 0.2529, 0.1859, 0.17617, 0.47484, 0.1847]
Predicted label: 3
Correct prediction
Energy consumption = 189.213690 pJ
sum error= 254
Actual label: 4
Output voltages: [0.13364, 0.16846, 0.2497, 0.18156, 0.74929, 0.053637, 0.26164, 0.30701, 0.24458, 0.15705]
Predicted label: 4
Correct prediction
Energy consumption = 193.982956 pJ
sum error= 254
Actual label: 7
Output voltages: [0.36471, 0.30074, 0.51485, 0.21629, 0.15374, 0.038312, 0.064066, 0.72804, 0.25472, 0.34344]
Predicted label: 7
Correct prediction
Energy consumption = 191.697185 pJ
sum error= 254
Actual label: 8
Output voltages: [0.24504, 0.19508, 0.24481, 0.33721, 0.11565, 0.31136, 0.2568, 0.10167, 0.7442, 0.22039]
Predicted label: 8
Correct prediction
Energy consumption = 188.024067 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 665 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 665 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 665 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31335, 0.10062, 0.17016, 0.15236, 0.38203, 0.2217, 0.080372, 0.15253, 0.44568, 0.62888]
Predicted label: 9
Correct prediction
Energy consumption = 188.711810 pJ
sum error= 254
Actual label: 0
Output voltages: [0.36617, 0.5209, 0.38373, 0.1733, 0.24245, 0.1902, 0.29344, 0.21657, 0.3835, 0.15245]
Predicted label: 1
Wrong prediction!
Energy consumption = 204.649840 pJ
sum error= 255
Actual label: 1
Output voltages: [0.17895, 0.69981, 0.28953, 0.18751, 0.38318, 0.061405, 0.30865, 0.13812, 0.31922, 0.18194]
Predicted label: 1
Correct prediction
Energy consumption = 193.539387 pJ
sum error= 255
Actual label: 7
Output voltages: [0.32848, 0.31072, 0.41205, 0.18363, 0.1969, 0.056029, 0.053005, 0.7566, 0.31676, 0.29458]
Predicted label: 7
Correct prediction
Energy consumption = 185.438859 pJ
sum error= 255
Actual label: 8
Output voltages: [0.19581, 0.15412, 0.23903, 0.40633, 0.093805, 0.40625, 0.25436, 0.069425, 0.7192, 0.23245]
Predicted label: 8
Correct prediction
Energy consumption = 190.082453 pJ
sum error= 255
Actual label: 9
Output voltages: [0.30123, 0.11239, 0.21257, 0.24789, 0.24687, 0.17638, 0.064373, 0.25115, 0.49725, 0.64117]
Predicted label: 9
Correct prediction
Energy consumption = 183.570356 pJ
sum error= 255
Actual label: 9
Output voltages: [0.32787, 0.11792, 0.25275, 0.18129, 0.32238, 0.081514, 0.072676, 0.17515, 0.47625, 0.60944]
Predicted label: 9
Correct prediction
Energy consumption = 178.072194 pJ
sum error= 255
Actual label: 8
Output voltages: [0.24911, 0.14132, 0.24019, 0.34332, 0.09481, 0.40901, 0.24577, 0.10181, 0.73695, 0.19372]
Predicted label: 8
Correct prediction
Energy consumption = 187.607034 pJ
sum error= 255
Actual label: 9
Output voltages: [0.30486, 0.10636, 0.19138, 0.1897, 0.32022, 0.1887, 0.081349, 0.21087, 0.48353, 0.63518]
Predicted label: 9
Correct prediction
Energy consumption = 188.964641 pJ
sum error= 255
Actual label: 8
Output voltages: [0.30768, 0.17292, 0.26124, 0.23296, 0.23278, 0.39151, 0.22116, 0.10558, 0.73575, 0.22541]
Predicted label: 8
Correct prediction
Energy consumption = 186.433475 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 666 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 666 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 666 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.12195, 0.17985, 0.26961, 0.19547, 0.75216, 0.11817, 0.27637, 0.28324, 0.22199, 0.20514]
Predicted label: 4
Correct prediction
Energy consumption = 190.661011 pJ
sum error= 255
Actual label: 1
Output voltages: [0.1681, 0.71532, 0.26095, 0.21557, 0.19797, 0.088217, 0.29362, 0.10269, 0.45303, 0.21352]
Predicted label: 1
Correct prediction
Energy consumption = 195.863403 pJ
sum error= 255
Actual label: 7
Output voltages: [0.48901, 0.24738, 0.42162, 0.34973, 0.054015, 0.094811, 0.09407, 0.62358, 0.27649, 0.29949]
Predicted label: 7
Correct prediction
Energy consumption = 199.710803 pJ
sum error= 255
Actual label: 7
Output voltages: [0.2863, 0.26819, 0.44839, 0.22855, 0.14282, 0.055394, 0.049962, 0.74668, 0.30861, 0.36886]
Predicted label: 7
Correct prediction
Energy consumption = 185.860492 pJ
sum error= 255
Actual label: 3
Output voltages: [0.31828, 0.053867, 0.40015, 0.69814, 0.17245, 0.21148, 0.15711, 0.20888, 0.43785, 0.15174]
Predicted label: 3
Correct prediction
Energy consumption = 186.481716 pJ
sum error= 255
Actual label: 3
Output voltages: [0.26929, 0.20735, 0.27529, 0.75107, 0.13836, 0.16208, 0.087028, 0.37224, 0.46598, 0.23024]
Predicted label: 3
Correct prediction
Energy consumption = 176.686384 pJ
sum error= 255
Actual label: 7
Output voltages: [0.38017, 0.17379, 0.28923, 0.33234, 0.19296, 0.11798, 0.05289, 0.75128, 0.27428, 0.37789]
Predicted label: 7
Correct prediction
Energy consumption = 183.515105 pJ
sum error= 255
Actual label: 6
Output voltages: [0.37806, 0.10162, 0.12374, 0.28184, 0.2411, 0.54075, 0.63679, 0.065295, 0.46738, 0.21516]
Predicted label: 6
Correct prediction
Energy consumption = 186.404125 pJ
sum error= 255
Actual label: 6
Output voltages: [0.3432, 0.10873, 0.20522, 0.1893, 0.34462, 0.43798, 0.6583, 0.043852, 0.47698, 0.15192]
Predicted label: 6
Correct prediction
Energy consumption = 184.378669 pJ
sum error= 255
Actual label: 6
Output voltages: [0.3266, 0.095941, 0.16161, 0.21417, 0.32258, 0.4706, 0.64144, 0.040703, 0.44286, 0.21552]
Predicted label: 6
Correct prediction
Energy consumption = 181.716188 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 667 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 667 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 667 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1545, 0.71242, 0.21937, 0.253, 0.38165, 0.08089, 0.33145, 0.14634, 0.31885, 0.1999]
Predicted label: 1
Correct prediction
Energy consumption = 202.687931 pJ
sum error= 255
Actual label: 9
Output voltages: [0.34378, 0.1416, 0.19319, 0.26781, 0.32324, 0.17775, 0.066341, 0.24086, 0.40137, 0.65514]
Predicted label: 9
Correct prediction
Energy consumption = 193.190096 pJ
sum error= 255
Actual label: 0
Output voltages: [0.64652, 0.17272, 0.22886, 0.077644, 0.20492, 0.17117, 0.46566, 0.28007, 0.28848, 0.30581]
Predicted label: 0
Correct prediction
Energy consumption = 195.815591 pJ
sum error= 255
Actual label: 1
Output voltages: [0.20338, 0.71895, 0.18714, 0.15844, 0.36464, 0.11816, 0.27949, 0.14037, 0.39834, 0.23843]
Predicted label: 1
Correct prediction
Energy consumption = 195.233189 pJ
sum error= 255
Actual label: 7
Output voltages: [0.36158, 0.18804, 0.27064, 0.32307, 0.18675, 0.11263, 0.050922, 0.7622, 0.25847, 0.34742]
Predicted label: 7
Correct prediction
Energy consumption = 190.434845 pJ
sum error= 255
Actual label: 6
Output voltages: [0.32563, 0.17236, 0.31387, 0.078516, 0.31735, 0.25741, 0.69301, 0.047047, 0.45319, 0.12853]
Predicted label: 6
Correct prediction
Energy consumption = 187.399325 pJ
sum error= 255
Actual label: 3
Output voltages: [0.35536, 0.12195, 0.4019, 0.73161, 0.22915, 0.18946, 0.10808, 0.19231, 0.5082, 0.14611]
Predicted label: 3
Correct prediction
Energy consumption = 186.771772 pJ
sum error= 255
Actual label: 2
Output voltages: [0.22859, 0.14439, 0.69123, 0.32376, 0.14445, 0.065217, 0.10217, 0.5155, 0.40939, 0.18751]
Predicted label: 2
Correct prediction
Energy consumption = 181.135254 pJ
sum error= 255
Actual label: 1
Output voltages: [0.26013, 0.74731, 0.16201, 0.15694, 0.37407, 0.1239, 0.29685, 0.17796, 0.3068, 0.26495]
Predicted label: 1
Correct prediction
Energy consumption = 207.432263 pJ
sum error= 255
Actual label: 7
Output voltages: [0.28221, 0.28576, 0.34614, 0.29979, 0.11256, 0.1099, 0.031041, 0.73897, 0.40351, 0.39946]
Predicted label: 7
Correct prediction
Energy consumption = 181.908332 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 668 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 668 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 668 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23907, 0.7236, 0.095216, 0.18286, 0.40246, 0.13839, 0.26665, 0.18585, 0.30621, 0.28929]
Predicted label: 1
Correct prediction
Energy consumption = 205.782653 pJ
sum error= 255
Actual label: 3
Output voltages: [0.43337, 0.13696, 0.34711, 0.74475, 0.083594, 0.2181, 0.14292, 0.16969, 0.4346, 0.18617]
Predicted label: 3
Correct prediction
Energy consumption = 197.378167 pJ
sum error= 255
Actual label: 9
Output voltages: [0.37206, 0.14572, 0.15646, 0.29834, 0.39526, 0.17834, 0.11287, 0.22746, 0.32491, 0.67029]
Predicted label: 9
Correct prediction
Energy consumption = 190.839365 pJ
sum error= 255
Actual label: 1
Output voltages: [0.20359, 0.74545, 0.19576, 0.21113, 0.37392, 0.073297, 0.30577, 0.18203, 0.25342, 0.27863]
Predicted label: 1
Correct prediction
Energy consumption = 201.490694 pJ
sum error= 255
Actual label: 7
Output voltages: [0.33341, 0.32258, 0.46241, 0.21588, 0.17311, 0.040453, 0.076068, 0.74034, 0.2447, 0.3211]
Predicted label: 7
Correct prediction
Energy consumption = 191.126258 pJ
sum error= 255
Actual label: 6
Output voltages: [0.28453, 0.17027, 0.33297, 0.065876, 0.36302, 0.35169, 0.74186, 0.069182, 0.40552, 0.12455]
Predicted label: 6
Correct prediction
Energy consumption = 183.956463 pJ
sum error= 255
Actual label: 8
Output voltages: [0.28745, 0.27754, 0.16033, 0.38232, 0.12831, 0.3552, 0.2342, 0.11589, 0.72092, 0.19809]
Predicted label: 8
Correct prediction
Energy consumption = 192.504384 pJ
sum error= 255
Actual label: 4
Output voltages: [0.11845, 0.19556, 0.29317, 0.20613, 0.75442, 0.087405, 0.25052, 0.31321, 0.15604, 0.22261]
Predicted label: 4
Correct prediction
Energy consumption = 187.276515 pJ
sum error= 255
Actual label: 1
Output voltages: [0.20844, 0.66596, 0.31012, 0.19843, 0.43862, 0.051203, 0.22079, 0.13885, 0.27317, 0.21778]
Predicted label: 1
Correct prediction
Energy consumption = 191.069359 pJ
sum error= 255
Actual label: 4
Output voltages: [0.20783, 0.13885, 0.348, 0.23222, 0.69615, 0.056535, 0.30789, 0.25834, 0.28066, 0.12288]
Predicted label: 4
Correct prediction
Energy consumption = 182.624774 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 669 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 669 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 669 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.20674, 0.17734, 0.31446, 0.73299, 0.16702, 0.22209, 0.087695, 0.2207, 0.56326, 0.1885]
Predicted label: 3
Correct prediction
Energy consumption = 184.815567 pJ
sum error= 255
Actual label: 6
Output voltages: [0.30658, 0.16673, 0.27247, 0.15461, 0.25877, 0.35648, 0.60999, 0.038607, 0.52711, 0.15633]
Predicted label: 6
Correct prediction
Energy consumption = 192.063039 pJ
sum error= 255
Actual label: 9
Output voltages: [0.34681, 0.10453, 0.12357, 0.16275, 0.36688, 0.28541, 0.06431, 0.28333, 0.41055, 0.60975]
Predicted label: 9
Correct prediction
Energy consumption = 191.314541 pJ
sum error= 255
Actual label: 6
Output voltages: [0.3012, 0.13687, 0.23543, 0.1433, 0.33753, 0.27988, 0.69017, 0.065047, 0.5082, 0.12693]
Predicted label: 6
Correct prediction
Energy consumption = 184.243398 pJ
sum error= 255
Actual label: 1
Output voltages: [0.18246, 0.68204, 0.34302, 0.22989, 0.36765, 0.053049, 0.20635, 0.21205, 0.29768, 0.16713]
Predicted label: 1
Correct prediction
Energy consumption = 195.360753 pJ
sum error= 255
Actual label: 4
Output voltages: [0.20209, 0.14761, 0.29556, 0.23705, 0.69556, 0.039655, 0.15467, 0.25432, 0.29899, 0.22511]
Predicted label: 4
Correct prediction
Energy consumption = 190.828883 pJ
sum error= 255
Actual label: 4
Output voltages: [0.13805, 0.21115, 0.29669, 0.26884, 0.73481, 0.042327, 0.1994, 0.31735, 0.18379, 0.23223]
Predicted label: 4
Correct prediction
Energy consumption = 183.430482 pJ
sum error= 255
Actual label: 7
Output voltages: [0.31561, 0.24912, 0.32408, 0.31285, 0.10347, 0.062978, 0.04031, 0.74517, 0.38102, 0.35964]
Predicted label: 7
Correct prediction
Energy consumption = 192.576670 pJ
sum error= 255
Actual label: 2
Output voltages: [0.38292, 0.19606, 0.74779, 0.35723, 0.14927, 0.045796, 0.24672, 0.20361, 0.38242, 0.14632]
Predicted label: 2
Correct prediction
Energy consumption = 189.925394 pJ
sum error= 255
Actual label: 4
Output voltages: [0.16315, 0.22767, 0.28652, 0.18055, 0.75463, 0.057555, 0.20044, 0.26757, 0.17032, 0.29396]
Predicted label: 4
Correct prediction
Energy consumption = 191.481956 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 670 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 670 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 670 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.29196, 0.24904, 0.23612, 0.12488, 0.72399, 0.10951, 0.41817, 0.14513, 0.24923, 0.21211]
Predicted label: 4
Correct prediction
Energy consumption = 196.433805 pJ
sum error= 255
Actual label: 0
Output voltages: [0.71356, 0.23803, 0.26115, 0.15237, 0.1625, 0.11174, 0.4324, 0.1835, 0.33631, 0.27706]
Predicted label: 0
Correct prediction
Energy consumption = 190.366280 pJ
sum error= 255
Actual label: 1
Output voltages: [0.11992, 0.75656, 0.21247, 0.18831, 0.27088, 0.138, 0.39415, 0.093406, 0.42294, 0.21358]
Predicted label: 1
Correct prediction
Energy consumption = 206.914077 pJ
sum error= 255
Actual label: 2
Output voltages: [0.35714, 0.17423, 0.73544, 0.32017, 0.14458, 0.03659, 0.2105, 0.31458, 0.44544, 0.15693]
Predicted label: 2
Correct prediction
Energy consumption = 184.539190 pJ
sum error= 255
Actual label: 3
Output voltages: [0.37143, 0.1214, 0.39039, 0.73789, 0.12463, 0.11171, 0.089844, 0.21139, 0.49311, 0.17905]
Predicted label: 3
Correct prediction
Energy consumption = 173.410832 pJ
sum error= 255
Actual label: 4
Output voltages: [0.21233, 0.11818, 0.29738, 0.14289, 0.75124, 0.13497, 0.30974, 0.23239, 0.30531, 0.16169]
Predicted label: 4
Correct prediction
Energy consumption = 193.199556 pJ
sum error= 255
Actual label: 5
Output voltages: [0.32728, 0.046034, 0.1896, 0.38848, 0.17649, 0.55687, 0.20455, 0.28357, 0.35568, 0.40194]
Predicted label: 5
Correct prediction
Energy consumption = 190.837201 pJ
sum error= 255
Actual label: 6
Output voltages: [0.2911, 0.21477, 0.29563, 0.088072, 0.37225, 0.30142, 0.74381, 0.083738, 0.36637, 0.10699]
Predicted label: 6
Correct prediction
Energy consumption = 188.716594 pJ
sum error= 255
Actual label: 7
Output voltages: [0.32906, 0.20967, 0.37747, 0.285, 0.14011, 0.072113, 0.034787, 0.66973, 0.43129, 0.37865]
Predicted label: 7
Correct prediction
Energy consumption = 191.408642 pJ
sum error= 255
Actual label: 8
Output voltages: [0.27634, 0.14263, 0.15817, 0.29423, 0.17394, 0.38547, 0.31107, 0.098243, 0.72401, 0.16106]
Predicted label: 8
Correct prediction
Energy consumption = 185.475312 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 671 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 671 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 671 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.44076, 0.11406, 0.17532, 0.18264, 0.26359, 0.14056, 0.23351, 0.15662, 0.36948, 0.63589]
Predicted label: 9
Correct prediction
Energy consumption = 195.927741 pJ
sum error= 255
Actual label: 0
Output voltages: [0.72658, 0.24227, 0.26589, 0.21735, 0.15904, 0.090167, 0.31543, 0.17935, 0.38388, 0.28074]
Predicted label: 0
Correct prediction
Energy consumption = 188.326297 pJ
sum error= 255
Actual label: 1
Output voltages: [0.25967, 0.73573, 0.31449, 0.14542, 0.35448, 0.066883, 0.40309, 0.047628, 0.26656, 0.25623]
Predicted label: 1
Correct prediction
Energy consumption = 203.983221 pJ
sum error= 255
Actual label: 2
Output voltages: [0.3768, 0.11947, 0.73765, 0.34602, 0.13946, 0.046524, 0.20549, 0.32237, 0.49381, 0.16921]
Predicted label: 2
Correct prediction
Energy consumption = 189.134201 pJ
sum error= 255
Actual label: 3
Output voltages: [0.35306, 0.20632, 0.29802, 0.76391, 0.14843, 0.18223, 0.11648, 0.23122, 0.43182, 0.25392]
Predicted label: 3
Correct prediction
Energy consumption = 177.746593 pJ
sum error= 255
Actual label: 4
Output voltages: [0.2203, 0.14771, 0.22826, 0.14605, 0.74384, 0.1014, 0.30363, 0.20042, 0.2853, 0.19766]
Predicted label: 4
Correct prediction
Energy consumption = 187.007736 pJ
sum error= 255
Actual label: 5
Output voltages: [0.35054, 0.071879, 0.070334, 0.29292, 0.35524, 0.66313, 0.42938, 0.059379, 0.35979, 0.16927]
Predicted label: 5
Correct prediction
Energy consumption = 186.532416 pJ
sum error= 255
Actual label: 6
Output voltages: [0.25966, 0.15682, 0.33904, 0.05361, 0.35779, 0.33884, 0.7333, 0.061886, 0.34638, 0.11432]
Predicted label: 6
Correct prediction
Energy consumption = 183.477981 pJ
sum error= 255
Actual label: 9
Output voltages: [0.35605, 0.079057, 0.15856, 0.14779, 0.32723, 0.20443, 0.23762, 0.16874, 0.42524, 0.55571]
Predicted label: 9
Correct prediction
Energy consumption = 189.956028 pJ
sum error= 255
Actual label: 0
Output voltages: [0.71572, 0.26376, 0.33743, 0.16536, 0.14445, 0.066014, 0.39511, 0.18472, 0.31615, 0.27628]
Predicted label: 0
Correct prediction
Energy consumption = 179.413627 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 672 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 672 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 672 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17144, 0.70298, 0.25218, 0.21238, 0.46858, 0.05699, 0.36342, 0.056845, 0.28624, 0.32791]
Predicted label: 1
Correct prediction
Energy consumption = 210.653611 pJ
sum error= 255
Actual label: 2
Output voltages: [0.20203, 0.16149, 0.68154, 0.35893, 0.21285, 0.030214, 0.22305, 0.39973, 0.4217, 0.25174]
Predicted label: 2
Correct prediction
Energy consumption = 180.723513 pJ
sum error= 255
Actual label: 3
Output voltages: [0.44388, 0.089024, 0.38137, 0.72609, 0.14763, 0.20845, 0.10014, 0.15976, 0.42759, 0.19467]
Predicted label: 3
Correct prediction
Energy consumption = 190.703792 pJ
sum error= 255
Actual label: 4
Output voltages: [0.24013, 0.16497, 0.32762, 0.12284, 0.69539, 0.049207, 0.31692, 0.29992, 0.22948, 0.1975]
Predicted label: 4
Correct prediction
Energy consumption = 188.190328 pJ
sum error= 255
Actual label: 7
Output voltages: [0.29303, 0.19388, 0.26444, 0.24633, 0.21997, 0.11919, 0.036187, 0.68449, 0.43169, 0.39641]
Predicted label: 7
Correct prediction
Energy consumption = 195.795828 pJ
sum error= 255
Actual label: 8
Output voltages: [0.2205, 0.11054, 0.25843, 0.18191, 0.30383, 0.22501, 0.33054, 0.071998, 0.67267, 0.29478]
Predicted label: 8
Correct prediction
Energy consumption = 190.051712 pJ
sum error= 255
Actual label: 1
Output voltages: [0.25885, 0.73782, 0.24674, 0.21077, 0.4246, 0.067752, 0.30154, 0.12882, 0.24158, 0.27811]
Predicted label: 1
Correct prediction
Energy consumption = 205.131973 pJ
sum error= 255
Actual label: 3
Output voltages: [0.29564, 0.16287, 0.28547, 0.74927, 0.22038, 0.15566, 0.10595, 0.25104, 0.50454, 0.24552]
Predicted label: 3
Correct prediction
Energy consumption = 182.063653 pJ
sum error= 255
Actual label: 5
Output voltages: [0.37526, 0.073513, 0.080259, 0.40629, 0.11379, 0.72611, 0.20636, 0.2031, 0.49019, 0.21645]
Predicted label: 5
Correct prediction
Energy consumption = 189.972493 pJ
sum error= 255
Actual label: 1
Output voltages: [0.1594, 0.76371, 0.2207, 0.21684, 0.25446, 0.1465, 0.44072, 0.16554, 0.31392, 0.22942]
Predicted label: 1
Correct prediction
Energy consumption = 199.298208 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 673 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 673 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 673 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24252, 0.18653, 0.33001, 0.24471, 0.27225, 0.054074, 0.027, 0.63466, 0.47297, 0.3179]
Predicted label: 7
Correct prediction
Energy consumption = 193.646072 pJ
sum error= 255
Actual label: 7
Output voltages: [0.27704, 0.3461, 0.35352, 0.27392, 0.17127, 0.076178, 0.037137, 0.73626, 0.27875, 0.36512]
Predicted label: 7
Correct prediction
Energy consumption = 185.914006 pJ
sum error= 255
Actual label: 2
Output voltages: [0.32995, 0.20468, 0.73362, 0.42271, 0.23028, 0.031244, 0.19984, 0.28446, 0.34156, 0.22324]
Predicted label: 2
Correct prediction
Energy consumption = 184.659309 pJ
sum error= 255
Actual label: 1
Output voltages: [0.20368, 0.70491, 0.2552, 0.12742, 0.33278, 0.14086, 0.37147, 0.079615, 0.37786, 0.17524]
Predicted label: 1
Correct prediction
Energy consumption = 196.406362 pJ
sum error= 255
Actual label: 4
Output voltages: [0.22939, 0.15883, 0.27732, 0.10235, 0.71889, 0.076342, 0.32824, 0.28008, 0.25139, 0.21566]
Predicted label: 4
Correct prediction
Energy consumption = 186.737919 pJ
sum error= 255
Actual label: 8
Output voltages: [0.39819, 0.22596, 0.25843, 0.22227, 0.18781, 0.31912, 0.30948, 0.15632, 0.72688, 0.17095]
Predicted label: 8
Correct prediction
Energy consumption = 191.418978 pJ
sum error= 255
Actual label: 3
Output voltages: [0.39403, 0.14867, 0.30565, 0.75353, 0.1867, 0.26156, 0.11342, 0.15641, 0.45396, 0.19098]
Predicted label: 3
Correct prediction
Energy consumption = 183.411122 pJ
sum error= 255
Actual label: 4
Output voltages: [0.26543, 0.083021, 0.33279, 0.09638, 0.6823, 0.090262, 0.32695, 0.12793, 0.41592, 0.12768]
Predicted label: 4
Correct prediction
Energy consumption = 190.449469 pJ
sum error= 255
Actual label: 4
Output voltages: [0.13672, 0.19082, 0.27563, 0.075022, 0.75797, 0.16024, 0.38849, 0.31926, 0.23204, 0.1912]
Predicted label: 4
Correct prediction
Energy consumption = 185.219242 pJ
sum error= 255
Actual label: 3
Output voltages: [0.30803, 0.095619, 0.36887, 0.67137, 0.086528, 0.20087, 0.090169, 0.21321, 0.61539, 0.20024]
Predicted label: 3
Correct prediction
Energy consumption = 180.059400 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 674 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 674 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 674 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.50753, 0.078165, 0.23592, 0.22219, 0.25287, 0.16208, 0.34217, 0.21042, 0.27692, 0.51912]
Predicted label: 9
Correct prediction
Energy consumption = 196.912922 pJ
sum error= 255
Actual label: 7
Output voltages: [0.3042, 0.17844, 0.22219, 0.20391, 0.23741, 0.12603, 0.030166, 0.64952, 0.46048, 0.42206]
Predicted label: 7
Correct prediction
Energy consumption = 187.279790 pJ
sum error= 255
Actual label: 4
Output voltages: [0.24711, 0.163, 0.30515, 0.15354, 0.74409, 0.049116, 0.28332, 0.24479, 0.25389, 0.21025]
Predicted label: 4
Correct prediction
Energy consumption = 183.234070 pJ
sum error= 255
Actual label: 1
Output voltages: [0.31242, 0.67293, 0.32843, 0.17086, 0.41795, 0.050189, 0.29595, 0.14504, 0.25573, 0.22639]
Predicted label: 1
Correct prediction
Energy consumption = 194.270324 pJ
sum error= 255
Actual label: 2
Output voltages: [0.1448, 0.12338, 0.62041, 0.32377, 0.1426, 0.05221, 0.2375, 0.55352, 0.52819, 0.13676]
Predicted label: 2
Correct prediction
Energy consumption = 188.702681 pJ
sum error= 255
Actual label: 3
Output voltages: [0.37069, 0.1319, 0.28545, 0.74897, 0.23285, 0.30894, 0.16359, 0.17612, 0.40394, 0.17743]
Predicted label: 3
Correct prediction
Energy consumption = 197.979147 pJ
sum error= 255
Actual label: 5
Output voltages: [0.21937, 0.046746, 0.16152, 0.27816, 0.33512, 0.51274, 0.34926, 0.092464, 0.50504, 0.17107]
Predicted label: 5
Correct prediction
Energy consumption = 185.112270 pJ
sum error= 255
Actual label: 9
Output voltages: [0.3526, 0.08756, 0.23772, 0.2206, 0.35929, 0.11524, 0.12122, 0.1673, 0.48434, 0.54175]
Predicted label: 9
Correct prediction
Energy consumption = 191.304092 pJ
sum error= 255
Actual label: 1
Output voltages: [0.19945, 0.70786, 0.248, 0.16546, 0.32524, 0.090381, 0.34845, 0.082841, 0.3874, 0.26484]
Predicted label: 1
Correct prediction
Energy consumption = 204.411579 pJ
sum error= 255
Actual label: 6
Output voltages: [0.34122, 0.1619, 0.22451, 0.21461, 0.27878, 0.38824, 0.64833, 0.078516, 0.48974, 0.16129]
Predicted label: 6
Correct prediction
Energy consumption = 186.257246 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 675 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 675 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 675 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.71424, 0.20191, 0.25798, 0.14049, 0.20612, 0.096976, 0.43881, 0.20366, 0.27817, 0.34305]
Predicted label: 0
Correct prediction
Energy consumption = 192.479780 pJ
sum error= 255
Actual label: 1
Output voltages: [0.28748, 0.67473, 0.28425, 0.12759, 0.42512, 0.062018, 0.31281, 0.088649, 0.31803, 0.27546]
Predicted label: 1
Correct prediction
Energy consumption = 201.881805 pJ
sum error= 255
Actual label: 0
Output voltages: [0.73669, 0.25249, 0.2678, 0.16685, 0.16993, 0.11383, 0.37783, 0.21372, 0.31421, 0.27975]
Predicted label: 0
Correct prediction
Energy consumption = 186.420401 pJ
sum error= 255
Actual label: 0
Output voltages: [0.71146, 0.23449, 0.32067, 0.13498, 0.13102, 0.08513, 0.44671, 0.19886, 0.27046, 0.30533]
Predicted label: 0
Correct prediction
Energy consumption = 180.192764 pJ
sum error= 255
Actual label: 2
Output voltages: [0.31845, 0.18595, 0.71297, 0.3304, 0.24042, 0.026366, 0.20243, 0.43367, 0.36524, 0.22244]
Predicted label: 2
Correct prediction
Energy consumption = 184.052743 pJ
sum error= 255
Actual label: 8
Output voltages: [0.30868, 0.24334, 0.27234, 0.27943, 0.12897, 0.11051, 0.15318, 0.17737, 0.67647, 0.3753]
Predicted label: 8
Correct prediction
Energy consumption = 199.084256 pJ
sum error= 255
Actual label: 7
Output voltages: [0.40795, 0.16817, 0.49578, 0.22986, 0.17145, 0.069353, 0.047077, 0.49382, 0.47295, 0.42024]
Predicted label: 2
Wrong prediction!
Energy consumption = 185.081378 pJ
sum error= 256
Actual label: 1
Output voltages: [0.27858, 0.74407, 0.25656, 0.26416, 0.28334, 0.070862, 0.38458, 0.081221, 0.292, 0.2485]
Predicted label: 1
Correct prediction
Energy consumption = 196.255505 pJ
sum error= 256
Actual label: 1
Output voltages: [0.24763, 0.68708, 0.33101, 0.20302, 0.32073, 0.045263, 0.34191, 0.076567, 0.31633, 0.2794]
Predicted label: 1
Correct prediction
Energy consumption = 190.216497 pJ
sum error= 256
Actual label: 4
Output voltages: [0.27128, 0.10891, 0.33216, 0.063861, 0.68222, 0.0663, 0.31124, 0.17497, 0.40417, 0.21944]
Predicted label: 4
Correct prediction
Energy consumption = 186.688757 pJ
sum error= 256
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 676 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 676 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 676 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.66674, 0.20741, 0.28212, 0.16395, 0.139, 0.11038, 0.49175, 0.16435, 0.31181, 0.3005]
Predicted label: 0
Correct prediction
Energy consumption = 191.091375 pJ
sum error= 256
Actual label: 4
Output voltages: [0.19653, 0.15344, 0.2186, 0.20976, 0.72469, 0.086658, 0.3091, 0.19914, 0.30419, 0.18238]
Predicted label: 4
Correct prediction
Energy consumption = 187.774771 pJ
sum error= 256
Actual label: 7
Output voltages: [0.33944, 0.21914, 0.42793, 0.32845, 0.12073, 0.046492, 0.041313, 0.66003, 0.43632, 0.3802]
Predicted label: 7
Correct prediction
Energy consumption = 190.899193 pJ
sum error= 256
Actual label: 3
Output voltages: [0.4228, 0.09996, 0.32019, 0.73441, 0.16191, 0.26003, 0.086824, 0.12744, 0.44928, 0.20906]
Predicted label: 3
Correct prediction
Energy consumption = 185.815942 pJ
sum error= 256
Actual label: 6
Output voltages: [0.22467, 0.14821, 0.31376, 0.17684, 0.2928, 0.39892, 0.70352, 0.077705, 0.43041, 0.12167]
Predicted label: 6
Correct prediction
Energy consumption = 193.262768 pJ
sum error= 256
Actual label: 8
Output voltages: [0.30033, 0.073831, 0.17129, 0.29715, 0.31659, 0.38622, 0.4488, 0.058654, 0.63112, 0.18976]
Predicted label: 8
Correct prediction
Energy consumption = 184.261640 pJ
sum error= 256
Actual label: 0
Output voltages: [0.7306, 0.26709, 0.29591, 0.18182, 0.15288, 0.090931, 0.37277, 0.18413, 0.32744, 0.28531]
Predicted label: 0
Correct prediction
Energy consumption = 187.367078 pJ
sum error= 256
Actual label: 3
Output voltages: [0.38997, 0.094121, 0.37861, 0.72927, 0.14467, 0.20075, 0.13554, 0.24704, 0.51665, 0.16767]
Predicted label: 3
Correct prediction
Energy consumption = 185.431582 pJ
sum error= 256
Actual label: 7
Output voltages: [0.19424, 0.29463, 0.57142, 0.30539, 0.082833, 0.044054, 0.04883, 0.57675, 0.4585, 0.21587]
Predicted label: 7
Correct prediction
Energy consumption = 185.422835 pJ
sum error= 256
Actual label: 4
Output voltages: [0.21891, 0.14641, 0.31441, 0.073654, 0.66611, 0.10476, 0.3458, 0.13202, 0.41259, 0.17678]
Predicted label: 4
Correct prediction
Energy consumption = 186.635300 pJ
sum error= 256
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 677 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 677 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 677 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73948, 0.25769, 0.31209, 0.18146, 0.13396, 0.11078, 0.39518, 0.18176, 0.3223, 0.25525]
Predicted label: 0
Correct prediction
Energy consumption = 188.500724 pJ
sum error= 256
Actual label: 6
Output voltages: [0.30133, 0.27661, 0.32217, 0.10018, 0.37749, 0.29687, 0.72508, 0.11918, 0.30384, 0.06621]
Predicted label: 6
Correct prediction
Energy consumption = 189.008296 pJ
sum error= 256
Actual label: 9
Output voltages: [0.34924, 0.10994, 0.21016, 0.26803, 0.47213, 0.090902, 0.14902, 0.15101, 0.34016, 0.51751]
Predicted label: 9
Correct prediction
Energy consumption = 197.442912 pJ
sum error= 256
Actual label: 2
Output voltages: [0.37928, 0.10797, 0.73278, 0.36042, 0.14689, 0.047721, 0.25312, 0.26833, 0.47171, 0.17167]
Predicted label: 2
Correct prediction
Energy consumption = 187.253464 pJ
sum error= 256
Actual label: 6
Output voltages: [0.2634, 0.16546, 0.32086, 0.078084, 0.35874, 0.25867, 0.70294, 0.067076, 0.48363, 0.11614]
Predicted label: 6
Correct prediction
Energy consumption = 188.276578 pJ
sum error= 256
Actual label: 5
Output voltages: [0.26385, 0.055772, 0.073964, 0.39198, 0.16217, 0.69933, 0.24048, 0.19405, 0.44722, 0.26625]
Predicted label: 5
Correct prediction
Energy consumption = 185.667379 pJ
sum error= 256
Actual label: 8
Output voltages: [0.21156, 0.15849, 0.29576, 0.29854, 0.14471, 0.31912, 0.33044, 0.10717, 0.72486, 0.24306]
Predicted label: 8
Correct prediction
Energy consumption = 190.024020 pJ
sum error= 256
Actual label: 6
Output voltages: [0.34315, 0.19489, 0.28364, 0.11302, 0.25901, 0.36886, 0.70054, 0.058718, 0.45688, 0.16335]
Predicted label: 6
Correct prediction
Energy consumption = 185.074775 pJ
sum error= 256
Actual label: 9
Output voltages: [0.35446, 0.1613, 0.20547, 0.22559, 0.25837, 0.13222, 0.084109, 0.17485, 0.44434, 0.64343]
Predicted label: 9
Correct prediction
Energy consumption = 194.533815 pJ
sum error= 256
Actual label: 0
Output voltages: [0.73069, 0.23555, 0.26441, 0.18036, 0.15428, 0.13557, 0.37013, 0.13884, 0.34425, 0.22593]
Predicted label: 0
Correct prediction
Energy consumption = 189.338752 pJ
sum error= 256
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 678 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 678 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 678 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.29938, 0.070673, 0.32569, 0.15056, 0.57811, 0.08024, 0.20282, 0.13951, 0.44857, 0.31935]
Predicted label: 4
Correct prediction
Energy consumption = 190.194562 pJ
sum error= 256
Actual label: 0
Output voltages: [0.70588, 0.28561, 0.32647, 0.15156, 0.19018, 0.05484, 0.43195, 0.14996, 0.32432, 0.27749]
Predicted label: 0
Correct prediction
Energy consumption = 187.439397 pJ
sum error= 256
Actual label: 6
Output voltages: [0.28181, 0.095934, 0.24948, 0.20864, 0.30309, 0.28462, 0.63605, 0.044058, 0.49072, 0.23067]
Predicted label: 6
Correct prediction
Energy consumption = 184.836620 pJ
sum error= 256
Actual label: 1
Output voltages: [0.31182, 0.42686, 0.27078, 0.29394, 0.34785, 0.16113, 0.58876, 0.11817, 0.39978, 0.065823]
Predicted label: 6
Wrong prediction!
Energy consumption = 203.378474 pJ
sum error= 257
Actual label: 9
Output voltages: [0.36279, 0.095729, 0.19095, 0.25572, 0.36551, 0.14443, 0.18393, 0.13723, 0.40499, 0.5713]
Predicted label: 9
Correct prediction
Energy consumption = 191.959773 pJ
sum error= 257
Actual label: 2
Output voltages: [0.22975, 0.088077, 0.60941, 0.50014, 0.27981, 0.056116, 0.26665, 0.29751, 0.36116, 0.21565]
Predicted label: 2
Correct prediction
Energy consumption = 185.006797 pJ
sum error= 257
Actual label: 0
Output voltages: [0.74493, 0.23882, 0.30688, 0.14917, 0.19673, 0.10377, 0.33502, 0.20528, 0.29941, 0.20672]
Predicted label: 0
Correct prediction
Energy consumption = 194.687634 pJ
sum error= 257
Actual label: 9
Output voltages: [0.34043, 0.16916, 0.14096, 0.27352, 0.36112, 0.096656, 0.10456, 0.13513, 0.40353, 0.62996]
Predicted label: 9
Correct prediction
Energy consumption = 199.958877 pJ
sum error= 257
Actual label: 5
Output voltages: [0.24072, 0.14325, 0.10048, 0.58084, 0.26969, 0.6109, 0.24903, 0.13483, 0.4541, 0.16879]
Predicted label: 5
Correct prediction
Energy consumption = 188.016886 pJ
sum error= 257
Actual label: 1
Output voltages: [0.23637, 0.74432, 0.26984, 0.16482, 0.4397, 0.1011, 0.42023, 0.11459, 0.18181, 0.254]
Predicted label: 1
Correct prediction
Energy consumption = 199.641697 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 679 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 679 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 679 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36254, 0.092225, 0.47541, 0.65724, 0.13711, 0.18694, 0.079288, 0.18575, 0.45348, 0.17448]
Predicted label: 3
Correct prediction
Energy consumption = 195.853856 pJ
sum error= 257
Actual label: 7
Output voltages: [0.29358, 0.25306, 0.38744, 0.24804, 0.21921, 0.056216, 0.030234, 0.6993, 0.3913, 0.33969]
Predicted label: 7
Correct prediction
Energy consumption = 189.833954 pJ
sum error= 257
Actual label: 6
Output voltages: [0.29659, 0.15102, 0.27936, 0.10673, 0.34502, 0.30498, 0.71933, 0.069553, 0.42132, 0.13219]
Predicted label: 6
Correct prediction
Energy consumption = 191.465877 pJ
sum error= 257
Actual label: 9
Output voltages: [0.33657, 0.12943, 0.23269, 0.21139, 0.42494, 0.12115, 0.11732, 0.17236, 0.41864, 0.55591]
Predicted label: 9
Correct prediction
Energy consumption = 193.270957 pJ
sum error= 257
Actual label: 3
Output voltages: [0.31945, 0.11521, 0.26077, 0.74253, 0.15185, 0.23512, 0.097455, 0.33878, 0.56772, 0.20258]
Predicted label: 3
Correct prediction
Energy consumption = 185.165472 pJ
sum error= 257
Actual label: 0
Output voltages: [0.73566, 0.23184, 0.2179, 0.16521, 0.18822, 0.16561, 0.42697, 0.17073, 0.29022, 0.25074]
Predicted label: 0
Correct prediction
Energy consumption = 192.400961 pJ
sum error= 257
Actual label: 2
Output voltages: [0.46043, 0.086205, 0.64453, 0.23633, 0.16798, 0.049847, 0.13169, 0.59085, 0.33258, 0.19595]
Predicted label: 2
Correct prediction
Energy consumption = 181.358739 pJ
sum error= 257
Actual label: 2
Output voltages: [0.40769, 0.24542, 0.7391, 0.29767, 0.093221, 0.042528, 0.2716, 0.27801, 0.41495, 0.14449]
Predicted label: 2
Correct prediction
Energy consumption = 189.486764 pJ
sum error= 257
Actual label: 0
Output voltages: [0.72815, 0.28043, 0.14702, 0.18304, 0.15529, 0.25895, 0.4104, 0.17969, 0.27187, 0.27909]
Predicted label: 0
Correct prediction
Energy consumption = 195.276238 pJ
sum error= 257
Actual label: 1
Output voltages: [0.16667, 0.76548, 0.25901, 0.25011, 0.21066, 0.083048, 0.4632, 0.16079, 0.29782, 0.1714]
Predicted label: 1
Correct prediction
Energy consumption = 204.408832 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 680 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 680 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 680 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.34488, 0.35055, 0.62939, 0.42389, 0.15898, 0.035625, 0.39975, 0.098905, 0.38068, 0.14161]
Predicted label: 2
Correct prediction
Energy consumption = 189.766751 pJ
sum error= 257
Actual label: 3
Output voltages: [0.42654, 0.15242, 0.29453, 0.75312, 0.13648, 0.22457, 0.22476, 0.19386, 0.35986, 0.14567]
Predicted label: 3
Correct prediction
Energy consumption = 187.185099 pJ
sum error= 257
Actual label: 4
Output voltages: [0.10246, 0.16904, 0.28897, 0.057266, 0.75319, 0.10727, 0.3966, 0.27285, 0.28453, 0.24408]
Predicted label: 4
Correct prediction
Energy consumption = 202.447252 pJ
sum error= 257
Actual label: 5
Output voltages: [0.26249, 0.056036, 0.084807, 0.35697, 0.26378, 0.72591, 0.38481, 0.16499, 0.41715, 0.24124]
Predicted label: 5
Correct prediction
Energy consumption = 185.008723 pJ
sum error= 257
Actual label: 6
Output voltages: [0.30304, 0.24663, 0.28489, 0.13013, 0.30504, 0.39478, 0.74924, 0.095924, 0.41857, 0.1355]
Predicted label: 6
Correct prediction
Energy consumption = 184.764646 pJ
sum error= 257
Actual label: 7
Output voltages: [0.30988, 0.33079, 0.32473, 0.36154, 0.10528, 0.042084, 0.057425, 0.74002, 0.22795, 0.36863]
Predicted label: 7
Correct prediction
Energy consumption = 206.718069 pJ
sum error= 257
Actual label: 8
Output voltages: [0.21717, 0.26778, 0.32802, 0.3348, 0.12725, 0.12224, 0.14501, 0.13475, 0.69451, 0.35047]
Predicted label: 8
Correct prediction
Energy consumption = 195.719826 pJ
sum error= 257
Actual label: 9
Output voltages: [0.29312, 0.12033, 0.21086, 0.19587, 0.25665, 0.17928, 0.07968, 0.25936, 0.46035, 0.65733]
Predicted label: 9
Correct prediction
Energy consumption = 190.324557 pJ
sum error= 257
Actual label: 0
Output voltages: [0.71371, 0.21055, 0.24464, 0.1541, 0.1729, 0.22053, 0.44677, 0.19279, 0.28627, 0.24434]
Predicted label: 0
Correct prediction
Energy consumption = 198.651646 pJ
sum error= 257
Actual label: 1
Output voltages: [0.2829, 0.76338, 0.19928, 0.29981, 0.24853, 0.076451, 0.27253, 0.20294, 0.32333, 0.27593]
Predicted label: 1
Correct prediction
Energy consumption = 214.059786 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 681 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 681 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 681 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35015, 0.40863, 0.71486, 0.29907, 0.14779, 0.024879, 0.31801, 0.2647, 0.3589, 0.23134]
Predicted label: 2
Correct prediction
Energy consumption = 190.235916 pJ
sum error= 257
Actual label: 3
Output voltages: [0.3391, 0.18685, 0.27082, 0.75354, 0.2794, 0.24166, 0.21945, 0.19718, 0.3433, 0.19416]
Predicted label: 3
Correct prediction
Energy consumption = 189.986446 pJ
sum error= 257
Actual label: 4
Output voltages: [0.18278, 0.19496, 0.27871, 0.12057, 0.75053, 0.059321, 0.34808, 0.27427, 0.2363, 0.22893]
Predicted label: 4
Correct prediction
Energy consumption = 200.388612 pJ
sum error= 257
Actual label: 5
Output voltages: [0.22038, 0.050872, 0.12754, 0.31022, 0.28543, 0.68893, 0.3831, 0.13591, 0.51349, 0.25113]
Predicted label: 5
Correct prediction
Energy consumption = 184.780715 pJ
sum error= 257
Actual label: 6
Output voltages: [0.256, 0.13957, 0.28228, 0.1186, 0.39044, 0.34585, 0.73038, 0.081746, 0.37273, 0.18124]
Predicted label: 6
Correct prediction
Energy consumption = 185.780088 pJ
sum error= 257
Actual label: 7
Output voltages: [0.30785, 0.21028, 0.24042, 0.27497, 0.16572, 0.11349, 0.058247, 0.76999, 0.30991, 0.32203]
Predicted label: 7
Correct prediction
Energy consumption = 199.614316 pJ
sum error= 257
Actual label: 8
Output voltages: [0.23997, 0.16382, 0.32039, 0.34906, 0.12027, 0.20773, 0.23623, 0.091476, 0.71811, 0.27663]
Predicted label: 8
Correct prediction
Energy consumption = 196.410579 pJ
sum error= 257
Actual label: 9
Output voltages: [0.30157, 0.066912, 0.15624, 0.25587, 0.2987, 0.22125, 0.056745, 0.30921, 0.42841, 0.62796]
Predicted label: 9
Correct prediction
Energy consumption = 193.069628 pJ
sum error= 257
Actual label: 0
Output voltages: [0.69616, 0.12092, 0.23366, 0.32781, 0.11445, 0.18112, 0.30815, 0.18749, 0.42722, 0.28154]
Predicted label: 0
Correct prediction
Energy consumption = 200.977017 pJ
sum error= 257
Actual label: 1
Output voltages: [0.12726, 0.76446, 0.23782, 0.22623, 0.2465, 0.14163, 0.42381, 0.13717, 0.3421, 0.21869]
Predicted label: 1
Correct prediction
Energy consumption = 209.542212 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 682 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 682 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 682 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.3515, 0.41151, 0.72279, 0.31633, 0.14355, 0.02654, 0.27643, 0.23342, 0.3036, 0.20728]
Predicted label: 2
Correct prediction
Energy consumption = 187.715634 pJ
sum error= 257
Actual label: 3
Output voltages: [0.45779, 0.21372, 0.28957, 0.75288, 0.13133, 0.25535, 0.23409, 0.22512, 0.31344, 0.11974]
Predicted label: 3
Correct prediction
Energy consumption = 186.240500 pJ
sum error= 257
Actual label: 4
Output voltages: [0.20204, 0.10493, 0.31693, 0.14499, 0.75298, 0.074385, 0.25993, 0.24039, 0.24562, 0.28891]
Predicted label: 4
Correct prediction
Energy consumption = 200.840759 pJ
sum error= 257
Actual label: 5
Output voltages: [0.1672, 0.05168, 0.16283, 0.47934, 0.23826, 0.61922, 0.30565, 0.17841, 0.4305, 0.22458]
Predicted label: 5
Correct prediction
Energy consumption = 192.399612 pJ
sum error= 257
Actual label: 6
Output voltages: [0.28063, 0.19797, 0.26461, 0.13935, 0.3437, 0.40367, 0.74083, 0.05248, 0.37769, 0.18584]
Predicted label: 6
Correct prediction
Energy consumption = 183.236428 pJ
sum error= 257
Actual label: 7
Output voltages: [0.26156, 0.31894, 0.26662, 0.35924, 0.11434, 0.045902, 0.046059, 0.73993, 0.3434, 0.32788]
Predicted label: 7
Correct prediction
Energy consumption = 204.403903 pJ
sum error= 257
Actual label: 8
Output voltages: [0.22762, 0.15832, 0.35339, 0.23437, 0.16651, 0.15898, 0.17899, 0.12564, 0.7387, 0.34037]
Predicted label: 8
Correct prediction
Energy consumption = 192.065299 pJ
sum error= 257
Actual label: 9
Output voltages: [0.23909, 0.14505, 0.15738, 0.21735, 0.2706, 0.12088, 0.056464, 0.20725, 0.48648, 0.59128]
Predicted label: 9
Correct prediction
Energy consumption = 199.241462 pJ
sum error= 257
Actual label: 2
Output voltages: [0.31347, 0.35916, 0.74508, 0.30468, 0.19578, 0.024646, 0.2916, 0.26396, 0.33179, 0.26597]
Predicted label: 2
Correct prediction
Energy consumption = 191.820559 pJ
sum error= 257
Actual label: 1
Output voltages: [0.23957, 0.75839, 0.21257, 0.24155, 0.16625, 0.12726, 0.27805, 0.11283, 0.43639, 0.21939]
Predicted label: 1
Correct prediction
Energy consumption = 205.377012 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 683 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 683 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 683 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.31133, 0.21292, 0.23861, 0.23039, 0.1909, 0.14983, 0.04708, 0.75693, 0.30824, 0.42824]
Predicted label: 7
Correct prediction
Energy consumption = 200.272123 pJ
sum error= 257
Actual label: 2
Output voltages: [0.34364, 0.35156, 0.72703, 0.32213, 0.1495, 0.026622, 0.30653, 0.1687, 0.39181, 0.26218]
Predicted label: 2
Correct prediction
Energy consumption = 190.035508 pJ
sum error= 257
Actual label: 5
Output voltages: [0.27792, 0.051257, 0.14182, 0.3675, 0.14393, 0.69835, 0.27892, 0.18539, 0.55882, 0.25282]
Predicted label: 5
Correct prediction
Energy consumption = 185.280027 pJ
sum error= 257
Actual label: 0
Output voltages: [0.73437, 0.25601, 0.20109, 0.18834, 0.15084, 0.19772, 0.4025, 0.16432, 0.28513, 0.37733]
Predicted label: 0
Correct prediction
Energy consumption = 190.309218 pJ
sum error= 257
Actual label: 8
Output voltages: [0.25678, 0.16058, 0.28911, 0.30222, 0.13971, 0.20304, 0.11779, 0.18304, 0.73775, 0.37133]
Predicted label: 8
Correct prediction
Energy consumption = 191.390316 pJ
sum error= 257
Actual label: 0
Output voltages: [0.71406, 0.1768, 0.31693, 0.18481, 0.13322, 0.26441, 0.39454, 0.10232, 0.25795, 0.29188]
Predicted label: 0
Correct prediction
Energy consumption = 194.771055 pJ
sum error= 257
Actual label: 2
Output voltages: [0.41401, 0.31228, 0.65375, 0.33841, 0.12395, 0.03655, 0.3938, 0.24805, 0.37318, 0.10253]
Predicted label: 2
Correct prediction
Energy consumption = 192.290608 pJ
sum error= 257
Actual label: 7
Output voltages: [0.32434, 0.21397, 0.3039, 0.27823, 0.08061, 0.057785, 0.043312, 0.74044, 0.41102, 0.33447]
Predicted label: 7
Correct prediction
Energy consumption = 196.823348 pJ
sum error= 257
Actual label: 8
Output voltages: [0.20515, 0.22204, 0.28331, 0.24846, 0.17741, 0.19725, 0.20092, 0.15233, 0.74435, 0.33288]
Predicted label: 8
Correct prediction
Energy consumption = 193.367462 pJ
sum error= 257
Actual label: 8
Output voltages: [0.29222, 0.14715, 0.30532, 0.34814, 0.096718, 0.25483, 0.18414, 0.15928, 0.74294, 0.29926]
Predicted label: 8
Correct prediction
Energy consumption = 187.201553 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 684 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 684 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 684 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.46481, 0.26244, 0.27683, 0.7483, 0.11821, 0.24015, 0.27423, 0.2393, 0.32236, 0.10699]
Predicted label: 3
Correct prediction
Energy consumption = 193.743240 pJ
sum error= 257
Actual label: 0
Output voltages: [0.71842, 0.15663, 0.39513, 0.33162, 0.14982, 0.10539, 0.25654, 0.17943, 0.36111, 0.30529]
Predicted label: 0
Correct prediction
Energy consumption = 199.454765 pJ
sum error= 257
Actual label: 6
Output voltages: [0.33427, 0.27736, 0.31505, 0.17019, 0.28417, 0.34334, 0.74562, 0.068696, 0.39229, 0.22389]
Predicted label: 6
Correct prediction
Energy consumption = 194.319164 pJ
sum error= 257
Actual label: 0
Output voltages: [0.71189, 0.14333, 0.22559, 0.16102, 0.21587, 0.21552, 0.42736, 0.20848, 0.31349, 0.31228]
Predicted label: 0
Correct prediction
Energy consumption = 200.799802 pJ
sum error= 257
Actual label: 2
Output voltages: [0.37295, 0.37315, 0.68999, 0.41465, 0.14044, 0.036355, 0.31446, 0.14906, 0.34414, 0.18767]
Predicted label: 2
Correct prediction
Energy consumption = 191.416901 pJ
sum error= 257
Actual label: 7
Output voltages: [0.32093, 0.24368, 0.3081, 0.40547, 0.084712, 0.07021, 0.04898, 0.7514, 0.26311, 0.35694]
Predicted label: 7
Correct prediction
Energy consumption = 199.778465 pJ
sum error= 257
Actual label: 6
Output voltages: [0.29985, 0.18581, 0.30537, 0.12756, 0.35441, 0.3648, 0.73854, 0.12179, 0.29591, 0.18379]
Predicted label: 6
Correct prediction
Energy consumption = 195.556517 pJ
sum error= 257
Actual label: 6
Output voltages: [0.21412, 0.17322, 0.21072, 0.14996, 0.45098, 0.3828, 0.6506, 0.14071, 0.28809, 0.16857]
Predicted label: 6
Correct prediction
Energy consumption = 189.665491 pJ
sum error= 257
Actual label: 1
Output voltages: [0.21375, 0.76665, 0.30595, 0.38847, 0.15518, 0.099291, 0.30472, 0.2174, 0.26968, 0.20667]
Predicted label: 1
Correct prediction
Energy consumption = 216.550340 pJ
sum error= 257
Actual label: 2
Output voltages: [0.34004, 0.46163, 0.66203, 0.38487, 0.14127, 0.02757, 0.27392, 0.20791, 0.2918, 0.22742]
Predicted label: 2
Correct prediction
Energy consumption = 182.232929 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 685 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 685 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 685 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2572, 0.16544, 0.35624, 0.28519, 0.17185, 0.13598, 0.16326, 0.10169, 0.73183, 0.31053]
Predicted label: 8
Correct prediction
Energy consumption = 198.249230 pJ
sum error= 257
Actual label: 8
Output voltages: [0.29537, 0.22699, 0.47375, 0.25972, 0.19241, 0.052158, 0.24297, 0.12472, 0.68053, 0.29583]
Predicted label: 8
Correct prediction
Energy consumption = 193.069134 pJ
sum error= 257
Actual label: 7
Output voltages: [0.35304, 0.31974, 0.27303, 0.32133, 0.11434, 0.061265, 0.048394, 0.70651, 0.2139, 0.40035]
Predicted label: 7
Correct prediction
Energy consumption = 208.596014 pJ
sum error= 257
Actual label: 7
Output voltages: [0.26538, 0.2914, 0.29447, 0.31653, 0.10064, 0.047014, 0.053233, 0.75072, 0.32151, 0.33626]
Predicted label: 7
Correct prediction
Energy consumption = 200.005609 pJ
sum error= 257
Actual label: 4
Output voltages: [0.053033, 0.2347, 0.072876, 0.083884, 0.7103, 0.24178, 0.2984, 0.26423, 0.34902, 0.30766]
Predicted label: 4
Correct prediction
Energy consumption = 202.302800 pJ
sum error= 257
Actual label: 7
Output voltages: [0.36386, 0.17221, 0.14393, 0.22071, 0.23659, 0.21104, 0.042814, 0.75743, 0.26725, 0.40715]
Predicted label: 7
Correct prediction
Energy consumption = 201.171515 pJ
sum error= 257
Actual label: 7
Output voltages: [0.28566, 0.31145, 0.23082, 0.27512, 0.15572, 0.11625, 0.044518, 0.75142, 0.2405, 0.39573]
Predicted label: 7
Correct prediction
Energy consumption = 192.015446 pJ
sum error= 257
Actual label: 3
Output voltages: [0.38725, 0.16479, 0.30091, 0.75737, 0.19692, 0.23636, 0.18188, 0.16492, 0.41058, 0.21855]
Predicted label: 3
Correct prediction
Energy consumption = 185.681934 pJ
sum error= 257
Actual label: 7
Output voltages: [0.29193, 0.17342, 0.11305, 0.30423, 0.18727, 0.19227, 0.038166, 0.7239, 0.32996, 0.41221]
Predicted label: 7
Correct prediction
Energy consumption = 200.946402 pJ
sum error= 257
Actual label: 4
Output voltages: [0.090445, 0.17709, 0.2308, 0.12867, 0.74174, 0.061653, 0.24672, 0.38261, 0.33063, 0.16522]
Predicted label: 4
Correct prediction
Energy consumption = 189.792150 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 686 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 686 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 686 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25002, 0.057844, 0.085691, 0.41933, 0.2232, 0.72624, 0.3481, 0.2113, 0.4614, 0.2656]
Predicted label: 5
Correct prediction
Energy consumption = 186.590210 pJ
sum error= 257
Actual label: 4
Output voltages: [0.1462, 0.14786, 0.29233, 0.15369, 0.75915, 0.074622, 0.23502, 0.32324, 0.24026, 0.25046]
Predicted label: 4
Correct prediction
Energy consumption = 194.576237 pJ
sum error= 257
Actual label: 3
Output voltages: [0.35531, 0.21093, 0.27877, 0.7615, 0.18643, 0.20069, 0.18927, 0.15554, 0.37581, 0.26248]
Predicted label: 3
Correct prediction
Energy consumption = 188.283520 pJ
sum error= 257
Actual label: 3
Output voltages: [0.37737, 0.19483, 0.28064, 0.75892, 0.22401, 0.19437, 0.15924, 0.17208, 0.40213, 0.22963]
Predicted label: 3
Correct prediction
Energy consumption = 177.949160 pJ
sum error= 257
Actual label: 8
Output voltages: [0.30262, 0.13933, 0.371, 0.42627, 0.075428, 0.19295, 0.18712, 0.15201, 0.72753, 0.26939]
Predicted label: 8
Correct prediction
Energy consumption = 193.805236 pJ
sum error= 257
Actual label: 4
Output voltages: [0.14604, 0.14533, 0.28312, 0.13415, 0.75167, 0.076961, 0.27242, 0.30363, 0.26874, 0.23339]
Predicted label: 4
Correct prediction
Energy consumption = 198.078447 pJ
sum error= 257
Actual label: 5
Output voltages: [0.25992, 0.06112, 0.067591, 0.3981, 0.24622, 0.73573, 0.36074, 0.19437, 0.46097, 0.26846]
Predicted label: 5
Correct prediction
Energy consumption = 192.343479 pJ
sum error= 257
Actual label: 4
Output voltages: [0.13266, 0.22822, 0.18808, 0.25191, 0.71481, 0.050194, 0.24147, 0.23433, 0.26275, 0.22432]
Predicted label: 4
Correct prediction
Energy consumption = 207.846134 pJ
sum error= 257
Actual label: 1
Output voltages: [0.18303, 0.75851, 0.32323, 0.21274, 0.25206, 0.059668, 0.40956, 0.13844, 0.29842, 0.22175]
Predicted label: 1
Correct prediction
Energy consumption = 207.549635 pJ
sum error= 257
Actual label: 1
Output voltages: [0.21344, 0.75427, 0.31423, 0.32238, 0.3022, 0.045308, 0.24955, 0.13417, 0.27861, 0.29511]
Predicted label: 1
Correct prediction
Energy consumption = 206.425534 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 687 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 687 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 687 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3535, 0.071739, 0.23016, 0.16695, 0.31403, 0.20699, 0.098682, 0.26956, 0.42123, 0.65697]
Predicted label: 9
Correct prediction
Energy consumption = 197.806534 pJ
sum error= 257
Actual label: 7
Output voltages: [0.37735, 0.20149, 0.3699, 0.41873, 0.081043, 0.048475, 0.068703, 0.68949, 0.3435, 0.37797]
Predicted label: 7
Correct prediction
Energy consumption = 199.906201 pJ
sum error= 257
Actual label: 4
Output voltages: [0.30544, 0.16626, 0.39448, 0.16006, 0.67313, 0.039371, 0.35569, 0.26787, 0.15145, 0.18717]
Predicted label: 4
Correct prediction
Energy consumption = 205.165841 pJ
sum error= 257
Actual label: 3
Output voltages: [0.38502, 0.20948, 0.34079, 0.75733, 0.24304, 0.11449, 0.1801, 0.17746, 0.41186, 0.23836]
Predicted label: 3
Correct prediction
Energy consumption = 183.678815 pJ
sum error= 257
Actual label: 7
Output voltages: [0.28695, 0.29762, 0.33486, 0.3685, 0.090308, 0.046359, 0.057424, 0.74391, 0.31879, 0.35781]
Predicted label: 7
Correct prediction
Energy consumption = 200.808034 pJ
sum error= 257
Actual label: 3
Output voltages: [0.38804, 0.18171, 0.33791, 0.75972, 0.2025, 0.12687, 0.15954, 0.18181, 0.42825, 0.2175]
Predicted label: 3
Correct prediction
Energy consumption = 180.479105 pJ
sum error= 257
Actual label: 3
Output voltages: [0.43117, 0.22096, 0.28846, 0.75798, 0.14482, 0.2411, 0.20102, 0.177, 0.36666, 0.18512]
Predicted label: 3
Correct prediction
Energy consumption = 183.100285 pJ
sum error= 257
Actual label: 0
Output voltages: [0.71969, 0.18967, 0.31563, 0.23021, 0.19462, 0.14971, 0.42315, 0.20968, 0.24871, 0.33846]
Predicted label: 0
Correct prediction
Energy consumption = 204.725772 pJ
sum error= 257
Actual label: 2
Output voltages: [0.33823, 0.40435, 0.56831, 0.32914, 0.27369, 0.084957, 0.48032, 0.15153, 0.30443, 0.075777]
Predicted label: 2
Correct prediction
Energy consumption = 195.193646 pJ
sum error= 257
Actual label: 5
Output voltages: [0.25224, 0.050199, 0.13241, 0.41913, 0.21646, 0.66681, 0.27933, 0.15497, 0.53168, 0.25317]
Predicted label: 5
Correct prediction
Energy consumption = 181.892932 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 688 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 688 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 688 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27745, 0.060857, 0.15229, 0.37026, 0.20866, 0.73009, 0.21367, 0.22688, 0.56162, 0.27628]
Predicted label: 5
Correct prediction
Energy consumption = 188.173421 pJ
sum error= 257
Actual label: 6
Output voltages: [0.31539, 0.25608, 0.2925, 0.11617, 0.30837, 0.35322, 0.75196, 0.084508, 0.37302, 0.15836]
Predicted label: 6
Correct prediction
Energy consumption = 187.603640 pJ
sum error= 257
Actual label: 3
Output voltages: [0.33532, 0.22577, 0.29801, 0.76369, 0.1771, 0.21051, 0.18825, 0.23263, 0.35384, 0.26857]
Predicted label: 3
Correct prediction
Energy consumption = 193.381582 pJ
sum error= 257
Actual label: 1
Output voltages: [0.20442, 0.73476, 0.38739, 0.26715, 0.21006, 0.055127, 0.4944, 0.096172, 0.27668, 0.18338]
Predicted label: 1
Correct prediction
Energy consumption = 193.764676 pJ
sum error= 257
Actual label: 5
Output voltages: [0.21229, 0.04402, 0.092293, 0.34091, 0.19297, 0.69891, 0.29611, 0.13133, 0.52439, 0.24069]
Predicted label: 5
Correct prediction
Energy consumption = 189.378248 pJ
sum error= 257
Actual label: 2
Output voltages: [0.36251, 0.42593, 0.61456, 0.32428, 0.16967, 0.039585, 0.44921, 0.18389, 0.3552, 0.1347]
Predicted label: 2
Correct prediction
Energy consumption = 195.886837 pJ
sum error= 257
Actual label: 5
Output voltages: [0.27327, 0.053393, 0.087724, 0.42802, 0.25066, 0.57891, 0.39905, 0.14591, 0.42327, 0.22307]
Predicted label: 5
Correct prediction
Energy consumption = 186.547108 pJ
sum error= 257
Actual label: 9
Output voltages: [0.28643, 0.092666, 0.21379, 0.23012, 0.23952, 0.20685, 0.085001, 0.23987, 0.50832, 0.59273]
Predicted label: 9
Correct prediction
Energy consumption = 192.961509 pJ
sum error= 257
Actual label: 9
Output voltages: [0.38672, 0.15812, 0.16754, 0.28056, 0.30079, 0.22799, 0.088706, 0.2281, 0.34755, 0.67198]
Predicted label: 9
Correct prediction
Energy consumption = 187.154353 pJ
sum error= 257
Actual label: 8
Output voltages: [0.21725, 0.18924, 0.32987, 0.22961, 0.1433, 0.16215, 0.1614, 0.14986, 0.73005, 0.36215]
Predicted label: 8
Correct prediction
Energy consumption = 185.549601 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 689 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 689 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 689 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.12715, 0.166, 0.28851, 0.13299, 0.75741, 0.061123, 0.24489, 0.31121, 0.24865, 0.2528]
Predicted label: 4
Correct prediction
Energy consumption = 195.580920 pJ
sum error= 257
Actual label: 1
Output voltages: [0.18206, 0.76269, 0.30091, 0.40372, 0.19521, 0.081912, 0.28854, 0.21338, 0.27866, 0.23797]
Predicted label: 1
Correct prediction
Energy consumption = 212.518944 pJ
sum error= 257
Actual label: 0
Output voltages: [0.72584, 0.18347, 0.22828, 0.15499, 0.20908, 0.20791, 0.43424, 0.16647, 0.26765, 0.29684]
Predicted label: 0
Correct prediction
Energy consumption = 202.805882 pJ
sum error= 257
Actual label: 6
Output voltages: [0.38124, 0.23441, 0.21694, 0.15295, 0.36653, 0.35276, 0.74015, 0.072608, 0.34692, 0.18536]
Predicted label: 6
Correct prediction
Energy consumption = 187.219233 pJ
sum error= 257
Actual label: 0
Output voltages: [0.73364, 0.20581, 0.26395, 0.36059, 0.12077, 0.099849, 0.29345, 0.26244, 0.36608, 0.21342]
Predicted label: 0
Correct prediction
Energy consumption = 205.435898 pJ
sum error= 257
Actual label: 9
Output voltages: [0.291, 0.16565, 0.10222, 0.25607, 0.26768, 0.14795, 0.061535, 0.33531, 0.37255, 0.67295]
Predicted label: 9
Correct prediction
Energy consumption = 202.234700 pJ
sum error= 257
Actual label: 6
Output voltages: [0.36437, 0.24731, 0.30295, 0.18181, 0.29218, 0.28786, 0.74269, 0.082144, 0.28211, 0.28927]
Predicted label: 6
Correct prediction
Energy consumption = 195.327567 pJ
sum error= 257
Actual label: 8
Output voltages: [0.28581, 0.13102, 0.41806, 0.12952, 0.19015, 0.10296, 0.2354, 0.13723, 0.71061, 0.30159]
Predicted label: 8
Correct prediction
Energy consumption = 198.690807 pJ
sum error= 257
Actual label: 8
Output voltages: [0.17257, 0.2155, 0.24879, 0.27824, 0.1372, 0.13722, 0.13479, 0.14537, 0.7164, 0.39705]
Predicted label: 8
Correct prediction
Energy consumption = 198.188112 pJ
sum error= 257
Actual label: 5
Output voltages: [0.15553, 0.070165, 0.12314, 0.33515, 0.22014, 0.64197, 0.28277, 0.10315, 0.5231, 0.27907]
Predicted label: 5
Correct prediction
Energy consumption = 181.571945 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 690 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 690 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 690 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29261, 0.29032, 0.23126, 0.21482, 0.25809, 0.39995, 0.74145, 0.10098, 0.35964, 0.20248]
Predicted label: 6
Correct prediction
Energy consumption = 198.571589 pJ
sum error= 257
Actual label: 1
Output voltages: [0.18738, 0.7642, 0.14753, 0.26403, 0.26596, 0.15139, 0.30532, 0.12199, 0.3368, 0.28614]
Predicted label: 1
Correct prediction
Energy consumption = 216.432423 pJ
sum error= 257
Actual label: 1
Output voltages: [0.22964, 0.76538, 0.23267, 0.27919, 0.16304, 0.075005, 0.27618, 0.19159, 0.33079, 0.31008]
Predicted label: 1
Correct prediction
Energy consumption = 215.169940 pJ
sum error= 257
Actual label: 9
Output voltages: [0.31379, 0.12097, 0.18737, 0.2033, 0.27059, 0.16542, 0.068367, 0.23339, 0.44225, 0.6447]
Predicted label: 9
Correct prediction
Energy consumption = 185.724536 pJ
sum error= 257
Actual label: 8
Output voltages: [0.2105, 0.20222, 0.35966, 0.3125, 0.13333, 0.16475, 0.21362, 0.12444, 0.72266, 0.3199]
Predicted label: 8
Correct prediction
Energy consumption = 188.855825 pJ
sum error= 257
Actual label: 9
Output voltages: [0.28136, 0.16189, 0.17675, 0.23618, 0.2624, 0.14985, 0.070858, 0.20324, 0.45673, 0.6666]
Predicted label: 9
Correct prediction
Energy consumption = 200.945993 pJ
sum error= 257
Actual label: 2
Output voltages: [0.39693, 0.29993, 0.48781, 0.33545, 0.42038, 0.099631, 0.52023, 0.34818, 0.14783, 0.055141]
Predicted label: 6
Wrong prediction!
Energy consumption = 198.459958 pJ
sum error= 258
Actual label: 3
Output voltages: [0.40971, 0.16831, 0.23631, 0.75444, 0.13691, 0.30562, 0.12569, 0.21714, 0.40923, 0.26947]
Predicted label: 3
Correct prediction
Energy consumption = 188.997420 pJ
sum error= 258
Actual label: 5
Output voltages: [0.24883, 0.055826, 0.093821, 0.37932, 0.22439, 0.70536, 0.29671, 0.15277, 0.49762, 0.23908]
Predicted label: 5
Correct prediction
Energy consumption = 181.299390 pJ
sum error= 258
Actual label: 5
Output voltages: [0.12469, 0.13223, 0.15127, 0.35689, 0.23807, 0.60021, 0.21529, 0.18971, 0.45281, 0.37349]
Predicted label: 5
Correct prediction
Energy consumption = 177.688205 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 691 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 691 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 691 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31942, 0.069286, 0.24888, 0.20739, 0.45681, 0.06921, 0.066738, 0.29212, 0.39372, 0.58158]
Predicted label: 9
Correct prediction
Energy consumption = 197.884156 pJ
sum error= 258
Actual label: 4
Output voltages: [0.12232, 0.16287, 0.2483, 0.099844, 0.7562, 0.084181, 0.25782, 0.26164, 0.28385, 0.26878]
Predicted label: 4
Correct prediction
Energy consumption = 192.707124 pJ
sum error= 258
Actual label: 2
Output voltages: [0.36577, 0.32342, 0.70353, 0.34061, 0.15402, 0.02865, 0.28531, 0.43186, 0.2832, 0.20429]
Predicted label: 2
Correct prediction
Energy consumption = 191.212939 pJ
sum error= 258
Actual label: 1
Output voltages: [0.26812, 0.772, 0.2475, 0.24963, 0.23211, 0.089908, 0.33526, 0.14472, 0.3367, 0.2362]
Predicted label: 1
Correct prediction
Energy consumption = 207.242525 pJ
sum error= 258
Actual label: 9
Output voltages: [0.30845, 0.26088, 0.21089, 0.13126, 0.39892, 0.15842, 0.065153, 0.22632, 0.32836, 0.68157]
Predicted label: 9
Correct prediction
Energy consumption = 205.757516 pJ
sum error= 258
Actual label: 4
Output voltages: [0.13489, 0.19378, 0.22489, 0.24148, 0.74516, 0.067953, 0.25765, 0.35486, 0.21576, 0.22076]
Predicted label: 4
Correct prediction
Energy consumption = 200.452518 pJ
sum error= 258
Actual label: 9
Output voltages: [0.3428, 0.10679, 0.23638, 0.20669, 0.3846, 0.16299, 0.1113, 0.30278, 0.32472, 0.65799]
Predicted label: 9
Correct prediction
Energy consumption = 193.142518 pJ
sum error= 258
Actual label: 1
Output voltages: [0.19123, 0.76633, 0.24369, 0.33287, 0.2662, 0.087514, 0.30434, 0.18503, 0.31453, 0.22064]
Predicted label: 1
Correct prediction
Energy consumption = 211.318758 pJ
sum error= 258
Actual label: 3
Output voltages: [0.37559, 0.21974, 0.30662, 0.76028, 0.12567, 0.18634, 0.16679, 0.19075, 0.33815, 0.25347]
Predicted label: 3
Correct prediction
Energy consumption = 185.269267 pJ
sum error= 258
Actual label: 9
Output voltages: [0.2663, 0.22659, 0.2059, 0.16039, 0.29109, 0.068372, 0.05373, 0.22804, 0.39844, 0.66958]
Predicted label: 9
Correct prediction
Energy consumption = 200.521192 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 692 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 692 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 692 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35447, 0.48336, 0.71438, 0.28386, 0.13272, 0.021687, 0.31626, 0.22544, 0.27685, 0.20635]
Predicted label: 2
Correct prediction
Energy consumption = 190.685691 pJ
sum error= 258
Actual label: 0
Output voltages: [0.7409, 0.2352, 0.27569, 0.17667, 0.1706, 0.17111, 0.37059, 0.1595, 0.2647, 0.29901]
Predicted label: 0
Correct prediction
Energy consumption = 195.188260 pJ
sum error= 258
Actual label: 6
Output voltages: [0.29042, 0.20448, 0.23757, 0.18122, 0.34233, 0.33528, 0.7311, 0.083472, 0.41939, 0.12837]
Predicted label: 6
Correct prediction
Energy consumption = 194.996888 pJ
sum error= 258
Actual label: 0
Output voltages: [0.74138, 0.20273, 0.31935, 0.18933, 0.18592, 0.11411, 0.33409, 0.18991, 0.3091, 0.34051]
Predicted label: 0
Correct prediction
Energy consumption = 200.969847 pJ
sum error= 258
Actual label: 4
Output voltages: [0.13135, 0.13549, 0.21303, 0.22703, 0.69934, 0.052467, 0.19635, 0.29757, 0.36514, 0.25821]
Predicted label: 4
Correct prediction
Energy consumption = 197.447824 pJ
sum error= 258
Actual label: 0
Output voltages: [0.67961, 0.20795, 0.37356, 0.22609, 0.14658, 0.078961, 0.3441, 0.20327, 0.41724, 0.29364]
Predicted label: 0
Correct prediction
Energy consumption = 205.658127 pJ
sum error= 258
Actual label: 6
Output voltages: [0.17298, 0.12154, 0.24113, 0.12268, 0.49913, 0.28829, 0.60807, 0.17696, 0.32318, 0.21988]
Predicted label: 6
Correct prediction
Energy consumption = 196.016898 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73639, 0.25188, 0.27091, 0.19435, 0.17053, 0.13765, 0.41186, 0.19058, 0.29281, 0.28146]
Predicted label: 0
Correct prediction
Energy consumption = 202.688561 pJ
sum error= 258
Actual label: 1
Output voltages: [0.16154, 0.7584, 0.30445, 0.22355, 0.28844, 0.062496, 0.34538, 0.13211, 0.29973, 0.26927]
Predicted label: 1
Correct prediction
Energy consumption = 208.981760 pJ
sum error= 258
Actual label: 2
Output voltages: [0.29878, 0.28823, 0.74129, 0.30463, 0.19101, 0.037565, 0.24917, 0.27193, 0.35325, 0.20872]
Predicted label: 2
Correct prediction
Energy consumption = 184.913466 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 693 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 693 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 693 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.41256, 0.13666, 0.34187, 0.75053, 0.18841, 0.14415, 0.10853, 0.19705, 0.43361, 0.21434]
Predicted label: 3
Correct prediction
Energy consumption = 192.144131 pJ
sum error= 258
Actual label: 4
Output voltages: [0.15951, 0.164, 0.2979, 0.24983, 0.75046, 0.042863, 0.20411, 0.27321, 0.18987, 0.22587]
Predicted label: 4
Correct prediction
Energy consumption = 190.960344 pJ
sum error= 258
Actual label: 5
Output voltages: [0.21931, 0.049521, 0.055289, 0.3589, 0.31259, 0.72902, 0.33545, 0.1251, 0.47494, 0.2163]
Predicted label: 5
Correct prediction
Energy consumption = 187.501924 pJ
sum error= 258
Actual label: 6
Output voltages: [0.2653, 0.21023, 0.29616, 0.10431, 0.38556, 0.31784, 0.74332, 0.060173, 0.36696, 0.13995]
Predicted label: 6
Correct prediction
Energy consumption = 185.407801 pJ
sum error= 258
Actual label: 7
Output voltages: [0.36864, 0.17567, 0.21054, 0.27397, 0.18085, 0.1724, 0.040961, 0.75304, 0.32722, 0.35699]
Predicted label: 7
Correct prediction
Energy consumption = 203.358611 pJ
sum error= 258
Actual label: 8
Output voltages: [0.20575, 0.2323, 0.33558, 0.24894, 0.17951, 0.18381, 0.21656, 0.16395, 0.75526, 0.27419]
Predicted label: 8
Correct prediction
Energy consumption = 192.952794 pJ
sum error= 258
Actual label: 9
Output voltages: [0.33147, 0.07519, 0.18364, 0.2112, 0.27819, 0.28725, 0.1234, 0.30112, 0.42325, 0.62407]
Predicted label: 9
Correct prediction
Energy consumption = 189.451651 pJ
sum error= 258
Actual label: 0
Output voltages: [0.68738, 0.24195, 0.36737, 0.20686, 0.11604, 0.088087, 0.42401, 0.18308, 0.30383, 0.23759]
Predicted label: 0
Correct prediction
Energy consumption = 193.590403 pJ
sum error= 258
Actual label: 1
Output voltages: [0.11908, 0.75345, 0.25107, 0.15735, 0.38064, 0.20525, 0.40444, 0.13696, 0.32215, 0.23247]
Predicted label: 1
Correct prediction
Energy consumption = 216.178694 pJ
sum error= 258
Actual label: 2
Output voltages: [0.34574, 0.21588, 0.7453, 0.28486, 0.20793, 0.038783, 0.26107, 0.26739, 0.40513, 0.19015]
Predicted label: 2
Correct prediction
Energy consumption = 192.357893 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 694 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 694 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 694 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.31085, 0.084405, 0.27022, 0.71384, 0.30306, 0.39025, 0.15515, 0.17142, 0.34137, 0.14517]
Predicted label: 3
Correct prediction
Energy consumption = 197.195469 pJ
sum error= 258
Actual label: 4
Output voltages: [0.1429, 0.14038, 0.26061, 0.14916, 0.75645, 0.10023, 0.24083, 0.30153, 0.26251, 0.21264]
Predicted label: 4
Correct prediction
Energy consumption = 190.141837 pJ
sum error= 258
Actual label: 5
Output voltages: [0.27556, 0.065833, 0.054758, 0.49301, 0.27954, 0.71736, 0.3668, 0.088253, 0.43857, 0.22367]
Predicted label: 5
Correct prediction
Energy consumption = 185.357189 pJ
sum error= 258
Actual label: 6
Output voltages: [0.30325, 0.19701, 0.28807, 0.076014, 0.37608, 0.32714, 0.73254, 0.12557, 0.38941, 0.079316]
Predicted label: 6
Correct prediction
Energy consumption = 187.971283 pJ
sum error= 258
Actual label: 7
Output voltages: [0.4067, 0.17033, 0.16085, 0.32857, 0.20377, 0.25886, 0.048657, 0.73271, 0.30551, 0.43683]
Predicted label: 7
Correct prediction
Energy consumption = 196.902754 pJ
sum error= 258
Actual label: 8
Output voltages: [0.29045, 0.21979, 0.26704, 0.17134, 0.1571, 0.11694, 0.08502, 0.33386, 0.6984, 0.37843]
Predicted label: 8
Correct prediction
Energy consumption = 192.848418 pJ
sum error= 258
Actual label: 9
Output voltages: [0.37695, 0.14875, 0.20006, 0.23791, 0.36062, 0.12346, 0.083247, 0.14793, 0.3521, 0.69839]
Predicted label: 9
Correct prediction
Energy consumption = 185.616567 pJ
sum error= 258
Actual label: 0
Output voltages: [0.71869, 0.24359, 0.27353, 0.19227, 0.185, 0.12009, 0.42315, 0.18077, 0.26223, 0.35242]
Predicted label: 0
Correct prediction
Energy consumption = 189.027762 pJ
sum error= 258
Actual label: 1
Output voltages: [0.16653, 0.75479, 0.33053, 0.17261, 0.26365, 0.088751, 0.46973, 0.13881, 0.30928, 0.18447]
Predicted label: 1
Correct prediction
Energy consumption = 204.943004 pJ
sum error= 258
Actual label: 2
Output voltages: [0.29809, 0.27543, 0.75413, 0.27761, 0.16063, 0.042074, 0.26204, 0.25274, 0.39395, 0.16152]
Predicted label: 2
Correct prediction
Energy consumption = 187.678258 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 695 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 695 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 695 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.31514, 0.12913, 0.29057, 0.71735, 0.13824, 0.25, 0.059818, 0.20099, 0.5433, 0.28511]
Predicted label: 3
Correct prediction
Energy consumption = 191.252655 pJ
sum error= 258
Actual label: 4
Output voltages: [0.10726, 0.18208, 0.26059, 0.18025, 0.74988, 0.06547, 0.20512, 0.22143, 0.25251, 0.22263]
Predicted label: 4
Correct prediction
Energy consumption = 194.908996 pJ
sum error= 258
Actual label: 5
Output voltages: [0.40591, 0.045081, 0.12125, 0.3405, 0.26746, 0.73239, 0.2602, 0.16171, 0.41501, 0.20347]
Predicted label: 5
Correct prediction
Energy consumption = 191.266123 pJ
sum error= 258
Actual label: 6
Output voltages: [0.36072, 0.27547, 0.22799, 0.17208, 0.31304, 0.40645, 0.74055, 0.068603, 0.36777, 0.19304]
Predicted label: 6
Correct prediction
Energy consumption = 185.637780 pJ
sum error= 258
Actual label: 7
Output voltages: [0.44246, 0.29404, 0.51382, 0.28627, 0.069105, 0.054428, 0.076293, 0.59585, 0.38028, 0.27547]
Predicted label: 7
Correct prediction
Energy consumption = 205.812599 pJ
sum error= 258
Actual label: 8
Output voltages: [0.26091, 0.2362, 0.25193, 0.28845, 0.18847, 0.2618, 0.24985, 0.088606, 0.73892, 0.30635]
Predicted label: 8
Correct prediction
Energy consumption = 196.459115 pJ
sum error= 258
Actual label: 9
Output voltages: [0.35631, 0.11073, 0.20138, 0.23857, 0.30268, 0.18033, 0.090604, 0.23517, 0.42362, 0.6373]
Predicted label: 9
Correct prediction
Energy consumption = 189.795944 pJ
sum error= 258
Actual label: 3
Output voltages: [0.37676, 0.17251, 0.34523, 0.7517, 0.14012, 0.12113, 0.12765, 0.13947, 0.44762, 0.22442]
Predicted label: 3
Correct prediction
Energy consumption = 188.173131 pJ
sum error= 258
Actual label: 8
Output voltages: [0.2183, 0.25029, 0.25369, 0.32237, 0.14871, 0.205, 0.17236, 0.1734, 0.75554, 0.23633]
Predicted label: 8
Correct prediction
Energy consumption = 187.660429 pJ
sum error= 258
Actual label: 0
Output voltages: [0.72395, 0.20878, 0.26258, 0.23759, 0.20416, 0.12715, 0.44902, 0.19422, 0.31448, 0.2327]
Predicted label: 0
Correct prediction
Energy consumption = 197.948977 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 696 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 696 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 696 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28157, 0.21217, 0.2336, 0.2298, 0.12747, 0.10953, 0.038533, 0.75497, 0.39666, 0.32961]
Predicted label: 7
Correct prediction
Energy consumption = 202.135256 pJ
sum error= 258
Actual label: 1
Output voltages: [0.16909, 0.76327, 0.22992, 0.26151, 0.22184, 0.061751, 0.37663, 0.11914, 0.33511, 0.25718]
Predicted label: 1
Correct prediction
Energy consumption = 213.091835 pJ
sum error= 258
Actual label: 0
Output voltages: [0.6988, 0.23793, 0.3139, 0.22879, 0.22052, 0.074077, 0.49118, 0.14492, 0.35241, 0.25151]
Predicted label: 0
Correct prediction
Energy consumption = 206.203746 pJ
sum error= 258
Actual label: 7
Output voltages: [0.28387, 0.23769, 0.29874, 0.24955, 0.13779, 0.050793, 0.04185, 0.75462, 0.37356, 0.3149]
Predicted label: 7
Correct prediction
Energy consumption = 196.941690 pJ
sum error= 258
Actual label: 5
Output voltages: [0.34917, 0.085234, 0.095083, 0.37669, 0.15062, 0.74143, 0.34141, 0.17894, 0.45779, 0.18572]
Predicted label: 5
Correct prediction
Energy consumption = 194.346419 pJ
sum error= 258
Actual label: 5
Output voltages: [0.24406, 0.096692, 0.057094, 0.36466, 0.21547, 0.73647, 0.33125, 0.097667, 0.48933, 0.18944]
Predicted label: 5
Correct prediction
Energy consumption = 189.968820 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27235, 0.23006, 0.27022, 0.11947, 0.34822, 0.35223, 0.73886, 0.094447, 0.34212, 0.094234]
Predicted label: 6
Correct prediction
Energy consumption = 192.949481 pJ
sum error= 258
Actual label: 9
Output voltages: [0.35631, 0.16389, 0.14624, 0.30012, 0.34959, 0.10306, 0.070928, 0.19522, 0.35244, 0.64924]
Predicted label: 9
Correct prediction
Energy consumption = 201.453451 pJ
sum error= 258
Actual label: 0
Output voltages: [0.71477, 0.28287, 0.32179, 0.1657, 0.13913, 0.1192, 0.39898, 0.25463, 0.35049, 0.22391]
Predicted label: 0
Correct prediction
Energy consumption = 195.626827 pJ
sum error= 258
Actual label: 1
Output voltages: [0.22951, 0.75694, 0.26197, 0.24556, 0.29997, 0.079821, 0.37359, 0.066567, 0.2593, 0.24272]
Predicted label: 1
Correct prediction
Energy consumption = 201.807460 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 697 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 697 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 697 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.65185, 0.16371, 0.39251, 0.27288, 0.19999, 0.075198, 0.30546, 0.1717, 0.43339, 0.23516]
Predicted label: 0
Correct prediction
Energy consumption = 198.538701 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73435, 0.20026, 0.41632, 0.2213, 0.15905, 0.087442, 0.31327, 0.21443, 0.34766, 0.23088]
Predicted label: 0
Correct prediction
Energy consumption = 195.267287 pJ
sum error= 258
Actual label: 8
Output voltages: [0.24265, 0.18558, 0.34722, 0.16039, 0.17509, 0.1457, 0.13951, 0.22692, 0.75226, 0.28526]
Predicted label: 8
Correct prediction
Energy consumption = 189.831668 pJ
sum error= 258
Actual label: 3
Output voltages: [0.46072, 0.15393, 0.32606, 0.75379, 0.18376, 0.21422, 0.13693, 0.20704, 0.36341, 0.15945]
Predicted label: 3
Correct prediction
Energy consumption = 189.103342 pJ
sum error= 258
Actual label: 4
Output voltages: [0.12698, 0.13274, 0.26289, 0.197, 0.75018, 0.053268, 0.25918, 0.27057, 0.2742, 0.17567]
Predicted label: 4
Correct prediction
Energy consumption = 195.805576 pJ
sum error= 258
Actual label: 3
Output voltages: [0.37796, 0.069234, 0.43504, 0.71587, 0.21209, 0.15629, 0.10239, 0.14789, 0.41507, 0.1939]
Predicted label: 3
Correct prediction
Energy consumption = 188.413607 pJ
sum error= 258
Actual label: 1
Output voltages: [0.188, 0.75577, 0.23497, 0.23963, 0.31713, 0.096459, 0.37348, 0.17204, 0.26172, 0.24413]
Predicted label: 1
Correct prediction
Energy consumption = 203.663645 pJ
sum error= 258
Actual label: 5
Output voltages: [0.26421, 0.1053, 0.056036, 0.42743, 0.21228, 0.74532, 0.24784, 0.23544, 0.46573, 0.25239]
Predicted label: 5
Correct prediction
Energy consumption = 197.120183 pJ
sum error= 258
Actual label: 0
Output voltages: [0.70678, 0.19009, 0.27296, 0.19202, 0.2106, 0.088244, 0.41659, 0.16517, 0.33939, 0.29779]
Predicted label: 0
Correct prediction
Energy consumption = 205.088192 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73028, 0.23355, 0.26669, 0.18913, 0.22101, 0.1713, 0.47918, 0.22791, 0.29132, 0.23402]
Predicted label: 0
Correct prediction
Energy consumption = 186.930248 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 698 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 698 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 698 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29801, 0.14168, 0.1742, 0.21968, 0.33832, 0.093845, 0.069209, 0.16545, 0.41686, 0.64419]
Predicted label: 9
Correct prediction
Energy consumption = 197.050152 pJ
sum error= 258
Actual label: 5
Output voltages: [0.29814, 0.043849, 0.099087, 0.34935, 0.26208, 0.70679, 0.41472, 0.12579, 0.48196, 0.21383]
Predicted label: 5
Correct prediction
Energy consumption = 196.334882 pJ
sum error= 258
Actual label: 3
Output voltages: [0.33177, 0.1705, 0.3042, 0.75119, 0.20585, 0.24212, 0.12927, 0.17292, 0.47025, 0.22067]
Predicted label: 3
Correct prediction
Energy consumption = 195.224972 pJ
sum error= 258
Actual label: 4
Output voltages: [0.22353, 0.17061, 0.29805, 0.26222, 0.62581, 0.047018, 0.064017, 0.17166, 0.32136, 0.36175]
Predicted label: 4
Correct prediction
Energy consumption = 191.767267 pJ
sum error= 258
Actual label: 9
Output voltages: [0.33221, 0.15994, 0.20596, 0.2996, 0.33004, 0.15435, 0.11997, 0.1802, 0.3365, 0.70766]
Predicted label: 9
Correct prediction
Energy consumption = 191.339995 pJ
sum error= 258
Actual label: 3
Output voltages: [0.39861, 0.13648, 0.3461, 0.74439, 0.17513, 0.17315, 0.12205, 0.13798, 0.5232, 0.2033]
Predicted label: 3
Correct prediction
Energy consumption = 183.844917 pJ
sum error= 258
Actual label: 7
Output voltages: [0.4107, 0.28791, 0.41008, 0.069348, 0.20792, 0.064923, 0.065356, 0.69806, 0.31118, 0.29725]
Predicted label: 7
Correct prediction
Energy consumption = 199.800117 pJ
sum error= 258
Actual label: 6
Output voltages: [0.25098, 0.24757, 0.30897, 0.16431, 0.33775, 0.3239, 0.74391, 0.078119, 0.36281, 0.087264]
Predicted label: 6
Correct prediction
Energy consumption = 195.122770 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34024, 0.13897, 0.20333, 0.22683, 0.26791, 0.13909, 0.076733, 0.17104, 0.45557, 0.65515]
Predicted label: 9
Correct prediction
Energy consumption = 198.702430 pJ
sum error= 258
Actual label: 2
Output voltages: [0.37052, 0.1863, 0.72809, 0.29104, 0.23369, 0.040055, 0.23768, 0.18472, 0.42865, 0.17446]
Predicted label: 2
Correct prediction
Energy consumption = 189.262377 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 699 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 699 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 699 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13855, 0.12633, 0.18635, 0.24359, 0.67619, 0.11518, 0.1707, 0.14746, 0.33043, 0.32658]
Predicted label: 4
Correct prediction
Energy consumption = 196.370247 pJ
sum error= 258
Actual label: 5
Output voltages: [0.26953, 0.048238, 0.059912, 0.39447, 0.30042, 0.69568, 0.38343, 0.10022, 0.4966, 0.16839]
Predicted label: 5
Correct prediction
Energy consumption = 186.520778 pJ
sum error= 258
Actual label: 7
Output voltages: [0.35129, 0.18092, 0.19465, 0.32442, 0.17873, 0.20375, 0.040978, 0.75722, 0.27974, 0.34734]
Predicted label: 7
Correct prediction
Energy consumption = 193.618269 pJ
sum error= 258
Actual label: 2
Output voltages: [0.3243, 0.20581, 0.75436, 0.24452, 0.18542, 0.043951, 0.26244, 0.22841, 0.42941, 0.16491]
Predicted label: 2
Correct prediction
Energy consumption = 181.982198 pJ
sum error= 258
Actual label: 6
Output voltages: [0.34719, 0.18239, 0.23969, 0.12449, 0.37649, 0.30163, 0.7274, 0.055346, 0.39364, 0.17169]
Predicted label: 6
Correct prediction
Energy consumption = 188.191860 pJ
sum error= 258
Actual label: 4
Output voltages: [0.12245, 0.17783, 0.21596, 0.20978, 0.76079, 0.098737, 0.27655, 0.29321, 0.19865, 0.20147]
Predicted label: 4
Correct prediction
Energy consumption = 191.702946 pJ
sum error= 258
Actual label: 9
Output voltages: [0.39056, 0.18999, 0.16139, 0.2685, 0.35277, 0.1625, 0.14688, 0.12829, 0.32947, 0.72685]
Predicted label: 9
Correct prediction
Energy consumption = 186.602551 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11582, 0.18444, 0.18694, 0.20723, 0.67079, 0.11631, 0.18043, 0.12721, 0.37442, 0.32536]
Predicted label: 4
Correct prediction
Energy consumption = 201.439333 pJ
sum error= 258
Actual label: 9
Output voltages: [0.37128, 0.13726, 0.17465, 0.2666, 0.36936, 0.15512, 0.12245, 0.16345, 0.34429, 0.67284]
Predicted label: 9
Correct prediction
Energy consumption = 190.289060 pJ
sum error= 258
Actual label: 4
Output voltages: [0.17085, 0.21707, 0.24294, 0.29287, 0.73291, 0.045187, 0.18736, 0.20588, 0.21059, 0.25908]
Predicted label: 4
Correct prediction
Energy consumption = 189.736029 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 700 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 700 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 700 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16595, 0.7499, 0.27213, 0.23038, 0.25085, 0.14359, 0.42061, 0.11977, 0.35443, 0.23279]
Predicted label: 1
Correct prediction
Energy consumption = 206.641890 pJ
sum error= 258
Actual label: 2
Output voltages: [0.31822, 0.26863, 0.70934, 0.31056, 0.20881, 0.035119, 0.31325, 0.22243, 0.4245, 0.20415]
Predicted label: 2
Correct prediction
Energy consumption = 194.155039 pJ
sum error= 258
Actual label: 2
Output voltages: [0.27372, 0.23632, 0.72969, 0.30684, 0.1582, 0.036965, 0.23695, 0.22753, 0.47908, 0.20177]
Predicted label: 2
Correct prediction
Energy consumption = 192.241862 pJ
sum error= 258
Actual label: 5
Output voltages: [0.25421, 0.054147, 0.09535, 0.46494, 0.19697, 0.68307, 0.33036, 0.16078, 0.4287, 0.28263]
Predicted label: 5
Correct prediction
Energy consumption = 194.540736 pJ
sum error= 258
Actual label: 8
Output voltages: [0.20709, 0.27179, 0.26259, 0.26876, 0.12966, 0.1948, 0.20603, 0.16858, 0.7525, 0.28802]
Predicted label: 8
Correct prediction
Energy consumption = 194.957582 pJ
sum error= 258
Actual label: 1
Output voltages: [0.16151, 0.75793, 0.32443, 0.22605, 0.2822, 0.093327, 0.39216, 0.22189, 0.2613, 0.21542]
Predicted label: 1
Correct prediction
Energy consumption = 209.548538 pJ
sum error= 258
Actual label: 3
Output voltages: [0.35464, 0.18172, 0.36457, 0.75477, 0.16974, 0.16869, 0.11649, 0.20318, 0.44284, 0.27039]
Predicted label: 3
Correct prediction
Energy consumption = 186.547265 pJ
sum error= 258
Actual label: 2
Output voltages: [0.30334, 0.26333, 0.74284, 0.29077, 0.15466, 0.042032, 0.28093, 0.25262, 0.4268, 0.16506]
Predicted label: 2
Correct prediction
Energy consumption = 186.005428 pJ
sum error= 258
Actual label: 9
Output voltages: [0.33067, 0.12074, 0.23937, 0.33187, 0.26505, 0.17912, 0.10007, 0.28676, 0.38426, 0.6603]
Predicted label: 9
Correct prediction
Energy consumption = 195.965482 pJ
sum error= 258
Actual label: 4
Output voltages: [0.18976, 0.18532, 0.29689, 0.24858, 0.73985, 0.046575, 0.1594, 0.21894, 0.20508, 0.27249]
Predicted label: 4
Correct prediction
Energy consumption = 191.947515 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 701 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 701 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 701 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30917, 0.21874, 0.31325, 0.73735, 0.070818, 0.18971, 0.1083, 0.18576, 0.53937, 0.22064]
Predicted label: 3
Correct prediction
Energy consumption = 185.171522 pJ
sum error= 258
Actual label: 8
Output voltages: [0.21086, 0.2068, 0.32791, 0.22024, 0.21103, 0.22804, 0.19372, 0.17835, 0.75702, 0.2395]
Predicted label: 8
Correct prediction
Energy consumption = 188.340797 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32803, 0.22183, 0.74722, 0.2884, 0.14419, 0.039916, 0.25739, 0.26742, 0.41565, 0.15631]
Predicted label: 2
Correct prediction
Energy consumption = 190.866784 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32346, 0.20829, 0.74825, 0.29078, 0.18387, 0.042054, 0.26711, 0.24137, 0.42202, 0.17317]
Predicted label: 2
Correct prediction
Energy consumption = 177.790185 pJ
sum error= 258
Actual label: 1
Output voltages: [0.22183, 0.7464, 0.37233, 0.29096, 0.21879, 0.044229, 0.33399, 0.082722, 0.31574, 0.26851]
Predicted label: 1
Correct prediction
Energy consumption = 210.805286 pJ
sum error= 258
Actual label: 2
Output voltages: [0.3175, 0.18978, 0.73548, 0.30125, 0.26589, 0.043891, 0.28286, 0.20978, 0.37839, 0.17428]
Predicted label: 2
Correct prediction
Energy consumption = 192.203226 pJ
sum error= 258
Actual label: 8
Output voltages: [0.29109, 0.16358, 0.33413, 0.41451, 0.10594, 0.14717, 0.21654, 0.10844, 0.71606, 0.26996]
Predicted label: 8
Correct prediction
Energy consumption = 193.334873 pJ
sum error= 258
Actual label: 6
Output voltages: [0.31162, 0.25261, 0.28784, 0.10923, 0.3503, 0.3453, 0.74669, 0.10789, 0.31619, 0.1408]
Predicted label: 6
Correct prediction
Energy consumption = 189.964060 pJ
sum error= 258
Actual label: 5
Output voltages: [0.25694, 0.059485, 0.10206, 0.35836, 0.21091, 0.72631, 0.32786, 0.14325, 0.47768, 0.26461]
Predicted label: 5
Correct prediction
Energy consumption = 185.854024 pJ
sum error= 258
Actual label: 1
Output voltages: [0.26323, 0.74087, 0.2648, 0.24878, 0.29492, 0.055752, 0.34436, 0.090816, 0.31702, 0.23736]
Predicted label: 1
Correct prediction
Energy consumption = 211.027215 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 702 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 702 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 702 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.33271, 0.26458, 0.18336, 0.19725, 0.33137, 0.46457, 0.72963, 0.063498, 0.34037, 0.10637]
Predicted label: 6
Correct prediction
Energy consumption = 193.438288 pJ
sum error= 258
Actual label: 7
Output voltages: [0.34051, 0.27574, 0.3749, 0.34446, 0.082955, 0.041027, 0.045562, 0.70865, 0.40118, 0.25566]
Predicted label: 7
Correct prediction
Energy consumption = 203.734764 pJ
sum error= 258
Actual label: 2
Output voltages: [0.36976, 0.16609, 0.74281, 0.32925, 0.19702, 0.044363, 0.28801, 0.2723, 0.40001, 0.16799]
Predicted label: 2
Correct prediction
Energy consumption = 188.874812 pJ
sum error= 258
Actual label: 1
Output voltages: [0.33351, 0.71931, 0.28817, 0.22243, 0.40009, 0.051668, 0.32025, 0.09437, 0.23671, 0.25906]
Predicted label: 1
Correct prediction
Energy consumption = 209.033061 pJ
sum error= 258
Actual label: 3
Output voltages: [0.41579, 0.1594, 0.31559, 0.75509, 0.17322, 0.2341, 0.13083, 0.18791, 0.45381, 0.16681]
Predicted label: 3
Correct prediction
Energy consumption = 193.121831 pJ
sum error= 258
Actual label: 9
Output voltages: [0.3058, 0.12401, 0.18536, 0.35247, 0.31288, 0.086281, 0.056934, 0.24821, 0.38547, 0.61317]
Predicted label: 9
Correct prediction
Energy consumption = 187.367105 pJ
sum error= 258
Actual label: 3
Output voltages: [0.46946, 0.17579, 0.21466, 0.75374, 0.20116, 0.31042, 0.088183, 0.26957, 0.38547, 0.13746]
Predicted label: 3
Correct prediction
Energy consumption = 185.121708 pJ
sum error= 258
Actual label: 8
Output voltages: [0.195, 0.21586, 0.26626, 0.28991, 0.11253, 0.25029, 0.13712, 0.19606, 0.75467, 0.26018]
Predicted label: 8
Correct prediction
Energy consumption = 190.165448 pJ
sum error= 258
Actual label: 7
Output voltages: [0.32034, 0.19939, 0.17437, 0.35207, 0.1434, 0.15432, 0.044546, 0.75042, 0.28435, 0.37084]
Predicted label: 7
Correct prediction
Energy consumption = 198.918559 pJ
sum error= 258
Actual label: 5
Output voltages: [0.37652, 0.15049, 0.05452, 0.45847, 0.27975, 0.74987, 0.37304, 0.068819, 0.36718, 0.23449]
Predicted label: 5
Correct prediction
Energy consumption = 192.452004 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 703 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 703 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 703 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30099, 0.3182, 0.40892, 0.2191, 0.18473, 0.037272, 0.050726, 0.71007, 0.31906, 0.39839]
Predicted label: 7
Correct prediction
Energy consumption = 203.120941 pJ
sum error= 258
Actual label: 0
Output voltages: [0.64216, 0.25725, 0.44856, 0.27478, 0.13047, 0.054823, 0.31094, 0.081835, 0.47241, 0.3423]
Predicted label: 0
Correct prediction
Energy consumption = 200.196313 pJ
sum error= 258
Actual label: 7
Output voltages: [0.29148, 0.21127, 0.13158, 0.27928, 0.21782, 0.10479, 0.049535, 0.72847, 0.39546, 0.43119]
Predicted label: 7
Correct prediction
Energy consumption = 203.667881 pJ
sum error= 258
Actual label: 4
Output voltages: [0.23465, 0.16944, 0.23843, 0.24978, 0.70727, 0.049194, 0.16271, 0.16701, 0.27551, 0.34263]
Predicted label: 4
Correct prediction
Energy consumption = 196.572306 pJ
sum error= 258
Actual label: 8
Output voltages: [0.18345, 0.2018, 0.3555, 0.20909, 0.17829, 0.13483, 0.19739, 0.15115, 0.74547, 0.28992]
Predicted label: 8
Correct prediction
Energy consumption = 189.530019 pJ
sum error= 258
Actual label: 8
Output voltages: [0.44816, 0.14439, 0.33809, 0.53097, 0.057509, 0.11791, 0.24102, 0.10464, 0.57896, 0.25536]
Predicted label: 8
Correct prediction
Energy consumption = 201.140717 pJ
sum error= 258
Actual label: 5
Output voltages: [0.22135, 0.043353, 0.073982, 0.32142, 0.29225, 0.73305, 0.33582, 0.15807, 0.56398, 0.20107]
Predicted label: 5
Correct prediction
Energy consumption = 178.843776 pJ
sum error= 258
Actual label: 0
Output voltages: [0.645, 0.25298, 0.22273, 0.17439, 0.2042, 0.13463, 0.5342, 0.16025, 0.29674, 0.20959]
Predicted label: 0
Correct prediction
Energy consumption = 197.535728 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27024, 0.24399, 0.28693, 0.12228, 0.27533, 0.31926, 0.74353, 0.10452, 0.37084, 0.1816]
Predicted label: 6
Correct prediction
Energy consumption = 187.339620 pJ
sum error= 258
Actual label: 6
Output voltages: [0.337, 0.24011, 0.21861, 0.19188, 0.32498, 0.4013, 0.73916, 0.10442, 0.39042, 0.1074]
Predicted label: 6
Correct prediction
Energy consumption = 181.843498 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 704 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 704 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 704 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.39575, 0.062367, 0.3245, 0.71168, 0.13522, 0.21778, 0.10554, 0.20041, 0.51109, 0.17014]
Predicted label: 3
Correct prediction
Energy consumption = 192.728004 pJ
sum error= 258
Actual label: 7
Output voltages: [0.33457, 0.19174, 0.31042, 0.25746, 0.18285, 0.13849, 0.038266, 0.74843, 0.37535, 0.39413]
Predicted label: 7
Correct prediction
Energy consumption = 193.069965 pJ
sum error= 258
Actual label: 6
Output voltages: [0.284, 0.1646, 0.26573, 0.10483, 0.32804, 0.41688, 0.71494, 0.09441, 0.41585, 0.092303]
Predicted label: 6
Correct prediction
Energy consumption = 194.788938 pJ
sum error= 258
Actual label: 9
Output voltages: [0.37993, 0.18833, 0.20919, 0.32715, 0.37906, 0.072051, 0.11204, 0.13746, 0.3569, 0.65392]
Predicted label: 9
Correct prediction
Energy consumption = 197.707035 pJ
sum error= 258
Actual label: 9
Output voltages: [0.35194, 0.15882, 0.15628, 0.27051, 0.34353, 0.12639, 0.064956, 0.15779, 0.36106, 0.66791]
Predicted label: 9
Correct prediction
Energy consumption = 187.522817 pJ
sum error= 258
Actual label: 4
Output voltages: [0.16342, 0.26936, 0.28832, 0.21773, 0.75693, 0.062509, 0.27219, 0.23055, 0.17375, 0.23513]
Predicted label: 4
Correct prediction
Energy consumption = 195.428573 pJ
sum error= 258
Actual label: 8
Output voltages: [0.23455, 0.2731, 0.26398, 0.28695, 0.14413, 0.20414, 0.20936, 0.13843, 0.74837, 0.27951]
Predicted label: 8
Correct prediction
Energy consumption = 196.550358 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11001, 0.15843, 0.25534, 0.27816, 0.73839, 0.10541, 0.14878, 0.19633, 0.26517, 0.30771]
Predicted label: 4
Correct prediction
Energy consumption = 195.111045 pJ
sum error= 258
Actual label: 1
Output voltages: [0.21455, 0.75275, 0.27871, 0.25755, 0.38327, 0.073782, 0.39204, 0.16178, 0.21245, 0.26238]
Predicted label: 1
Correct prediction
Energy consumption = 207.252239 pJ
sum error= 258
Actual label: 0
Output voltages: [0.56568, 0.13239, 0.32296, 0.18221, 0.28954, 0.096935, 0.46066, 0.16746, 0.42581, 0.17357]
Predicted label: 0
Correct prediction
Energy consumption = 199.837466 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 705 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 705 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 705 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.34735, 0.2085, 0.2597, 0.13855, 0.36077, 0.2912, 0.72442, 0.063765, 0.43376, 0.15486]
Predicted label: 6
Correct prediction
Energy consumption = 194.582865 pJ
sum error= 258
Actual label: 6
Output voltages: [0.3221, 0.18973, 0.26799, 0.17118, 0.28021, 0.27783, 0.64972, 0.10916, 0.49927, 0.099538]
Predicted label: 6
Correct prediction
Energy consumption = 185.586966 pJ
sum error= 258
Actual label: 0
Output voltages: [0.71117, 0.2688, 0.28104, 0.1657, 0.18594, 0.10574, 0.41404, 0.15424, 0.34977, 0.23884]
Predicted label: 0
Correct prediction
Energy consumption = 190.201036 pJ
sum error= 258
Actual label: 1
Output voltages: [0.19412, 0.76168, 0.19155, 0.21908, 0.22712, 0.074387, 0.42419, 0.093752, 0.35158, 0.23801]
Predicted label: 1
Correct prediction
Energy consumption = 208.244124 pJ
sum error= 258
Actual label: 2
Output voltages: [0.33176, 0.29039, 0.68084, 0.23915, 0.19434, 0.022709, 0.17598, 0.52626, 0.33536, 0.18565]
Predicted label: 2
Correct prediction
Energy consumption = 193.792963 pJ
sum error= 258
Actual label: 3
Output voltages: [0.23332, 0.25278, 0.26108, 0.75513, 0.13475, 0.17222, 0.099258, 0.26599, 0.46565, 0.21733]
Predicted label: 3
Correct prediction
Energy consumption = 181.789048 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11636, 0.14568, 0.17839, 0.11998, 0.73779, 0.14138, 0.29866, 0.31824, 0.34341, 0.1482]
Predicted label: 4
Correct prediction
Energy consumption = 185.932436 pJ
sum error= 258
Actual label: 5
Output voltages: [0.26161, 0.048585, 0.058479, 0.33977, 0.19934, 0.72258, 0.29724, 0.13492, 0.50914, 0.19457]
Predicted label: 5
Correct prediction
Energy consumption = 185.874400 pJ
sum error= 258
Actual label: 6
Output voltages: [0.2901, 0.1982, 0.28841, 0.066093, 0.38561, 0.32851, 0.73445, 0.096684, 0.36806, 0.099005]
Predicted label: 6
Correct prediction
Energy consumption = 188.404594 pJ
sum error= 258
Actual label: 7
Output voltages: [0.35938, 0.2779, 0.3857, 0.2121, 0.13691, 0.053295, 0.041954, 0.72938, 0.31208, 0.32542]
Predicted label: 7
Correct prediction
Energy consumption = 196.437288 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 706 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 706 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 706 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18913, 0.17852, 0.21396, 0.3262, 0.097312, 0.41112, 0.20513, 0.09025, 0.74161, 0.21908]
Predicted label: 8
Correct prediction
Energy consumption = 198.319181 pJ
sum error= 258
Actual label: 9
Output voltages: [0.37417, 0.19176, 0.16022, 0.21454, 0.42822, 0.090441, 0.070491, 0.23527, 0.33729, 0.61105]
Predicted label: 9
Correct prediction
Energy consumption = 201.019760 pJ
sum error= 258
Actual label: 0
Output voltages: [0.71222, 0.24537, 0.2559, 0.15268, 0.18683, 0.17035, 0.4191, 0.15716, 0.32466, 0.21214]
Predicted label: 0
Correct prediction
Energy consumption = 193.904641 pJ
sum error= 258
Actual label: 1
Output voltages: [0.23488, 0.75506, 0.26064, 0.21911, 0.26378, 0.064495, 0.37156, 0.11589, 0.33121, 0.23754]
Predicted label: 1
Correct prediction
Energy consumption = 209.673956 pJ
sum error= 258
Actual label: 2
Output voltages: [0.24969, 0.28165, 0.73245, 0.32331, 0.18018, 0.029477, 0.23331, 0.4251, 0.34949, 0.1799]
Predicted label: 2
Correct prediction
Energy consumption = 186.607171 pJ
sum error= 258
Actual label: 3
Output voltages: [0.30097, 0.27946, 0.28537, 0.75836, 0.14482, 0.15721, 0.10782, 0.19158, 0.4346, 0.28142]
Predicted label: 3
Correct prediction
Energy consumption = 184.660760 pJ
sum error= 258
Actual label: 4
Output voltages: [0.12447, 0.17232, 0.21787, 0.053529, 0.74977, 0.15122, 0.3006, 0.30853, 0.39844, 0.13078]
Predicted label: 4
Correct prediction
Energy consumption = 186.909153 pJ
sum error= 258
Actual label: 5
Output voltages: [0.24258, 0.061962, 0.05978, 0.31146, 0.25761, 0.69989, 0.36654, 0.060757, 0.49858, 0.17996]
Predicted label: 5
Correct prediction
Energy consumption = 188.802505 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27899, 0.19528, 0.25324, 0.097106, 0.29333, 0.33425, 0.732, 0.10652, 0.46029, 0.11229]
Predicted label: 6
Correct prediction
Energy consumption = 192.286145 pJ
sum error= 258
Actual label: 7
Output voltages: [0.35323, 0.17176, 0.30058, 0.2978, 0.11095, 0.055983, 0.043725, 0.74981, 0.38941, 0.28681]
Predicted label: 7
Correct prediction
Energy consumption = 192.834847 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 707 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 707 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 707 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.22941, 0.36078, 0.2735, 0.2303, 0.16986, 0.13661, 0.15038, 0.17237, 0.70832, 0.25057]
Predicted label: 8
Correct prediction
Energy consumption = 204.249269 pJ
sum error= 258
Actual label: 9
Output voltages: [0.32996, 0.12572, 0.18013, 0.24952, 0.39645, 0.14089, 0.10408, 0.23268, 0.37456, 0.62734]
Predicted label: 9
Correct prediction
Energy consumption = 192.759853 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73065, 0.27304, 0.22799, 0.2249, 0.12409, 0.1882, 0.40144, 0.19092, 0.27734, 0.22853]
Predicted label: 0
Correct prediction
Energy consumption = 198.602026 pJ
sum error= 258
Actual label: 1
Output voltages: [0.19495, 0.76302, 0.28483, 0.24611, 0.22722, 0.067592, 0.41452, 0.1401, 0.29753, 0.19847]
Predicted label: 1
Correct prediction
Energy consumption = 205.624185 pJ
sum error= 258
Actual label: 2
Output voltages: [0.3515, 0.26553, 0.73294, 0.31196, 0.13606, 0.030396, 0.22135, 0.38843, 0.38471, 0.15788]
Predicted label: 2
Correct prediction
Energy consumption = 195.380931 pJ
sum error= 258
Actual label: 3
Output voltages: [0.35388, 0.10487, 0.35492, 0.74266, 0.17618, 0.25713, 0.12766, 0.19191, 0.43194, 0.17029]
Predicted label: 3
Correct prediction
Energy consumption = 182.681280 pJ
sum error= 258
Actual label: 4
Output voltages: [0.12532, 0.17754, 0.21817, 0.17311, 0.75219, 0.092186, 0.25165, 0.30155, 0.25849, 0.18668]
Predicted label: 4
Correct prediction
Energy consumption = 192.117267 pJ
sum error= 258
Actual label: 5
Output voltages: [0.25133, 0.07101, 0.050061, 0.37995, 0.23144, 0.72055, 0.35009, 0.08002, 0.46748, 0.19917]
Predicted label: 5
Correct prediction
Energy consumption = 186.093630 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28673, 0.23693, 0.33393, 0.066259, 0.3856, 0.27951, 0.7477, 0.062735, 0.31845, 0.162]
Predicted label: 6
Correct prediction
Energy consumption = 189.813447 pJ
sum error= 258
Actual label: 7
Output voltages: [0.36083, 0.19453, 0.23266, 0.33973, 0.11016, 0.085663, 0.041628, 0.75203, 0.38642, 0.32124]
Predicted label: 7
Correct prediction
Energy consumption = 194.046039 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 708 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 708 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 708 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.29099, 0.27982, 0.3561, 0.20191, 0.2083, 0.10409, 0.26992, 0.098082, 0.72929, 0.29449]
Predicted label: 8
Correct prediction
Energy consumption = 197.743533 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34537, 0.10327, 0.1617, 0.19589, 0.54622, 0.1753, 0.15463, 0.18799, 0.3081, 0.60603]
Predicted label: 9
Correct prediction
Energy consumption = 194.945502 pJ
sum error= 258
Actual label: 7
Output voltages: [0.30734, 0.19317, 0.24972, 0.24275, 0.12823, 0.073965, 0.035173, 0.74098, 0.46268, 0.36432]
Predicted label: 7
Correct prediction
Energy consumption = 200.020005 pJ
sum error= 258
Actual label: 4
Output voltages: [0.064877, 0.15028, 0.15849, 0.22471, 0.70352, 0.13289, 0.22021, 0.32645, 0.34736, 0.23466]
Predicted label: 4
Correct prediction
Energy consumption = 200.262312 pJ
sum error= 258
Actual label: 0
Output voltages: [0.6977, 0.20021, 0.29768, 0.17392, 0.18454, 0.096207, 0.37023, 0.18732, 0.3579, 0.28839]
Predicted label: 0
Correct prediction
Energy consumption = 208.014561 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11135, 0.10617, 0.16869, 0.15464, 0.74488, 0.14882, 0.26607, 0.29545, 0.34671, 0.17121]
Predicted label: 4
Correct prediction
Energy consumption = 190.567748 pJ
sum error= 258
Actual label: 0
Output voltages: [0.68793, 0.24688, 0.32572, 0.15181, 0.22592, 0.11452, 0.37546, 0.19179, 0.29944, 0.1514]
Predicted label: 0
Correct prediction
Energy consumption = 200.179950 pJ
sum error= 258
Actual label: 1
Output voltages: [0.26216, 0.75481, 0.30322, 0.24121, 0.37787, 0.050689, 0.30857, 0.13253, 0.2129, 0.27174]
Predicted label: 1
Correct prediction
Energy consumption = 209.133670 pJ
sum error= 258
Actual label: 7
Output voltages: [0.32037, 0.21661, 0.31252, 0.24943, 0.15804, 0.077034, 0.042349, 0.75845, 0.35893, 0.34479]
Predicted label: 7
Correct prediction
Energy consumption = 197.512785 pJ
sum error= 258
Actual label: 9
Output voltages: [0.29267, 0.14404, 0.19253, 0.28363, 0.50054, 0.14709, 0.15938, 0.22874, 0.27134, 0.59227]
Predicted label: 9
Correct prediction
Energy consumption = 190.880887 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 709 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 709 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 709 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.31563, 0.18225, 0.052007, 0.38638, 0.26381, 0.74711, 0.31576, 0.075762, 0.35393, 0.22542]
Predicted label: 5
Correct prediction
Energy consumption = 199.203256 pJ
sum error= 258
Actual label: 1
Output voltages: [0.24906, 0.73088, 0.30121, 0.16358, 0.35368, 0.05891, 0.36547, 0.11067, 0.26263, 0.24029]
Predicted label: 1
Correct prediction
Energy consumption = 207.383562 pJ
sum error= 258
Actual label: 4
Output voltages: [0.13102, 0.14893, 0.20725, 0.095324, 0.7545, 0.15135, 0.30415, 0.32515, 0.32163, 0.15503]
Predicted label: 4
Correct prediction
Energy consumption = 187.730561 pJ
sum error= 258
Actual label: 2
Output voltages: [0.35353, 0.18812, 0.73622, 0.25611, 0.14371, 0.03528, 0.20813, 0.38313, 0.45669, 0.14744]
Predicted label: 2
Correct prediction
Energy consumption = 193.392568 pJ
sum error= 258
Actual label: 8
Output voltages: [0.2672, 0.16723, 0.2523, 0.18864, 0.16452, 0.15559, 0.099666, 0.19069, 0.66579, 0.43831]
Predicted label: 8
Correct prediction
Energy consumption = 196.758424 pJ
sum error= 258
Actual label: 9
Output voltages: [0.30017, 0.1623, 0.18874, 0.253, 0.41577, 0.12655, 0.085894, 0.13103, 0.35129, 0.64992]
Predicted label: 9
Correct prediction
Energy consumption = 188.824549 pJ
sum error= 258
Actual label: 4
Output voltages: [0.1079, 0.16857, 0.18346, 0.069686, 0.74291, 0.16742, 0.30254, 0.31867, 0.36027, 0.13788]
Predicted label: 4
Correct prediction
Energy consumption = 180.160430 pJ
sum error= 258
Actual label: 3
Output voltages: [0.33632, 0.25707, 0.25942, 0.76006, 0.12291, 0.18432, 0.083084, 0.31746, 0.46058, 0.21682]
Predicted label: 3
Correct prediction
Energy consumption = 190.406512 pJ
sum error= 258
Actual label: 7
Output voltages: [0.33634, 0.19283, 0.17122, 0.43643, 0.090341, 0.16404, 0.034574, 0.72031, 0.3825, 0.40099]
Predicted label: 7
Correct prediction
Energy consumption = 194.458780 pJ
sum error= 258
Actual label: 8
Output voltages: [0.27469, 0.22529, 0.24235, 0.3505, 0.078029, 0.29361, 0.14398, 0.20683, 0.74371, 0.19516]
Predicted label: 8
Correct prediction
Energy consumption = 194.928455 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 710 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 710 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 710 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.30333, 0.24639, 0.74205, 0.33209, 0.19989, 0.030211, 0.21298, 0.40231, 0.35654, 0.1903]
Predicted label: 2
Correct prediction
Energy consumption = 185.681721 pJ
sum error= 258
Actual label: 4
Output voltages: [0.084386, 0.15517, 0.21468, 0.16012, 0.7485, 0.12517, 0.21811, 0.28439, 0.31345, 0.20095]
Predicted label: 4
Correct prediction
Energy consumption = 186.692510 pJ
sum error= 258
Actual label: 4
Output voltages: [0.08663, 0.17686, 0.19445, 0.13637, 0.72679, 0.14097, 0.23494, 0.22788, 0.35344, 0.24887]
Predicted label: 4
Correct prediction
Energy consumption = 188.086274 pJ
sum error= 258
Actual label: 3
Output voltages: [0.29795, 0.25587, 0.26105, 0.7639, 0.13774, 0.24652, 0.14109, 0.24921, 0.41958, 0.26891]
Predicted label: 3
Correct prediction
Energy consumption = 184.130838 pJ
sum error= 258
Actual label: 3
Output voltages: [0.30127, 0.19457, 0.35483, 0.75472, 0.17072, 0.13558, 0.10907, 0.26582, 0.43652, 0.23286]
Predicted label: 3
Correct prediction
Energy consumption = 173.675092 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27907, 0.22073, 0.31136, 0.066249, 0.33475, 0.29333, 0.73778, 0.075291, 0.37524, 0.11492]
Predicted label: 6
Correct prediction
Energy consumption = 189.357587 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34115, 0.16029, 0.18409, 0.23584, 0.36812, 0.12386, 0.071533, 0.13515, 0.36245, 0.66879]
Predicted label: 9
Correct prediction
Energy consumption = 188.942260 pJ
sum error= 258
Actual label: 9
Output voltages: [0.32411, 0.17255, 0.20331, 0.27278, 0.39303, 0.10934, 0.073168, 0.19054, 0.33435, 0.66541]
Predicted label: 9
Correct prediction
Energy consumption = 182.256821 pJ
sum error= 258
Actual label: 5
Output voltages: [0.31274, 0.18541, 0.039414, 0.38567, 0.2864, 0.74247, 0.35472, 0.1203, 0.33975, 0.2683]
Predicted label: 5
Correct prediction
Energy consumption = 187.335872 pJ
sum error= 258
Actual label: 8
Output voltages: [0.25854, 0.20966, 0.30407, 0.3647, 0.13935, 0.17583, 0.18708, 0.14139, 0.75434, 0.25723]
Predicted label: 8
Correct prediction
Energy consumption = 188.470858 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 711 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 711 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 711 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.34062, 0.21853, 0.23664, 0.14395, 0.33227, 0.38969, 0.72796, 0.11312, 0.39496, 0.082822]
Predicted label: 6
Correct prediction
Energy consumption = 196.880749 pJ
sum error= 258
Actual label: 7
Output voltages: [0.30981, 0.25334, 0.366, 0.31815, 0.10654, 0.070898, 0.039401, 0.75225, 0.37183, 0.33354]
Predicted label: 7
Correct prediction
Energy consumption = 198.452211 pJ
sum error= 258
Actual label: 0
Output voltages: [0.69159, 0.30711, 0.28982, 0.15144, 0.10724, 0.10044, 0.39965, 0.17843, 0.29253, 0.23991]
Predicted label: 0
Correct prediction
Energy consumption = 197.501006 pJ
sum error= 258
Actual label: 6
Output voltages: [0.31485, 0.18626, 0.34145, 0.050804, 0.3541, 0.25854, 0.72396, 0.074175, 0.30163, 0.096473]
Predicted label: 6
Correct prediction
Energy consumption = 185.321033 pJ
sum error= 258
Actual label: 8
Output voltages: [0.22228, 0.22085, 0.27348, 0.2634, 0.19811, 0.19505, 0.21803, 0.14002, 0.75504, 0.27303]
Predicted label: 8
Correct prediction
Energy consumption = 188.629712 pJ
sum error= 258
Actual label: 2
Output voltages: [0.28365, 0.22434, 0.73889, 0.34643, 0.21552, 0.03081, 0.18858, 0.40892, 0.37611, 0.20685]
Predicted label: 2
Correct prediction
Energy consumption = 183.052187 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27885, 0.22986, 0.36692, 0.053072, 0.34328, 0.25714, 0.74279, 0.060495, 0.35303, 0.12591]
Predicted label: 6
Correct prediction
Energy consumption = 185.673659 pJ
sum error= 258
Actual label: 3
Output voltages: [0.20553, 0.19585, 0.34216, 0.7233, 0.086943, 0.12463, 0.089243, 0.25111, 0.53264, 0.23229]
Predicted label: 3
Correct prediction
Energy consumption = 183.493903 pJ
sum error= 258
Actual label: 9
Output voltages: [0.30891, 0.15193, 0.16862, 0.29452, 0.25518, 0.11293, 0.047232, 0.29207, 0.40886, 0.62385]
Predicted label: 9
Correct prediction
Energy consumption = 190.238843 pJ
sum error= 258
Actual label: 3
Output voltages: [0.27959, 0.23469, 0.30818, 0.75666, 0.15241, 0.21463, 0.13468, 0.21338, 0.49989, 0.21982]
Predicted label: 3
Correct prediction
Energy consumption = 177.729752 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 712 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 712 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 712 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24481, 0.28121, 0.72471, 0.32905, 0.1685, 0.039865, 0.19259, 0.3919, 0.43637, 0.16356]
Predicted label: 2
Correct prediction
Energy consumption = 191.793267 pJ
sum error= 258
Actual label: 8
Output voltages: [0.24026, 0.22277, 0.25753, 0.2043, 0.22753, 0.087057, 0.13758, 0.14014, 0.65722, 0.42129]
Predicted label: 8
Correct prediction
Energy consumption = 202.712201 pJ
sum error= 258
Actual label: 6
Output voltages: [0.33897, 0.29193, 0.2599, 0.13895, 0.36086, 0.3546, 0.74058, 0.12967, 0.27979, 0.1167]
Predicted label: 6
Correct prediction
Energy consumption = 200.067808 pJ
sum error= 258
Actual label: 1
Output voltages: [0.1852, 0.75582, 0.21645, 0.26256, 0.34886, 0.083024, 0.39023, 0.12549, 0.24422, 0.23048]
Predicted label: 1
Correct prediction
Energy consumption = 205.307365 pJ
sum error= 258
Actual label: 7
Output voltages: [0.32288, 0.25904, 0.38368, 0.24948, 0.11089, 0.057293, 0.038531, 0.74435, 0.38956, 0.31084]
Predicted label: 7
Correct prediction
Energy consumption = 193.894403 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11124, 0.12367, 0.18493, 0.099445, 0.7414, 0.14008, 0.27513, 0.27097, 0.38058, 0.14575]
Predicted label: 4
Correct prediction
Energy consumption = 191.022234 pJ
sum error= 258
Actual label: 8
Output voltages: [0.19797, 0.20414, 0.25628, 0.27437, 0.17652, 0.19724, 0.16963, 0.11273, 0.74341, 0.31639]
Predicted label: 8
Correct prediction
Energy consumption = 190.498812 pJ
sum error= 258
Actual label: 8
Output voltages: [0.18098, 0.27029, 0.27114, 0.31688, 0.10364, 0.17881, 0.098302, 0.21538, 0.73943, 0.30008]
Predicted label: 8
Correct prediction
Energy consumption = 186.676013 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34358, 0.12491, 0.23474, 0.19971, 0.33566, 0.096176, 0.055784, 0.20165, 0.4035, 0.66044]
Predicted label: 9
Correct prediction
Energy consumption = 188.989050 pJ
sum error= 258
Actual label: 0
Output voltages: [0.70107, 0.28232, 0.27477, 0.17372, 0.19163, 0.11757, 0.34758, 0.17838, 0.33379, 0.18075]
Predicted label: 0
Correct prediction
Energy consumption = 193.947633 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 713 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 713 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 713 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.22421, 0.25741, 0.31623, 0.74092, 0.1135, 0.11841, 0.085256, 0.26061, 0.43057, 0.30259]
Predicted label: 3
Correct prediction
Energy consumption = 191.651240 pJ
sum error= 258
Actual label: 3
Output voltages: [0.28855, 0.27913, 0.26787, 0.76561, 0.13403, 0.21205, 0.087894, 0.29599, 0.46319, 0.21074]
Predicted label: 3
Correct prediction
Energy consumption = 175.984677 pJ
sum error= 258
Actual label: 9
Output voltages: [0.26093, 0.16733, 0.18262, 0.22549, 0.39323, 0.14688, 0.13377, 0.28921, 0.33345, 0.61158]
Predicted label: 9
Correct prediction
Energy consumption = 190.663876 pJ
sum error= 258
Actual label: 0
Output voltages: [0.68456, 0.25428, 0.30335, 0.23171, 0.2083, 0.075171, 0.43608, 0.15071, 0.37298, 0.24104]
Predicted label: 0
Correct prediction
Energy consumption = 205.096733 pJ
sum error= 258
Actual label: 5
Output voltages: [0.27706, 0.060434, 0.0501, 0.32467, 0.3616, 0.73602, 0.33072, 0.090055, 0.3999, 0.24894]
Predicted label: 5
Correct prediction
Energy consumption = 187.330699 pJ
sum error= 258
Actual label: 2
Output voltages: [0.25647, 0.2215, 0.71597, 0.34706, 0.14756, 0.034727, 0.22832, 0.43046, 0.38082, 0.14986]
Predicted label: 2
Correct prediction
Energy consumption = 187.438311 pJ
sum error= 258
Actual label: 9
Output voltages: [0.28715, 0.13494, 0.1876, 0.25083, 0.36519, 0.10482, 0.084665, 0.19857, 0.41155, 0.57751]
Predicted label: 9
Correct prediction
Energy consumption = 193.226234 pJ
sum error= 258
Actual label: 4
Output voltages: [0.18589, 0.11922, 0.31955, 0.17799, 0.73309, 0.085581, 0.24764, 0.19085, 0.34127, 0.17051]
Predicted label: 4
Correct prediction
Energy consumption = 183.967470 pJ
sum error= 258
Actual label: 1
Output voltages: [0.26979, 0.72719, 0.29117, 0.22739, 0.36402, 0.099259, 0.41172, 0.14542, 0.26885, 0.15882]
Predicted label: 1
Correct prediction
Energy consumption = 196.875349 pJ
sum error= 258
Actual label: 0
Output voltages: [0.70989, 0.23296, 0.29532, 0.15673, 0.18357, 0.076468, 0.36845, 0.15559, 0.34941, 0.23055]
Predicted label: 0
Correct prediction
Energy consumption = 192.480850 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 714 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 714 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 714 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36816, 0.19917, 0.31875, 0.76145, 0.19038, 0.20834, 0.17486, 0.20962, 0.37145, 0.20263]
Predicted label: 3
Correct prediction
Energy consumption = 188.444565 pJ
sum error= 258
Actual label: 7
Output voltages: [0.26719, 0.25909, 0.3251, 0.32233, 0.079321, 0.057751, 0.038988, 0.75347, 0.38819, 0.31845]
Predicted label: 7
Correct prediction
Energy consumption = 196.510451 pJ
sum error= 258
Actual label: 5
Output voltages: [0.2324, 0.047643, 0.052826, 0.27818, 0.30995, 0.72499, 0.35591, 0.09367, 0.48806, 0.2321]
Predicted label: 5
Correct prediction
Energy consumption = 190.795963 pJ
sum error= 258
Actual label: 8
Output voltages: [0.20428, 0.25714, 0.24848, 0.33344, 0.14163, 0.19789, 0.17534, 0.18038, 0.7451, 0.25293]
Predicted label: 8
Correct prediction
Energy consumption = 191.287474 pJ
sum error= 258
Actual label: 7
Output voltages: [0.38403, 0.21119, 0.27555, 0.27699, 0.11878, 0.077697, 0.047494, 0.7483, 0.42581, 0.3145]
Predicted label: 7
Correct prediction
Energy consumption = 195.019238 pJ
sum error= 258
Actual label: 7
Output voltages: [0.38783, 0.22828, 0.35013, 0.19933, 0.15991, 0.060322, 0.063127, 0.74394, 0.33848, 0.3201]
Predicted label: 7
Correct prediction
Energy consumption = 191.924779 pJ
sum error= 258
Actual label: 8
Output voltages: [0.20796, 0.20187, 0.27496, 0.25925, 0.20429, 0.1648, 0.21948, 0.12041, 0.74125, 0.26756]
Predicted label: 8
Correct prediction
Energy consumption = 193.984019 pJ
sum error= 258
Actual label: 2
Output voltages: [0.3618, 0.17149, 0.74113, 0.30556, 0.15084, 0.038163, 0.267, 0.38694, 0.44718, 0.16277]
Predicted label: 2
Correct prediction
Energy consumption = 179.892861 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34759, 0.10495, 0.16005, 0.29975, 0.32699, 0.18621, 0.069666, 0.22947, 0.38399, 0.63227]
Predicted label: 9
Correct prediction
Energy consumption = 193.377223 pJ
sum error= 258
Actual label: 7
Output voltages: [0.31698, 0.24463, 0.33732, 0.2498, 0.16439, 0.080954, 0.034633, 0.74403, 0.37745, 0.36746]
Predicted label: 7
Correct prediction
Energy consumption = 182.841035 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 715 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 715 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 715 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.22945, 0.74523, 0.29539, 0.27052, 0.38813, 0.059379, 0.36402, 0.11408, 0.21872, 0.26005]
Predicted label: 1
Correct prediction
Energy consumption = 205.370189 pJ
sum error= 258
Actual label: 2
Output voltages: [0.31755, 0.20839, 0.73608, 0.36096, 0.1699, 0.033758, 0.21012, 0.3618, 0.42877, 0.17905]
Predicted label: 2
Correct prediction
Energy consumption = 184.125799 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28029, 0.21831, 0.31027, 0.072667, 0.32268, 0.3281, 0.74841, 0.063537, 0.36526, 0.12921]
Predicted label: 6
Correct prediction
Energy consumption = 186.485545 pJ
sum error= 258
Actual label: 4
Output voltages: [0.087005, 0.17698, 0.2231, 0.050314, 0.73061, 0.20086, 0.2149, 0.24321, 0.41147, 0.2476]
Predicted label: 4
Correct prediction
Energy consumption = 189.679923 pJ
sum error= 258
Actual label: 2
Output voltages: [0.31762, 0.256, 0.74131, 0.28512, 0.11102, 0.029939, 0.20592, 0.39579, 0.42408, 0.17109]
Predicted label: 2
Correct prediction
Energy consumption = 192.435450 pJ
sum error= 258
Actual label: 5
Output voltages: [0.3249, 0.084206, 0.058716, 0.46751, 0.21883, 0.72102, 0.3204, 0.096758, 0.43499, 0.20351]
Predicted label: 5
Correct prediction
Energy consumption = 188.270584 pJ
sum error= 258
Actual label: 2
Output voltages: [0.30401, 0.24696, 0.75249, 0.23969, 0.15506, 0.034983, 0.1943, 0.43281, 0.35919, 0.20854]
Predicted label: 2
Correct prediction
Energy consumption = 187.577803 pJ
sum error= 258
Actual label: 3
Output voltages: [0.28651, 0.27872, 0.29524, 0.7597, 0.13004, 0.13845, 0.105, 0.19687, 0.48206, 0.22091]
Predicted label: 3
Correct prediction
Energy consumption = 184.393554 pJ
sum error= 258
Actual label: 6
Output voltages: [0.30254, 0.21824, 0.28214, 0.087001, 0.38823, 0.34851, 0.73335, 0.092338, 0.28996, 0.088205]
Predicted label: 6
Correct prediction
Energy consumption = 198.516601 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28881, 0.21939, 0.30101, 0.07988, 0.32708, 0.3007, 0.74669, 0.111, 0.35128, 0.1492]
Predicted label: 6
Correct prediction
Energy consumption = 180.859480 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 716 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 716 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 716 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.28499, 0.069372, 0.061257, 0.37657, 0.28373, 0.72172, 0.42224, 0.079362, 0.4282, 0.18479]
Predicted label: 5
Correct prediction
Energy consumption = 191.159770 pJ
sum error= 258
Actual label: 0
Output voltages: [0.65167, 0.22871, 0.34044, 0.17825, 0.25514, 0.072795, 0.37957, 0.19617, 0.36956, 0.17811]
Predicted label: 0
Correct prediction
Energy consumption = 201.768359 pJ
sum error= 258
Actual label: 0
Output voltages: [0.68238, 0.16858, 0.3101, 0.18182, 0.21683, 0.091887, 0.36884, 0.16863, 0.45898, 0.25203]
Predicted label: 0
Correct prediction
Energy consumption = 203.034290 pJ
sum error= 258
Actual label: 2
Output voltages: [0.33167, 0.18658, 0.74025, 0.3122, 0.14712, 0.038943, 0.21597, 0.43385, 0.4394, 0.1816]
Predicted label: 2
Correct prediction
Energy consumption = 181.364340 pJ
sum error= 258
Actual label: 8
Output voltages: [0.17147, 0.25253, 0.28509, 0.26099, 0.17083, 0.21458, 0.15773, 0.18246, 0.75381, 0.25044]
Predicted label: 8
Correct prediction
Energy consumption = 196.893266 pJ
sum error= 258
Actual label: 1
Output voltages: [0.21359, 0.74115, 0.24806, 0.17912, 0.37389, 0.072584, 0.31915, 0.096273, 0.26958, 0.28262]
Predicted label: 1
Correct prediction
Energy consumption = 205.615955 pJ
sum error= 258
Actual label: 6
Output voltages: [0.26905, 0.19223, 0.34484, 0.051547, 0.41381, 0.2759, 0.7464, 0.062032, 0.3224, 0.10846]
Predicted label: 6
Correct prediction
Energy consumption = 185.361563 pJ
sum error= 258
Actual label: 1
Output voltages: [0.19469, 0.75473, 0.17679, 0.20944, 0.33346, 0.11861, 0.38564, 0.12706, 0.29864, 0.23905]
Predicted label: 1
Correct prediction
Energy consumption = 205.598051 pJ
sum error= 258
Actual label: 0
Output voltages: [0.70305, 0.26192, 0.37689, 0.16804, 0.19732, 0.061557, 0.39112, 0.15389, 0.36361, 0.23104]
Predicted label: 0
Correct prediction
Energy consumption = 195.127966 pJ
sum error= 258
Actual label: 4
Output voltages: [0.10136, 0.17644, 0.23182, 0.073533, 0.74281, 0.14054, 0.26741, 0.28529, 0.39023, 0.16275]
Predicted label: 4
Correct prediction
Energy consumption = 188.962416 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 717 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 717 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 717 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29586, 0.32774, 0.2767, 0.74511, 0.05787, 0.15464, 0.062412, 0.33102, 0.51242, 0.19136]
Predicted label: 3
Correct prediction
Energy consumption = 188.907491 pJ
sum error= 258
Actual label: 1
Output voltages: [0.19317, 0.74785, 0.22053, 0.21445, 0.37517, 0.08831, 0.39289, 0.072604, 0.28628, 0.26055]
Predicted label: 1
Correct prediction
Energy consumption = 205.563387 pJ
sum error= 258
Actual label: 6
Output voltages: [0.26994, 0.21233, 0.34084, 0.059375, 0.38286, 0.28439, 0.74018, 0.060454, 0.34312, 0.094341]
Predicted label: 6
Correct prediction
Energy consumption = 188.134026 pJ
sum error= 258
Actual label: 1
Output voltages: [0.21343, 0.71413, 0.26011, 0.2117, 0.30302, 0.12829, 0.45965, 0.052283, 0.36121, 0.21571]
Predicted label: 1
Correct prediction
Energy consumption = 192.508660 pJ
sum error= 258
Actual label: 9
Output voltages: [0.33126, 0.10878, 0.22373, 0.21856, 0.33941, 0.085783, 0.062995, 0.19466, 0.43172, 0.62688]
Predicted label: 9
Correct prediction
Energy consumption = 193.382886 pJ
sum error= 258
Actual label: 0
Output voltages: [0.7412, 0.29323, 0.24209, 0.22684, 0.14671, 0.25563, 0.37198, 0.19568, 0.25289, 0.27818]
Predicted label: 0
Correct prediction
Energy consumption = 191.228333 pJ
sum error= 258
Actual label: 1
Output voltages: [0.21937, 0.76915, 0.20736, 0.24719, 0.25035, 0.11919, 0.40088, 0.17088, 0.28549, 0.20667]
Predicted label: 1
Correct prediction
Energy consumption = 212.525602 pJ
sum error= 258
Actual label: 4
Output voltages: [0.13485, 0.23316, 0.26818, 0.25429, 0.75155, 0.049567, 0.1655, 0.26739, 0.21434, 0.24512]
Predicted label: 4
Correct prediction
Energy consumption = 198.383540 pJ
sum error= 258
Actual label: 5
Output voltages: [0.23781, 0.061887, 0.093135, 0.46037, 0.2145, 0.68036, 0.30501, 0.25449, 0.38695, 0.27257]
Predicted label: 5
Correct prediction
Energy consumption = 188.590352 pJ
sum error= 258
Actual label: 6
Output voltages: [0.23499, 0.11116, 0.24211, 0.1872, 0.27767, 0.38281, 0.68684, 0.047841, 0.46817, 0.20946]
Predicted label: 6
Correct prediction
Energy consumption = 179.201167 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 718 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 718 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 718 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28929, 0.27366, 0.27005, 0.3318, 0.15689, 0.067941, 0.049591, 0.75976, 0.24309, 0.38593]
Predicted label: 7
Correct prediction
Energy consumption = 200.118657 pJ
sum error= 258
Actual label: 8
Output voltages: [0.24422, 0.21548, 0.38245, 0.47538, 0.086751, 0.13351, 0.18919, 0.11345, 0.71426, 0.25764]
Predicted label: 8
Correct prediction
Energy consumption = 189.962085 pJ
sum error= 258
Actual label: 9
Output voltages: [0.33038, 0.079966, 0.20509, 0.31142, 0.18269, 0.32141, 0.083945, 0.36326, 0.35787, 0.62902]
Predicted label: 9
Correct prediction
Energy consumption = 191.559678 pJ
sum error= 258
Actual label: 1
Output voltages: [0.17878, 0.76402, 0.26273, 0.2275, 0.23447, 0.09761, 0.34765, 0.11645, 0.32341, 0.23039]
Predicted label: 1
Correct prediction
Energy consumption = 211.181516 pJ
sum error= 258
Actual label: 2
Output voltages: [0.38161, 0.10881, 0.71626, 0.38756, 0.12724, 0.048536, 0.17765, 0.27073, 0.47476, 0.18654]
Predicted label: 2
Correct prediction
Energy consumption = 186.457014 pJ
sum error= 258
Actual label: 3
Output voltages: [0.37107, 0.14367, 0.29307, 0.75863, 0.11075, 0.2035, 0.15453, 0.18897, 0.39622, 0.1937]
Predicted label: 3
Correct prediction
Energy consumption = 183.584774 pJ
sum error= 258
Actual label: 4
Output voltages: [0.10653, 0.12682, 0.21357, 0.25352, 0.73253, 0.11978, 0.17497, 0.22431, 0.29974, 0.26544]
Predicted label: 4
Correct prediction
Energy consumption = 189.676360 pJ
sum error= 258
Actual label: 5
Output voltages: [0.37903, 0.093517, 0.062256, 0.51857, 0.17673, 0.73759, 0.3098, 0.22595, 0.37335, 0.17946]
Predicted label: 5
Correct prediction
Energy consumption = 183.257045 pJ
sum error= 258
Actual label: 6
Output voltages: [0.26679, 0.13877, 0.28462, 0.1014, 0.25479, 0.37029, 0.70164, 0.16005, 0.46616, 0.061735]
Predicted label: 6
Correct prediction
Energy consumption = 186.547848 pJ
sum error= 258
Actual label: 7
Output voltages: [0.32562, 0.24976, 0.32819, 0.30823, 0.14741, 0.05112, 0.037169, 0.71672, 0.29148, 0.32657]
Predicted label: 7
Correct prediction
Energy consumption = 193.574455 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 719 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 719 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 719 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74032, 0.19305, 0.29539, 0.19623, 0.072286, 0.20939, 0.37633, 0.26093, 0.25016, 0.25707]
Predicted label: 0
Correct prediction
Energy consumption = 188.600285 pJ
sum error= 258
Actual label: 1
Output voltages: [0.23403, 0.71494, 0.26303, 0.14306, 0.36314, 0.074342, 0.35213, 0.09196, 0.31725, 0.22116]
Predicted label: 1
Correct prediction
Energy consumption = 203.170999 pJ
sum error= 258
Actual label: 2
Output voltages: [0.36029, 0.15929, 0.74858, 0.28225, 0.15111, 0.039405, 0.22508, 0.24549, 0.46777, 0.1467]
Predicted label: 2
Correct prediction
Energy consumption = 180.494313 pJ
sum error= 258
Actual label: 3
Output voltages: [0.44185, 0.18674, 0.32061, 0.75017, 0.1058, 0.28779, 0.15544, 0.17511, 0.37018, 0.15641]
Predicted label: 3
Correct prediction
Energy consumption = 184.778696 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11406, 0.24066, 0.29941, 0.23161, 0.7578, 0.066309, 0.24635, 0.27233, 0.16063, 0.23993]
Predicted label: 4
Correct prediction
Energy consumption = 187.820009 pJ
sum error= 258
Actual label: 5
Output voltages: [0.33293, 0.052652, 0.051765, 0.39197, 0.23854, 0.73162, 0.33226, 0.25, 0.38442, 0.20574]
Predicted label: 5
Correct prediction
Energy consumption = 185.089774 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28965, 0.075357, 0.25205, 0.20262, 0.29872, 0.37111, 0.66859, 0.043923, 0.44556, 0.23841]
Predicted label: 6
Correct prediction
Energy consumption = 185.668036 pJ
sum error= 258
Actual label: 7
Output voltages: [0.46521, 0.16056, 0.16001, 0.26007, 0.23671, 0.24681, 0.053431, 0.74542, 0.31923, 0.35235]
Predicted label: 7
Correct prediction
Energy consumption = 191.512006 pJ
sum error= 258
Actual label: 8
Output voltages: [0.37384, 0.19298, 0.40315, 0.34735, 0.2074, 0.059202, 0.18894, 0.082501, 0.63271, 0.35946]
Predicted label: 8
Correct prediction
Energy consumption = 194.395710 pJ
sum error= 258
Actual label: 9
Output voltages: [0.31132, 0.11373, 0.16505, 0.26975, 0.29236, 0.19276, 0.071282, 0.28132, 0.42771, 0.66812]
Predicted label: 9
Correct prediction
Energy consumption = 184.679131 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 720 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 720 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 720 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2554, 0.2243, 0.30846, 0.35974, 0.16684, 0.11146, 0.19573, 0.12407, 0.71617, 0.27532]
Predicted label: 8
Correct prediction
Energy consumption = 201.758888 pJ
sum error= 258
Actual label: 4
Output voltages: [0.13996, 0.17009, 0.30508, 0.20935, 0.74999, 0.050054, 0.1896, 0.26334, 0.25433, 0.20964]
Predicted label: 4
Correct prediction
Energy consumption = 189.512072 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73269, 0.28365, 0.27472, 0.27421, 0.095044, 0.17793, 0.32594, 0.2628, 0.30184, 0.25882]
Predicted label: 0
Correct prediction
Energy consumption = 196.608645 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73238, 0.25126, 0.24127, 0.19316, 0.18447, 0.11519, 0.38697, 0.16385, 0.28454, 0.21634]
Predicted label: 0
Correct prediction
Energy consumption = 189.292849 pJ
sum error= 258
Actual label: 7
Output voltages: [0.36346, 0.26026, 0.47002, 0.28565, 0.15136, 0.033942, 0.048347, 0.71162, 0.30365, 0.27879]
Predicted label: 7
Correct prediction
Energy consumption = 194.758343 pJ
sum error= 258
Actual label: 2
Output voltages: [0.28763, 0.18004, 0.75004, 0.23144, 0.12394, 0.037493, 0.19909, 0.3875, 0.44269, 0.15786]
Predicted label: 2
Correct prediction
Energy consumption = 175.358451 pJ
sum error= 258
Actual label: 4
Output voltages: [0.13248, 0.21572, 0.25942, 0.21683, 0.75709, 0.104, 0.23288, 0.25688, 0.21575, 0.22674]
Predicted label: 4
Correct prediction
Energy consumption = 187.426451 pJ
sum error= 258
Actual label: 3
Output voltages: [0.3687, 0.161, 0.32317, 0.75503, 0.1586, 0.19999, 0.11487, 0.14183, 0.4555, 0.1864]
Predicted label: 3
Correct prediction
Energy consumption = 181.449050 pJ
sum error= 258
Actual label: 8
Output voltages: [0.20811, 0.26617, 0.43809, 0.36888, 0.052125, 0.055409, 0.16884, 0.31972, 0.65398, 0.30376]
Predicted label: 8
Correct prediction
Energy consumption = 186.504558 pJ
sum error= 258
Actual label: 6
Output voltages: [0.31308, 0.092144, 0.13959, 0.23155, 0.27465, 0.51433, 0.63364, 0.063385, 0.50775, 0.19717]
Predicted label: 6
Correct prediction
Energy consumption = 184.121008 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 721 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 721 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 721 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32781, 0.18063, 0.20265, 0.23154, 0.30261, 0.33121, 0.66349, 0.074933, 0.51636, 0.17713]
Predicted label: 6
Correct prediction
Energy consumption = 193.393672 pJ
sum error= 258
Actual label: 3
Output voltages: [0.3657, 0.065601, 0.20256, 0.70019, 0.16212, 0.46661, 0.15713, 0.18755, 0.49293, 0.16997]
Predicted label: 3
Correct prediction
Energy consumption = 186.847315 pJ
sum error= 258
Actual label: 2
Output voltages: [0.2584, 0.10209, 0.71318, 0.32956, 0.24752, 0.038691, 0.14627, 0.4175, 0.37187, 0.19208]
Predicted label: 2
Correct prediction
Energy consumption = 182.261910 pJ
sum error= 258
Actual label: 6
Output voltages: [0.25954, 0.14152, 0.30271, 0.086397, 0.3726, 0.3678, 0.72187, 0.06054, 0.38773, 0.17483]
Predicted label: 6
Correct prediction
Energy consumption = 182.604863 pJ
sum error= 258
Actual label: 3
Output voltages: [0.33441, 0.13732, 0.29149, 0.75233, 0.14984, 0.17623, 0.11917, 0.20392, 0.46606, 0.17637]
Predicted label: 3
Correct prediction
Energy consumption = 190.755831 pJ
sum error= 258
Actual label: 3
Output voltages: [0.32569, 0.18587, 0.28456, 0.75781, 0.14366, 0.30186, 0.10407, 0.19996, 0.47418, 0.18229]
Predicted label: 3
Correct prediction
Energy consumption = 171.384025 pJ
sum error= 258
Actual label: 0
Output voltages: [0.68245, 0.21723, 0.20497, 0.30375, 0.08226, 0.23358, 0.48812, 0.2786, 0.34193, 0.16863]
Predicted label: 0
Correct prediction
Energy consumption = 187.127105 pJ
sum error= 258
Actual label: 1
Output voltages: [0.26526, 0.7028, 0.28838, 0.12848, 0.42063, 0.054611, 0.26168, 0.11431, 0.2604, 0.30412]
Predicted label: 1
Correct prediction
Energy consumption = 202.428739 pJ
sum error= 258
Actual label: 4
Output voltages: [0.062388, 0.27011, 0.26164, 0.14386, 0.75916, 0.13393, 0.28023, 0.37231, 0.1998, 0.19234]
Predicted label: 4
Correct prediction
Energy consumption = 193.413945 pJ
sum error= 258
Actual label: 7
Output voltages: [0.42783, 0.21129, 0.12349, 0.18905, 0.24878, 0.18782, 0.055632, 0.75738, 0.28556, 0.33047]
Predicted label: 7
Correct prediction
Energy consumption = 191.002971 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 722 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 722 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 722 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20663, 0.25402, 0.31832, 0.45772, 0.096767, 0.14535, 0.21137, 0.12086, 0.66629, 0.32247]
Predicted label: 8
Correct prediction
Energy consumption = 194.728341 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73388, 0.2641, 0.25747, 0.22999, 0.14769, 0.1566, 0.32613, 0.20928, 0.33188, 0.27681]
Predicted label: 0
Correct prediction
Energy consumption = 191.948765 pJ
sum error= 258
Actual label: 3
Output voltages: [0.3298, 0.18644, 0.29572, 0.76082, 0.12123, 0.19233, 0.12048, 0.21052, 0.45583, 0.22219]
Predicted label: 3
Correct prediction
Energy consumption = 180.800807 pJ
sum error= 258
Actual label: 1
Output voltages: [0.28841, 0.72771, 0.15502, 0.22091, 0.39413, 0.11598, 0.26573, 0.17714, 0.30833, 0.21531]
Predicted label: 1
Correct prediction
Energy consumption = 201.253958 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34066, 0.17298, 0.1798, 0.29178, 0.28549, 0.23382, 0.15362, 0.29132, 0.35443, 0.69236]
Predicted label: 9
Correct prediction
Energy consumption = 189.615147 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73171, 0.27369, 0.25661, 0.21359, 0.15537, 0.15065, 0.449, 0.15128, 0.29047, 0.2922]
Predicted label: 0
Correct prediction
Energy consumption = 196.583222 pJ
sum error= 258
Actual label: 1
Output voltages: [0.2819, 0.67652, 0.22303, 0.17718, 0.39498, 0.075238, 0.31817, 0.14635, 0.2929, 0.25368]
Predicted label: 1
Correct prediction
Energy consumption = 202.426241 pJ
sum error= 258
Actual label: 9
Output voltages: [0.38807, 0.15931, 0.18384, 0.31756, 0.35354, 0.18188, 0.1175, 0.20516, 0.34151, 0.69905]
Predicted label: 9
Correct prediction
Energy consumption = 190.289587 pJ
sum error= 258
Actual label: 1
Output voltages: [0.28218, 0.6836, 0.27885, 0.12397, 0.38471, 0.094714, 0.39974, 0.053094, 0.31678, 0.25012]
Predicted label: 1
Correct prediction
Energy consumption = 205.881024 pJ
sum error= 258
Actual label: 2
Output voltages: [0.33451, 0.095388, 0.72538, 0.27626, 0.20773, 0.04841, 0.18743, 0.39425, 0.4595, 0.22592]
Predicted label: 2
Correct prediction
Energy consumption = 184.710121 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 723 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 723 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 723 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34717, 0.24142, 0.25655, 0.22099, 0.21814, 0.14654, 0.040258, 0.74085, 0.26247, 0.38357]
Predicted label: 7
Correct prediction
Energy consumption = 202.481650 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73509, 0.25568, 0.20005, 0.22344, 0.16616, 0.14531, 0.39108, 0.2219, 0.35835, 0.24169]
Predicted label: 0
Correct prediction
Energy consumption = 189.920297 pJ
sum error= 258
Actual label: 1
Output voltages: [0.21118, 0.72615, 0.27357, 0.11393, 0.3452, 0.11946, 0.42362, 0.087923, 0.35529, 0.28573]
Predicted label: 1
Correct prediction
Energy consumption = 209.535994 pJ
sum error= 258
Actual label: 3
Output voltages: [0.57554, 0.062273, 0.15426, 0.63783, 0.062215, 0.4152, 0.15209, 0.29702, 0.35601, 0.17548]
Predicted label: 3
Correct prediction
Energy consumption = 196.625272 pJ
sum error= 258
Actual label: 8
Output voltages: [0.2736, 0.18489, 0.38888, 0.31746, 0.12858, 0.17861, 0.14708, 0.17699, 0.73249, 0.29393]
Predicted label: 8
Correct prediction
Energy consumption = 186.521863 pJ
sum error= 258
Actual label: 2
Output voltages: [0.28333, 0.06131, 0.71119, 0.26157, 0.1797, 0.097208, 0.17043, 0.33131, 0.49097, 0.19953]
Predicted label: 2
Correct prediction
Energy consumption = 182.797164 pJ
sum error= 258
Actual label: 9
Output voltages: [0.4084, 0.099429, 0.20788, 0.28555, 0.31592, 0.20057, 0.11745, 0.25096, 0.37782, 0.6278]
Predicted label: 9
Correct prediction
Energy consumption = 193.074600 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32196, 0.070198, 0.65729, 0.43193, 0.10669, 0.16449, 0.19502, 0.21863, 0.5216, 0.11566]
Predicted label: 2
Correct prediction
Energy consumption = 183.199235 pJ
sum error= 258
Actual label: 7
Output voltages: [0.3276, 0.30608, 0.35762, 0.24881, 0.24288, 0.054332, 0.051497, 0.71285, 0.19686, 0.36789]
Predicted label: 7
Correct prediction
Energy consumption = 199.730086 pJ
sum error= 258
Actual label: 6
Output voltages: [0.32767, 0.20045, 0.29803, 0.10388, 0.35627, 0.28012, 0.7279, 0.095691, 0.41574, 0.10832]
Predicted label: 6
Correct prediction
Energy consumption = 184.653063 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 724 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 724 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 724 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.29523, 0.088429, 0.10612, 0.52313, 0.3314, 0.64915, 0.21703, 0.17319, 0.43687, 0.10712]
Predicted label: 5
Correct prediction
Energy consumption = 186.094489 pJ
sum error= 258
Actual label: 5
Output voltages: [0.25043, 0.074644, 0.050916, 0.41118, 0.32255, 0.69972, 0.3228, 0.12714, 0.37857, 0.25761]
Predicted label: 5
Correct prediction
Energy consumption = 178.918971 pJ
sum error= 258
Actual label: 9
Output voltages: [0.35105, 0.10334, 0.17882, 0.28963, 0.33298, 0.21341, 0.1143, 0.26608, 0.36661, 0.64332]
Predicted label: 9
Correct prediction
Energy consumption = 189.936373 pJ
sum error= 258
Actual label: 9
Output voltages: [0.38149, 0.13765, 0.19384, 0.31694, 0.33074, 0.20032, 0.14032, 0.23815, 0.34817, 0.68067]
Predicted label: 9
Correct prediction
Energy consumption = 180.734976 pJ
sum error= 258
Actual label: 8
Output voltages: [0.20857, 0.15699, 0.27533, 0.33522, 0.091681, 0.26568, 0.14045, 0.11725, 0.74393, 0.27015]
Predicted label: 8
Correct prediction
Energy consumption = 184.533874 pJ
sum error= 258
Actual label: 2
Output voltages: [0.33281, 0.11844, 0.74377, 0.29996, 0.11402, 0.046362, 0.18853, 0.32827, 0.48543, 0.13762]
Predicted label: 2
Correct prediction
Energy consumption = 181.542860 pJ
sum error= 258
Actual label: 9
Output voltages: [0.35852, 0.087857, 0.23215, 0.26226, 0.28813, 0.13116, 0.066404, 0.31986, 0.40187, 0.62331]
Predicted label: 9
Correct prediction
Energy consumption = 189.707750 pJ
sum error= 258
Actual label: 1
Output voltages: [0.22107, 0.67094, 0.31964, 0.18998, 0.37316, 0.064608, 0.34023, 0.14525, 0.31534, 0.16638]
Predicted label: 1
Correct prediction
Energy consumption = 200.448783 pJ
sum error= 258
Actual label: 3
Output voltages: [0.34985, 0.072054, 0.23478, 0.67846, 0.11188, 0.37015, 0.13554, 0.23575, 0.44419, 0.18824]
Predicted label: 3
Correct prediction
Energy consumption = 191.997858 pJ
sum error= 258
Actual label: 2
Output voltages: [0.43232, 0.049275, 0.62204, 0.28979, 0.143, 0.12953, 0.21895, 0.33827, 0.41273, 0.16538]
Predicted label: 2
Correct prediction
Energy consumption = 185.510639 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 725 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 725 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 725 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.44257, 0.13662, 0.29628, 0.74764, 0.11417, 0.30872, 0.085825, 0.18551, 0.46567, 0.14062]
Predicted label: 3
Correct prediction
Energy consumption = 183.434919 pJ
sum error= 258
Actual label: 4
Output voltages: [0.16489, 0.1742, 0.31795, 0.14658, 0.75711, 0.11077, 0.33399, 0.28782, 0.25374, 0.16125]
Predicted label: 4
Correct prediction
Energy consumption = 187.158315 pJ
sum error= 258
Actual label: 3
Output voltages: [0.43187, 0.15434, 0.27125, 0.73618, 0.098491, 0.22241, 0.17243, 0.1239, 0.45243, 0.18623]
Predicted label: 3
Correct prediction
Energy consumption = 192.762659 pJ
sum error= 258
Actual label: 1
Output voltages: [0.23001, 0.66668, 0.30349, 0.18502, 0.44873, 0.049074, 0.33368, 0.10659, 0.25449, 0.21077]
Predicted label: 1
Correct prediction
Energy consumption = 197.992407 pJ
sum error= 258
Actual label: 9
Output voltages: [0.38203, 0.12135, 0.19317, 0.30081, 0.29718, 0.18361, 0.11127, 0.18275, 0.39313, 0.66501]
Predicted label: 9
Correct prediction
Energy consumption = 188.748281 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73142, 0.24206, 0.30235, 0.19366, 0.15074, 0.13042, 0.31547, 0.25687, 0.33838, 0.22281]
Predicted label: 0
Correct prediction
Energy consumption = 188.299277 pJ
sum error= 258
Actual label: 9
Output voltages: [0.30483, 0.12851, 0.15575, 0.3441, 0.24009, 0.13929, 0.063369, 0.25768, 0.4503, 0.6277]
Predicted label: 9
Correct prediction
Energy consumption = 187.903943 pJ
sum error= 258
Actual label: 3
Output voltages: [0.40745, 0.12168, 0.29505, 0.74829, 0.15862, 0.32359, 0.15117, 0.19306, 0.35758, 0.15655]
Predicted label: 3
Correct prediction
Energy consumption = 186.836970 pJ
sum error= 258
Actual label: 6
Output voltages: [0.33061, 0.098874, 0.21109, 0.16335, 0.32049, 0.43333, 0.67203, 0.052517, 0.44737, 0.20026]
Predicted label: 6
Correct prediction
Energy consumption = 188.045352 pJ
sum error= 258
Actual label: 8
Output voltages: [0.23021, 0.26591, 0.42893, 0.38677, 0.053246, 0.053058, 0.22159, 0.25176, 0.62012, 0.31493]
Predicted label: 8
Correct prediction
Energy consumption = 185.980535 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 726 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 726 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 726 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.45898, 0.27552, 0.26515, 0.16846, 0.2591, 0.092981, 0.098727, 0.70239, 0.21425, 0.32852]
Predicted label: 7
Correct prediction
Energy consumption = 196.394730 pJ
sum error= 258
Actual label: 0
Output voltages: [0.69495, 0.27966, 0.29285, 0.16407, 0.13717, 0.090399, 0.43734, 0.17565, 0.32931, 0.27619]
Predicted label: 0
Correct prediction
Energy consumption = 187.270156 pJ
sum error= 258
Actual label: 1
Output voltages: [0.19397, 0.66461, 0.20292, 0.18169, 0.34679, 0.10411, 0.24291, 0.068806, 0.48808, 0.28638]
Predicted label: 1
Correct prediction
Energy consumption = 196.118562 pJ
sum error= 258
Actual label: 0
Output voltages: [0.70905, 0.25565, 0.31573, 0.21466, 0.22644, 0.073491, 0.3453, 0.1537, 0.32565, 0.18043]
Predicted label: 0
Correct prediction
Energy consumption = 191.996458 pJ
sum error= 258
Actual label: 5
Output voltages: [0.38837, 0.053522, 0.11954, 0.41715, 0.16853, 0.72079, 0.30253, 0.20142, 0.47435, 0.22648]
Predicted label: 5
Correct prediction
Energy consumption = 188.678907 pJ
sum error= 258
Actual label: 8
Output voltages: [0.2638, 0.16379, 0.2747, 0.52595, 0.12742, 0.22597, 0.14513, 0.0742, 0.70449, 0.29007]
Predicted label: 8
Correct prediction
Energy consumption = 187.614137 pJ
sum error= 258
Actual label: 2
Output voltages: [0.34637, 0.15144, 0.74584, 0.24371, 0.10557, 0.066186, 0.19311, 0.30011, 0.47564, 0.13467]
Predicted label: 2
Correct prediction
Energy consumption = 188.065308 pJ
sum error= 258
Actual label: 7
Output voltages: [0.46086, 0.20108, 0.17522, 0.20565, 0.15245, 0.27254, 0.16723, 0.6837, 0.23899, 0.29555]
Predicted label: 7
Correct prediction
Energy consumption = 198.119705 pJ
sum error= 258
Actual label: 7
Output voltages: [0.35401, 0.33426, 0.22154, 0.1839, 0.30659, 0.044092, 0.056186, 0.52469, 0.34429, 0.38216]
Predicted label: 7
Correct prediction
Energy consumption = 201.717025 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73643, 0.19321, 0.24838, 0.19105, 0.24449, 0.13798, 0.37622, 0.17327, 0.37432, 0.26589]
Predicted label: 0
Correct prediction
Energy consumption = 195.826223 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 727 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 727 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 727 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.2037, 0.76995, 0.23425, 0.27453, 0.20086, 0.1283, 0.39655, 0.16657, 0.2796, 0.21774]
Predicted label: 1
Correct prediction
Energy consumption = 214.328385 pJ
sum error= 258
Actual label: 2
Output voltages: [0.2781, 0.29888, 0.66742, 0.45563, 0.13238, 0.03615, 0.17692, 0.32866, 0.38627, 0.19738]
Predicted label: 2
Correct prediction
Energy consumption = 197.297009 pJ
sum error= 258
Actual label: 3
Output voltages: [0.30081, 0.20165, 0.29142, 0.74763, 0.22715, 0.14148, 0.12669, 0.15052, 0.42689, 0.30667]
Predicted label: 3
Correct prediction
Energy consumption = 193.314528 pJ
sum error= 258
Actual label: 4
Output voltages: [0.15044, 0.17741, 0.2517, 0.2065, 0.75349, 0.055981, 0.24576, 0.30894, 0.21027, 0.18793]
Predicted label: 4
Correct prediction
Energy consumption = 192.423178 pJ
sum error= 258
Actual label: 5
Output voltages: [0.22957, 0.043007, 0.079658, 0.35217, 0.2282, 0.73878, 0.28968, 0.26213, 0.50124, 0.2608]
Predicted label: 5
Correct prediction
Energy consumption = 194.410525 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28582, 0.26263, 0.24482, 0.17508, 0.31213, 0.37703, 0.74792, 0.081782, 0.4028, 0.087325]
Predicted label: 6
Correct prediction
Energy consumption = 193.176956 pJ
sum error= 258
Actual label: 7
Output voltages: [0.38114, 0.26759, 0.24153, 0.27055, 0.13933, 0.045849, 0.039301, 0.70937, 0.3658, 0.31614]
Predicted label: 7
Correct prediction
Energy consumption = 206.175173 pJ
sum error= 258
Actual label: 8
Output voltages: [0.28505, 0.17358, 0.38492, 0.29747, 0.16846, 0.09299, 0.20372, 0.14076, 0.72995, 0.32556]
Predicted label: 8
Correct prediction
Energy consumption = 188.881147 pJ
sum error= 258
Actual label: 9
Output voltages: [0.33453, 0.14265, 0.23322, 0.1843, 0.2843, 0.080357, 0.074415, 0.12743, 0.45915, 0.65055]
Predicted label: 9
Correct prediction
Energy consumption = 194.399906 pJ
sum error= 258
Actual label: 0
Output voltages: [0.72938, 0.24169, 0.35211, 0.2408, 0.079988, 0.18431, 0.34767, 0.24993, 0.35691, 0.18369]
Predicted label: 0
Correct prediction
Energy consumption = 193.044670 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 728 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 728 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 728 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.22049, 0.76919, 0.25987, 0.30196, 0.294, 0.081836, 0.31887, 0.11617, 0.22087, 0.27246]
Predicted label: 1
Correct prediction
Energy consumption = 215.780997 pJ
sum error= 258
Actual label: 2
Output voltages: [0.37691, 0.26794, 0.75822, 0.30474, 0.18767, 0.041625, 0.31519, 0.27553, 0.3747, 0.2095]
Predicted label: 2
Correct prediction
Energy consumption = 186.640356 pJ
sum error= 258
Actual label: 3
Output voltages: [0.39774, 0.15038, 0.38656, 0.74492, 0.14477, 0.10451, 0.12386, 0.12862, 0.44177, 0.24301]
Predicted label: 3
Correct prediction
Energy consumption = 182.896695 pJ
sum error= 258
Actual label: 4
Output voltages: [0.22603, 0.2435, 0.24487, 0.16931, 0.72916, 0.04094, 0.2813, 0.23178, 0.2451, 0.23454]
Predicted label: 4
Correct prediction
Energy consumption = 201.511962 pJ
sum error= 258
Actual label: 5
Output voltages: [0.21591, 0.078743, 0.10423, 0.37559, 0.16186, 0.66987, 0.30105, 0.078088, 0.55015, 0.21446]
Predicted label: 5
Correct prediction
Energy consumption = 191.293592 pJ
sum error= 258
Actual label: 6
Output voltages: [0.2747, 0.22883, 0.27178, 0.12686, 0.35648, 0.33412, 0.73823, 0.10391, 0.38131, 0.11991]
Predicted label: 6
Correct prediction
Energy consumption = 192.524956 pJ
sum error= 258
Actual label: 7
Output voltages: [0.35034, 0.23365, 0.16076, 0.23955, 0.21088, 0.15925, 0.044075, 0.75377, 0.29185, 0.36374]
Predicted label: 7
Correct prediction
Energy consumption = 199.303539 pJ
sum error= 258
Actual label: 8
Output voltages: [0.35933, 0.17113, 0.36961, 0.28059, 0.17526, 0.16025, 0.30479, 0.093054, 0.6987, 0.2541]
Predicted label: 8
Correct prediction
Energy consumption = 197.481277 pJ
sum error= 258
Actual label: 9
Output voltages: [0.31314, 0.18126, 0.14323, 0.3533, 0.32089, 0.17136, 0.094023, 0.18692, 0.31441, 0.70558]
Predicted label: 9
Correct prediction
Energy consumption = 196.682893 pJ
sum error= 258
Actual label: 0
Output voltages: [0.72825, 0.2301, 0.24705, 0.1761, 0.14921, 0.17349, 0.44479, 0.17351, 0.31574, 0.24244]
Predicted label: 0
Correct prediction
Energy consumption = 190.383509 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 729 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 729 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 729 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20936, 0.7632, 0.31892, 0.24381, 0.25084, 0.063424, 0.37823, 0.09731, 0.28651, 0.22213]
Predicted label: 1
Correct prediction
Energy consumption = 216.819834 pJ
sum error= 258
Actual label: 2
Output voltages: [0.45766, 0.27063, 0.66453, 0.34695, 0.10097, 0.048726, 0.22936, 0.22971, 0.35575, 0.27748]
Predicted label: 2
Correct prediction
Energy consumption = 203.343363 pJ
sum error= 258
Actual label: 3
Output voltages: [0.40197, 0.18253, 0.31599, 0.75569, 0.18635, 0.12921, 0.14497, 0.17668, 0.40152, 0.28866]
Predicted label: 3
Correct prediction
Energy consumption = 184.220065 pJ
sum error= 258
Actual label: 4
Output voltages: [0.2836, 0.19168, 0.13255, 0.25442, 0.72189, 0.19022, 0.22546, 0.31376, 0.19785, 0.45738]
Predicted label: 4
Correct prediction
Energy consumption = 204.160305 pJ
sum error= 258
Actual label: 5
Output voltages: [0.24833, 0.079742, 0.054288, 0.44486, 0.27456, 0.73007, 0.35048, 0.099435, 0.41078, 0.22977]
Predicted label: 5
Correct prediction
Energy consumption = 193.135105 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27874, 0.21342, 0.32026, 0.081233, 0.38187, 0.3399, 0.74604, 0.07405, 0.3582, 0.10951]
Predicted label: 6
Correct prediction
Energy consumption = 192.860247 pJ
sum error= 258
Actual label: 7
Output voltages: [0.34774, 0.21996, 0.15455, 0.27978, 0.19406, 0.18584, 0.040643, 0.71861, 0.31611, 0.44769]
Predicted label: 7
Correct prediction
Energy consumption = 203.428607 pJ
sum error= 258
Actual label: 8
Output voltages: [0.27343, 0.21606, 0.37807, 0.27607, 0.17298, 0.14752, 0.2822, 0.1077, 0.72216, 0.29704]
Predicted label: 8
Correct prediction
Energy consumption = 195.171314 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34958, 0.1312, 0.19572, 0.21557, 0.30255, 0.15168, 0.064817, 0.18811, 0.38972, 0.67509]
Predicted label: 9
Correct prediction
Energy consumption = 195.371867 pJ
sum error= 258
Actual label: 1
Output voltages: [0.15119, 0.7637, 0.2165, 0.28161, 0.27285, 0.083496, 0.35405, 0.19094, 0.3054, 0.25322]
Predicted label: 1
Correct prediction
Energy consumption = 210.231430 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 730 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 730 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 730 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37979, 0.20383, 0.12165, 0.29868, 0.20519, 0.17358, 0.045729, 0.71675, 0.3376, 0.40979]
Predicted label: 7
Correct prediction
Energy consumption = 202.215556 pJ
sum error= 258
Actual label: 4
Output voltages: [0.2177, 0.30695, 0.28821, 0.26552, 0.74006, 0.049235, 0.26006, 0.33204, 0.14891, 0.21287]
Predicted label: 4
Correct prediction
Energy consumption = 193.602867 pJ
sum error= 258
Actual label: 8
Output voltages: [0.29509, 0.23163, 0.38829, 0.37359, 0.16494, 0.066858, 0.25373, 0.069174, 0.68113, 0.33146]
Predicted label: 8
Correct prediction
Energy consumption = 199.863551 pJ
sum error= 258
Actual label: 1
Output voltages: [0.1516, 0.76451, 0.28732, 0.29528, 0.22505, 0.081634, 0.32862, 0.1274, 0.30528, 0.25656]
Predicted label: 1
Correct prediction
Energy consumption = 213.497785 pJ
sum error= 258
Actual label: 5
Output voltages: [0.25755, 0.058029, 0.063809, 0.46174, 0.19568, 0.68356, 0.26777, 0.13372, 0.46324, 0.29797]
Predicted label: 5
Correct prediction
Energy consumption = 200.929062 pJ
sum error= 258
Actual label: 6
Output voltages: [0.25699, 0.19992, 0.34736, 0.063081, 0.37119, 0.2747, 0.74194, 0.06127, 0.34174, 0.13703]
Predicted label: 6
Correct prediction
Energy consumption = 192.151154 pJ
sum error= 258
Actual label: 5
Output voltages: [0.21642, 0.054491, 0.069404, 0.37997, 0.23544, 0.7352, 0.35355, 0.17108, 0.46702, 0.1604]
Predicted label: 5
Correct prediction
Energy consumption = 191.493549 pJ
sum error= 258
Actual label: 7
Output voltages: [0.36264, 0.26478, 0.20993, 0.30099, 0.18291, 0.06745, 0.03361, 0.72931, 0.23199, 0.38982]
Predicted label: 7
Correct prediction
Energy consumption = 199.721145 pJ
sum error= 258
Actual label: 2
Output voltages: [0.39246, 0.22102, 0.72561, 0.4287, 0.15406, 0.03944, 0.22188, 0.22483, 0.40178, 0.2291]
Predicted label: 2
Correct prediction
Energy consumption = 186.240043 pJ
sum error= 258
Actual label: 8
Output voltages: [0.43417, 0.18531, 0.30846, 0.2979, 0.13872, 0.12902, 0.23737, 0.12525, 0.665, 0.25434]
Predicted label: 8
Correct prediction
Energy consumption = 195.868131 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 731 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 731 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 731 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.2318, 0.18696, 0.32705, 0.098182, 0.38266, 0.31106, 0.73581, 0.11337, 0.35258, 0.095525]
Predicted label: 6
Correct prediction
Energy consumption = 195.974709 pJ
sum error= 258
Actual label: 3
Output voltages: [0.37265, 0.17776, 0.34858, 0.75906, 0.20468, 0.17464, 0.15263, 0.16, 0.41171, 0.25173]
Predicted label: 3
Correct prediction
Energy consumption = 189.100914 pJ
sum error= 258
Actual label: 3
Output voltages: [0.27735, 0.15934, 0.31513, 0.74829, 0.17245, 0.11268, 0.10706, 0.18188, 0.46355, 0.23678]
Predicted label: 3
Correct prediction
Energy consumption = 170.384266 pJ
sum error= 258
Actual label: 8
Output voltages: [0.21058, 0.1856, 0.29774, 0.33222, 0.14647, 0.20744, 0.186, 0.14167, 0.75093, 0.29362]
Predicted label: 8
Correct prediction
Energy consumption = 185.061153 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27447, 0.23744, 0.30803, 0.071841, 0.38089, 0.33403, 0.74294, 0.1129, 0.32309, 0.099435]
Predicted label: 6
Correct prediction
Energy consumption = 200.636769 pJ
sum error= 258
Actual label: 5
Output voltages: [0.1873, 0.071447, 0.11011, 0.50135, 0.28754, 0.66691, 0.26348, 0.22551, 0.42223, 0.30599]
Predicted label: 5
Correct prediction
Energy consumption = 191.745244 pJ
sum error= 258
Actual label: 4
Output voltages: [0.15333, 0.18552, 0.21806, 0.19337, 0.75464, 0.074866, 0.30005, 0.34242, 0.2333, 0.17173]
Predicted label: 4
Correct prediction
Energy consumption = 194.888830 pJ
sum error= 258
Actual label: 0
Output voltages: [0.74195, 0.24534, 0.26999, 0.15478, 0.19907, 0.16598, 0.35764, 0.2182, 0.31199, 0.19996]
Predicted label: 0
Correct prediction
Energy consumption = 193.058475 pJ
sum error= 258
Actual label: 9
Output voltages: [0.34647, 0.13274, 0.22837, 0.31253, 0.31846, 0.14847, 0.086355, 0.28933, 0.35024, 0.65729]
Predicted label: 9
Correct prediction
Energy consumption = 197.372388 pJ
sum error= 258
Actual label: 1
Output voltages: [0.25024, 0.73984, 0.32153, 0.2668, 0.21261, 0.049148, 0.39183, 0.05796, 0.36773, 0.21526]
Predicted label: 1
Correct prediction
Energy consumption = 204.249311 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 732 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 732 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 732 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37055, 0.17363, 0.18437, 0.21552, 0.18986, 0.15258, 0.05233, 0.72575, 0.45961, 0.35136]
Predicted label: 7
Correct prediction
Energy consumption = 203.690696 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32641, 0.25669, 0.75176, 0.23849, 0.15821, 0.035042, 0.223, 0.30976, 0.41988, 0.19357]
Predicted label: 2
Correct prediction
Energy consumption = 189.929948 pJ
sum error= 258
Actual label: 9
Output voltages: [0.35255, 0.1325, 0.18161, 0.36786, 0.28897, 0.2649, 0.11541, 0.34069, 0.35122, 0.67708]
Predicted label: 9
Correct prediction
Energy consumption = 200.392178 pJ
sum error= 258
Actual label: 1
Output voltages: [0.1853, 0.76765, 0.24507, 0.2905, 0.2703, 0.12784, 0.42831, 0.16263, 0.24816, 0.23157]
Predicted label: 1
Correct prediction
Energy consumption = 215.446894 pJ
sum error= 258
Actual label: 5
Output voltages: [0.21241, 0.062779, 0.1056, 0.47192, 0.21835, 0.62222, 0.22198, 0.14994, 0.48804, 0.32138]
Predicted label: 5
Correct prediction
Energy consumption = 191.529948 pJ
sum error= 258
Actual label: 1
Output voltages: [0.28341, 0.72407, 0.32611, 0.22746, 0.33134, 0.0427, 0.39573, 0.14881, 0.22511, 0.16891]
Predicted label: 1
Correct prediction
Energy consumption = 212.239499 pJ
sum error= 258
Actual label: 3
Output voltages: [0.35981, 0.17414, 0.3463, 0.75139, 0.16247, 0.14064, 0.13148, 0.14544, 0.48195, 0.2079]
Predicted label: 3
Correct prediction
Energy consumption = 185.805018 pJ
sum error= 258
Actual label: 2
Output voltages: [0.34809, 0.28714, 0.74066, 0.37114, 0.19828, 0.041701, 0.24416, 0.25888, 0.34361, 0.2375]
Predicted label: 2
Correct prediction
Energy consumption = 186.680346 pJ
sum error= 258
Actual label: 2
Output voltages: [0.30744, 0.3197, 0.72931, 0.38508, 0.19373, 0.033732, 0.23194, 0.24951, 0.30394, 0.22333]
Predicted label: 2
Correct prediction
Energy consumption = 187.818916 pJ
sum error= 258
Actual label: 3
Output voltages: [0.38004, 0.10524, 0.32007, 0.73935, 0.13527, 0.18784, 0.10433, 0.17504, 0.52776, 0.19615]
Predicted label: 3
Correct prediction
Energy consumption = 176.363717 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 733 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 733 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 733 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73705, 0.25586, 0.29551, 0.17302, 0.16618, 0.17522, 0.37747, 0.20362, 0.27271, 0.18508]
Predicted label: 0
Correct prediction
Energy consumption = 194.359433 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28596, 0.17314, 0.27933, 0.10906, 0.45077, 0.37279, 0.72938, 0.051834, 0.3044, 0.10082]
Predicted label: 6
Correct prediction
Energy consumption = 188.755629 pJ
sum error= 258
Actual label: 4
Output voltages: [0.19202, 0.17824, 0.24765, 0.27769, 0.74835, 0.04533, 0.2534, 0.22553, 0.20712, 0.19378]
Predicted label: 4
Correct prediction
Energy consumption = 202.025831 pJ
sum error= 258
Actual label: 3
Output voltages: [0.29698, 0.14907, 0.27055, 0.67535, 0.17658, 0.1437, 0.12088, 0.11601, 0.56559, 0.23482]
Predicted label: 3
Correct prediction
Energy consumption = 197.502794 pJ
sum error= 258
Actual label: 7
Output voltages: [0.42928, 0.23832, 0.44073, 0.30832, 0.10131, 0.04135, 0.062176, 0.68921, 0.31335, 0.30749]
Predicted label: 7
Correct prediction
Energy consumption = 197.096234 pJ
sum error= 258
Actual label: 6
Output voltages: [0.29537, 0.22022, 0.24294, 0.13773, 0.36612, 0.31182, 0.73475, 0.10833, 0.37799, 0.13539]
Predicted label: 6
Correct prediction
Energy consumption = 195.876229 pJ
sum error= 258
Actual label: 9
Output voltages: [0.37473, 0.12945, 0.2021, 0.29771, 0.27027, 0.17942, 0.075234, 0.26053, 0.34869, 0.66092]
Predicted label: 9
Correct prediction
Energy consumption = 193.787963 pJ
sum error= 258
Actual label: 0
Output voltages: [0.61618, 0.2428, 0.31001, 0.23116, 0.15643, 0.10613, 0.41876, 0.088245, 0.46778, 0.21741]
Predicted label: 0
Correct prediction
Energy consumption = 197.766448 pJ
sum error= 258
Actual label: 4
Output voltages: [0.23707, 0.20281, 0.25657, 0.22087, 0.6179, 0.0509, 0.33859, 0.13398, 0.36001, 0.2253]
Predicted label: 4
Correct prediction
Energy consumption = 204.626872 pJ
sum error= 258
Actual label: 8
Output voltages: [0.29024, 0.15736, 0.326, 0.41032, 0.14555, 0.068373, 0.16573, 0.10476, 0.67079, 0.3031]
Predicted label: 8
Correct prediction
Energy consumption = 195.139379 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 734 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 734 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 734 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20744, 0.75628, 0.21582, 0.28967, 0.19437, 0.062372, 0.25563, 0.16245, 0.41598, 0.23876]
Predicted label: 1
Correct prediction
Energy consumption = 212.886878 pJ
sum error= 258
Actual label: 4
Output voltages: [0.12609, 0.20421, 0.28496, 0.14937, 0.75367, 0.060658, 0.25632, 0.29406, 0.22295, 0.30621]
Predicted label: 4
Correct prediction
Energy consumption = 198.579077 pJ
sum error= 258
Actual label: 0
Output voltages: [0.7071, 0.18723, 0.27743, 0.17431, 0.14606, 0.1924, 0.37267, 0.1672, 0.34966, 0.26266]
Predicted label: 0
Correct prediction
Energy consumption = 201.489409 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27735, 0.21648, 0.32806, 0.09094, 0.33853, 0.31881, 0.74913, 0.084173, 0.35404, 0.10411]
Predicted label: 6
Correct prediction
Energy consumption = 191.192739 pJ
sum error= 258
Actual label: 1
Output voltages: [0.23548, 0.74941, 0.27916, 0.26067, 0.29391, 0.051967, 0.39848, 0.12485, 0.28195, 0.21614]
Predicted label: 1
Correct prediction
Energy consumption = 207.314762 pJ
sum error= 258
Actual label: 2
Output voltages: [0.30299, 0.40853, 0.67186, 0.37315, 0.12345, 0.034875, 0.21747, 0.24053, 0.35514, 0.18603]
Predicted label: 2
Correct prediction
Energy consumption = 197.742548 pJ
sum error= 258
Actual label: 6
Output voltages: [0.29051, 0.21487, 0.30471, 0.074048, 0.35462, 0.37064, 0.73754, 0.079142, 0.36086, 0.09069]
Predicted label: 6
Correct prediction
Energy consumption = 190.833979 pJ
sum error= 258
Actual label: 9
Output voltages: [0.35162, 0.11338, 0.24747, 0.22338, 0.25047, 0.15943, 0.095682, 0.26316, 0.43453, 0.64256]
Predicted label: 9
Correct prediction
Energy consumption = 194.903356 pJ
sum error= 258
Actual label: 2
Output voltages: [0.27714, 0.36566, 0.69916, 0.3374, 0.10274, 0.03, 0.21485, 0.31481, 0.4091, 0.2163]
Predicted label: 2
Correct prediction
Energy consumption = 193.935138 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32202, 0.33759, 0.72842, 0.20823, 0.16776, 0.031084, 0.20457, 0.36417, 0.40227, 0.18115]
Predicted label: 2
Correct prediction
Energy consumption = 185.922693 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 735 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 735 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 735 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29514, 0.22437, 0.27624, 0.76325, 0.17151, 0.182, 0.11318, 0.21364, 0.35841, 0.25993]
Predicted label: 3
Correct prediction
Energy consumption = 192.865248 pJ
sum error= 258
Actual label: 5
Output voltages: [0.23533, 0.050367, 0.063674, 0.45967, 0.29579, 0.71619, 0.29998, 0.13792, 0.45316, 0.21267]
Predicted label: 5
Correct prediction
Energy consumption = 190.749668 pJ
sum error= 258
Actual label: 5
Output voltages: [0.23922, 0.04244, 0.072007, 0.37885, 0.30692, 0.71682, 0.2715, 0.20313, 0.43748, 0.34955]
Predicted label: 5
Correct prediction
Energy consumption = 187.083569 pJ
sum error= 258
Actual label: 1
Output voltages: [0.17901, 0.75995, 0.37456, 0.26498, 0.26332, 0.044813, 0.36244, 0.15705, 0.26093, 0.19703]
Predicted label: 1
Correct prediction
Energy consumption = 206.723839 pJ
sum error= 258
Actual label: 0
Output voltages: [0.66811, 0.23415, 0.2116, 0.16701, 0.23007, 0.166, 0.53737, 0.15253, 0.29154, 0.21789]
Predicted label: 0
Correct prediction
Energy consumption = 201.632711 pJ
sum error= 258
Actual label: 7
Output voltages: [0.31578, 0.26527, 0.21408, 0.26614, 0.14956, 0.16645, 0.048826, 0.7546, 0.27011, 0.38169]
Predicted label: 7
Correct prediction
Energy consumption = 199.029857 pJ
sum error= 258
Actual label: 7
Output voltages: [0.37108, 0.25788, 0.53417, 0.18477, 0.1746, 0.031149, 0.07372, 0.70955, 0.27058, 0.29626]
Predicted label: 7
Correct prediction
Energy consumption = 189.190334 pJ
sum error= 258
Actual label: 9
Output voltages: [0.27195, 0.16526, 0.16358, 0.29445, 0.23796, 0.15742, 0.054985, 0.21181, 0.44228, 0.63376]
Predicted label: 9
Correct prediction
Energy consumption = 190.546134 pJ
sum error= 258
Actual label: 6
Output voltages: [0.29415, 0.18969, 0.29745, 0.077844, 0.39794, 0.37187, 0.7437, 0.10215, 0.31676, 0.10614]
Predicted label: 6
Correct prediction
Energy consumption = 195.100420 pJ
sum error= 258
Actual label: 2
Output voltages: [0.28112, 0.33896, 0.65965, 0.4064, 0.12554, 0.049643, 0.19599, 0.22322, 0.38932, 0.15365]
Predicted label: 2
Correct prediction
Energy consumption = 194.847062 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 736 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 736 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 736 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31919, 0.12901, 0.19983, 0.26836, 0.33684, 0.1986, 0.10571, 0.25577, 0.3922, 0.67843]
Predicted label: 9
Correct prediction
Energy consumption = 188.128415 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11985, 0.2062, 0.19795, 0.21165, 0.74811, 0.053947, 0.26414, 0.28077, 0.22456, 0.20924]
Predicted label: 4
Correct prediction
Energy consumption = 200.518620 pJ
sum error= 258
Actual label: 7
Output voltages: [0.29189, 0.24588, 0.23752, 0.31827, 0.11715, 0.083676, 0.039647, 0.75459, 0.32411, 0.35451]
Predicted label: 7
Correct prediction
Energy consumption = 196.578743 pJ
sum error= 258
Actual label: 0
Output voltages: [0.68213, 0.24031, 0.29002, 0.13058, 0.19415, 0.11716, 0.43604, 0.20339, 0.28908, 0.3006]
Predicted label: 0
Correct prediction
Energy consumption = 201.315993 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32262, 0.30623, 0.72908, 0.37852, 0.23726, 0.0398, 0.2337, 0.26178, 0.34279, 0.19954]
Predicted label: 2
Correct prediction
Energy consumption = 195.189796 pJ
sum error= 258
Actual label: 3
Output voltages: [0.29707, 0.16905, 0.33559, 0.75001, 0.15947, 0.14822, 0.11101, 0.12722, 0.50078, 0.21781]
Predicted label: 3
Correct prediction
Energy consumption = 178.757491 pJ
sum error= 258
Actual label: 4
Output voltages: [0.11895, 0.12688, 0.1929, 0.12288, 0.7501, 0.092897, 0.25337, 0.27915, 0.34521, 0.16351]
Predicted label: 4
Correct prediction
Energy consumption = 194.610614 pJ
sum error= 258
Actual label: 0
Output voltages: [0.73479, 0.22123, 0.27052, 0.14108, 0.20439, 0.13384, 0.38153, 0.20216, 0.29747, 0.19399]
Predicted label: 0
Correct prediction
Energy consumption = 196.063605 pJ
sum error= 258
Actual label: 0
Output voltages: [0.70976, 0.23789, 0.29752, 0.12384, 0.17169, 0.13881, 0.40914, 0.19896, 0.33977, 0.20817]
Predicted label: 0
Correct prediction
Energy consumption = 195.879752 pJ
sum error= 258
Actual label: 8
Output voltages: [0.2429, 0.18251, 0.32989, 0.24554, 0.16211, 0.19772, 0.18372, 0.13303, 0.74523, 0.28219]
Predicted label: 8
Correct prediction
Energy consumption = 185.685275 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 737 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 737 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 737 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.37552, 0.14546, 0.27675, 0.31228, 0.16391, 0.18311, 0.24736, 0.072723, 0.65761, 0.33243]
Predicted label: 8
Correct prediction
Energy consumption = 197.821819 pJ
sum error= 258
Actual label: 8
Output voltages: [0.28661, 0.12523, 0.3508, 0.21571, 0.14957, 0.24883, 0.18196, 0.11882, 0.74117, 0.27655]
Predicted label: 8
Correct prediction
Energy consumption = 188.525976 pJ
sum error= 258
Actual label: 5
Output voltages: [0.2105, 0.046796, 0.10292, 0.36401, 0.20233, 0.68942, 0.27367, 0.15924, 0.51011, 0.27319]
Predicted label: 5
Correct prediction
Energy consumption = 194.653663 pJ
sum error= 258
Actual label: 1
Output voltages: [0.23999, 0.7457, 0.32804, 0.29659, 0.20796, 0.049977, 0.38195, 0.12167, 0.34804, 0.22823]
Predicted label: 1
Correct prediction
Energy consumption = 208.172117 pJ
sum error= 258
Actual label: 3
Output voltages: [0.33653, 0.22949, 0.26491, 0.76117, 0.11489, 0.19706, 0.1171, 0.1936, 0.44608, 0.25812]
Predicted label: 3
Correct prediction
Energy consumption = 187.018634 pJ
sum error= 258
Actual label: 7
Output voltages: [0.33348, 0.28333, 0.42039, 0.29838, 0.15885, 0.049592, 0.044345, 0.73565, 0.32473, 0.33887]
Predicted label: 7
Correct prediction
Energy consumption = 192.226534 pJ
sum error= 258
Actual label: 4
Output voltages: [0.15639, 0.16763, 0.25945, 0.1432, 0.7605, 0.082304, 0.29779, 0.26377, 0.28068, 0.15663]
Predicted label: 4
Correct prediction
Energy consumption = 191.694220 pJ
sum error= 258
Actual label: 9
Output voltages: [0.31429, 0.14402, 0.164, 0.24817, 0.33576, 0.15397, 0.056682, 0.16491, 0.39478, 0.63559]
Predicted label: 9
Correct prediction
Energy consumption = 189.114072 pJ
sum error= 258
Actual label: 8
Output voltages: [0.33846, 0.22018, 0.32737, 0.29561, 0.16317, 0.12231, 0.22163, 0.074757, 0.70125, 0.29587]
Predicted label: 8
Correct prediction
Energy consumption = 191.793061 pJ
sum error= 258
Actual label: 8
Output voltages: [0.22154, 0.13465, 0.31285, 0.35631, 0.1424, 0.14257, 0.19854, 0.13201, 0.72222, 0.29503]
Predicted label: 8
Correct prediction
Energy consumption = 186.964712 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 738 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 738 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 738 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34126, 0.16359, 0.20446, 0.22978, 0.35369, 0.084978, 0.070503, 0.17582, 0.38667, 0.64495]
Predicted label: 9
Correct prediction
Energy consumption = 200.169545 pJ
sum error= 258
Actual label: 0
Output voltages: [0.68245, 0.23718, 0.29058, 0.18458, 0.22532, 0.10325, 0.39837, 0.13285, 0.38831, 0.26143]
Predicted label: 0
Correct prediction
Energy consumption = 208.938041 pJ
sum error= 258
Actual label: 9
Output voltages: [0.32902, 0.11112, 0.22652, 0.19603, 0.24982, 0.12051, 0.064892, 0.22439, 0.46059, 0.64547]
Predicted label: 9
Correct prediction
Energy consumption = 199.338541 pJ
sum error= 258
Actual label: 8
Output voltages: [0.25669, 0.21473, 0.36328, 0.30217, 0.15889, 0.16616, 0.21647, 0.12691, 0.74134, 0.30982]
Predicted label: 8
Correct prediction
Energy consumption = 188.868115 pJ
sum error= 258
Actual label: 9
Output voltages: [0.30304, 0.14835, 0.18352, 0.21543, 0.24845, 0.1233, 0.071695, 0.16247, 0.47766, 0.6606]
Predicted label: 9
Correct prediction
Energy consumption = 192.245906 pJ
sum error= 258
Actual label: 0
Output voltages: [0.7111, 0.25101, 0.27248, 0.16381, 0.15406, 0.089685, 0.37219, 0.20133, 0.36899, 0.24145]
Predicted label: 0
Correct prediction
Energy consumption = 185.321442 pJ
sum error= 258
Actual label: 2
Output voltages: [0.3676, 0.25437, 0.7211, 0.3817, 0.15334, 0.034949, 0.20605, 0.26522, 0.41013, 0.22664]
Predicted label: 2
Correct prediction
Energy consumption = 192.765953 pJ
sum error= 258
Actual label: 6
Output voltages: [0.32997, 0.19428, 0.29548, 0.067037, 0.33315, 0.27075, 0.72649, 0.10156, 0.34508, 0.10353]
Predicted label: 6
Correct prediction
Energy consumption = 196.180944 pJ
sum error= 258
Actual label: 5
Output voltages: [0.22461, 0.044356, 0.07459, 0.51153, 0.22825, 0.625, 0.31176, 0.18056, 0.43173, 0.18369]
Predicted label: 5
Correct prediction
Energy consumption = 189.637283 pJ
sum error= 258
Actual label: 6
Output voltages: [0.27303, 0.25565, 0.29651, 0.08038, 0.40036, 0.34455, 0.73971, 0.095851, 0.33139, 0.10917]
Predicted label: 6
Correct prediction
Energy consumption = 187.222603 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 739 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 739 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 739 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37522, 0.29225, 0.48091, 0.22765, 0.18056, 0.034504, 0.068118, 0.71904, 0.24945, 0.30714]
Predicted label: 7
Correct prediction
Energy consumption = 197.089176 pJ
sum error= 258
Actual label: 4
Output voltages: [0.17195, 0.11898, 0.19528, 0.23329, 0.73032, 0.11075, 0.23751, 0.19832, 0.29891, 0.26446]
Predicted label: 4
Correct prediction
Energy consumption = 196.221266 pJ
sum error= 258
Actual label: 7
Output voltages: [0.35117, 0.25206, 0.28923, 0.2488, 0.18106, 0.057597, 0.038629, 0.66645, 0.40177, 0.35419]
Predicted label: 7
Correct prediction
Energy consumption = 206.933927 pJ
sum error= 258
Actual label: 5
Output voltages: [0.27222, 0.054214, 0.0656, 0.41012, 0.20439, 0.74541, 0.32817, 0.19776, 0.48056, 0.21093]
Predicted label: 5
Correct prediction
Energy consumption = 190.474697 pJ
sum error= 258
Actual label: 4
Output voltages: [0.18251, 0.23232, 0.22177, 0.23738, 0.7208, 0.053389, 0.26601, 0.21724, 0.30157, 0.24963]
Predicted label: 4
Correct prediction
Energy consumption = 204.899584 pJ
sum error= 258
Actual label: 1
Output voltages: [0.22043, 0.73171, 0.26063, 0.19649, 0.3357, 0.071746, 0.40134, 0.050217, 0.29074, 0.32282]
Predicted label: 1
Correct prediction
Energy consumption = 205.582166 pJ
sum error= 258
Actual label: 3
Output voltages: [0.32134, 0.20711, 0.1992, 0.75626, 0.12778, 0.21977, 0.11293, 0.20577, 0.50196, 0.22703]
Predicted label: 3
Correct prediction
Energy consumption = 193.627030 pJ
sum error= 258
Actual label: 5
Output voltages: [0.20859, 0.044962, 0.058908, 0.31647, 0.30364, 0.74213, 0.37734, 0.17929, 0.51585, 0.19435]
Predicted label: 5
Correct prediction
Energy consumption = 185.482042 pJ
sum error= 258
Actual label: 3
Output voltages: [0.30749, 0.13549, 0.2987, 0.74591, 0.17468, 0.38057, 0.082921, 0.20014, 0.46974, 0.27736]
Predicted label: 3
Correct prediction
Energy consumption = 191.150862 pJ
sum error= 258
Actual label: 1
Output voltages: [0.30312, 0.74402, 0.22301, 0.21191, 0.35754, 0.070399, 0.28217, 0.17448, 0.24611, 0.2995]
Predicted label: 1
Correct prediction
Energy consumption = 203.612639 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 740 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 740 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 740 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.37164, 0.21504, 0.70819, 0.19876, 0.23929, 0.028198, 0.18686, 0.36273, 0.33777, 0.2376]
Predicted label: 2
Correct prediction
Energy consumption = 189.306462 pJ
sum error= 258
Actual label: 3
Output voltages: [0.59713, 0.23273, 0.23963, 0.74839, 0.060622, 0.32564, 0.10278, 0.27987, 0.33022, 0.14579]
Predicted label: 3
Correct prediction
Energy consumption = 191.830835 pJ
sum error= 258
Actual label: 4
Output voltages: [0.16402, 0.23672, 0.20378, 0.06747, 0.73122, 0.11303, 0.2663, 0.22359, 0.37296, 0.18138]
Predicted label: 4
Correct prediction
Energy consumption = 205.576553 pJ
sum error= 258
Actual label: 5
Output voltages: [0.23181, 0.077333, 0.093035, 0.45753, 0.1598, 0.66515, 0.26214, 0.19844, 0.50439, 0.24805]
Predicted label: 5
Correct prediction
Energy consumption = 191.803096 pJ
sum error= 258
Actual label: 6
Output voltages: [0.39593, 0.20389, 0.28335, 0.080718, 0.41002, 0.23295, 0.70268, 0.13043, 0.28073, 0.17197]
Predicted label: 6
Correct prediction
Energy consumption = 200.765711 pJ
sum error= 258
Actual label: 1
Output voltages: [0.14847, 0.73851, 0.21294, 0.14894, 0.31094, 0.26084, 0.43868, 0.13448, 0.36824, 0.14207]
Predicted label: 1
Correct prediction
Energy consumption = 198.349822 pJ
sum error= 258
Actual label: 2
Output voltages: [0.4114, 0.097078, 0.73446, 0.31095, 0.13963, 0.043665, 0.19932, 0.29989, 0.51003, 0.16952]
Predicted label: 2
Correct prediction
Energy consumption = 186.894311 pJ
sum error= 258
Actual label: 3
Output voltages: [0.4183, 0.14769, 0.24075, 0.73694, 0.12172, 0.25056, 0.051665, 0.42274, 0.32734, 0.27027]
Predicted label: 3
Correct prediction
Energy consumption = 184.095434 pJ
sum error= 258
Actual label: 4
Output voltages: [0.20705, 0.17214, 0.26254, 0.13869, 0.73507, 0.11598, 0.30756, 0.19885, 0.28324, 0.20936]
Predicted label: 4
Correct prediction
Energy consumption = 193.115451 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28443, 0.20521, 0.30824, 0.057889, 0.37205, 0.276, 0.73763, 0.053428, 0.34492, 0.13611]
Predicted label: 6
Correct prediction
Energy consumption = 180.805002 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 741 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 741 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 741 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72252, 0.25843, 0.19351, 0.21478, 0.14021, 0.21296, 0.39126, 0.31642, 0.24166, 0.24232]
Predicted label: 0
Correct prediction
Energy consumption = 203.550797 pJ
sum error= 258
Actual label: 1
Output voltages: [0.13973, 0.7468, 0.1681, 0.18937, 0.38729, 0.11345, 0.36362, 0.16958, 0.27857, 0.26676]
Predicted label: 1
Correct prediction
Energy consumption = 204.960211 pJ
sum error= 258
Actual label: 2
Output voltages: [0.36545, 0.13569, 0.72228, 0.38146, 0.21076, 0.041382, 0.17807, 0.1991, 0.41975, 0.14108]
Predicted label: 2
Correct prediction
Energy consumption = 188.390051 pJ
sum error= 258
Actual label: 4
Output voltages: [0.41393, 0.25893, 0.38549, 0.10729, 0.54495, 0.039456, 0.28617, 0.15336, 0.34508, 0.21075]
Predicted label: 4
Correct prediction
Energy consumption = 196.729858 pJ
sum error= 258
Actual label: 5
Output voltages: [0.35374, 0.057069, 0.055678, 0.36758, 0.16745, 0.75405, 0.29056, 0.21689, 0.48205, 0.11453]
Predicted label: 5
Correct prediction
Energy consumption = 190.006340 pJ
sum error= 258
Actual label: 6
Output voltages: [0.30831, 0.20975, 0.30746, 0.06471, 0.31446, 0.30299, 0.73034, 0.11187, 0.36112, 0.092566]
Predicted label: 6
Correct prediction
Energy consumption = 184.787338 pJ
sum error= 258
Actual label: 7
Output voltages: [0.31291, 0.22625, 0.4658, 0.24277, 0.13949, 0.058139, 0.046066, 0.74739, 0.34332, 0.36226]
Predicted label: 7
Correct prediction
Energy consumption = 190.874590 pJ
sum error= 258
Actual label: 8
Output voltages: [0.17418, 0.14181, 0.19342, 0.20918, 0.25004, 0.39723, 0.22434, 0.19127, 0.74781, 0.16306]
Predicted label: 8
Correct prediction
Energy consumption = 192.677507 pJ
sum error= 258
Actual label: 1
Output voltages: [0.18592, 0.73998, 0.26369, 0.16288, 0.3759, 0.14012, 0.44251, 0.14232, 0.25827, 0.17065]
Predicted label: 1
Correct prediction
Energy consumption = 204.132276 pJ
sum error= 258
Actual label: 7
Output voltages: [0.29158, 0.32256, 0.47769, 0.29376, 0.11306, 0.037964, 0.043644, 0.71479, 0.29825, 0.3628]
Predicted label: 7
Correct prediction
Energy consumption = 192.263575 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 742 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 742 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 742 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31642, 0.13577, 0.63616, 0.29099, 0.12913, 0.05048, 0.20104, 0.24658, 0.60904, 0.25039]
Predicted label: 2
Correct prediction
Energy consumption = 189.121671 pJ
sum error= 258
Actual label: 4
Output voltages: [0.19361, 0.24999, 0.30932, 0.15314, 0.74899, 0.081026, 0.2672, 0.16878, 0.21237, 0.28646]
Predicted label: 4
Correct prediction
Energy consumption = 199.720551 pJ
sum error= 258
Actual label: 1
Output voltages: [0.19416, 0.73937, 0.31448, 0.22116, 0.32929, 0.056275, 0.35288, 0.15486, 0.31077, 0.1863]
Predicted label: 1
Correct prediction
Energy consumption = 193.583399 pJ
sum error= 258
Actual label: 4
Output voltages: [0.091219, 0.18353, 0.21153, 0.12771, 0.72254, 0.14601, 0.16488, 0.11757, 0.3553, 0.35302]
Predicted label: 4
Correct prediction
Energy consumption = 194.344852 pJ
sum error= 258
Actual label: 1
Output voltages: [0.24867, 0.73077, 0.25997, 0.10259, 0.34505, 0.14075, 0.38664, 0.075692, 0.34037, 0.26402]
Predicted label: 1
Correct prediction
Energy consumption = 203.592182 pJ
sum error= 258
Actual label: 4
Output voltages: [0.141, 0.16388, 0.2242, 0.14075, 0.73367, 0.11671, 0.25124, 0.18965, 0.31937, 0.21809]
Predicted label: 4
Correct prediction
Energy consumption = 197.293751 pJ
sum error= 258
Actual label: 9
Output voltages: [0.20718, 0.056562, 0.11359, 0.19078, 0.30473, 0.44073, 0.25054, 0.2503, 0.411, 0.47182]
Predicted label: 9
Correct prediction
Energy consumption = 198.088012 pJ
sum error= 258
Actual label: 6
Output voltages: [0.38281, 0.20304, 0.29372, 0.055399, 0.36133, 0.29596, 0.72669, 0.15152, 0.34548, 0.071895]
Predicted label: 6
Correct prediction
Energy consumption = 184.763147 pJ
sum error= 258
Actual label: 8
Output voltages: [0.26011, 0.2063, 0.29185, 0.40354, 0.094673, 0.26476, 0.22434, 0.12877, 0.75051, 0.26365]
Predicted label: 8
Correct prediction
Energy consumption = 192.025771 pJ
sum error= 258
Actual label: 4
Output voltages: [0.086475, 0.20296, 0.20408, 0.15774, 0.74168, 0.15632, 0.35578, 0.26754, 0.26292, 0.19235]
Predicted label: 4
Correct prediction
Energy consumption = 192.738381 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 743 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 743 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 743 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22791, 0.08829, 0.061473, 0.56109, 0.36771, 0.64976, 0.25473, 0.3271, 0.3189, 0.16974]
Predicted label: 5
Correct prediction
Energy consumption = 196.396588 pJ
sum error= 258
Actual label: 3
Output voltages: [0.39318, 0.12355, 0.3041, 0.72171, 0.16601, 0.14971, 0.059985, 0.30031, 0.44139, 0.21974]
Predicted label: 3
Correct prediction
Energy consumption = 187.928087 pJ
sum error= 258
Actual label: 7
Output voltages: [0.21097, 0.37735, 0.58546, 0.29302, 0.078212, 0.038307, 0.074996, 0.46205, 0.49066, 0.33336]
Predicted label: 2
Wrong prediction!
Energy consumption = 193.301724 pJ
sum error= 259
Actual label: 8
Output voltages: [0.2839, 0.20856, 0.18097, 0.33223, 0.14841, 0.32415, 0.33661, 0.11632, 0.71288, 0.14277]
Predicted label: 8
Correct prediction
Energy consumption = 197.517997 pJ
sum error= 259
Actual label: 4
Output voltages: [0.16391, 0.33399, 0.14379, 0.26398, 0.56254, 0.074095, 0.13541, 0.17935, 0.36847, 0.36439]
Predicted label: 4
Correct prediction
Energy consumption = 195.663274 pJ
sum error= 259
Actual label: 3
Output voltages: [0.26142, 0.21868, 0.26542, 0.76248, 0.13582, 0.19331, 0.13722, 0.28086, 0.419, 0.25465]
Predicted label: 3
Correct prediction
Energy consumption = 176.692168 pJ
sum error= 259
Actual label: 3
Output voltages: [0.27042, 0.22474, 0.36589, 0.73668, 0.067569, 0.13948, 0.098574, 0.26469, 0.49232, 0.20411]
Predicted label: 3
Correct prediction
Energy consumption = 177.920507 pJ
sum error= 259
Actual label: 5
Output voltages: [0.3283, 0.058172, 0.055171, 0.41225, 0.20553, 0.6723, 0.2573, 0.1258, 0.56385, 0.15611]
Predicted label: 5
Correct prediction
Energy consumption = 180.953367 pJ
sum error= 259
Actual label: 6
Output voltages: [0.28722, 0.2476, 0.31558, 0.075033, 0.34774, 0.31677, 0.73594, 0.11497, 0.31829, 0.1248]
Predicted label: 6
Correct prediction
Energy consumption = 191.844113 pJ
sum error= 259
Actual label: 7
Output voltages: [0.33152, 0.25412, 0.50164, 0.33098, 0.1009, 0.029174, 0.054407, 0.65849, 0.30928, 0.31502]
Predicted label: 7
Correct prediction
Energy consumption = 196.564001 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 744 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 744 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 744 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.6618, 0.16234, 0.2787, 0.21613, 0.31124, 0.057336, 0.33422, 0.21889, 0.40064, 0.19289]
Predicted label: 0
Correct prediction
Energy consumption = 202.245749 pJ
sum error= 259
Actual label: 6
Output voltages: [0.3071, 0.16282, 0.25179, 0.058074, 0.45581, 0.3403, 0.67918, 0.11675, 0.25169, 0.17022]
Predicted label: 6
Correct prediction
Energy consumption = 189.840165 pJ
sum error= 259
Actual label: 1
Output voltages: [0.21503, 0.7114, 0.20502, 0.15722, 0.43502, 0.10391, 0.35747, 0.10061, 0.28569, 0.25159]
Predicted label: 1
Correct prediction
Energy consumption = 201.991496 pJ
sum error= 259
Actual label: 6
Output voltages: [0.2404, 0.21406, 0.30186, 0.062286, 0.35113, 0.31556, 0.6909, 0.077432, 0.30883, 0.16213]
Predicted label: 6
Correct prediction
Energy consumption = 189.268501 pJ
sum error= 259
Actual label: 8
Output voltages: [0.14555, 0.19188, 0.17615, 0.18788, 0.35038, 0.3416, 0.27479, 0.19072, 0.73217, 0.13314]
Predicted label: 8
Correct prediction
Energy consumption = 193.669140 pJ
sum error= 259
Actual label: 7
Output voltages: [0.2744, 0.28521, 0.41056, 0.30807, 0.11037, 0.046565, 0.047889, 0.71637, 0.33958, 0.40893]
Predicted label: 7
Correct prediction
Energy consumption = 189.574779 pJ
sum error= 259
Actual label: 0
Output voltages: [0.73524, 0.15039, 0.36611, 0.19446, 0.14433, 0.079201, 0.35716, 0.34876, 0.29035, 0.25021]
Predicted label: 0
Correct prediction
Energy consumption = 189.558892 pJ
sum error= 259
Actual label: 1
Output voltages: [0.1309, 0.70108, 0.393, 0.19938, 0.28915, 0.063869, 0.25089, 0.19768, 0.34079, 0.2081]
Predicted label: 1
Correct prediction
Energy consumption = 196.074405 pJ
sum error= 259
Actual label: 5
Output voltages: [0.32704, 0.08802, 0.060098, 0.39425, 0.20706, 0.74189, 0.366, 0.19155, 0.40876, 0.20363]
Predicted label: 5
Correct prediction
Energy consumption = 194.643902 pJ
sum error= 259
Actual label: 0
Output voltages: [0.73072, 0.19096, 0.28179, 0.13573, 0.22535, 0.13094, 0.30889, 0.30841, 0.36133, 0.18138]
Predicted label: 0
Correct prediction
Energy consumption = 192.028141 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 745 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 745 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 745 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20062, 0.21107, 0.2385, 0.28921, 0.096145, 0.31009, 0.23865, 0.20455, 0.75244, 0.20531]
Predicted label: 8
Correct prediction
Energy consumption = 188.778968 pJ
sum error= 259
Actual label: 5
Output voltages: [0.20549, 0.17081, 0.059963, 0.47559, 0.32829, 0.60893, 0.36756, 0.045855, 0.42602, 0.208]
Predicted label: 5
Correct prediction
Energy consumption = 189.278624 pJ
sum error= 259
Actual label: 0
Output voltages: [0.74777, 0.18358, 0.30147, 0.13573, 0.19591, 0.11993, 0.40724, 0.34751, 0.23557, 0.23497]
Predicted label: 0
Correct prediction
Energy consumption = 194.876601 pJ
sum error= 259
Actual label: 1
Output voltages: [0.19252, 0.73345, 0.27116, 0.14228, 0.26442, 0.087117, 0.36977, 0.072234, 0.39341, 0.29324]
Predicted label: 1
Correct prediction
Energy consumption = 201.571449 pJ
sum error= 259
Actual label: 5
Output voltages: [0.24749, 0.057438, 0.049366, 0.34306, 0.32902, 0.73185, 0.26418, 0.16639, 0.37537, 0.26661]
Predicted label: 5
Correct prediction
Energy consumption = 187.415316 pJ
sum error= 259
Actual label: 8
Output voltages: [0.32253, 0.2318, 0.22598, 0.33491, 0.073251, 0.31817, 0.15448, 0.15952, 0.74115, 0.2367]
Predicted label: 8
Correct prediction
Energy consumption = 197.045185 pJ
sum error= 259
Actual label: 4
Output voltages: [0.21181, 0.18195, 0.30236, 0.15834, 0.72948, 0.095357, 0.28214, 0.13049, 0.26488, 0.2479]
Predicted label: 4
Correct prediction
Energy consumption = 193.405912 pJ
sum error= 259
Actual label: 2
Output voltages: [0.29228, 0.14134, 0.65549, 0.37043, 0.080552, 0.034001, 0.13675, 0.47682, 0.53319, 0.14077]
Predicted label: 2
Correct prediction
Energy consumption = 189.336048 pJ
sum error= 259
Actual label: 3
Output voltages: [0.34047, 0.18793, 0.31796, 0.76209, 0.13754, 0.22156, 0.14242, 0.23435, 0.42466, 0.23702]
Predicted label: 3
Correct prediction
Energy consumption = 182.415400 pJ
sum error= 259
Actual label: 9
Output voltages: [0.23101, 0.056614, 0.13546, 0.17739, 0.22511, 0.44003, 0.16142, 0.12123, 0.53621, 0.4336]
Predicted label: 8
Wrong prediction!
Energy consumption = 193.821825 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 746 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 746 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 746 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33862, 0.31669, 0.37291, 0.30422, 0.12351, 0.043728, 0.056043, 0.74639, 0.27804, 0.31991]
Predicted label: 7
Correct prediction
Energy consumption = 201.504065 pJ
sum error= 260
Actual label: 6
Output voltages: [0.33639, 0.13632, 0.30452, 0.046143, 0.47341, 0.2477, 0.71204, 0.10337, 0.2499, 0.16928]
Predicted label: 6
Correct prediction
Energy consumption = 188.945317 pJ
sum error= 260
Actual label: 9
Output voltages: [0.3452, 0.067661, 0.18501, 0.27622, 0.2255, 0.22784, 0.079806, 0.28978, 0.50548, 0.60143]
Predicted label: 9
Correct prediction
Energy consumption = 190.046642 pJ
sum error= 260
Actual label: 1
Output voltages: [0.16864, 0.73338, 0.30408, 0.15739, 0.3184, 0.092098, 0.33991, 0.16813, 0.39283, 0.1799]
Predicted label: 1
Correct prediction
Energy consumption = 194.797605 pJ
sum error= 260
Actual label: 9
Output voltages: [0.2937, 0.089318, 0.17448, 0.20681, 0.25792, 0.23406, 0.11336, 0.18129, 0.50127, 0.62233]
Predicted label: 9
Correct prediction
Energy consumption = 190.851403 pJ
sum error= 260
Actual label: 0
Output voltages: [0.59485, 0.20995, 0.32241, 0.13702, 0.33846, 0.074952, 0.46536, 0.20252, 0.33355, 0.14597]
Predicted label: 0
Correct prediction
Energy consumption = 199.948086 pJ
sum error= 260
Actual label: 6
Output voltages: [0.36077, 0.30653, 0.26282, 0.15802, 0.28282, 0.32688, 0.70214, 0.11755, 0.43008, 0.09353]
Predicted label: 6
Correct prediction
Energy consumption = 185.280975 pJ
sum error= 260
Actual label: 7
Output voltages: [0.33478, 0.19644, 0.43863, 0.22562, 0.108, 0.048724, 0.048561, 0.75021, 0.39913, 0.2796]
Predicted label: 7
Correct prediction
Energy consumption = 197.832006 pJ
sum error= 260
Actual label: 1
Output voltages: [0.13012, 0.69332, 0.23181, 0.1692, 0.28505, 0.15539, 0.27754, 0.10158, 0.47937, 0.25446]
Predicted label: 1
Correct prediction
Energy consumption = 192.360746 pJ
sum error= 260
Actual label: 2
Output voltages: [0.27243, 0.123, 0.7517, 0.27542, 0.22986, 0.046735, 0.22284, 0.22083, 0.47764, 0.2068]
Predicted label: 2
Correct prediction
Energy consumption = 177.909890 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 747 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 747 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 747 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36669, 0.18328, 0.31716, 0.75978, 0.13839, 0.21168, 0.10499, 0.30034, 0.44731, 0.23146]
Predicted label: 3
Correct prediction
Energy consumption = 184.628305 pJ
sum error= 260
Actual label: 9
Output voltages: [0.22578, 0.056288, 0.13283, 0.24021, 0.31164, 0.37033, 0.14291, 0.2691, 0.45707, 0.54744]
Predicted label: 9
Correct prediction
Energy consumption = 193.975971 pJ
sum error= 260
Actual label: 2
Output voltages: [0.33657, 0.13429, 0.73878, 0.34518, 0.17023, 0.04276, 0.1496, 0.32964, 0.42023, 0.31166]
Predicted label: 2
Correct prediction
Energy consumption = 185.084952 pJ
sum error= 260
Actual label: 4
Output voltages: [0.2326, 0.29913, 0.13646, 0.14982, 0.64755, 0.11686, 0.32543, 0.22723, 0.28287, 0.39457]
Predicted label: 4
Correct prediction
Energy consumption = 205.166366 pJ
sum error= 260
Actual label: 5
Output voltages: [0.28744, 0.055985, 0.049088, 0.37462, 0.26418, 0.74986, 0.32125, 0.17134, 0.45091, 0.15998]
Predicted label: 5
Correct prediction
Energy consumption = 188.186248 pJ
sum error= 260
Actual label: 5
Output voltages: [0.20803, 0.066324, 0.070826, 0.43102, 0.25705, 0.72731, 0.27168, 0.173, 0.47676, 0.2657]
Predicted label: 5
Correct prediction
Energy consumption = 189.598333 pJ
sum error= 260
Actual label: 3
Output voltages: [0.57538, 0.10817, 0.35117, 0.62062, 0.069999, 0.16304, 0.055858, 0.39689, 0.36122, 0.19808]
Predicted label: 3
Correct prediction
Energy consumption = 197.860046 pJ
sum error= 260
Actual label: 7
Output voltages: [0.39279, 0.2356, 0.44379, 0.43638, 0.087948, 0.029348, 0.084501, 0.63472, 0.29238, 0.27389]
Predicted label: 7
Correct prediction
Energy consumption = 190.667907 pJ
sum error= 260
Actual label: 5
Output voltages: [0.30773, 0.1057, 0.0793, 0.42339, 0.20472, 0.73209, 0.35956, 0.11507, 0.40934, 0.24765]
Predicted label: 5
Correct prediction
Energy consumption = 194.264252 pJ
sum error= 260
Actual label: 3
Output voltages: [0.32824, 0.22334, 0.25118, 0.76039, 0.11745, 0.26874, 0.112, 0.19451, 0.41771, 0.27427]
Predicted label: 3
Correct prediction
Energy consumption = 185.920157 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 748 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 748 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 748 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1752, 0.73633, 0.27068, 0.14116, 0.3559, 0.1407, 0.46154, 0.10521, 0.34374, 0.15946]
Predicted label: 1
Correct prediction
Energy consumption = 205.761433 pJ
sum error= 260
Actual label: 8
Output voltages: [0.19863, 0.27808, 0.13419, 0.32238, 0.16942, 0.38108, 0.25418, 0.16598, 0.72143, 0.098362]
Predicted label: 8
Correct prediction
Energy consumption = 199.330391 pJ
sum error= 260
Actual label: 2
Output voltages: [0.38007, 0.093253, 0.71848, 0.35277, 0.12739, 0.040844, 0.21356, 0.37491, 0.53659, 0.16245]
Predicted label: 2
Correct prediction
Energy consumption = 184.700631 pJ
sum error= 260
Actual label: 2
Output voltages: [0.28124, 0.16331, 0.73679, 0.28189, 0.14571, 0.044143, 0.16507, 0.42362, 0.45786, 0.1779]
Predicted label: 2
Correct prediction
Energy consumption = 180.275772 pJ
sum error= 260
Actual label: 3
Output voltages: [0.29329, 0.26805, 0.26641, 0.75468, 0.097695, 0.21516, 0.097328, 0.26706, 0.48483, 0.20874]
Predicted label: 3
Correct prediction
Energy consumption = 187.254988 pJ
sum error= 260
Actual label: 0
Output voltages: [0.72618, 0.23577, 0.27527, 0.17557, 0.18357, 0.11977, 0.3802, 0.24092, 0.33497, 0.17962]
Predicted label: 0
Correct prediction
Energy consumption = 192.613012 pJ
sum error= 260
Actual label: 2
Output voltages: [0.35028, 0.13706, 0.73912, 0.291, 0.126, 0.040129, 0.22955, 0.35956, 0.52688, 0.15884]
Predicted label: 2
Correct prediction
Energy consumption = 180.649005 pJ
sum error= 260
Actual label: 9
Output voltages: [0.25682, 0.10031, 0.17692, 0.23977, 0.34504, 0.25265, 0.099748, 0.13553, 0.46291, 0.63311]
Predicted label: 9
Correct prediction
Energy consumption = 185.383852 pJ
sum error= 260
Actual label: 4
Output voltages: [0.23546, 0.17371, 0.31256, 0.17167, 0.72727, 0.057183, 0.21259, 0.25553, 0.21039, 0.23491]
Predicted label: 4
Correct prediction
Energy consumption = 193.624158 pJ
sum error= 260
Actual label: 9
Output voltages: [0.2576, 0.12813, 0.21703, 0.23104, 0.2768, 0.19747, 0.081441, 0.20347, 0.46899, 0.656]
Predicted label: 9
Correct prediction
Energy consumption = 188.150514 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 749 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 749 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 749 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.27512, 0.26494, 0.51589, 0.24218, 0.12783, 0.0419, 0.043762, 0.73627, 0.36414, 0.3432]
Predicted label: 7
Correct prediction
Energy consumption = 185.941852 pJ
sum error= 260
Actual label: 0
Output voltages: [0.67832, 0.18061, 0.19586, 0.11489, 0.25248, 0.13546, 0.4202, 0.30322, 0.30859, 0.22467]
Predicted label: 0
Correct prediction
Energy consumption = 196.149393 pJ
sum error= 260
Actual label: 2
Output voltages: [0.46605, 0.22225, 0.57915, 0.33488, 0.078345, 0.030375, 0.16462, 0.50514, 0.38705, 0.15412]
Predicted label: 2
Correct prediction
Energy consumption = 195.180405 pJ
sum error= 260
Actual label: 7
Output voltages: [0.318, 0.34267, 0.47623, 0.26081, 0.12075, 0.031308, 0.059687, 0.71284, 0.25553, 0.33162]
Predicted label: 7
Correct prediction
Energy consumption = 193.023848 pJ
sum error= 260
Actual label: 4
Output voltages: [0.27962, 0.31428, 0.2767, 0.10584, 0.63685, 0.07018, 0.47248, 0.23895, 0.19861, 0.11626]
Predicted label: 4
Correct prediction
Energy consumption = 207.697112 pJ
sum error= 260
Actual label: 9
Output voltages: [0.28205, 0.20704, 0.19427, 0.26636, 0.3117, 0.080455, 0.063806, 0.17849, 0.41761, 0.63078]
Predicted label: 9
Correct prediction
Energy consumption = 203.669458 pJ
sum error= 260
Actual label: 9
Output voltages: [0.36484, 0.14138, 0.19024, 0.21908, 0.33046, 0.13331, 0.075006, 0.22339, 0.34504, 0.69557]
Predicted label: 9
Correct prediction
Energy consumption = 188.345399 pJ
sum error= 260
Actual label: 2
Output voltages: [0.34774, 0.34343, 0.73559, 0.32906, 0.18653, 0.031926, 0.21924, 0.35316, 0.33981, 0.19879]
Predicted label: 2
Correct prediction
Energy consumption = 187.758722 pJ
sum error= 260
Actual label: 5
Output voltages: [0.32231, 0.19268, 0.18518, 0.26334, 0.059082, 0.64063, 0.42276, 0.19508, 0.41116, 0.1362]
Predicted label: 5
Correct prediction
Energy consumption = 201.046920 pJ
sum error= 260
Actual label: 9
Output voltages: [0.3389, 0.14618, 0.1962, 0.22099, 0.26875, 0.14457, 0.056203, 0.19093, 0.43343, 0.67269]
Predicted label: 9
Correct prediction
Energy consumption = 190.937005 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 750 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 750 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 750 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20177, 0.30653, 0.24256, 0.28278, 0.14252, 0.22079, 0.2132, 0.16477, 0.74936, 0.26856]
Predicted label: 8
Correct prediction
Energy consumption = 200.386233 pJ
sum error= 260
Actual label: 3
Output voltages: [0.34947, 0.21908, 0.32741, 0.75848, 0.12023, 0.33633, 0.11457, 0.24891, 0.41677, 0.19581]
Predicted label: 3
Correct prediction
Energy consumption = 193.771380 pJ
sum error= 260
Actual label: 8
Output voltages: [0.23473, 0.14654, 0.26865, 0.40943, 0.092347, 0.33608, 0.14905, 0.17293, 0.75007, 0.19473]
Predicted label: 8
Correct prediction
Energy consumption = 190.348528 pJ
sum error= 260
Actual label: 6
Output voltages: [0.32939, 0.19326, 0.27759, 0.086442, 0.26609, 0.27505, 0.68538, 0.071698, 0.41053, 0.10133]
Predicted label: 6
Correct prediction
Energy consumption = 187.123958 pJ
sum error= 260
Actual label: 7
Output voltages: [0.28637, 0.25382, 0.47899, 0.28143, 0.10723, 0.046475, 0.043445, 0.73527, 0.37723, 0.37126]
Predicted label: 7
Correct prediction
Energy consumption = 191.674946 pJ
sum error= 260
Actual label: 0
Output voltages: [0.64838, 0.18587, 0.35036, 0.10324, 0.33534, 0.059103, 0.38849, 0.23475, 0.34185, 0.1708]
Predicted label: 0
Correct prediction
Energy consumption = 201.296190 pJ
sum error= 260
Actual label: 0
Output voltages: [0.68615, 0.22994, 0.24302, 0.15556, 0.17609, 0.12789, 0.47219, 0.14293, 0.3006, 0.24326]
Predicted label: 0
Correct prediction
Energy consumption = 194.182486 pJ
sum error= 260
Actual label: 1
Output voltages: [0.24013, 0.73474, 0.33263, 0.2197, 0.41925, 0.091374, 0.44275, 0.13552, 0.20358, 0.2013]
Predicted label: 1
Correct prediction
Energy consumption = 202.624877 pJ
sum error= 260
Actual label: 2
Output voltages: [0.27896, 0.29903, 0.73109, 0.34162, 0.16701, 0.03516, 0.32042, 0.18438, 0.44561, 0.1694]
Predicted label: 2
Correct prediction
Energy consumption = 184.588805 pJ
sum error= 260
Actual label: 3
Output voltages: [0.31485, 0.1722, 0.32005, 0.75165, 0.17115, 0.17213, 0.15799, 0.14503, 0.45552, 0.25061]
Predicted label: 3
Correct prediction
Energy consumption = 184.072475 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 751 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 751 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 751 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.12309, 0.1657, 0.22604, 0.16991, 0.75079, 0.14308, 0.30578, 0.3066, 0.30646, 0.19584]
Predicted label: 4
Correct prediction
Energy consumption = 194.251270 pJ
sum error= 260
Actual label: 5
Output voltages: [0.38116, 0.047158, 0.21065, 0.40065, 0.17594, 0.5489, 0.32272, 0.21075, 0.35481, 0.23529]
Predicted label: 5
Correct prediction
Energy consumption = 198.514186 pJ
sum error= 260
Actual label: 6
Output voltages: [0.27494, 0.29186, 0.30329, 0.18752, 0.29631, 0.33139, 0.73119, 0.078772, 0.36047, 0.074839]
Predicted label: 6
Correct prediction
Energy consumption = 192.130426 pJ
sum error= 260
Actual label: 7
Output voltages: [0.30662, 0.22594, 0.19625, 0.21131, 0.27195, 0.17175, 0.042285, 0.76598, 0.27812, 0.27749]
Predicted label: 7
Correct prediction
Energy consumption = 192.374442 pJ
sum error= 260
Actual label: 8
Output voltages: [0.43797, 0.073501, 0.24773, 0.32223, 0.20711, 0.29684, 0.29751, 0.053873, 0.62985, 0.29908]
Predicted label: 8
Correct prediction
Energy consumption = 200.070168 pJ
sum error= 260
Actual label: 9
Output voltages: [0.37706, 0.12399, 0.26204, 0.28722, 0.34145, 0.10609, 0.10916, 0.21687, 0.35449, 0.63148]
Predicted label: 9
Correct prediction
Energy consumption = 184.784780 pJ
sum error= 260
Actual label: 0
Output voltages: [0.69857, 0.22889, 0.28522, 0.1669, 0.19598, 0.090417, 0.40708, 0.18598, 0.35414, 0.20314]
Predicted label: 0
Correct prediction
Energy consumption = 191.377879 pJ
sum error= 260
Actual label: 1
Output voltages: [0.28801, 0.59353, 0.28455, 0.26721, 0.20837, 0.16439, 0.51694, 0.036856, 0.40751, 0.24618]
Predicted label: 1
Correct prediction
Energy consumption = 205.984255 pJ
sum error= 260
Actual label: 2
Output voltages: [0.30639, 0.22565, 0.70314, 0.3727, 0.083533, 0.044926, 0.19776, 0.21933, 0.49357, 0.10379]
Predicted label: 2
Correct prediction
Energy consumption = 179.555939 pJ
sum error= 260
Actual label: 3
Output voltages: [0.29987, 0.17335, 0.33165, 0.75189, 0.14118, 0.25742, 0.12016, 0.1467, 0.40387, 0.20901]
Predicted label: 3
Correct prediction
Energy consumption = 179.988460 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 752 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 752 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 752 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.16539, 0.23819, 0.36603, 0.18284, 0.7418, 0.056525, 0.2257, 0.3696, 0.16515, 0.2372]
Predicted label: 4
Correct prediction
Energy consumption = 190.602340 pJ
sum error= 260
Actual label: 5
Output voltages: [0.27521, 0.12445, 0.042415, 0.37464, 0.28823, 0.72695, 0.34649, 0.14386, 0.32781, 0.27024]
Predicted label: 5
Correct prediction
Energy consumption = 187.863710 pJ
sum error= 260
Actual label: 6
Output voltages: [0.25263, 0.35256, 0.36644, 0.24155, 0.369, 0.18824, 0.70634, 0.10873, 0.24718, 0.059838]
Predicted label: 6
Correct prediction
Energy consumption = 194.081695 pJ
sum error= 260
Actual label: 7
Output voltages: [0.21248, 0.36227, 0.39597, 0.24386, 0.18155, 0.050702, 0.043656, 0.74223, 0.35805, 0.25832]
Predicted label: 7
Correct prediction
Energy consumption = 199.117971 pJ
sum error= 260
Actual label: 8
Output voltages: [0.35727, 0.14123, 0.25296, 0.38468, 0.15592, 0.20695, 0.31415, 0.048892, 0.66439, 0.25875]
Predicted label: 8
Correct prediction
Energy consumption = 196.653678 pJ
sum error= 260
Actual label: 9
Output voltages: [0.37834, 0.14752, 0.19099, 0.31354, 0.36497, 0.099102, 0.055968, 0.22417, 0.33545, 0.64544]
Predicted label: 9
Correct prediction
Energy consumption = 193.129727 pJ
sum error= 260
Actual label: 0
Output voltages: [0.72597, 0.23074, 0.25318, 0.166, 0.18134, 0.11066, 0.34867, 0.19257, 0.36847, 0.20514]
Predicted label: 0
Correct prediction
Energy consumption = 194.585635 pJ
sum error= 260
Actual label: 1
Output voltages: [0.17209, 0.74347, 0.25355, 0.23636, 0.24155, 0.16509, 0.47891, 0.058756, 0.40106, 0.20949]
Predicted label: 1
Correct prediction
Energy consumption = 204.058309 pJ
sum error= 260
Actual label: 2
Output voltages: [0.3426, 0.22847, 0.72466, 0.34706, 0.10634, 0.039073, 0.25371, 0.22287, 0.46025, 0.12953]
Predicted label: 2
Correct prediction
Energy consumption = 188.864093 pJ
sum error= 260
Actual label: 3
Output voltages: [0.34632, 0.10565, 0.28016, 0.71914, 0.23946, 0.20571, 0.091126, 0.15169, 0.38715, 0.32608]
Predicted label: 3
Correct prediction
Energy consumption = 190.525010 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 753 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 753 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 753 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.2694, 0.24779, 0.33858, 0.15702, 0.69017, 0.03788, 0.16668, 0.25424, 0.26779, 0.26032]
Predicted label: 4
Correct prediction
Energy consumption = 196.467494 pJ
sum error= 260
Actual label: 5
Output voltages: [0.38208, 0.054882, 0.059944, 0.40507, 0.242, 0.72333, 0.3253, 0.15957, 0.34452, 0.21514]
Predicted label: 5
Correct prediction
Energy consumption = 186.560652 pJ
sum error= 260
Actual label: 6
Output voltages: [0.25847, 0.1871, 0.3931, 0.10906, 0.41331, 0.27791, 0.71557, 0.14908, 0.33701, 0.059995]
Predicted label: 6
Correct prediction
Energy consumption = 189.542461 pJ
sum error= 260
Actual label: 7
Output voltages: [0.36271, 0.22477, 0.20877, 0.28939, 0.23987, 0.22182, 0.038907, 0.74493, 0.2859, 0.33915]
Predicted label: 7
Correct prediction
Energy consumption = 199.517481 pJ
sum error= 260
Actual label: 8
Output voltages: [0.39151, 0.16134, 0.27666, 0.34508, 0.16726, 0.20401, 0.36361, 0.058285, 0.64965, 0.20138]
Predicted label: 8
Correct prediction
Energy consumption = 194.365015 pJ
sum error= 260
Actual label: 9
Output voltages: [0.32627, 0.11755, 0.17433, 0.20393, 0.41202, 0.13966, 0.067411, 0.21482, 0.37375, 0.63947]
Predicted label: 9
Correct prediction
Energy consumption = 198.423063 pJ
sum error= 260
Actual label: 0
Output voltages: [0.72143, 0.2029, 0.24949, 0.19807, 0.21496, 0.13106, 0.33115, 0.19642, 0.38993, 0.28955]
Predicted label: 0
Correct prediction
Energy consumption = 197.256308 pJ
sum error= 260
Actual label: 0
Output voltages: [0.69354, 0.22611, 0.25486, 0.17724, 0.17215, 0.12803, 0.44751, 0.18447, 0.40538, 0.18262]
Predicted label: 0
Correct prediction
Energy consumption = 187.379644 pJ
sum error= 260
Actual label: 7
Output voltages: [0.29079, 0.28863, 0.24373, 0.16938, 0.30263, 0.084532, 0.03931, 0.68513, 0.26141, 0.44608]
Predicted label: 7
Correct prediction
Energy consumption = 204.775676 pJ
sum error= 260
Actual label: 2
Output voltages: [0.25956, 0.34994, 0.66198, 0.3392, 0.23547, 0.02868, 0.14717, 0.3506, 0.38682, 0.1698]
Predicted label: 2
Correct prediction
Energy consumption = 191.730600 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 754 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 754 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 754 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27689, 0.19874, 0.33518, 0.054982, 0.37921, 0.27235, 0.74066, 0.081122, 0.33367, 0.13953]
Predicted label: 6
Correct prediction
Energy consumption = 191.322901 pJ
sum error= 260
Actual label: 5
Output voltages: [0.34717, 0.116, 0.044528, 0.41307, 0.39431, 0.71959, 0.28939, 0.16464, 0.27656, 0.19404]
Predicted label: 5
Correct prediction
Energy consumption = 188.967543 pJ
sum error= 260
Actual label: 5
Output voltages: [0.29503, 0.19801, 0.053728, 0.3188, 0.31895, 0.72481, 0.41606, 0.093547, 0.27212, 0.16953]
Predicted label: 5
Correct prediction
Energy consumption = 181.679818 pJ
sum error= 260
Actual label: 3
Output voltages: [0.31908, 0.17326, 0.34234, 0.74342, 0.11317, 0.19591, 0.14927, 0.13947, 0.47903, 0.19369]
Predicted label: 3
Correct prediction
Energy consumption = 185.500303 pJ
sum error= 260
Actual label: 7
Output voltages: [0.3189, 0.27625, 0.29397, 0.28507, 0.22509, 0.06246, 0.035643, 0.73275, 0.29559, 0.35461]
Predicted label: 7
Correct prediction
Energy consumption = 194.988929 pJ
sum error= 260
Actual label: 8
Output voltages: [0.3059, 0.12901, 0.27909, 0.45338, 0.19127, 0.21168, 0.18869, 0.06391, 0.66537, 0.28497]
Predicted label: 8
Correct prediction
Energy consumption = 202.953552 pJ
sum error= 260
Actual label: 6
Output voltages: [0.29523, 0.24309, 0.35818, 0.13592, 0.3624, 0.26895, 0.73763, 0.11621, 0.35182, 0.087765]
Predicted label: 6
Correct prediction
Energy consumption = 190.757267 pJ
sum error= 260
Actual label: 6
Output voltages: [0.30833, 0.22629, 0.3375, 0.085895, 0.36329, 0.32023, 0.74365, 0.09101, 0.35242, 0.093423]
Predicted label: 6
Correct prediction
Energy consumption = 183.203279 pJ
sum error= 260
Actual label: 6
Output voltages: [0.31655, 0.19861, 0.33875, 0.046292, 0.395, 0.26675, 0.74104, 0.073959, 0.32406, 0.12891]
Predicted label: 6
Correct prediction
Energy consumption = 184.187037 pJ
sum error= 260
Actual label: 6
Output voltages: [0.34657, 0.28999, 0.22165, 0.16774, 0.28225, 0.39318, 0.73085, 0.1353, 0.41212, 0.095157]
Predicted label: 6
Correct prediction
Energy consumption = 190.109828 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 755 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 755 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 755 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.21892, 0.17819, 0.3519, 0.22809, 0.72841, 0.038167, 0.22131, 0.31367, 0.23351, 0.20406]
Predicted label: 4
Correct prediction
Energy consumption = 193.919451 pJ
sum error= 260
Actual label: 3
Output voltages: [0.32557, 0.16474, 0.3035, 0.75379, 0.20299, 0.21658, 0.16092, 0.13308, 0.42722, 0.24518]
Predicted label: 3
Correct prediction
Energy consumption = 193.796825 pJ
sum error= 260
Actual label: 8
Output voltages: [0.32567, 0.1912, 0.21526, 0.33103, 0.14082, 0.16653, 0.18343, 0.1209, 0.66156, 0.40482]
Predicted label: 8
Correct prediction
Energy consumption = 198.117186 pJ
sum error= 260
Actual label: 8
Output voltages: [0.38576, 0.16262, 0.30371, 0.38251, 0.14545, 0.15011, 0.24565, 0.048017, 0.63952, 0.3832]
Predicted label: 8
Correct prediction
Energy consumption = 193.142531 pJ
sum error= 260
Actual label: 3
Output voltages: [0.36122, 0.19215, 0.24505, 0.76432, 0.17445, 0.26858, 0.14417, 0.1539, 0.40382, 0.23186]
Predicted label: 3
Correct prediction
Energy consumption = 187.349765 pJ
sum error= 260
Actual label: 0
Output voltages: [0.68688, 0.23715, 0.29587, 0.17922, 0.16879, 0.092617, 0.40506, 0.13005, 0.34087, 0.23403]
Predicted label: 0
Correct prediction
Energy consumption = 194.901130 pJ
sum error= 260
Actual label: 1
Output voltages: [0.22074, 0.67171, 0.39044, 0.30192, 0.31605, 0.042674, 0.23569, 0.20569, 0.32234, 0.30798]
Predicted label: 1
Correct prediction
Energy consumption = 205.668292 pJ
sum error= 260
Actual label: 9
Output voltages: [0.36061, 0.17185, 0.20061, 0.28439, 0.39711, 0.10827, 0.099587, 0.11103, 0.28718, 0.67023]
Predicted label: 9
Correct prediction
Energy consumption = 191.389725 pJ
sum error= 260
Actual label: 0
Output voltages: [0.63675, 0.137, 0.31038, 0.15921, 0.24427, 0.076147, 0.42967, 0.19804, 0.40834, 0.24823]
Predicted label: 0
Correct prediction
Energy consumption = 202.666796 pJ
sum error= 260
Actual label: 5
Output voltages: [0.31469, 0.066124, 0.10117, 0.42949, 0.16722, 0.73875, 0.28288, 0.23291, 0.42402, 0.26304]
Predicted label: 5
Correct prediction
Energy consumption = 189.215744 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 756 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 756 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 756 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.12581, 0.16153, 0.19355, 0.15792, 0.73777, 0.12742, 0.25747, 0.41789, 0.33761, 0.14265]
Predicted label: 4
Correct prediction
Energy consumption = 193.857104 pJ
sum error= 260
Actual label: 1
Output voltages: [0.25517, 0.74088, 0.25331, 0.24967, 0.30532, 0.066891, 0.39386, 0.067151, 0.29357, 0.23134]
Predicted label: 1
Correct prediction
Energy consumption = 207.211597 pJ
sum error= 260
Actual label: 9
Output voltages: [0.29362, 0.14505, 0.18066, 0.32046, 0.41577, 0.097742, 0.062717, 0.15326, 0.33017, 0.61277]
Predicted label: 9
Correct prediction
Energy consumption = 194.090621 pJ
sum error= 260
Actual label: 1
Output voltages: [0.19456, 0.69759, 0.28494, 0.11655, 0.29491, 0.10166, 0.34893, 0.071563, 0.45313, 0.23838]
Predicted label: 1
Correct prediction
Energy consumption = 197.045739 pJ
sum error= 260
Actual label: 2
Output voltages: [0.2754, 0.26148, 0.72974, 0.32911, 0.14901, 0.02944, 0.20989, 0.34632, 0.44781, 0.11133]
Predicted label: 2
Correct prediction
Energy consumption = 191.400062 pJ
sum error= 260
Actual label: 7
Output voltages: [0.34686, 0.25861, 0.11202, 0.30887, 0.35515, 0.18339, 0.049861, 0.72606, 0.25125, 0.097112]
Predicted label: 7
Correct prediction
Energy consumption = 199.682681 pJ
sum error= 260
Actual label: 0
Output voltages: [0.72685, 0.26156, 0.30989, 0.18704, 0.17761, 0.064075, 0.37513, 0.13609, 0.31505, 0.25995]
Predicted label: 0
Correct prediction
Energy consumption = 189.484813 pJ
sum error= 260
Actual label: 1
Output voltages: [0.21127, 0.73129, 0.22546, 0.24833, 0.43454, 0.055249, 0.27774, 0.19796, 0.23291, 0.2802]
Predicted label: 1
Correct prediction
Energy consumption = 199.907284 pJ
sum error= 260
Actual label: 3
Output voltages: [0.29844, 0.090663, 0.35329, 0.65871, 0.1083, 0.22613, 0.18715, 0.083376, 0.55766, 0.20547]
Predicted label: 3
Correct prediction
Energy consumption = 195.230531 pJ
sum error= 260
Actual label: 8
Output voltages: [0.35339, 0.159, 0.28351, 0.30132, 0.16955, 0.20967, 0.21241, 0.094633, 0.70886, 0.28294]
Predicted label: 8
Correct prediction
Energy consumption = 192.392221 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 757 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 757 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 757 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31037, 0.26474, 0.7435, 0.2715, 0.128, 0.029988, 0.28679, 0.25734, 0.44408, 0.12817]
Predicted label: 2
Correct prediction
Energy consumption = 184.191475 pJ
sum error= 260
Actual label: 9
Output voltages: [0.36945, 0.13146, 0.19253, 0.28964, 0.35031, 0.13713, 0.097878, 0.19531, 0.34809, 0.65408]
Predicted label: 9
Correct prediction
Energy consumption = 190.446699 pJ
sum error= 260
Actual label: 2
Output voltages: [0.27674, 0.14234, 0.73977, 0.346, 0.15709, 0.039845, 0.2456, 0.28708, 0.43999, 0.16977]
Predicted label: 2
Correct prediction
Energy consumption = 184.321915 pJ
sum error= 260
Actual label: 7
Output voltages: [0.36325, 0.29412, 0.28977, 0.18869, 0.21942, 0.063535, 0.044495, 0.65495, 0.31084, 0.37179]
Predicted label: 7
Correct prediction
Energy consumption = 193.767936 pJ
sum error= 260
Actual label: 4
Output voltages: [0.12616, 0.43686, 0.18968, 0.17893, 0.73631, 0.11565, 0.25586, 0.22304, 0.19545, 0.33228]
Predicted label: 4
Correct prediction
Energy consumption = 193.758650 pJ
sum error= 260
Actual label: 2
Output voltages: [0.30715, 0.26266, 0.73379, 0.3164, 0.1068, 0.03399, 0.28566, 0.25319, 0.45043, 0.17709]
Predicted label: 2
Correct prediction
Energy consumption = 188.988787 pJ
sum error= 260
Actual label: 6
Output voltages: [0.28685, 0.19466, 0.25188, 0.15452, 0.27113, 0.39518, 0.72042, 0.12603, 0.42179, 0.14077]
Predicted label: 6
Correct prediction
Energy consumption = 193.974231 pJ
sum error= 260
Actual label: 5
Output voltages: [0.36266, 0.051595, 0.057823, 0.39998, 0.28197, 0.73231, 0.29176, 0.13572, 0.42955, 0.16475]
Predicted label: 5
Correct prediction
Energy consumption = 183.741036 pJ
sum error= 260
Actual label: 5
Output voltages: [0.35453, 0.061456, 0.061003, 0.42213, 0.24256, 0.74614, 0.31785, 0.16511, 0.36903, 0.21133]
Predicted label: 5
Correct prediction
Energy consumption = 179.183721 pJ
sum error= 260
Actual label: 9
Output voltages: [0.24902, 0.12784, 0.17366, 0.4247, 0.51923, 0.13307, 0.10279, 0.24555, 0.31059, 0.48633]
Predicted label: 4
Wrong prediction!
Energy consumption = 195.111483 pJ
sum error= 261
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 758 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 758 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 758 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3687, 0.15781, 0.15332, 0.36338, 0.48758, 0.071193, 0.13978, 0.11125, 0.22877, 0.54714]
Predicted label: 9
Correct prediction
Energy consumption = 197.814820 pJ
sum error= 261
Actual label: 1
Output voltages: [0.26552, 0.74498, 0.29087, 0.15417, 0.29898, 0.073162, 0.33161, 0.079696, 0.33407, 0.22927]
Predicted label: 1
Correct prediction
Energy consumption = 200.342292 pJ
sum error= 261
Actual label: 1
Output voltages: [0.22963, 0.72177, 0.17671, 0.21487, 0.42692, 0.073757, 0.28149, 0.20585, 0.29244, 0.2737]
Predicted label: 1
Correct prediction
Energy consumption = 195.125872 pJ
sum error= 261
Actual label: 5
Output voltages: [0.37322, 0.17567, 0.040883, 0.39387, 0.33804, 0.75415, 0.31013, 0.097131, 0.28, 0.26264]
Predicted label: 5
Correct prediction
Energy consumption = 190.050075 pJ
sum error= 261
Actual label: 7
Output voltages: [0.32291, 0.23702, 0.20434, 0.3246, 0.22989, 0.085408, 0.031087, 0.68088, 0.3036, 0.42397]
Predicted label: 7
Correct prediction
Energy consumption = 203.483239 pJ
sum error= 261
Actual label: 6
Output voltages: [0.26998, 0.18492, 0.25002, 0.13499, 0.35974, 0.33915, 0.72755, 0.088124, 0.35744, 0.13713]
Predicted label: 6
Correct prediction
Energy consumption = 198.862647 pJ
sum error= 261
Actual label: 8
Output voltages: [0.32842, 0.15666, 0.35192, 0.31531, 0.13504, 0.18899, 0.27779, 0.086703, 0.722, 0.27372]
Predicted label: 8
Correct prediction
Energy consumption = 194.787769 pJ
sum error= 261
Actual label: 2
Output voltages: [0.26139, 0.34562, 0.62171, 0.42853, 0.07984, 0.035489, 0.26674, 0.16767, 0.47962, 0.20146]
Predicted label: 2
Correct prediction
Energy consumption = 192.880682 pJ
sum error= 261
Actual label: 9
Output voltages: [0.32511, 0.1736, 0.20654, 0.24139, 0.48108, 0.076903, 0.058701, 0.10609, 0.2745, 0.63918]
Predicted label: 9
Correct prediction
Energy consumption = 196.582500 pJ
sum error= 261
Actual label: 4
Output voltages: [0.13419, 0.13889, 0.3566, 0.17622, 0.75616, 0.056592, 0.27971, 0.32023, 0.21184, 0.20629]
Predicted label: 4
Correct prediction
Energy consumption = 185.436828 pJ
sum error= 261
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 759 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 759 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 759 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30457, 0.19239, 0.25179, 0.7603, 0.17761, 0.18112, 0.13478, 0.18951, 0.45015, 0.24041]
Predicted label: 3
Correct prediction
Energy consumption = 185.996943 pJ
sum error= 261
Actual label: 1
Output voltages: [0.17866, 0.75581, 0.33349, 0.26918, 0.29108, 0.050558, 0.37498, 0.1458, 0.27433, 0.2193]
Predicted label: 1
Correct prediction
Energy consumption = 206.868666 pJ
sum error= 261
Actual label: 9
Output voltages: [0.31838, 0.14038, 0.21021, 0.27053, 0.56308, 0.11693, 0.15267, 0.15046, 0.25569, 0.54763]
Predicted label: 4
Wrong prediction!
Energy consumption = 199.565071 pJ
sum error= 262
Actual label: 0
Output voltages: [0.67229, 0.27079, 0.26822, 0.19924, 0.24237, 0.10085, 0.47861, 0.1443, 0.29677, 0.19993]
Predicted label: 0
Correct prediction
Energy consumption = 195.172718 pJ
sum error= 262
Actual label: 9
Output voltages: [0.30134, 0.14591, 0.20415, 0.26492, 0.33888, 0.12788, 0.075739, 0.20541, 0.37554, 0.67627]
Predicted label: 9
Correct prediction
Energy consumption = 186.037090 pJ
sum error= 262
Actual label: 3
Output voltages: [0.33242, 0.15147, 0.32781, 0.57636, 0.10331, 0.15636, 0.14891, 0.06068, 0.5865, 0.2687]
Predicted label: 8
Wrong prediction!
Energy consumption = 188.309591 pJ
sum error= 263
Actual label: 6
Output voltages: [0.27136, 0.21393, 0.31151, 0.072226, 0.35949, 0.32966, 0.74587, 0.098832, 0.35063, 0.093284]
Predicted label: 6
Correct prediction
Energy consumption = 190.158164 pJ
sum error= 263
Actual label: 8
Output voltages: [0.28381, 0.14333, 0.29099, 0.39798, 0.14135, 0.21684, 0.16937, 0.10083, 0.73333, 0.23757]
Predicted label: 8
Correct prediction
Energy consumption = 196.901756 pJ
sum error= 263
Actual label: 7
Output voltages: [0.31846, 0.18131, 0.21316, 0.32226, 0.1678, 0.15517, 0.037431, 0.76126, 0.29183, 0.3597]
Predicted label: 7
Correct prediction
Energy consumption = 195.519488 pJ
sum error= 263
Actual label: 0
Output voltages: [0.6317, 0.2126, 0.3079, 0.23995, 0.21115, 0.055527, 0.37491, 0.12113, 0.42853, 0.2875]
Predicted label: 0
Correct prediction
Energy consumption = 198.116797 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 760 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 760 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 760 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.25589, 0.7457, 0.26938, 0.19186, 0.42085, 0.1172, 0.38743, 0.10997, 0.24132, 0.20607]
Predicted label: 1
Correct prediction
Energy consumption = 198.695162 pJ
sum error= 263
Actual label: 0
Output voltages: [0.70024, 0.25867, 0.26477, 0.13476, 0.18338, 0.10308, 0.44505, 0.20682, 0.28825, 0.19703]
Predicted label: 0
Correct prediction
Energy consumption = 194.332307 pJ
sum error= 263
Actual label: 5
Output voltages: [0.38994, 0.061934, 0.063476, 0.46957, 0.2129, 0.73185, 0.27438, 0.19018, 0.41287, 0.29827]
Predicted label: 5
Correct prediction
Energy consumption = 187.409327 pJ
sum error= 263
Actual label: 8
Output voltages: [0.35226, 0.13648, 0.2981, 0.34406, 0.18968, 0.16043, 0.27176, 0.051233, 0.69718, 0.28073]
Predicted label: 8
Correct prediction
Energy consumption = 190.940970 pJ
sum error= 263
Actual label: 2
Output voltages: [0.36157, 0.23688, 0.69079, 0.44899, 0.1022, 0.037084, 0.20144, 0.2231, 0.44546, 0.17317]
Predicted label: 2
Correct prediction
Energy consumption = 184.107146 pJ
sum error= 263
Actual label: 7
Output voltages: [0.27037, 0.25902, 0.25875, 0.14207, 0.24318, 0.065896, 0.037822, 0.73971, 0.35975, 0.35117]
Predicted label: 7
Correct prediction
Energy consumption = 196.003842 pJ
sum error= 263
Actual label: 7
Output voltages: [0.27923, 0.2696, 0.35762, 0.14668, 0.19705, 0.058516, 0.039859, 0.65741, 0.42511, 0.31892]
Predicted label: 7
Correct prediction
Energy consumption = 191.231207 pJ
sum error= 263
Actual label: 0
Output voltages: [0.73248, 0.22365, 0.18679, 0.18864, 0.17795, 0.1915, 0.45405, 0.16516, 0.27828, 0.28199]
Predicted label: 0
Correct prediction
Energy consumption = 200.664228 pJ
sum error= 263
Actual label: 1
Output voltages: [0.21602, 0.73219, 0.3023, 0.26837, 0.31775, 0.13413, 0.43079, 0.067902, 0.28454, 0.23605]
Predicted label: 1
Correct prediction
Energy consumption = 205.051356 pJ
sum error= 263
Actual label: 2
Output voltages: [0.41378, 0.17565, 0.74479, 0.32044, 0.16989, 0.040539, 0.27397, 0.2451, 0.41528, 0.16161]
Predicted label: 2
Correct prediction
Energy consumption = 182.036168 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 761 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 761 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 761 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26939, 0.22707, 0.30797, 0.74174, 0.23866, 0.18156, 0.1907, 0.27425, 0.42255, 0.18114]
Predicted label: 3
Correct prediction
Energy consumption = 193.063026 pJ
sum error= 263
Actual label: 4
Output voltages: [0.17378, 0.12609, 0.27664, 0.13901, 0.75054, 0.16674, 0.3021, 0.2433, 0.24474, 0.26416]
Predicted label: 4
Correct prediction
Energy consumption = 201.461328 pJ
sum error= 263
Actual label: 5
Output voltages: [0.22087, 0.057321, 0.1211, 0.37509, 0.21663, 0.71997, 0.32811, 0.22706, 0.50617, 0.2379]
Predicted label: 5
Correct prediction
Energy consumption = 191.632070 pJ
sum error= 263
Actual label: 6
Output voltages: [0.33532, 0.26646, 0.31766, 0.076442, 0.30241, 0.32074, 0.74608, 0.083258, 0.3807, 0.14105]
Predicted label: 6
Correct prediction
Energy consumption = 188.895882 pJ
sum error= 263
Actual label: 7
Output voltages: [0.2846, 0.29509, 0.27258, 0.25423, 0.12654, 0.059692, 0.047671, 0.75569, 0.38078, 0.31974]
Predicted label: 7
Correct prediction
Energy consumption = 199.063097 pJ
sum error= 263
Actual label: 8
Output voltages: [0.20319, 0.21655, 0.29474, 0.29947, 0.13996, 0.22605, 0.21086, 0.13919, 0.75037, 0.29819]
Predicted label: 8
Correct prediction
Energy consumption = 192.223794 pJ
sum error= 263
Actual label: 9
Output voltages: [0.38556, 0.15048, 0.22316, 0.30892, 0.32255, 0.21418, 0.12394, 0.26333, 0.31215, 0.67664]
Predicted label: 9
Correct prediction
Energy consumption = 199.103584 pJ
sum error= 263
Actual label: 0
Output voltages: [0.74771, 0.28065, 0.24389, 0.18353, 0.13609, 0.24793, 0.3593, 0.15377, 0.25163, 0.29618]
Predicted label: 0
Correct prediction
Energy consumption = 193.479715 pJ
sum error= 263
Actual label: 1
Output voltages: [0.20639, 0.76615, 0.2376, 0.26886, 0.22119, 0.16245, 0.4333, 0.10325, 0.28246, 0.22819]
Predicted label: 1
Correct prediction
Energy consumption = 206.689366 pJ
sum error= 263
Actual label: 2
Output voltages: [0.40182, 0.075673, 0.53423, 0.55859, 0.17794, 0.053151, 0.12748, 0.24488, 0.51499, 0.16326]
Predicted label: 3
Wrong prediction!
Energy consumption = 196.315756 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 762 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 762 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 762 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23192, 0.17892, 0.27504, 0.75059, 0.2259, 0.17777, 0.10547, 0.28196, 0.45701, 0.24596]
Predicted label: 3
Correct prediction
Energy consumption = 185.120723 pJ
sum error= 264
Actual label: 4
Output voltages: [0.1727, 0.14187, 0.36384, 0.19637, 0.75527, 0.081128, 0.32727, 0.22599, 0.19336, 0.31386]
Predicted label: 4
Correct prediction
Energy consumption = 197.363244 pJ
sum error= 264
Actual label: 5
Output voltages: [0.30474, 0.084392, 0.090894, 0.41547, 0.20293, 0.7261, 0.32822, 0.2301, 0.52369, 0.23112]
Predicted label: 5
Correct prediction
Energy consumption = 195.467084 pJ
sum error= 264
Actual label: 8
Output voltages: [0.25375, 0.23161, 0.3178, 0.2784, 0.18106, 0.15311, 0.28424, 0.10267, 0.73628, 0.33325]
Predicted label: 8
Correct prediction
Energy consumption = 190.954917 pJ
sum error= 264
Actual label: 9
Output voltages: [0.4031, 0.098368, 0.26199, 0.35466, 0.30724, 0.17593, 0.16577, 0.29523, 0.25513, 0.66216]
Predicted label: 9
Correct prediction
Energy consumption = 199.390029 pJ
sum error= 264
Actual label: 0
Output voltages: [0.71963, 0.24437, 0.24379, 0.1625, 0.19653, 0.17431, 0.47742, 0.15003, 0.3119, 0.23237]
Predicted label: 0
Correct prediction
Energy consumption = 195.742180 pJ
sum error= 264
Actual label: 1
Output voltages: [0.15677, 0.77021, 0.27545, 0.28134, 0.22521, 0.096375, 0.36535, 0.15527, 0.31564, 0.23948]
Predicted label: 1
Correct prediction
Energy consumption = 209.995265 pJ
sum error= 264
Actual label: 2
Output voltages: [0.51901, 0.086949, 0.66605, 0.35567, 0.10009, 0.15105, 0.31112, 0.2888, 0.40652, 0.098853]
Predicted label: 2
Correct prediction
Energy consumption = 195.507917 pJ
sum error= 264
Actual label: 3
Output voltages: [0.27841, 0.18208, 0.3548, 0.74797, 0.24753, 0.16514, 0.074716, 0.28827, 0.43042, 0.21945]
Predicted label: 3
Correct prediction
Energy consumption = 184.501727 pJ
sum error= 264
Actual label: 4
Output voltages: [0.18017, 0.10063, 0.26299, 0.13128, 0.7497, 0.07906, 0.27928, 0.29996, 0.25618, 0.27753]
Predicted label: 4
Correct prediction
Energy consumption = 197.467406 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 763 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 763 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 763 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22959, 0.062516, 0.14859, 0.3267, 0.23028, 0.73043, 0.33605, 0.24813, 0.49952, 0.26005]
Predicted label: 5
Correct prediction
Energy consumption = 193.701048 pJ
sum error= 264
Actual label: 6
Output voltages: [0.32243, 0.19544, 0.23548, 0.13464, 0.33301, 0.42555, 0.7301, 0.083748, 0.37354, 0.10637]
Predicted label: 6
Correct prediction
Energy consumption = 185.951575 pJ
sum error= 264
Actual label: 7
Output voltages: [0.29695, 0.24522, 0.23399, 0.25625, 0.13548, 0.11078, 0.044586, 0.75837, 0.39819, 0.37704]
Predicted label: 7
Correct prediction
Energy consumption = 201.541288 pJ
sum error= 264
Actual label: 8
Output voltages: [0.22942, 0.22785, 0.30657, 0.33941, 0.11542, 0.24718, 0.27761, 0.12235, 0.74582, 0.2883]
Predicted label: 8
Correct prediction
Energy consumption = 189.162262 pJ
sum error= 264
Actual label: 9
Output voltages: [0.33252, 0.18929, 0.1837, 0.29848, 0.30276, 0.16359, 0.13221, 0.18803, 0.35297, 0.70198]
Predicted label: 9
Correct prediction
Energy consumption = 196.024771 pJ
sum error= 264
Actual label: 2
Output voltages: [0.40952, 0.12896, 0.73892, 0.35795, 0.1378, 0.047202, 0.20711, 0.24524, 0.46949, 0.19329]
Predicted label: 2
Correct prediction
Energy consumption = 189.306812 pJ
sum error= 264
Actual label: 1
Output voltages: [0.1251, 0.75855, 0.2361, 0.27612, 0.24077, 0.12735, 0.36738, 0.16276, 0.27199, 0.25125]
Predicted label: 1
Correct prediction
Energy consumption = 214.835893 pJ
sum error= 264
Actual label: 2
Output voltages: [0.46828, 0.087857, 0.64512, 0.48571, 0.11289, 0.05963, 0.19272, 0.22065, 0.47345, 0.21617]
Predicted label: 2
Correct prediction
Energy consumption = 199.405325 pJ
sum error= 264
Actual label: 1
Output voltages: [0.13436, 0.73033, 0.17629, 0.32457, 0.27806, 0.18172, 0.26998, 0.13732, 0.30579, 0.28141]
Predicted label: 1
Correct prediction
Energy consumption = 213.251802 pJ
sum error= 264
Actual label: 3
Output voltages: [0.25264, 0.11175, 0.3247, 0.7255, 0.25033, 0.24148, 0.12374, 0.18871, 0.51518, 0.20958]
Predicted label: 3
Correct prediction
Energy consumption = 182.622446 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 764 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 764 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 764 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37658, 0.17337, 0.25999, 0.23499, 0.34834, 0.14604, 0.15311, 0.19508, 0.29157, 0.70759]
Predicted label: 9
Correct prediction
Energy consumption = 207.399424 pJ
sum error= 264
Actual label: 9
Output voltages: [0.25607, 0.14869, 0.27852, 0.20637, 0.27613, 0.14849, 0.15973, 0.15654, 0.43935, 0.66261]
Predicted label: 9
Correct prediction
Energy consumption = 200.699791 pJ
sum error= 264
Actual label: 8
Output voltages: [0.18469, 0.26491, 0.27369, 0.27537, 0.17787, 0.21428, 0.30466, 0.14793, 0.74355, 0.26216]
Predicted label: 8
Correct prediction
Energy consumption = 197.570764 pJ
sum error= 264
Actual label: 5
Output voltages: [0.32136, 0.043514, 0.15113, 0.34862, 0.14784, 0.72521, 0.33668, 0.25692, 0.5309, 0.18679]
Predicted label: 5
Correct prediction
Energy consumption = 186.446593 pJ
sum error= 264
Actual label: 3
Output voltages: [0.33669, 0.097449, 0.24886, 0.74397, 0.20702, 0.35846, 0.13648, 0.23216, 0.41987, 0.24082]
Predicted label: 3
Correct prediction
Energy consumption = 183.052001 pJ
sum error= 264
Actual label: 7
Output voltages: [0.35281, 0.16765, 0.21131, 0.21609, 0.13828, 0.15173, 0.051672, 0.71083, 0.44958, 0.39987]
Predicted label: 7
Correct prediction
Energy consumption = 193.275328 pJ
sum error= 264
Actual label: 0
Output voltages: [0.71245, 0.25047, 0.32207, 0.20165, 0.25313, 0.1164, 0.35338, 0.16001, 0.33368, 0.19035]
Predicted label: 0
Correct prediction
Energy consumption = 205.149192 pJ
sum error= 264
Actual label: 7
Output voltages: [0.27739, 0.25526, 0.4406, 0.227, 0.12152, 0.050286, 0.037884, 0.75308, 0.40842, 0.31298]
Predicted label: 7
Correct prediction
Energy consumption = 190.789086 pJ
sum error= 264
Actual label: 7
Output voltages: [0.27651, 0.28182, 0.40592, 0.2476, 0.12243, 0.053048, 0.042422, 0.74996, 0.36297, 0.35834]
Predicted label: 7
Correct prediction
Energy consumption = 184.964115 pJ
sum error= 264
Actual label: 5
Output voltages: [0.25833, 0.051822, 0.094845, 0.32493, 0.23816, 0.73002, 0.29216, 0.20892, 0.52171, 0.27157]
Predicted label: 5
Correct prediction
Energy consumption = 187.975856 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 765 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 765 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 765 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25211, 0.3226, 0.23596, 0.25515, 0.12099, 0.068344, 0.048569, 0.73976, 0.3785, 0.36316]
Predicted label: 7
Correct prediction
Energy consumption = 206.204264 pJ
sum error= 264
Actual label: 9
Output voltages: [0.29078, 0.2176, 0.28252, 0.21057, 0.36009, 0.051668, 0.12437, 0.093453, 0.41795, 0.57099]
Predicted label: 9
Correct prediction
Energy consumption = 203.296907 pJ
sum error= 264
Actual label: 9
Output voltages: [0.30471, 0.14901, 0.2505, 0.19591, 0.35277, 0.14832, 0.19399, 0.17736, 0.35327, 0.68194]
Predicted label: 9
Correct prediction
Energy consumption = 188.922686 pJ
sum error= 264
Actual label: 4
Output voltages: [0.18856, 0.18144, 0.29251, 0.17825, 0.74897, 0.063935, 0.37409, 0.26139, 0.16925, 0.30305]
Predicted label: 4
Correct prediction
Energy consumption = 193.171089 pJ
sum error= 264
Actual label: 7
Output voltages: [0.27601, 0.26505, 0.27809, 0.26983, 0.11538, 0.095094, 0.041566, 0.75913, 0.36804, 0.34821]
Predicted label: 7
Correct prediction
Energy consumption = 193.964482 pJ
sum error= 264
Actual label: 0
Output voltages: [0.70838, 0.2513, 0.24329, 0.17489, 0.13709, 0.18954, 0.42471, 0.1474, 0.34817, 0.20238]
Predicted label: 0
Correct prediction
Energy consumption = 200.138683 pJ
sum error= 264
Actual label: 3
Output voltages: [0.23387, 0.24067, 0.30545, 0.74848, 0.23743, 0.14452, 0.20899, 0.31201, 0.40908, 0.18321]
Predicted label: 3
Correct prediction
Energy consumption = 200.085177 pJ
sum error= 264
Actual label: 4
Output voltages: [0.19149, 0.23405, 0.22779, 0.11163, 0.74797, 0.15132, 0.2815, 0.20701, 0.17472, 0.44996]
Predicted label: 4
Correct prediction
Energy consumption = 203.205977 pJ
sum error= 264
Actual label: 1
Output voltages: [0.21798, 0.76315, 0.21056, 0.29033, 0.12759, 0.14889, 0.38713, 0.09631, 0.39246, 0.20797]
Predicted label: 1
Correct prediction
Energy consumption = 215.126839 pJ
sum error= 264
Actual label: 5
Output voltages: [0.21717, 0.056027, 0.13256, 0.39263, 0.18974, 0.66878, 0.25369, 0.19415, 0.5746, 0.26037]
Predicted label: 5
Correct prediction
Energy consumption = 184.420647 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 766 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 766 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 766 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2329, 0.23039, 0.32405, 0.33462, 0.10099, 0.20414, 0.24039, 0.12563, 0.74174, 0.28539]
Predicted label: 8
Correct prediction
Energy consumption = 194.932143 pJ
sum error= 264
Actual label: 1
Output voltages: [0.15406, 0.75316, 0.15591, 0.2138, 0.26848, 0.29564, 0.5121, 0.14109, 0.28722, 0.18187]
Predicted label: 1
Correct prediction
Energy consumption = 213.755298 pJ
sum error= 264
Actual label: 4
Output voltages: [0.10162, 0.15665, 0.3264, 0.19809, 0.7454, 0.080769, 0.24552, 0.30655, 0.26154, 0.24941]
Predicted label: 4
Correct prediction
Energy consumption = 198.636250 pJ
sum error= 264
Actual label: 8
Output voltages: [0.1995, 0.26505, 0.32579, 0.2638, 0.15611, 0.19153, 0.19603, 0.18065, 0.7558, 0.26992]
Predicted label: 8
Correct prediction
Energy consumption = 191.547152 pJ
sum error= 264
Actual label: 4
Output voltages: [0.14852, 0.18587, 0.26085, 0.13199, 0.75837, 0.16679, 0.3219, 0.24858, 0.20871, 0.30808]
Predicted label: 4
Correct prediction
Energy consumption = 197.263738 pJ
sum error= 264
Actual label: 1
Output voltages: [0.15662, 0.75802, 0.18528, 0.29182, 0.28715, 0.069026, 0.32997, 0.11306, 0.30125, 0.34124]
Predicted label: 1
Correct prediction
Energy consumption = 210.806959 pJ
sum error= 264
Actual label: 8
Output voltages: [0.21319, 0.2104, 0.31713, 0.25048, 0.17721, 0.22619, 0.19103, 0.16221, 0.75426, 0.26835]
Predicted label: 8
Correct prediction
Energy consumption = 192.487486 pJ
sum error= 264
Actual label: 6
Output voltages: [0.29017, 0.2603, 0.35075, 0.064808, 0.31072, 0.25942, 0.74533, 0.063872, 0.37969, 0.17878]
Predicted label: 6
Correct prediction
Energy consumption = 185.718684 pJ
sum error= 264
Actual label: 6
Output voltages: [0.2305, 0.2257, 0.40206, 0.051845, 0.34166, 0.32317, 0.72569, 0.062954, 0.34426, 0.068814]
Predicted label: 6
Correct prediction
Energy consumption = 185.776436 pJ
sum error= 264
Actual label: 4
Output voltages: [0.16072, 0.14688, 0.30407, 0.16725, 0.75206, 0.091693, 0.2713, 0.24485, 0.19996, 0.31402]
Predicted label: 4
Correct prediction
Energy consumption = 197.085087 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 767 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 767 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 767 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30259, 0.25688, 0.27405, 0.12486, 0.33812, 0.42171, 0.74042, 0.11301, 0.40459, 0.087233]
Predicted label: 6
Correct prediction
Energy consumption = 193.161527 pJ
sum error= 264
Actual label: 0
Output voltages: [0.63016, 0.18415, 0.25476, 0.14678, 0.1906, 0.24249, 0.48537, 0.14693, 0.36167, 0.26144]
Predicted label: 0
Correct prediction
Energy consumption = 206.103492 pJ
sum error= 264
Actual label: 5
Output voltages: [0.26605, 0.059699, 0.15924, 0.38897, 0.10782, 0.64118, 0.24475, 0.25354, 0.58457, 0.24329]
Predicted label: 5
Correct prediction
Energy consumption = 190.163340 pJ
sum error= 264
Actual label: 5
Output voltages: [0.30201, 0.092376, 0.094699, 0.56033, 0.085139, 0.60208, 0.25365, 0.21907, 0.45508, 0.28005]
Predicted label: 5
Correct prediction
Energy consumption = 192.038137 pJ
sum error= 264
Actual label: 3
Output voltages: [0.29996, 0.17948, 0.31036, 0.76138, 0.18111, 0.19686, 0.16309, 0.20541, 0.43695, 0.27344]
Predicted label: 3
Correct prediction
Energy consumption = 177.806773 pJ
sum error= 264
Actual label: 3
Output voltages: [0.29086, 0.20595, 0.32213, 0.76094, 0.19952, 0.17583, 0.1542, 0.22086, 0.39407, 0.28209]
Predicted label: 3
Correct prediction
Energy consumption = 177.629517 pJ
sum error= 264
Actual label: 5
Output voltages: [0.16602, 0.053484, 0.12418, 0.46976, 0.19541, 0.6507, 0.28787, 0.19829, 0.49598, 0.28609]
Predicted label: 5
Correct prediction
Energy consumption = 189.426085 pJ
sum error= 264
Actual label: 7
Output voltages: [0.34644, 0.30818, 0.37815, 0.29308, 0.1005, 0.035268, 0.071439, 0.7016, 0.31965, 0.37139]
Predicted label: 7
Correct prediction
Energy consumption = 201.405244 pJ
sum error= 264
Actual label: 2
Output voltages: [0.43334, 0.21608, 0.74637, 0.31845, 0.17402, 0.036622, 0.25852, 0.25936, 0.39838, 0.16494]
Predicted label: 2
Correct prediction
Energy consumption = 185.394327 pJ
sum error= 264
Actual label: 5
Output voltages: [0.35382, 0.091257, 0.16635, 0.30414, 0.12086, 0.60272, 0.25647, 0.32049, 0.51886, 0.26488]
Predicted label: 5
Correct prediction
Energy consumption = 196.017134 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 768 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 768 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 768 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32859, 0.1538, 0.20913, 0.25048, 0.33999, 0.097327, 0.12611, 0.21125, 0.34364, 0.68628]
Predicted label: 9
Correct prediction
Energy consumption = 196.850232 pJ
sum error= 264
Actual label: 6
Output voltages: [0.30453, 0.23056, 0.28997, 0.1051, 0.31398, 0.36896, 0.74956, 0.088036, 0.41285, 0.15194]
Predicted label: 6
Correct prediction
Energy consumption = 186.981359 pJ
sum error= 264
Actual label: 9
Output voltages: [0.31614, 0.14479, 0.19091, 0.22878, 0.3269, 0.14468, 0.073513, 0.15081, 0.37891, 0.6944]
Predicted label: 9
Correct prediction
Energy consumption = 195.542968 pJ
sum error= 264
Actual label: 2
Output voltages: [0.49365, 0.13552, 0.62601, 0.50407, 0.088793, 0.052958, 0.17693, 0.21233, 0.47534, 0.20051]
Predicted label: 2
Correct prediction
Energy consumption = 195.586291 pJ
sum error= 264
Actual label: 6
Output voltages: [0.28319, 0.22125, 0.34089, 0.074635, 0.34498, 0.34566, 0.749, 0.076024, 0.37989, 0.11866]
Predicted label: 6
Correct prediction
Energy consumption = 185.716258 pJ
sum error= 264
Actual label: 2
Output voltages: [0.45709, 0.26908, 0.74434, 0.28394, 0.16252, 0.035164, 0.28412, 0.23565, 0.38877, 0.22484]
Predicted label: 2
Correct prediction
Energy consumption = 190.285154 pJ
sum error= 264
Actual label: 1
Output voltages: [0.22249, 0.76539, 0.27108, 0.22965, 0.26286, 0.17958, 0.34574, 0.12516, 0.34438, 0.28548]
Predicted label: 1
Correct prediction
Energy consumption = 211.454312 pJ
sum error= 264
Actual label: 2
Output voltages: [0.45862, 0.12794, 0.71061, 0.36484, 0.10012, 0.051307, 0.27201, 0.28498, 0.47038, 0.15123]
Predicted label: 2
Correct prediction
Energy consumption = 190.276260 pJ
sum error= 264
Actual label: 0
Output voltages: [0.72983, 0.19629, 0.23971, 0.13927, 0.20558, 0.24517, 0.43469, 0.16319, 0.27245, 0.26279]
Predicted label: 0
Correct prediction
Energy consumption = 193.164885 pJ
sum error= 264
Actual label: 8
Output voltages: [0.31967, 0.26338, 0.26013, 0.42361, 0.1114, 0.07987, 0.18455, 0.27633, 0.65538, 0.21913]
Predicted label: 8
Correct prediction
Energy consumption = 206.647995 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 769 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 769 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 769 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30415, 0.19529, 0.3323, 0.75795, 0.25238, 0.14896, 0.14763, 0.23845, 0.39077, 0.23849]
Predicted label: 3
Correct prediction
Energy consumption = 188.925734 pJ
sum error= 264
Actual label: 8
Output voltages: [0.11198, 0.32151, 0.2436, 0.28817, 0.27873, 0.23266, 0.25457, 0.1117, 0.68557, 0.275]
Predicted label: 8
Correct prediction
Energy consumption = 203.844541 pJ
sum error= 264
Actual label: 3
Output voltages: [0.31507, 0.18509, 0.28752, 0.76031, 0.24074, 0.21408, 0.20912, 0.17699, 0.46158, 0.23793]
Predicted label: 3
Correct prediction
Energy consumption = 192.578281 pJ
sum error= 264
Actual label: 0
Output voltages: [0.72087, 0.17735, 0.24456, 0.12478, 0.1844, 0.24946, 0.42602, 0.13789, 0.2656, 0.29168]
Predicted label: 0
Correct prediction
Energy consumption = 194.249809 pJ
sum error= 264
Actual label: 8
Output voltages: [0.20876, 0.14218, 0.31899, 0.26734, 0.11687, 0.34547, 0.30255, 0.069256, 0.71354, 0.29296]
Predicted label: 8
Correct prediction
Energy consumption = 196.839642 pJ
sum error= 264
Actual label: 7
Output voltages: [0.33558, 0.25655, 0.27427, 0.34566, 0.13594, 0.055806, 0.051162, 0.75345, 0.26615, 0.35511]
Predicted label: 7
Correct prediction
Energy consumption = 197.712548 pJ
sum error= 264
Actual label: 4
Output voltages: [0.1914, 0.13902, 0.33009, 0.11741, 0.75129, 0.091291, 0.28391, 0.2283, 0.24233, 0.31131]
Predicted label: 4
Correct prediction
Energy consumption = 198.567020 pJ
sum error= 264
Actual label: 9
Output voltages: [0.3385, 0.22734, 0.1847, 0.30313, 0.41476, 0.096171, 0.10094, 0.26522, 0.21359, 0.66956]
Predicted label: 9
Correct prediction
Energy consumption = 197.484818 pJ
sum error= 264
Actual label: 5
Output voltages: [0.29881, 0.069806, 0.06998, 0.43051, 0.12898, 0.6708, 0.19797, 0.2827, 0.45744, 0.31969]
Predicted label: 5
Correct prediction
Energy consumption = 193.731298 pJ
sum error= 264
Actual label: 0
Output voltages: [0.73997, 0.28141, 0.25244, 0.18318, 0.15438, 0.1767, 0.41337, 0.16928, 0.26648, 0.27202]
Predicted label: 0
Correct prediction
Energy consumption = 190.759291 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 770 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 770 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 770 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34354, 0.14949, 0.24226, 0.22758, 0.23251, 0.21801, 0.11202, 0.24473, 0.4424, 0.63455]
Predicted label: 9
Correct prediction
Energy consumption = 194.331180 pJ
sum error= 264
Actual label: 7
Output voltages: [0.44051, 0.14858, 0.34607, 0.27577, 0.12253, 0.063901, 0.045519, 0.74569, 0.39536, 0.29685]
Predicted label: 7
Correct prediction
Energy consumption = 191.606911 pJ
sum error= 264
Actual label: 0
Output voltages: [0.71367, 0.20445, 0.18848, 0.18003, 0.20637, 0.15655, 0.46283, 0.16767, 0.31737, 0.2691]
Predicted label: 0
Correct prediction
Energy consumption = 196.071965 pJ
sum error= 264
Actual label: 0
Output voltages: [0.72915, 0.22966, 0.26907, 0.22816, 0.17995, 0.13541, 0.40858, 0.16719, 0.3332, 0.29523]
Predicted label: 0
Correct prediction
Energy consumption = 193.032251 pJ
sum error= 264
Actual label: 4
Output voltages: [0.14981, 0.22781, 0.3061, 0.14149, 0.74412, 0.065971, 0.25355, 0.31421, 0.20554, 0.33482]
Predicted label: 4
Correct prediction
Energy consumption = 199.742481 pJ
sum error= 264
Actual label: 6
Output voltages: [0.33139, 0.25878, 0.2518, 0.15966, 0.33265, 0.35224, 0.7387, 0.051422, 0.35588, 0.23627]
Predicted label: 6
Correct prediction
Energy consumption = 190.572228 pJ
sum error= 264
Actual label: 0
Output voltages: [0.70662, 0.21288, 0.21703, 0.24986, 0.15611, 0.24246, 0.40943, 0.15209, 0.38719, 0.25304]
Predicted label: 0
Correct prediction
Energy consumption = 201.308319 pJ
sum error= 264
Actual label: 9
Output voltages: [0.3527, 0.13237, 0.21974, 0.24886, 0.28075, 0.14249, 0.068725, 0.26705, 0.36982, 0.65559]
Predicted label: 9
Correct prediction
Energy consumption = 190.116127 pJ
sum error= 264
Actual label: 1
Output voltages: [0.22936, 0.7551, 0.22069, 0.15806, 0.33636, 0.12208, 0.38831, 0.10716, 0.30231, 0.24595]
Predicted label: 1
Correct prediction
Energy consumption = 206.138827 pJ
sum error= 264
Actual label: 6
Output voltages: [0.28251, 0.2596, 0.35766, 0.10219, 0.23667, 0.24066, 0.73696, 0.072916, 0.41965, 0.1558]
Predicted label: 6
Correct prediction
Energy consumption = 183.574355 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 771 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 771 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 771 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.42132, 0.1615, 0.74111, 0.3099, 0.15467, 0.039551, 0.29514, 0.2696, 0.40412, 0.15542]
Predicted label: 2
Correct prediction
Energy consumption = 189.595857 pJ
sum error= 264
Actual label: 7
Output voltages: [0.38587, 0.19633, 0.094956, 0.30494, 0.13668, 0.29395, 0.064007, 0.75122, 0.2886, 0.31172]
Predicted label: 7
Correct prediction
Energy consumption = 198.421571 pJ
sum error= 264
Actual label: 6
Output voltages: [0.31438, 0.23162, 0.35909, 0.11266, 0.28676, 0.23212, 0.72581, 0.050716, 0.43085, 0.21014]
Predicted label: 6
Correct prediction
Energy consumption = 187.847475 pJ
sum error= 264
Actual label: 8
Output voltages: [0.32147, 0.1042, 0.22995, 0.30086, 0.12708, 0.4346, 0.26616, 0.059478, 0.70958, 0.21758]
Predicted label: 8
Correct prediction
Energy consumption = 200.287061 pJ
sum error= 264
Actual label: 3
Output voltages: [0.20902, 0.17326, 0.37246, 0.72258, 0.27008, 0.22277, 0.14296, 0.16842, 0.46059, 0.19213]
Predicted label: 3
Correct prediction
Energy consumption = 183.649861 pJ
sum error= 264
Actual label: 5
Output voltages: [0.23581, 0.052524, 0.11905, 0.39016, 0.18286, 0.71637, 0.22436, 0.25007, 0.48759, 0.30753]
Predicted label: 5
Correct prediction
Energy consumption = 187.410277 pJ
sum error= 264
Actual label: 2
Output voltages: [0.39618, 0.19098, 0.74205, 0.29971, 0.18072, 0.033611, 0.27126, 0.24114, 0.39782, 0.19801]
Predicted label: 2
Correct prediction
Energy consumption = 188.705494 pJ
sum error= 264
Actual label: 1
Output voltages: [0.20124, 0.75931, 0.16929, 0.26699, 0.18888, 0.24469, 0.49532, 0.11419, 0.31113, 0.17821]
Predicted label: 1
Correct prediction
Energy consumption = 210.759708 pJ
sum error= 264
Actual label: 8
Output voltages: [0.33883, 0.16068, 0.26881, 0.24654, 0.16679, 0.2045, 0.23993, 0.086245, 0.72416, 0.27916]
Predicted label: 8
Correct prediction
Energy consumption = 195.977178 pJ
sum error= 264
Actual label: 3
Output voltages: [0.2666, 0.15043, 0.30669, 0.7521, 0.20945, 0.2215, 0.14388, 0.20061, 0.44557, 0.23242]
Predicted label: 3
Correct prediction
Energy consumption = 177.476216 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 772 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 772 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 772 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.3825, 0.172, 0.25424, 0.32993, 0.10515, 0.40085, 0.32395, 0.10164, 0.70574, 0.16863]
Predicted label: 8
Correct prediction
Energy consumption = 203.873387 pJ
sum error= 264
Actual label: 6
Output voltages: [0.30822, 0.25191, 0.28739, 0.091623, 0.36812, 0.40761, 0.74637, 0.06196, 0.33768, 0.18961]
Predicted label: 6
Correct prediction
Energy consumption = 189.389276 pJ
sum error= 264
Actual label: 1
Output voltages: [0.16883, 0.75991, 0.26548, 0.1969, 0.20219, 0.076957, 0.44656, 0.094718, 0.35865, 0.21092]
Predicted label: 1
Correct prediction
Energy consumption = 209.677681 pJ
sum error= 264
Actual label: 0
Output voltages: [0.74372, 0.24683, 0.23403, 0.16522, 0.18598, 0.19173, 0.38966, 0.14552, 0.30275, 0.2547]
Predicted label: 0
Correct prediction
Energy consumption = 193.678316 pJ
sum error= 264
Actual label: 2
Output voltages: [0.49149, 0.22046, 0.69714, 0.36798, 0.15592, 0.03657, 0.27651, 0.22401, 0.36709, 0.20407]
Predicted label: 2
Correct prediction
Energy consumption = 194.485937 pJ
sum error= 264
Actual label: 1
Output voltages: [0.22757, 0.76457, 0.21352, 0.2478, 0.29686, 0.089946, 0.26383, 0.1728, 0.31625, 0.31035]
Predicted label: 1
Correct prediction
Energy consumption = 206.923745 pJ
sum error= 264
Actual label: 4
Output voltages: [0.16107, 0.12758, 0.33051, 0.17084, 0.75945, 0.059547, 0.32192, 0.25415, 0.19983, 0.21031]
Predicted label: 4
Correct prediction
Energy consumption = 195.652611 pJ
sum error= 264
Actual label: 0
Output voltages: [0.71855, 0.23186, 0.24374, 0.15301, 0.19205, 0.20138, 0.45513, 0.19028, 0.28346, 0.16953]
Predicted label: 0
Correct prediction
Energy consumption = 193.657644 pJ
sum error= 264
Actual label: 1
Output voltages: [0.16577, 0.74087, 0.25533, 0.27169, 0.2374, 0.057459, 0.3346, 0.13865, 0.42978, 0.23593]
Predicted label: 1
Correct prediction
Energy consumption = 208.716415 pJ
sum error= 264
Actual label: 2
Output voltages: [0.35898, 0.22754, 0.69574, 0.32838, 0.18626, 0.037555, 0.27569, 0.18842, 0.47268, 0.25078]
Predicted label: 2
Correct prediction
Energy consumption = 183.546371 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 773 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 773 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 773 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.42363, 0.1687, 0.413, 0.72597, 0.11019, 0.1201, 0.11577, 0.13788, 0.40611, 0.21055]
Predicted label: 3
Correct prediction
Energy consumption = 200.679620 pJ
sum error= 264
Actual label: 4
Output voltages: [0.14137, 0.15628, 0.18247, 0.11124, 0.73411, 0.12444, 0.26549, 0.34053, 0.35118, 0.15871]
Predicted label: 4
Correct prediction
Energy consumption = 197.574385 pJ
sum error= 264
Actual label: 5
Output voltages: [0.22935, 0.076484, 0.17919, 0.30228, 0.11224, 0.57177, 0.27683, 0.08897, 0.63192, 0.18785]
Predicted label: 8
Wrong prediction!
Energy consumption = 194.382126 pJ
sum error= 265
Actual label: 6
Output voltages: [0.30785, 0.21814, 0.28429, 0.096826, 0.35595, 0.32245, 0.74076, 0.058384, 0.34385, 0.14971]
Predicted label: 6
Correct prediction
Energy consumption = 183.629823 pJ
sum error= 265
Actual label: 7
Output voltages: [0.2598, 0.24361, 0.28005, 0.26157, 0.10383, 0.085725, 0.039073, 0.72685, 0.41749, 0.29691]
Predicted label: 7
Correct prediction
Energy consumption = 205.219140 pJ
sum error= 265
Actual label: 8
Output voltages: [0.31473, 0.18751, 0.32894, 0.39742, 0.092102, 0.17936, 0.21052, 0.069944, 0.71869, 0.25666]
Predicted label: 8
Correct prediction
Energy consumption = 195.974898 pJ
sum error= 265
Actual label: 9
Output voltages: [0.34011, 0.19825, 0.38442, 0.21419, 0.31174, 0.049678, 0.053927, 0.31174, 0.44612, 0.46537]
Predicted label: 9
Correct prediction
Energy consumption = 202.193410 pJ
sum error= 265
Actual label: 0
Output voltages: [0.73252, 0.24733, 0.25463, 0.21006, 0.18172, 0.14628, 0.41596, 0.18392, 0.31222, 0.21567]
Predicted label: 0
Correct prediction
Energy consumption = 192.102755 pJ
sum error= 265
Actual label: 1
Output voltages: [0.23752, 0.69561, 0.20085, 0.24888, 0.34261, 0.047117, 0.28636, 0.06789, 0.37115, 0.28369]
Predicted label: 1
Correct prediction
Energy consumption = 206.286108 pJ
sum error= 265
Actual label: 2
Output voltages: [0.36563, 0.12739, 0.70501, 0.45247, 0.12655, 0.052838, 0.17354, 0.256, 0.41567, 0.16039]
Predicted label: 2
Correct prediction
Energy consumption = 188.055547 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 774 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 774 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 774 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.38904, 0.1936, 0.27571, 0.75991, 0.16673, 0.15266, 0.12922, 0.19451, 0.43825, 0.20068]
Predicted label: 3
Correct prediction
Energy consumption = 184.616805 pJ
sum error= 265
Actual label: 4
Output voltages: [0.20494, 0.15173, 0.27835, 0.13559, 0.74667, 0.08564, 0.25903, 0.25511, 0.26053, 0.22114]
Predicted label: 4
Correct prediction
Energy consumption = 188.987555 pJ
sum error= 265
Actual label: 5
Output voltages: [0.25708, 0.036886, 0.13593, 0.333, 0.23529, 0.6791, 0.36069, 0.14399, 0.5541, 0.15787]
Predicted label: 5
Correct prediction
Energy consumption = 192.188406 pJ
sum error= 265
Actual label: 6
Output voltages: [0.24853, 0.18201, 0.34098, 0.082448, 0.39843, 0.34157, 0.73377, 0.054851, 0.34146, 0.10578]
Predicted label: 6
Correct prediction
Energy consumption = 190.707456 pJ
sum error= 265
Actual label: 7
Output voltages: [0.37215, 0.26939, 0.38018, 0.26748, 0.15865, 0.036501, 0.056167, 0.74633, 0.28944, 0.23211]
Predicted label: 7
Correct prediction
Energy consumption = 199.750955 pJ
sum error= 265
Actual label: 8
Output voltages: [0.23907, 0.18771, 0.33518, 0.28917, 0.19181, 0.18649, 0.23991, 0.084411, 0.74099, 0.29872]
Predicted label: 8
Correct prediction
Energy consumption = 190.922602 pJ
sum error= 265
Actual label: 9
Output voltages: [0.38221, 0.066992, 0.26936, 0.27716, 0.28814, 0.066317, 0.059687, 0.21705, 0.46217, 0.52181]
Predicted label: 9
Correct prediction
Energy consumption = 195.395287 pJ
sum error= 265
Actual label: 0
Output voltages: [0.70809, 0.14185, 0.31152, 0.15597, 0.1711, 0.16578, 0.42315, 0.16598, 0.26948, 0.35626]
Predicted label: 0
Correct prediction
Energy consumption = 186.731936 pJ
sum error= 265
Actual label: 1
Output voltages: [0.20902, 0.70253, 0.20741, 0.28164, 0.30786, 0.050235, 0.25172, 0.10256, 0.38057, 0.31454]
Predicted label: 1
Correct prediction
Energy consumption = 207.124313 pJ
sum error= 265
Actual label: 2
Output voltages: [0.32351, 0.11703, 0.67617, 0.41118, 0.18403, 0.04472, 0.17134, 0.21567, 0.53742, 0.21959]
Predicted label: 2
Correct prediction
Energy consumption = 188.334013 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 775 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 775 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 775 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.38583, 0.17307, 0.29948, 0.74994, 0.11448, 0.23722, 0.079643, 0.25657, 0.39544, 0.22746]
Predicted label: 3
Correct prediction
Energy consumption = 187.417457 pJ
sum error= 265
Actual label: 4
Output voltages: [0.17127, 0.15496, 0.24608, 0.11293, 0.74683, 0.17702, 0.32053, 0.25161, 0.296, 0.16189]
Predicted label: 4
Correct prediction
Energy consumption = 188.454043 pJ
sum error= 265
Actual label: 5
Output voltages: [0.30075, 0.053313, 0.10645, 0.40179, 0.11651, 0.66245, 0.29805, 0.17887, 0.51395, 0.16844]
Predicted label: 5
Correct prediction
Energy consumption = 191.810164 pJ
sum error= 265
Actual label: 6
Output voltages: [0.30848, 0.201, 0.25884, 0.1808, 0.31386, 0.38781, 0.7391, 0.052865, 0.41028, 0.19522]
Predicted label: 6
Correct prediction
Energy consumption = 183.953340 pJ
sum error= 265
Actual label: 7
Output voltages: [0.31973, 0.28324, 0.26747, 0.27603, 0.19826, 0.12843, 0.0457, 0.74136, 0.24799, 0.40372]
Predicted label: 7
Correct prediction
Energy consumption = 198.200911 pJ
sum error= 265
Actual label: 8
Output voltages: [0.2425, 0.22828, 0.41145, 0.28539, 0.16508, 0.092834, 0.25967, 0.11627, 0.72273, 0.23737]
Predicted label: 8
Correct prediction
Energy consumption = 192.873969 pJ
sum error= 265
Actual label: 9
Output voltages: [0.33303, 0.13454, 0.2023, 0.17778, 0.28317, 0.094354, 0.062397, 0.22131, 0.50005, 0.58248]
Predicted label: 9
Correct prediction
Energy consumption = 201.565884 pJ
sum error= 265
Actual label: 7
Output voltages: [0.27957, 0.37664, 0.36271, 0.3224, 0.13674, 0.04589, 0.041361, 0.68259, 0.2941, 0.2858]
Predicted label: 7
Correct prediction
Energy consumption = 202.066104 pJ
sum error= 265
Actual label: 6
Output voltages: [0.30557, 0.24387, 0.2954, 0.11195, 0.32252, 0.32271, 0.74509, 0.06412, 0.34319, 0.19109]
Predicted label: 6
Correct prediction
Energy consumption = 192.897230 pJ
sum error= 265
Actual label: 4
Output voltages: [0.09304, 0.13401, 0.17235, 0.16461, 0.73949, 0.11131, 0.30455, 0.28994, 0.29773, 0.1658]
Predicted label: 4
Correct prediction
Energy consumption = 192.594881 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 776 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 776 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 776 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3178, 0.22698, 0.16754, 0.33815, 0.15151, 0.15267, 0.034181, 0.74629, 0.36396, 0.37741]
Predicted label: 7
Correct prediction
Energy consumption = 199.991782 pJ
sum error= 265
Actual label: 6
Output voltages: [0.30555, 0.22037, 0.3118, 0.075825, 0.3413, 0.31671, 0.74273, 0.062516, 0.39323, 0.12564]
Predicted label: 6
Correct prediction
Energy consumption = 186.323832 pJ
sum error= 265
Actual label: 2
Output voltages: [0.32243, 0.20621, 0.74201, 0.30846, 0.19729, 0.038513, 0.20889, 0.22311, 0.44077, 0.2096]
Predicted label: 2
Correct prediction
Energy consumption = 185.370721 pJ
sum error= 265
Actual label: 3
Output voltages: [0.40166, 0.23503, 0.22598, 0.76485, 0.13708, 0.18105, 0.096707, 0.2481, 0.36382, 0.25396]
Predicted label: 3
Correct prediction
Energy consumption = 183.972149 pJ
sum error= 265
Actual label: 4
Output voltages: [0.2338, 0.14336, 0.22576, 0.1655, 0.74154, 0.064128, 0.23348, 0.26542, 0.24631, 0.21407]
Predicted label: 4
Correct prediction
Energy consumption = 192.885981 pJ
sum error= 265
Actual label: 8
Output voltages: [0.18285, 0.19069, 0.25809, 0.28134, 0.17403, 0.18914, 0.19227, 0.12608, 0.74377, 0.30126]
Predicted label: 8
Correct prediction
Energy consumption = 194.392043 pJ
sum error= 265
Actual label: 7
Output voltages: [0.38217, 0.18389, 0.15469, 0.23617, 0.19002, 0.17821, 0.045062, 0.75159, 0.3507, 0.31259]
Predicted label: 7
Correct prediction
Energy consumption = 194.105432 pJ
sum error= 265
Actual label: 8
Output voltages: [0.19981, 0.16599, 0.28113, 0.31023, 0.19056, 0.25782, 0.24008, 0.12962, 0.74965, 0.23091]
Predicted label: 8
Correct prediction
Energy consumption = 189.918570 pJ
sum error= 265
Actual label: 6
Output voltages: [0.28062, 0.27129, 0.27962, 0.18336, 0.30484, 0.42455, 0.74351, 0.081144, 0.34726, 0.074927]
Predicted label: 6
Correct prediction
Energy consumption = 193.029367 pJ
sum error= 265
Actual label: 9
Output voltages: [0.32292, 0.13427, 0.22303, 0.19248, 0.23185, 0.14328, 0.068358, 0.23158, 0.49039, 0.62993]
Predicted label: 9
Correct prediction
Energy consumption = 189.799799 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 777 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 777 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 777 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.25403, 0.22816, 0.35004, 0.38899, 0.14065, 0.1271, 0.24796, 0.090882, 0.70483, 0.29152]
Predicted label: 8
Correct prediction
Energy consumption = 195.476447 pJ
sum error= 265
Actual label: 3
Output voltages: [0.43708, 0.1391, 0.29686, 0.75342, 0.13446, 0.18124, 0.089826, 0.2017, 0.39996, 0.19838]
Predicted label: 3
Correct prediction
Energy consumption = 190.512688 pJ
sum error= 265
Actual label: 2
Output voltages: [0.37151, 0.17678, 0.73776, 0.37164, 0.14806, 0.042878, 0.21642, 0.26879, 0.42663, 0.13734]
Predicted label: 2
Correct prediction
Energy consumption = 181.523565 pJ
sum error= 265
Actual label: 2
Output voltages: [0.34461, 0.23029, 0.73488, 0.33706, 0.18784, 0.032732, 0.23291, 0.26961, 0.42616, 0.17599]
Predicted label: 2
Correct prediction
Energy consumption = 183.996050 pJ
sum error= 265
Actual label: 8
Output voltages: [0.15511, 0.18918, 0.28593, 0.23484, 0.25718, 0.17179, 0.22357, 0.16759, 0.73942, 0.25258]
Predicted label: 8
Correct prediction
Energy consumption = 188.601727 pJ
sum error= 265
Actual label: 4
Output voltages: [0.16497, 0.1661, 0.26397, 0.14851, 0.74577, 0.057935, 0.2705, 0.33578, 0.21044, 0.20344]
Predicted label: 4
Correct prediction
Energy consumption = 189.221350 pJ
sum error= 265
Actual label: 8
Output voltages: [0.22715, 0.14093, 0.27183, 0.31606, 0.17012, 0.29265, 0.21702, 0.14045, 0.7527, 0.18427]
Predicted label: 8
Correct prediction
Energy consumption = 193.175486 pJ
sum error= 265
Actual label: 5
Output voltages: [0.27941, 0.053901, 0.090331, 0.40764, 0.20432, 0.72065, 0.36456, 0.19093, 0.46604, 0.18729]
Predicted label: 5
Correct prediction
Energy consumption = 187.501532 pJ
sum error= 265
Actual label: 6
Output voltages: [0.28633, 0.18647, 0.30121, 0.071203, 0.37013, 0.39022, 0.74178, 0.06277, 0.36489, 0.13973]
Predicted label: 6
Correct prediction
Energy consumption = 186.702983 pJ
sum error= 265
Actual label: 5
Output voltages: [0.29724, 0.054928, 0.19637, 0.32217, 0.14375, 0.65246, 0.41496, 0.12963, 0.52127, 0.13886]
Predicted label: 5
Correct prediction
Energy consumption = 183.052806 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 778 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 778 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 778 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73754, 0.20498, 0.23295, 0.17492, 0.15523, 0.2079, 0.40317, 0.23971, 0.31325, 0.19156]
Predicted label: 0
Correct prediction
Energy consumption = 197.079015 pJ
sum error= 265
Actual label: 2
Output voltages: [0.35431, 0.13023, 0.72819, 0.43469, 0.18775, 0.057883, 0.23063, 0.26181, 0.4147, 0.21598]
Predicted label: 2
Correct prediction
Energy consumption = 193.457269 pJ
sum error= 265
Actual label: 0
Output voltages: [0.71663, 0.21857, 0.20943, 0.18383, 0.16448, 0.17124, 0.40721, 0.22011, 0.32631, 0.26885]
Predicted label: 0
Correct prediction
Energy consumption = 188.693364 pJ
sum error= 265
Actual label: 1
Output voltages: [0.27373, 0.66761, 0.28718, 0.35504, 0.16137, 0.063089, 0.29366, 0.1196, 0.46107, 0.26852]
Predicted label: 1
Correct prediction
Energy consumption = 208.011958 pJ
sum error= 265
Actual label: 1
Output voltages: [0.27974, 0.74819, 0.25401, 0.22317, 0.31162, 0.060343, 0.27738, 0.12894, 0.31632, 0.29029]
Predicted label: 1
Correct prediction
Energy consumption = 201.661349 pJ
sum error= 265
Actual label: 2
Output voltages: [0.36351, 0.17572, 0.73466, 0.32193, 0.19449, 0.035721, 0.23161, 0.30763, 0.43727, 0.17993]
Predicted label: 2
Correct prediction
Energy consumption = 187.781188 pJ
sum error= 265
Actual label: 9
Output voltages: [0.31434, 0.099096, 0.20014, 0.26904, 0.21378, 0.18124, 0.0679, 0.3291, 0.43511, 0.62606]
Predicted label: 9
Correct prediction
Energy consumption = 191.927982 pJ
sum error= 265
Actual label: 6
Output voltages: [0.29509, 0.20081, 0.32231, 0.094066, 0.37893, 0.31989, 0.74683, 0.053315, 0.36222, 0.16718]
Predicted label: 6
Correct prediction
Energy consumption = 186.413843 pJ
sum error= 265
Actual label: 8
Output voltages: [0.2683, 0.21253, 0.43412, 0.23765, 0.25706, 0.086854, 0.28158, 0.093179, 0.66598, 0.26026]
Predicted label: 8
Correct prediction
Energy consumption = 204.276217 pJ
sum error= 265
Actual label: 2
Output voltages: [0.31302, 0.28691, 0.74966, 0.27381, 0.1603, 0.034594, 0.2234, 0.28859, 0.37473, 0.17155]
Predicted label: 2
Correct prediction
Energy consumption = 183.310706 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 779 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 779 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 779 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17254, 0.64047, 0.28385, 0.4183, 0.23722, 0.042457, 0.27243, 0.20692, 0.44369, 0.20927]
Predicted label: 1
Correct prediction
Energy consumption = 214.220310 pJ
sum error= 265
Actual label: 0
Output voltages: [0.65364, 0.17653, 0.26891, 0.13476, 0.2334, 0.11538, 0.45481, 0.17041, 0.23983, 0.33393]
Predicted label: 0
Correct prediction
Energy consumption = 191.498837 pJ
sum error= 265
Actual label: 6
Output voltages: [0.31244, 0.20889, 0.31915, 0.07081, 0.34985, 0.35037, 0.7448, 0.067322, 0.39107, 0.15179]
Predicted label: 6
Correct prediction
Energy consumption = 180.570541 pJ
sum error= 265
Actual label: 5
Output voltages: [0.22908, 0.077477, 0.08209, 0.35691, 0.1957, 0.69622, 0.29257, 0.13469, 0.55829, 0.19358]
Predicted label: 5
Correct prediction
Energy consumption = 188.577736 pJ
sum error= 265
Actual label: 2
Output voltages: [0.36354, 0.12564, 0.73412, 0.28672, 0.24895, 0.042585, 0.23545, 0.22878, 0.4603, 0.22093]
Predicted label: 2
Correct prediction
Energy consumption = 183.915631 pJ
sum error= 265
Actual label: 9
Output voltages: [0.3928, 0.12353, 0.17753, 0.33445, 0.3219, 0.21046, 0.14609, 0.25335, 0.31515, 0.65929]
Predicted label: 9
Correct prediction
Energy consumption = 196.260430 pJ
sum error= 265
Actual label: 7
Output voltages: [0.32164, 0.26277, 0.22975, 0.2723, 0.20228, 0.134, 0.038899, 0.74717, 0.31947, 0.38219]
Predicted label: 7
Correct prediction
Energy consumption = 192.819520 pJ
sum error= 265
Actual label: 5
Output voltages: [0.17975, 0.049544, 0.16586, 0.28697, 0.22717, 0.63255, 0.42619, 0.13675, 0.4812, 0.1525]
Predicted label: 5
Correct prediction
Energy consumption = 194.927233 pJ
sum error= 265
Actual label: 3
Output voltages: [0.38266, 0.072176, 0.33556, 0.72769, 0.15241, 0.27691, 0.095475, 0.16512, 0.44319, 0.18323]
Predicted label: 3
Correct prediction
Energy consumption = 186.421648 pJ
sum error= 265
Actual label: 9
Output voltages: [0.32322, 0.14954, 0.19531, 0.25121, 0.27032, 0.12207, 0.064264, 0.20583, 0.43352, 0.67068]
Predicted label: 9
Correct prediction
Energy consumption = 187.979759 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 780 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 780 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 780 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.49755, 0.14665, 0.4186, 0.73146, 0.13423, 0.16725, 0.22324, 0.15066, 0.41816, 0.13767]
Predicted label: 3
Correct prediction
Energy consumption = 192.809932 pJ
sum error= 265
Actual label: 7
Output voltages: [0.30173, 0.23635, 0.21937, 0.29374, 0.15675, 0.14534, 0.041054, 0.76346, 0.26829, 0.32613]
Predicted label: 7
Correct prediction
Energy consumption = 199.273660 pJ
sum error= 265
Actual label: 1
Output voltages: [0.27043, 0.68231, 0.2128, 0.22046, 0.37079, 0.04824, 0.27452, 0.055446, 0.33741, 0.28123]
Predicted label: 1
Correct prediction
Energy consumption = 207.480828 pJ
sum error= 265
Actual label: 8
Output voltages: [0.3038, 0.14202, 0.34938, 0.35322, 0.14527, 0.19586, 0.21332, 0.087454, 0.73902, 0.2624]
Predicted label: 8
Correct prediction
Energy consumption = 189.155892 pJ
sum error= 265
Actual label: 3
Output voltages: [0.44662, 0.084554, 0.38375, 0.72683, 0.11352, 0.14756, 0.13282, 0.19794, 0.46547, 0.21475]
Predicted label: 3
Correct prediction
Energy consumption = 190.892205 pJ
sum error= 265
Actual label: 8
Output voltages: [0.21853, 0.16182, 0.28439, 0.25752, 0.18752, 0.26185, 0.28667, 0.12645, 0.74543, 0.23535]
Predicted label: 8
Correct prediction
Energy consumption = 185.549781 pJ
sum error= 265
Actual label: 1
Output voltages: [0.21732, 0.71699, 0.2194, 0.16371, 0.3346, 0.057404, 0.31871, 0.086634, 0.37883, 0.26231]
Predicted label: 1
Correct prediction
Energy consumption = 202.410968 pJ
sum error= 265
Actual label: 9
Output voltages: [0.35617, 0.1206, 0.24307, 0.29092, 0.19645, 0.13084, 0.07603, 0.25074, 0.47157, 0.60267]
Predicted label: 9
Correct prediction
Energy consumption = 193.893277 pJ
sum error= 265
Actual label: 5
Output voltages: [0.19189, 0.050745, 0.088999, 0.34915, 0.25113, 0.69857, 0.31217, 0.14406, 0.46065, 0.22915]
Predicted label: 5
Correct prediction
Energy consumption = 186.596203 pJ
sum error= 265
Actual label: 5
Output voltages: [0.25377, 0.043178, 0.1728, 0.29499, 0.17868, 0.63123, 0.35164, 0.10671, 0.5437, 0.20939]
Predicted label: 5
Correct prediction
Energy consumption = 183.311564 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 781 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 781 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 781 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69521, 0.19717, 0.28438, 0.12201, 0.2403, 0.15125, 0.48025, 0.20035, 0.30246, 0.18266]
Predicted label: 0
Correct prediction
Energy consumption = 193.160422 pJ
sum error= 265
Actual label: 1
Output voltages: [0.21654, 0.7259, 0.18749, 0.29372, 0.26116, 0.051429, 0.33239, 0.065394, 0.41362, 0.24319]
Predicted label: 1
Correct prediction
Energy consumption = 208.800429 pJ
sum error= 265
Actual label: 1
Output voltages: [0.24639, 0.5464, 0.20097, 0.34162, 0.24384, 0.069324, 0.25649, 0.097451, 0.54471, 0.2611]
Predicted label: 1
Correct prediction
Energy consumption = 206.544083 pJ
sum error= 265
Actual label: 9
Output voltages: [0.32523, 0.10151, 0.22157, 0.185, 0.26514, 0.14916, 0.072036, 0.23183, 0.52488, 0.61239]
Predicted label: 9
Correct prediction
Energy consumption = 191.420222 pJ
sum error= 265
Actual label: 8
Output voltages: [0.26638, 0.16081, 0.30618, 0.3191, 0.1412, 0.25075, 0.16924, 0.098259, 0.74466, 0.30076]
Predicted label: 8
Correct prediction
Energy consumption = 185.469197 pJ
sum error= 265
Actual label: 2
Output voltages: [0.35565, 0.12546, 0.72984, 0.34763, 0.16125, 0.049737, 0.23507, 0.24951, 0.45252, 0.16135]
Predicted label: 2
Correct prediction
Energy consumption = 190.177629 pJ
sum error= 265
Actual label: 6
Output voltages: [0.252, 0.2016, 0.30882, 0.093436, 0.3339, 0.38166, 0.73638, 0.068112, 0.45174, 0.11696]
Predicted label: 6
Correct prediction
Energy consumption = 190.361493 pJ
sum error= 265
Actual label: 0
Output voltages: [0.74217, 0.2155, 0.25969, 0.19313, 0.1372, 0.19077, 0.40947, 0.2243, 0.29135, 0.22426]
Predicted label: 0
Correct prediction
Energy consumption = 186.365218 pJ
sum error= 265
Actual label: 4
Output voltages: [0.12137, 0.18345, 0.17177, 0.062195, 0.72218, 0.18315, 0.40138, 0.28432, 0.34296, 0.20339]
Predicted label: 4
Correct prediction
Energy consumption = 196.922744 pJ
sum error= 265
Actual label: 5
Output voltages: [0.30344, 0.046176, 0.12205, 0.29454, 0.15725, 0.707, 0.29906, 0.17203, 0.61176, 0.10628]
Predicted label: 5
Correct prediction
Energy consumption = 188.195808 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 782 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 782 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 782 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.70796, 0.14219, 0.27403, 0.16938, 0.19924, 0.18257, 0.44462, 0.22522, 0.22834, 0.29432]
Predicted label: 0
Correct prediction
Energy consumption = 192.135741 pJ
sum error= 265
Actual label: 3
Output voltages: [0.41501, 0.10678, 0.46085, 0.73247, 0.1256, 0.15325, 0.17925, 0.1573, 0.44191, 0.15495]
Predicted label: 3
Correct prediction
Energy consumption = 186.076074 pJ
sum error= 265
Actual label: 1
Output voltages: [0.24769, 0.63962, 0.28163, 0.26349, 0.328, 0.142, 0.40394, 0.04087, 0.39891, 0.27264]
Predicted label: 1
Correct prediction
Energy consumption = 209.046785 pJ
sum error= 265
Actual label: 8
Output voltages: [0.27214, 0.095299, 0.34944, 0.39044, 0.14127, 0.1968, 0.27345, 0.12969, 0.70921, 0.23894]
Predicted label: 8
Correct prediction
Energy consumption = 193.650359 pJ
sum error= 265
Actual label: 6
Output voltages: [0.30885, 0.12729, 0.25757, 0.15738, 0.31208, 0.40631, 0.70342, 0.052425, 0.44099, 0.2184]
Predicted label: 6
Correct prediction
Energy consumption = 183.749744 pJ
sum error= 265
Actual label: 7
Output voltages: [0.34112, 0.31048, 0.40774, 0.31965, 0.068158, 0.037237, 0.070243, 0.67798, 0.39393, 0.22003]
Predicted label: 7
Correct prediction
Energy consumption = 200.187118 pJ
sum error= 265
Actual label: 5
Output voltages: [0.27293, 0.049435, 0.10244, 0.334, 0.23058, 0.69371, 0.34024, 0.15724, 0.5223, 0.096894]
Predicted label: 5
Correct prediction
Energy consumption = 187.966260 pJ
sum error= 265
Actual label: 9
Output voltages: [0.3236, 0.12573, 0.20201, 0.24897, 0.26355, 0.17793, 0.096627, 0.27945, 0.44126, 0.67147]
Predicted label: 9
Correct prediction
Energy consumption = 186.976258 pJ
sum error= 265
Actual label: 9
Output voltages: [0.36429, 0.14899, 0.215, 0.27306, 0.34757, 0.20017, 0.13034, 0.19817, 0.3144, 0.68532]
Predicted label: 9
Correct prediction
Energy consumption = 185.437010 pJ
sum error= 265
Actual label: 3
Output voltages: [0.38664, 0.19037, 0.37313, 0.75043, 0.12214, 0.11476, 0.14084, 0.21463, 0.42311, 0.20162]
Predicted label: 3
Correct prediction
Energy consumption = 183.532518 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 783 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 783 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 783 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.71636, 0.14974, 0.25954, 0.16682, 0.14429, 0.21163, 0.42184, 0.18526, 0.25133, 0.30227]
Predicted label: 0
Correct prediction
Energy consumption = 190.760685 pJ
sum error= 265
Actual label: 3
Output voltages: [0.44541, 0.11778, 0.36315, 0.74217, 0.094093, 0.18216, 0.10572, 0.19707, 0.41263, 0.18947]
Predicted label: 3
Correct prediction
Energy consumption = 191.168878 pJ
sum error= 265
Actual label: 1
Output voltages: [0.24128, 0.7448, 0.27747, 0.22427, 0.32809, 0.068984, 0.34324, 0.092485, 0.3077, 0.22719]
Predicted label: 1
Correct prediction
Energy consumption = 202.633704 pJ
sum error= 265
Actual label: 4
Output voltages: [0.10299, 0.13188, 0.21228, 0.18693, 0.75748, 0.075165, 0.2477, 0.33644, 0.27588, 0.15069]
Predicted label: 4
Correct prediction
Energy consumption = 186.879078 pJ
sum error= 265
Actual label: 4
Output voltages: [0.11262, 0.15154, 0.21716, 0.17444, 0.75162, 0.06343, 0.26679, 0.33479, 0.29911, 0.16995]
Predicted label: 4
Correct prediction
Energy consumption = 183.541935 pJ
sum error= 265
Actual label: 0
Output voltages: [0.72745, 0.19701, 0.24294, 0.20502, 0.16938, 0.21367, 0.42963, 0.22552, 0.31532, 0.1915]
Predicted label: 0
Correct prediction
Energy consumption = 197.507856 pJ
sum error= 265
Actual label: 4
Output voltages: [0.14023, 0.19157, 0.21815, 0.1085, 0.73622, 0.097672, 0.32763, 0.31872, 0.26614, 0.17558]
Predicted label: 4
Correct prediction
Energy consumption = 194.564845 pJ
sum error= 265
Actual label: 9
Output voltages: [0.33721, 0.1665, 0.20233, 0.21463, 0.24902, 0.10746, 0.052261, 0.23415, 0.47703, 0.60132]
Predicted label: 9
Correct prediction
Energy consumption = 194.346743 pJ
sum error= 265
Actual label: 0
Output voltages: [0.69961, 0.26616, 0.2756, 0.15937, 0.16183, 0.1089, 0.43011, 0.19934, 0.32936, 0.26699]
Predicted label: 0
Correct prediction
Energy consumption = 189.922062 pJ
sum error= 265
Actual label: 1
Output voltages: [0.31665, 0.50226, 0.25791, 0.28393, 0.28777, 0.048824, 0.37973, 0.043818, 0.46479, 0.28382]
Predicted label: 1
Correct prediction
Energy consumption = 207.696023 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 784 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 784 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 784 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33798, 0.18775, 0.74575, 0.27219, 0.23361, 0.046184, 0.24857, 0.27703, 0.37841, 0.13094]
Predicted label: 2
Correct prediction
Energy consumption = 191.632662 pJ
sum error= 265
Actual label: 3
Output voltages: [0.33671, 0.13944, 0.24089, 0.69243, 0.22344, 0.25794, 0.15821, 0.10899, 0.50769, 0.25631]
Predicted label: 3
Correct prediction
Energy consumption = 201.987879 pJ
sum error= 265
Actual label: 5
Output voltages: [0.32986, 0.056471, 0.11194, 0.30519, 0.24479, 0.46209, 0.44313, 0.10294, 0.57219, 0.073654]
Predicted label: 8
Wrong prediction!
Energy consumption = 192.184028 pJ
sum error= 266
Actual label: 6
Output voltages: [0.34094, 0.21839, 0.27697, 0.085742, 0.37465, 0.29711, 0.73769, 0.073118, 0.40568, 0.11257]
Predicted label: 6
Correct prediction
Energy consumption = 184.230272 pJ
sum error= 266
Actual label: 7
Output voltages: [0.38519, 0.253, 0.14282, 0.17218, 0.16275, 0.18473, 0.073401, 0.72218, 0.4149, 0.28334]
Predicted label: 7
Correct prediction
Energy consumption = 201.657173 pJ
sum error= 266
Actual label: 8
Output voltages: [0.35441, 0.16006, 0.34977, 0.24668, 0.14673, 0.16755, 0.28469, 0.15062, 0.71914, 0.19375]
Predicted label: 8
Correct prediction
Energy consumption = 193.816546 pJ
sum error= 266
Actual label: 0
Output voltages: [0.70011, 0.25946, 0.33776, 0.18413, 0.16165, 0.059863, 0.32712, 0.13912, 0.39849, 0.22554]
Predicted label: 0
Correct prediction
Energy consumption = 181.303457 pJ
sum error= 266
Actual label: 1
Output voltages: [0.30506, 0.47815, 0.29909, 0.29628, 0.46168, 0.073018, 0.34424, 0.049156, 0.38019, 0.22642]
Predicted label: 1
Correct prediction
Energy consumption = 197.114465 pJ
sum error= 266
Actual label: 2
Output voltages: [0.2893, 0.093567, 0.73885, 0.29979, 0.28209, 0.04693, 0.24904, 0.22447, 0.37451, 0.29076]
Predicted label: 2
Correct prediction
Energy consumption = 190.632991 pJ
sum error= 266
Actual label: 3
Output voltages: [0.31717, 0.067911, 0.44202, 0.43218, 0.42898, 0.15474, 0.27742, 0.056359, 0.3505, 0.34635]
Predicted label: 2
Wrong prediction!
Energy consumption = 192.171412 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 785 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 785 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 785 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.40042, 0.044086, 0.17353, 0.3038, 0.20966, 0.58966, 0.35734, 0.12985, 0.49783, 0.14884]
Predicted label: 5
Correct prediction
Energy consumption = 197.126157 pJ
sum error= 267
Actual label: 6
Output voltages: [0.31901, 0.18464, 0.35286, 0.11379, 0.31236, 0.2108, 0.70064, 0.048505, 0.40383, 0.14501]
Predicted label: 6
Correct prediction
Energy consumption = 189.896696 pJ
sum error= 267
Actual label: 7
Output voltages: [0.34533, 0.24384, 0.27061, 0.3101, 0.098734, 0.10604, 0.049265, 0.75061, 0.35659, 0.24459]
Predicted label: 7
Correct prediction
Energy consumption = 204.340792 pJ
sum error= 267
Actual label: 8
Output voltages: [0.42412, 0.28151, 0.41294, 0.20012, 0.17686, 0.093754, 0.38322, 0.093261, 0.58732, 0.23702]
Predicted label: 8
Correct prediction
Energy consumption = 192.190330 pJ
sum error= 267
Actual label: 9
Output voltages: [0.39986, 0.14211, 0.18757, 0.32195, 0.36658, 0.2036, 0.1716, 0.17446, 0.29405, 0.63354]
Predicted label: 9
Correct prediction
Energy consumption = 193.259515 pJ
sum error= 267
Actual label: 0
Output voltages: [0.74133, 0.24137, 0.27338, 0.15108, 0.17134, 0.11508, 0.31246, 0.1717, 0.34012, 0.28429]
Predicted label: 0
Correct prediction
Energy consumption = 188.438582 pJ
sum error= 267
Actual label: 1
Output voltages: [0.33835, 0.51438, 0.31207, 0.18329, 0.39455, 0.056942, 0.29177, 0.091192, 0.40811, 0.28482]
Predicted label: 1
Correct prediction
Energy consumption = 198.558602 pJ
sum error= 267
Actual label: 2
Output voltages: [0.26137, 0.13869, 0.69824, 0.40332, 0.25008, 0.0523, 0.21037, 0.1569, 0.49888, 0.2133]
Predicted label: 2
Correct prediction
Energy consumption = 185.722946 pJ
sum error= 267
Actual label: 3
Output voltages: [0.38664, 0.10574, 0.39851, 0.66023, 0.13495, 0.30895, 0.19046, 0.091701, 0.49555, 0.23166]
Predicted label: 3
Correct prediction
Energy consumption = 194.633236 pJ
sum error= 267
Actual label: 5
Output voltages: [0.34337, 0.092906, 0.093787, 0.37967, 0.20593, 0.64799, 0.42369, 0.11906, 0.42435, 0.15766]
Predicted label: 5
Correct prediction
Energy consumption = 187.099128 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 786 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 786 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 786 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.33984, 0.21025, 0.30975, 0.1224, 0.31114, 0.22561, 0.67638, 0.062076, 0.38178, 0.090244]
Predicted label: 6
Correct prediction
Energy consumption = 195.990506 pJ
sum error= 267
Actual label: 7
Output voltages: [0.37669, 0.2386, 0.20878, 0.22489, 0.18745, 0.10863, 0.042483, 0.73339, 0.34616, 0.19551]
Predicted label: 7
Correct prediction
Energy consumption = 202.880259 pJ
sum error= 267
Actual label: 8
Output voltages: [0.33648, 0.22211, 0.33248, 0.27396, 0.18571, 0.16327, 0.33245, 0.067861, 0.70089, 0.27396]
Predicted label: 8
Correct prediction
Energy consumption = 191.680350 pJ
sum error= 267
Actual label: 9
Output voltages: [0.27686, 0.17257, 0.14054, 0.2059, 0.27174, 0.17568, 0.0912, 0.20506, 0.47784, 0.61078]
Predicted label: 9
Correct prediction
Energy consumption = 192.673906 pJ
sum error= 267
Actual label: 9
Output voltages: [0.39232, 0.10967, 0.1838, 0.31734, 0.29965, 0.2202, 0.13129, 0.32095, 0.34048, 0.6324]
Predicted label: 9
Correct prediction
Energy consumption = 193.939056 pJ
sum error= 267
Actual label: 7
Output voltages: [0.31362, 0.23859, 0.22476, 0.26046, 0.14371, 0.095174, 0.040066, 0.67932, 0.47772, 0.31896]
Predicted label: 7
Correct prediction
Energy consumption = 200.337262 pJ
sum error= 267
Actual label: 0
Output voltages: [0.72682, 0.20944, 0.28945, 0.15776, 0.17684, 0.085265, 0.40202, 0.26295, 0.29769, 0.27138]
Predicted label: 0
Correct prediction
Energy consumption = 186.293372 pJ
sum error= 267
Actual label: 9
Output voltages: [0.36795, 0.10765, 0.22918, 0.29152, 0.33786, 0.15139, 0.12402, 0.24765, 0.37861, 0.63771]
Predicted label: 9
Correct prediction
Energy consumption = 190.285225 pJ
sum error= 267
Actual label: 0
Output voltages: [0.70301, 0.19535, 0.25004, 0.17712, 0.20156, 0.14217, 0.31032, 0.17754, 0.40712, 0.26358]
Predicted label: 0
Correct prediction
Energy consumption = 189.933051 pJ
sum error= 267
Actual label: 1
Output voltages: [0.2537, 0.61109, 0.26233, 0.26397, 0.30512, 0.047935, 0.2819, 0.058497, 0.42305, 0.31967]
Predicted label: 1
Correct prediction
Energy consumption = 197.286808 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 787 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 787 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 787 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27589, 0.036189, 0.14245, 0.3494, 0.3311, 0.65257, 0.22657, 0.19301, 0.34488, 0.28341]
Predicted label: 5
Correct prediction
Energy consumption = 190.082895 pJ
sum error= 267
Actual label: 8
Output voltages: [0.23273, 0.15428, 0.35561, 0.27354, 0.15923, 0.21412, 0.24506, 0.1335, 0.74564, 0.21462]
Predicted label: 8
Correct prediction
Energy consumption = 189.888461 pJ
sum error= 267
Actual label: 8
Output voltages: [0.31698, 0.1998, 0.26643, 0.27116, 0.1707, 0.2252, 0.28336, 0.09699, 0.73837, 0.19356]
Predicted label: 8
Correct prediction
Energy consumption = 187.826342 pJ
sum error= 267
Actual label: 0
Output voltages: [0.7184, 0.27245, 0.2529, 0.16884, 0.12756, 0.13065, 0.4077, 0.19687, 0.32333, 0.26677]
Predicted label: 0
Correct prediction
Energy consumption = 181.921735 pJ
sum error= 267
Actual label: 9
Output voltages: [0.39755, 0.1418, 0.16351, 0.24513, 0.28838, 0.19637, 0.24322, 0.11567, 0.40885, 0.61011]
Predicted label: 9
Correct prediction
Energy consumption = 189.935880 pJ
sum error= 267
Actual label: 3
Output voltages: [0.37062, 0.14149, 0.2799, 0.69018, 0.19713, 0.22907, 0.14425, 0.050362, 0.39987, 0.31083]
Predicted label: 3
Correct prediction
Energy consumption = 190.232741 pJ
sum error= 267
Actual label: 2
Output voltages: [0.31058, 0.10219, 0.664, 0.21951, 0.41683, 0.047145, 0.23665, 0.13687, 0.38474, 0.32312]
Predicted label: 2
Correct prediction
Energy consumption = 183.628348 pJ
sum error= 267
Actual label: 7
Output voltages: [0.32672, 0.2813, 0.38159, 0.15649, 0.23493, 0.052288, 0.033235, 0.66465, 0.34727, 0.29267]
Predicted label: 7
Correct prediction
Energy consumption = 204.454646 pJ
sum error= 267
Actual label: 8
Output voltages: [0.30989, 0.21188, 0.4156, 0.30286, 0.1232, 0.091131, 0.24117, 0.14061, 0.72423, 0.25032]
Predicted label: 8
Correct prediction
Energy consumption = 186.993251 pJ
sum error= 267
Actual label: 4
Output voltages: [0.1605, 0.21855, 0.24923, 0.11939, 0.75195, 0.095525, 0.27351, 0.35269, 0.24017, 0.18327]
Predicted label: 4
Correct prediction
Energy consumption = 185.054247 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 788 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 788 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 788 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27423, 0.17441, 0.36317, 0.052434, 0.40592, 0.29064, 0.74067, 0.087599, 0.34264, 0.083432]
Predicted label: 6
Correct prediction
Energy consumption = 189.314062 pJ
sum error= 267
Actual label: 1
Output voltages: [0.19828, 0.74549, 0.23344, 0.18848, 0.33028, 0.078959, 0.35817, 0.085848, 0.31989, 0.24568]
Predicted label: 1
Correct prediction
Energy consumption = 197.948942 pJ
sum error= 267
Actual label: 0
Output voltages: [0.74127, 0.25721, 0.28698, 0.17688, 0.16333, 0.10538, 0.35487, 0.17923, 0.30895, 0.27121]
Predicted label: 0
Correct prediction
Energy consumption = 188.513662 pJ
sum error= 267
Actual label: 4
Output voltages: [0.18687, 0.17754, 0.36781, 0.1892, 0.75218, 0.080087, 0.38839, 0.25635, 0.19105, 0.15177]
Predicted label: 4
Correct prediction
Energy consumption = 193.579651 pJ
sum error= 267
Actual label: 9
Output voltages: [0.33812, 0.10289, 0.21733, 0.27665, 0.33681, 0.1867, 0.10321, 0.25544, 0.38438, 0.64711]
Predicted label: 9
Correct prediction
Energy consumption = 187.475535 pJ
sum error= 267
Actual label: 4
Output voltages: [0.22351, 0.15399, 0.37928, 0.16464, 0.74373, 0.055987, 0.41664, 0.29449, 0.19443, 0.18928]
Predicted label: 4
Correct prediction
Energy consumption = 185.826247 pJ
sum error= 267
Actual label: 2
Output voltages: [0.28746, 0.099572, 0.66057, 0.28475, 0.45309, 0.043525, 0.25437, 0.14114, 0.38264, 0.36967]
Predicted label: 2
Correct prediction
Energy consumption = 189.239220 pJ
sum error= 267
Actual label: 0
Output voltages: [0.68968, 0.24563, 0.24059, 0.12961, 0.19233, 0.13583, 0.42664, 0.15335, 0.30906, 0.30774]
Predicted label: 0
Correct prediction
Energy consumption = 191.840810 pJ
sum error= 267
Actual label: 5
Output voltages: [0.20913, 0.064434, 0.076984, 0.36981, 0.42887, 0.64074, 0.33191, 0.11976, 0.32639, 0.263]
Predicted label: 5
Correct prediction
Energy consumption = 186.807737 pJ
sum error= 267
Actual label: 0
Output voltages: [0.71532, 0.22699, 0.2204, 0.15552, 0.23521, 0.1803, 0.45476, 0.18471, 0.27977, 0.24294]
Predicted label: 0
Correct prediction
Energy consumption = 188.751278 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 789 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 789 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 789 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23496, 0.73496, 0.21478, 0.24153, 0.2526, 0.06037, 0.25927, 0.13336, 0.38971, 0.2387]
Predicted label: 1
Correct prediction
Energy consumption = 206.578121 pJ
sum error= 267
Actual label: 6
Output voltages: [0.29955, 0.17828, 0.27849, 0.12812, 0.33418, 0.29444, 0.71423, 0.059179, 0.44915, 0.19314]
Predicted label: 6
Correct prediction
Energy consumption = 191.282457 pJ
sum error= 267
Actual label: 9
Output voltages: [0.33688, 0.13193, 0.18817, 0.23543, 0.29687, 0.12782, 0.09283, 0.19241, 0.41449, 0.67708]
Predicted label: 9
Correct prediction
Energy consumption = 194.934890 pJ
sum error= 267
Actual label: 3
Output voltages: [0.40302, 0.094974, 0.42211, 0.61721, 0.22765, 0.084099, 0.14303, 0.13042, 0.48654, 0.19649]
Predicted label: 3
Correct prediction
Energy consumption = 198.485874 pJ
sum error= 267
Actual label: 2
Output voltages: [0.34782, 0.076286, 0.73082, 0.28702, 0.25602, 0.043889, 0.20841, 0.29666, 0.46913, 0.23532]
Predicted label: 2
Correct prediction
Energy consumption = 179.586237 pJ
sum error= 267
Actual label: 9
Output voltages: [0.42412, 0.10524, 0.19892, 0.28814, 0.33816, 0.10825, 0.13246, 0.17345, 0.38118, 0.61013]
Predicted label: 9
Correct prediction
Energy consumption = 200.768443 pJ
sum error= 267
Actual label: 1
Output voltages: [0.29046, 0.6865, 0.18062, 0.29095, 0.36307, 0.054654, 0.33234, 0.058049, 0.35052, 0.29911]
Predicted label: 1
Correct prediction
Energy consumption = 206.624174 pJ
sum error= 267
Actual label: 6
Output voltages: [0.34389, 0.22097, 0.29389, 0.10506, 0.3177, 0.29622, 0.73424, 0.059011, 0.40679, 0.15819]
Predicted label: 6
Correct prediction
Energy consumption = 192.894956 pJ
sum error= 267
Actual label: 0
Output voltages: [0.63498, 0.16446, 0.24035, 0.14986, 0.17131, 0.22958, 0.48253, 0.16312, 0.31014, 0.24401]
Predicted label: 0
Correct prediction
Energy consumption = 188.850033 pJ
sum error= 267
Actual label: 1
Output voltages: [0.369, 0.52014, 0.23408, 0.22666, 0.35904, 0.056337, 0.32039, 0.12383, 0.36951, 0.23489]
Predicted label: 1
Correct prediction
Energy consumption = 206.156960 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 790 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 790 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 790 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.28418, 0.62181, 0.25566, 0.1567, 0.30956, 0.074928, 0.35478, 0.055361, 0.43209, 0.23458]
Predicted label: 1
Correct prediction
Energy consumption = 204.157306 pJ
sum error= 267
Actual label: 8
Output voltages: [0.32747, 0.21231, 0.28897, 0.21189, 0.22958, 0.16508, 0.33904, 0.083251, 0.69825, 0.2806]
Predicted label: 8
Correct prediction
Energy consumption = 192.920401 pJ
sum error= 267
Actual label: 7
Output voltages: [0.34026, 0.10753, 0.2473, 0.23264, 0.19727, 0.12719, 0.03985, 0.51579, 0.57693, 0.40796]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.874314 pJ
sum error= 268
Actual label: 7
Output voltages: [0.32022, 0.29119, 0.38119, 0.2591, 0.11117, 0.047275, 0.055078, 0.67023, 0.4767, 0.18186]
Predicted label: 7
Correct prediction
Energy consumption = 192.328055 pJ
sum error= 268
Actual label: 6
Output voltages: [0.3206, 0.22054, 0.28568, 0.1134, 0.36057, 0.23839, 0.73109, 0.048033, 0.38525, 0.18354]
Predicted label: 6
Correct prediction
Energy consumption = 192.290951 pJ
sum error= 268
Actual label: 3
Output voltages: [0.41907, 0.21727, 0.36095, 0.67971, 0.09206, 0.24229, 0.20484, 0.058836, 0.4164, 0.28938]
Predicted label: 3
Correct prediction
Energy consumption = 192.984513 pJ
sum error= 268
Actual label: 6
Output voltages: [0.34714, 0.18344, 0.30897, 0.1129, 0.44685, 0.26849, 0.72015, 0.064797, 0.27294, 0.16211]
Predicted label: 6
Correct prediction
Energy consumption = 193.990843 pJ
sum error= 268
Actual label: 0
Output voltages: [0.71405, 0.1993, 0.18574, 0.23276, 0.20667, 0.17812, 0.33977, 0.16019, 0.33209, 0.28366]
Predicted label: 0
Correct prediction
Energy consumption = 189.607252 pJ
sum error= 268
Actual label: 7
Output voltages: [0.31548, 0.22499, 0.22405, 0.15069, 0.24761, 0.1186, 0.038586, 0.72219, 0.39598, 0.35283]
Predicted label: 7
Correct prediction
Energy consumption = 199.169399 pJ
sum error= 268
Actual label: 2
Output voltages: [0.29417, 0.23821, 0.74234, 0.21314, 0.30632, 0.033469, 0.22236, 0.35797, 0.31012, 0.22622]
Predicted label: 2
Correct prediction
Energy consumption = 188.178128 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 791 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 791 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 791 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25185, 0.17447, 0.31934, 0.10093, 0.74594, 0.059039, 0.35999, 0.26937, 0.20399, 0.19771]
Predicted label: 4
Correct prediction
Energy consumption = 189.104477 pJ
sum error= 268
Actual label: 1
Output voltages: [0.31772, 0.61072, 0.2667, 0.17433, 0.3469, 0.055521, 0.29132, 0.12023, 0.34369, 0.24888]
Predicted label: 1
Correct prediction
Energy consumption = 199.019699 pJ
sum error= 268
Actual label: 7
Output voltages: [0.27989, 0.24873, 0.25252, 0.23508, 0.19129, 0.099338, 0.030748, 0.70015, 0.46885, 0.30576]
Predicted label: 7
Correct prediction
Energy consumption = 199.949851 pJ
sum error= 268
Actual label: 0
Output voltages: [0.7232, 0.24115, 0.31496, 0.16648, 0.20231, 0.055449, 0.38069, 0.17701, 0.35152, 0.27286]
Predicted label: 0
Correct prediction
Energy consumption = 190.521794 pJ
sum error= 268
Actual label: 6
Output voltages: [0.29243, 0.19681, 0.30542, 0.097808, 0.33677, 0.30062, 0.73657, 0.057646, 0.42416, 0.13968]
Predicted label: 6
Correct prediction
Energy consumption = 185.737992 pJ
sum error= 268
Actual label: 7
Output voltages: [0.30571, 0.28352, 0.17738, 0.12125, 0.2528, 0.13397, 0.038903, 0.51037, 0.60728, 0.32743]
Predicted label: 8
Wrong prediction!
Energy consumption = 198.908266 pJ
sum error= 269
Actual label: 1
Output voltages: [0.24829, 0.6299, 0.26995, 0.32421, 0.31746, 0.088986, 0.34603, 0.048121, 0.42391, 0.28349]
Predicted label: 1
Correct prediction
Energy consumption = 194.912364 pJ
sum error= 269
Actual label: 2
Output voltages: [0.34577, 0.11391, 0.71854, 0.22264, 0.37852, 0.040298, 0.27618, 0.13911, 0.40053, 0.31187]
Predicted label: 2
Correct prediction
Energy consumption = 186.790754 pJ
sum error= 269
Actual label: 5
Output voltages: [0.33206, 0.15279, 0.13705, 0.29712, 0.23174, 0.53867, 0.4998, 0.054313, 0.43868, 0.083276]
Predicted label: 5
Correct prediction
Energy consumption = 190.332696 pJ
sum error= 269
Actual label: 8
Output voltages: [0.32529, 0.16416, 0.37231, 0.18842, 0.21419, 0.12981, 0.25857, 0.10965, 0.71189, 0.28658]
Predicted label: 8
Correct prediction
Energy consumption = 184.178231 pJ
sum error= 269
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 792 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 792 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 792 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.29021, 0.60058, 0.29677, 0.26204, 0.29045, 0.059414, 0.27123, 0.052182, 0.45688, 0.34955]
Predicted label: 1
Correct prediction
Energy consumption = 203.428365 pJ
sum error= 269
Actual label: 8
Output voltages: [0.32114, 0.12795, 0.34644, 0.38278, 0.081631, 0.32978, 0.27952, 0.1288, 0.73238, 0.20173]
Predicted label: 8
Correct prediction
Energy consumption = 184.430441 pJ
sum error= 269
Actual label: 2
Output voltages: [0.38112, 0.15717, 0.71448, 0.25623, 0.34626, 0.036979, 0.23979, 0.25386, 0.34298, 0.24043]
Predicted label: 2
Correct prediction
Energy consumption = 188.222562 pJ
sum error= 269
Actual label: 8
Output voltages: [0.33101, 0.19147, 0.33701, 0.22236, 0.17644, 0.18774, 0.28832, 0.097114, 0.73783, 0.27041]
Predicted label: 8
Correct prediction
Energy consumption = 187.708781 pJ
sum error= 269
Actual label: 7
Output voltages: [0.36803, 0.21539, 0.14922, 0.28631, 0.16525, 0.15783, 0.03481, 0.62458, 0.46291, 0.3441]
Predicted label: 7
Correct prediction
Energy consumption = 199.223170 pJ
sum error= 269
Actual label: 6
Output voltages: [0.32944, 0.22821, 0.29645, 0.10934, 0.41503, 0.24568, 0.70181, 0.050503, 0.37254, 0.11717]
Predicted label: 6
Correct prediction
Energy consumption = 191.680298 pJ
sum error= 269
Actual label: 8
Output voltages: [0.30467, 0.21851, 0.39474, 0.217, 0.16659, 0.1399, 0.27808, 0.1027, 0.73604, 0.25761]
Predicted label: 8
Correct prediction
Energy consumption = 189.031946 pJ
sum error= 269
Actual label: 7
Output voltages: [0.33258, 0.21905, 0.2714, 0.23396, 0.2365, 0.079283, 0.03803, 0.60462, 0.38176, 0.42988]
Predicted label: 7
Correct prediction
Energy consumption = 200.080210 pJ
sum error= 269
Actual label: 1
Output voltages: [0.30168, 0.41915, 0.22306, 0.22989, 0.31017, 0.11789, 0.34118, 0.063299, 0.52757, 0.22991]
Predicted label: 8
Wrong prediction!
Energy consumption = 199.892501 pJ
sum error= 270
Actual label: 6
Output voltages: [0.28573, 0.20139, 0.32064, 0.080727, 0.33487, 0.28058, 0.71851, 0.062599, 0.38223, 0.087806]
Predicted label: 6
Correct prediction
Energy consumption = 194.646092 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 793 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 793 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 793 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32489, 0.15287, 0.74577, 0.26275, 0.29385, 0.042087, 0.22061, 0.2074, 0.45884, 0.24747]
Predicted label: 2
Correct prediction
Energy consumption = 186.818966 pJ
sum error= 270
Actual label: 9
Output voltages: [0.37954, 0.12058, 0.23598, 0.27576, 0.23598, 0.11073, 0.07231, 0.21109, 0.46162, 0.59679]
Predicted label: 9
Correct prediction
Energy consumption = 191.727172 pJ
sum error= 270
Actual label: 3
Output voltages: [0.39287, 0.072203, 0.42107, 0.71809, 0.21591, 0.16004, 0.097181, 0.15311, 0.48706, 0.16771]
Predicted label: 3
Correct prediction
Energy consumption = 187.198666 pJ
sum error= 270
Actual label: 0
Output voltages: [0.70064, 0.26994, 0.34281, 0.1802, 0.1172, 0.068803, 0.37044, 0.23503, 0.31374, 0.26863]
Predicted label: 0
Correct prediction
Energy consumption = 186.580187 pJ
sum error= 270
Actual label: 1
Output voltages: [0.19476, 0.72092, 0.17633, 0.24797, 0.21972, 0.09075, 0.38088, 0.052472, 0.44191, 0.27908]
Predicted label: 1
Correct prediction
Energy consumption = 204.931185 pJ
sum error= 270
Actual label: 2
Output voltages: [0.35088, 0.18973, 0.73154, 0.36332, 0.19074, 0.035518, 0.23826, 0.36328, 0.39822, 0.18896]
Predicted label: 2
Correct prediction
Energy consumption = 187.110182 pJ
sum error= 270
Actual label: 3
Output voltages: [0.33567, 0.18883, 0.29123, 0.75381, 0.18122, 0.11775, 0.15659, 0.16601, 0.43651, 0.24622]
Predicted label: 3
Correct prediction
Energy consumption = 180.287273 pJ
sum error= 270
Actual label: 4
Output voltages: [0.20549, 0.13493, 0.23315, 0.12959, 0.74829, 0.068733, 0.33069, 0.25481, 0.29511, 0.14259]
Predicted label: 4
Correct prediction
Energy consumption = 192.313837 pJ
sum error= 270
Actual label: 5
Output voltages: [0.30648, 0.043797, 0.09522, 0.34347, 0.27096, 0.69054, 0.39542, 0.11387, 0.53887, 0.21279]
Predicted label: 5
Correct prediction
Energy consumption = 187.903531 pJ
sum error= 270
Actual label: 6
Output voltages: [0.30255, 0.15343, 0.29681, 0.11615, 0.36777, 0.37857, 0.72327, 0.057125, 0.33955, 0.12748]
Predicted label: 6
Correct prediction
Energy consumption = 183.450081 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 794 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 794 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 794 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.38083, 0.16589, 0.30134, 0.30735, 0.13835, 0.072207, 0.04317, 0.75206, 0.34897, 0.29809]
Predicted label: 7
Correct prediction
Energy consumption = 203.118667 pJ
sum error= 270
Actual label: 8
Output voltages: [0.30498, 0.23615, 0.36764, 0.23725, 0.22278, 0.089399, 0.28194, 0.084066, 0.71601, 0.30396]
Predicted label: 8
Correct prediction
Energy consumption = 191.885561 pJ
sum error= 270
Actual label: 9
Output voltages: [0.28517, 0.12747, 0.18876, 0.22171, 0.26431, 0.12238, 0.062667, 0.21641, 0.4654, 0.62349]
Predicted label: 9
Correct prediction
Energy consumption = 188.329689 pJ
sum error= 270
Actual label: 0
Output voltages: [0.68285, 0.16303, 0.31415, 0.21365, 0.061494, 0.21873, 0.4376, 0.20905, 0.32901, 0.23877]
Predicted label: 0
Correct prediction
Energy consumption = 190.043551 pJ
sum error= 270
Actual label: 1
Output voltages: [0.24712, 0.74512, 0.1883, 0.22419, 0.31039, 0.064581, 0.31264, 0.076421, 0.35582, 0.2792]
Predicted label: 1
Correct prediction
Energy consumption = 210.198239 pJ
sum error= 270
Actual label: 2
Output voltages: [0.42421, 0.10973, 0.64124, 0.49045, 0.22125, 0.07949, 0.29607, 0.22282, 0.32524, 0.16606]
Predicted label: 2
Correct prediction
Energy consumption = 198.725617 pJ
sum error= 270
Actual label: 3
Output voltages: [0.36629, 0.12427, 0.46267, 0.65392, 0.11646, 0.10092, 0.17652, 0.10381, 0.55379, 0.20802]
Predicted label: 3
Correct prediction
Energy consumption = 184.271590 pJ
sum error= 270
Actual label: 4
Output voltages: [0.21441, 0.18866, 0.26205, 0.17871, 0.73812, 0.046578, 0.29999, 0.28053, 0.20885, 0.22468]
Predicted label: 4
Correct prediction
Energy consumption = 194.803159 pJ
sum error= 270
Actual label: 5
Output voltages: [0.21244, 0.055227, 0.1366, 0.27672, 0.19263, 0.65672, 0.35718, 0.098968, 0.56971, 0.19254]
Predicted label: 5
Correct prediction
Energy consumption = 195.693142 pJ
sum error= 270
Actual label: 6
Output voltages: [0.31003, 0.2053, 0.22269, 0.17659, 0.3341, 0.40606, 0.73033, 0.056942, 0.38111, 0.16815]
Predicted label: 6
Correct prediction
Energy consumption = 188.490184 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 795 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 795 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 795 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.42102, 0.17079, 0.4381, 0.28549, 0.12668, 0.038799, 0.052438, 0.6959, 0.42362, 0.18001]
Predicted label: 7
Correct prediction
Energy consumption = 201.906344 pJ
sum error= 270
Actual label: 8
Output voltages: [0.25051, 0.23973, 0.31421, 0.17285, 0.23462, 0.10422, 0.18227, 0.10987, 0.72598, 0.39126]
Predicted label: 8
Correct prediction
Energy consumption = 191.092870 pJ
sum error= 270
Actual label: 9
Output voltages: [0.34114, 0.12615, 0.20212, 0.16691, 0.31887, 0.14305, 0.059521, 0.18386, 0.41839, 0.67616]
Predicted label: 9
Correct prediction
Energy consumption = 189.218035 pJ
sum error= 270
Actual label: 0
Output voltages: [0.73235, 0.28032, 0.25133, 0.15178, 0.11257, 0.13866, 0.41332, 0.1788, 0.27056, 0.27553]
Predicted label: 0
Correct prediction
Energy consumption = 189.631072 pJ
sum error= 270
Actual label: 1
Output voltages: [0.18046, 0.73802, 0.14102, 0.22981, 0.30677, 0.077087, 0.32633, 0.082593, 0.36253, 0.28529]
Predicted label: 1
Correct prediction
Energy consumption = 206.020007 pJ
sum error= 270
Actual label: 2
Output voltages: [0.38698, 0.1237, 0.73474, 0.35592, 0.24753, 0.041455, 0.16479, 0.24908, 0.39562, 0.19289]
Predicted label: 2
Correct prediction
Energy consumption = 190.153616 pJ
sum error= 270
Actual label: 3
Output voltages: [0.37058, 0.19141, 0.31865, 0.75611, 0.21661, 0.17116, 0.213, 0.16801, 0.39956, 0.17489]
Predicted label: 3
Correct prediction
Energy consumption = 184.416589 pJ
sum error= 270
Actual label: 4
Output voltages: [0.071941, 0.18342, 0.14675, 0.14417, 0.72956, 0.1691, 0.31292, 0.28644, 0.32772, 0.16494]
Predicted label: 4
Correct prediction
Energy consumption = 190.845018 pJ
sum error= 270
Actual label: 5
Output voltages: [0.25654, 0.040506, 0.087766, 0.37719, 0.20533, 0.69507, 0.27353, 0.22803, 0.53165, 0.19959]
Predicted label: 5
Correct prediction
Energy consumption = 186.716946 pJ
sum error= 270
Actual label: 6
Output voltages: [0.33474, 0.19961, 0.26745, 0.14683, 0.31238, 0.35172, 0.73214, 0.055909, 0.41818, 0.19418]
Predicted label: 6
Correct prediction
Energy consumption = 180.390221 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 796 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 796 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 796 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30507, 0.25753, 0.41454, 0.18716, 0.12215, 0.073449, 0.054737, 0.75387, 0.37369, 0.37008]
Predicted label: 7
Correct prediction
Energy consumption = 193.897068 pJ
sum error= 270
Actual label: 8
Output voltages: [0.25222, 0.23534, 0.3258, 0.21705, 0.19087, 0.11279, 0.22018, 0.11651, 0.74402, 0.34558]
Predicted label: 8
Correct prediction
Energy consumption = 185.493028 pJ
sum error= 270
Actual label: 9
Output voltages: [0.36684, 0.10978, 0.22245, 0.19419, 0.2714, 0.1777, 0.070141, 0.26571, 0.45063, 0.64201]
Predicted label: 9
Correct prediction
Energy consumption = 186.807012 pJ
sum error= 270
Actual label: 8
Output voltages: [0.23537, 0.15723, 0.32145, 0.28561, 0.15048, 0.21434, 0.2112, 0.14615, 0.74744, 0.29609]
Predicted label: 8
Correct prediction
Energy consumption = 191.041120 pJ
sum error= 270
Actual label: 9
Output voltages: [0.27128, 0.17602, 0.2105, 0.1932, 0.2262, 0.1243, 0.08801, 0.15927, 0.49252, 0.65027]
Predicted label: 9
Correct prediction
Energy consumption = 189.097909 pJ
sum error= 270
Actual label: 5
Output voltages: [0.2277, 0.052225, 0.10352, 0.34358, 0.22736, 0.73477, 0.25914, 0.23702, 0.58549, 0.24286]
Predicted label: 5
Correct prediction
Energy consumption = 182.032403 pJ
sum error= 270
Actual label: 7
Output voltages: [0.35448, 0.22486, 0.41905, 0.37501, 0.067243, 0.043487, 0.058623, 0.72521, 0.3731, 0.26302]
Predicted label: 7
Correct prediction
Energy consumption = 197.253749 pJ
sum error= 270
Actual label: 0
Output voltages: [0.74179, 0.22164, 0.27122, 0.15657, 0.18312, 0.13364, 0.40546, 0.17339, 0.30898, 0.2058]
Predicted label: 0
Correct prediction
Energy consumption = 186.244112 pJ
sum error= 270
Actual label: 3
Output voltages: [0.37191, 0.14903, 0.36439, 0.75558, 0.21688, 0.14926, 0.13173, 0.16903, 0.44557, 0.22949]
Predicted label: 3
Correct prediction
Energy consumption = 183.686857 pJ
sum error= 270
Actual label: 1
Output voltages: [0.18057, 0.75865, 0.24797, 0.22191, 0.2936, 0.13748, 0.4784, 0.16892, 0.26795, 0.17414]
Predicted label: 1
Correct prediction
Energy consumption = 199.206571 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 797 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 797 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 797 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30077, 0.19122, 0.26517, 0.12406, 0.34438, 0.38408, 0.74698, 0.060792, 0.34881, 0.13016]
Predicted label: 6
Correct prediction
Energy consumption = 188.037864 pJ
sum error= 270
Actual label: 8
Output voltages: [0.36111, 0.22323, 0.30911, 0.19985, 0.20088, 0.068992, 0.16871, 0.22043, 0.65665, 0.38943]
Predicted label: 8
Correct prediction
Energy consumption = 197.320962 pJ
sum error= 270
Actual label: 4
Output voltages: [0.1558, 0.17958, 0.23041, 0.20962, 0.72648, 0.062911, 0.24231, 0.31463, 0.25743, 0.15772]
Predicted label: 4
Correct prediction
Energy consumption = 195.703910 pJ
sum error= 270
Actual label: 1
Output voltages: [0.23632, 0.74086, 0.27535, 0.19188, 0.36377, 0.083447, 0.31496, 0.11653, 0.27516, 0.23301]
Predicted label: 1
Correct prediction
Energy consumption = 207.558846 pJ
sum error= 270
Actual label: 5
Output voltages: [0.30754, 0.050936, 0.046252, 0.36812, 0.19712, 0.73903, 0.30101, 0.17916, 0.51449, 0.16448]
Predicted label: 5
Correct prediction
Energy consumption = 186.053513 pJ
sum error= 270
Actual label: 6
Output voltages: [0.31547, 0.14581, 0.25043, 0.15462, 0.33136, 0.39719, 0.70408, 0.050389, 0.42321, 0.1767]
Predicted label: 6
Correct prediction
Energy consumption = 185.893350 pJ
sum error= 270
Actual label: 4
Output voltages: [0.1672, 0.18323, 0.31609, 0.17257, 0.74803, 0.052664, 0.30965, 0.32311, 0.1779, 0.1967]
Predicted label: 4
Correct prediction
Energy consumption = 188.218856 pJ
sum error= 270
Actual label: 2
Output voltages: [0.35256, 0.1771, 0.68866, 0.41921, 0.18342, 0.032667, 0.21297, 0.28362, 0.42073, 0.18514]
Predicted label: 2
Correct prediction
Energy consumption = 186.764143 pJ
sum error= 270
Actual label: 7
Output voltages: [0.44436, 0.13324, 0.43891, 0.29174, 0.068606, 0.053629, 0.062599, 0.62398, 0.51857, 0.21249]
Predicted label: 7
Correct prediction
Energy consumption = 190.957120 pJ
sum error= 270
Actual label: 8
Output voltages: [0.25686, 0.17948, 0.3454, 0.17873, 0.18406, 0.18056, 0.18295, 0.13535, 0.74475, 0.30351]
Predicted label: 8
Correct prediction
Energy consumption = 180.127974 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 798 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 798 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 798 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.22387, 0.73701, 0.36085, 0.26563, 0.31906, 0.04537, 0.39053, 0.12096, 0.29093, 0.21459]
Predicted label: 1
Correct prediction
Energy consumption = 209.099992 pJ
sum error= 270
Actual label: 3
Output voltages: [0.37117, 0.15305, 0.3333, 0.76029, 0.18532, 0.18707, 0.15719, 0.18128, 0.4312, 0.2427]
Predicted label: 3
Correct prediction
Energy consumption = 184.712090 pJ
sum error= 270
Actual label: 4
Output voltages: [0.17915, 0.23077, 0.2679, 0.19436, 0.64557, 0.054349, 0.28193, 0.19727, 0.40497, 0.16696]
Predicted label: 4
Correct prediction
Energy consumption = 199.653098 pJ
sum error= 270
Actual label: 3
Output voltages: [0.31859, 0.16526, 0.29664, 0.7539, 0.21823, 0.21895, 0.17141, 0.14218, 0.44907, 0.24105]
Predicted label: 3
Correct prediction
Energy consumption = 187.403650 pJ
sum error= 270
Actual label: 4
Output voltages: [0.14137, 0.15562, 0.239, 0.18957, 0.7508, 0.076902, 0.26567, 0.28507, 0.26956, 0.15068]
Predicted label: 4
Correct prediction
Energy consumption = 193.582817 pJ
sum error= 270
Actual label: 7
Output voltages: [0.3466, 0.21209, 0.41687, 0.26727, 0.082631, 0.042223, 0.044832, 0.70898, 0.47327, 0.26943]
Predicted label: 7
Correct prediction
Energy consumption = 195.766015 pJ
sum error= 270
Actual label: 2
Output voltages: [0.47826, 0.11581, 0.68225, 0.35413, 0.14043, 0.038535, 0.23532, 0.34668, 0.44829, 0.16505]
Predicted label: 2
Correct prediction
Energy consumption = 181.915263 pJ
sum error= 270
Actual label: 0
Output voltages: [0.70557, 0.24744, 0.37932, 0.16901, 0.1417, 0.077922, 0.38829, 0.14647, 0.36792, 0.23827]
Predicted label: 0
Correct prediction
Energy consumption = 188.285689 pJ
sum error= 270
Actual label: 5
Output voltages: [0.27009, 0.062758, 0.073996, 0.26521, 0.24933, 0.74334, 0.40175, 0.19966, 0.45139, 0.18694]
Predicted label: 5
Correct prediction
Energy consumption = 187.451053 pJ
sum error= 270
Actual label: 0
Output voltages: [0.69211, 0.20509, 0.2724, 0.16859, 0.1596, 0.12202, 0.46865, 0.12836, 0.33004, 0.28372]
Predicted label: 0
Correct prediction
Energy consumption = 177.979427 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 799 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 799 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 799 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.26723, 0.60039, 0.16263, 0.23608, 0.26694, 0.15149, 0.33114, 0.06655, 0.55516, 0.22686]
Predicted label: 1
Correct prediction
Energy consumption = 202.798569 pJ
sum error= 270
Actual label: 9
Output voltages: [0.3118, 0.098744, 0.24876, 0.14926, 0.24068, 0.11559, 0.060971, 0.28014, 0.61059, 0.49934]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.670942 pJ
sum error= 271
Actual label: 2
Output voltages: [0.3609, 0.19834, 0.74678, 0.33182, 0.21579, 0.038678, 0.22692, 0.29558, 0.41737, 0.2036]
Predicted label: 2
Correct prediction
Energy consumption = 186.148685 pJ
sum error= 271
Actual label: 3
Output voltages: [0.38264, 0.10298, 0.26616, 0.75702, 0.17771, 0.32075, 0.12655, 0.22028, 0.41539, 0.18241]
Predicted label: 3
Correct prediction
Energy consumption = 181.712893 pJ
sum error= 271
Actual label: 2
Output voltages: [0.40534, 0.10113, 0.74785, 0.33205, 0.21586, 0.051729, 0.21813, 0.27089, 0.44966, 0.20614]
Predicted label: 2
Correct prediction
Energy consumption = 186.443420 pJ
sum error= 271
Actual label: 3
Output voltages: [0.37772, 0.17398, 0.33142, 0.76194, 0.20551, 0.17664, 0.1554, 0.19666, 0.39551, 0.23998]
Predicted label: 3
Correct prediction
Energy consumption = 181.189034 pJ
sum error= 271
Actual label: 5
Output voltages: [0.26951, 0.070003, 0.055192, 0.36146, 0.31328, 0.73768, 0.36432, 0.12999, 0.47418, 0.09454]
Predicted label: 5
Correct prediction
Energy consumption = 185.235235 pJ
sum error= 271
Actual label: 5
Output voltages: [0.29166, 0.059965, 0.058909, 0.38355, 0.18721, 0.73937, 0.30517, 0.15918, 0.51932, 0.15474]
Predicted label: 5
Correct prediction
Energy consumption = 178.997843 pJ
sum error= 271
Actual label: 7
Output voltages: [0.35471, 0.097591, 0.29377, 0.26396, 0.095242, 0.11697, 0.048387, 0.67888, 0.50979, 0.37139]
Predicted label: 7
Correct prediction
Energy consumption = 195.232180 pJ
sum error= 271
Actual label: 8
Output voltages: [0.47622, 0.19284, 0.41678, 0.13708, 0.15455, 0.12798, 0.27099, 0.18339, 0.63421, 0.27417]
Predicted label: 8
Correct prediction
Energy consumption = 189.468156 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 800 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 800 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 800 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.27484, 0.17586, 0.4382, 0.15404, 0.69265, 0.044113, 0.40351, 0.25019, 0.23351, 0.18057]
Predicted label: 4
Correct prediction
Energy consumption = 190.326344 pJ
sum error= 271
Actual label: 9
Output voltages: [0.33992, 0.11502, 0.19251, 0.31335, 0.28761, 0.16133, 0.080556, 0.27701, 0.39532, 0.65725]
Predicted label: 9
Correct prediction
Energy consumption = 189.102703 pJ
sum error= 271
Actual label: 9
Output voltages: [0.27735, 0.1388, 0.1681, 0.25325, 0.19094, 0.14359, 0.060391, 0.24658, 0.51888, 0.58543]
Predicted label: 9
Correct prediction
Energy consumption = 190.043907 pJ
sum error= 271
Actual label: 7
Output voltages: [0.32826, 0.2715, 0.41665, 0.38488, 0.10396, 0.050197, 0.040465, 0.62384, 0.43437, 0.39231]
Predicted label: 7
Correct prediction
Energy consumption = 191.213232 pJ
sum error= 271
Actual label: 1
Output voltages: [0.44351, 0.58797, 0.31575, 0.165, 0.27569, 0.11844, 0.47936, 0.041153, 0.325, 0.24895]
Predicted label: 1
Correct prediction
Energy consumption = 204.880930 pJ
sum error= 271
Actual label: 1
Output voltages: [0.18793, 0.7571, 0.20821, 0.15607, 0.27964, 0.13943, 0.39254, 0.15637, 0.32837, 0.21202]
Predicted label: 1
Correct prediction
Energy consumption = 200.217129 pJ
sum error= 271
Actual label: 9
Output voltages: [0.36181, 0.11111, 0.20487, 0.22081, 0.20978, 0.20408, 0.087588, 0.27852, 0.4865, 0.64706]
Predicted label: 9
Correct prediction
Energy consumption = 190.588525 pJ
sum error= 271
Actual label: 0
Output voltages: [0.71194, 0.23839, 0.28838, 0.13122, 0.17628, 0.088304, 0.44761, 0.22632, 0.35089, 0.22717]
Predicted label: 0
Correct prediction
Energy consumption = 183.383398 pJ
sum error= 271
Actual label: 7
Output voltages: [0.33791, 0.21049, 0.45846, 0.25045, 0.097036, 0.044747, 0.051937, 0.70062, 0.48024, 0.34964]
Predicted label: 7
Correct prediction
Energy consumption = 191.819656 pJ
sum error= 271
Actual label: 8
Output voltages: [0.24839, 0.15969, 0.39789, 0.15406, 0.18179, 0.16988, 0.20687, 0.12421, 0.73709, 0.31821]
Predicted label: 8
Correct prediction
Energy consumption = 186.410153 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 801 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 801 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 801 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.45776, 0.078432, 0.38903, 0.73293, 0.14554, 0.12316, 0.15457, 0.17926, 0.51061, 0.15456]
Predicted label: 3
Correct prediction
Energy consumption = 195.505392 pJ
sum error= 271
Actual label: 4
Output voltages: [0.19565, 0.18512, 0.18445, 0.16232, 0.7272, 0.075417, 0.29129, 0.2662, 0.26788, 0.21651]
Predicted label: 4
Correct prediction
Energy consumption = 200.056605 pJ
sum error= 271
Actual label: 8
Output voltages: [0.31136, 0.22689, 0.375, 0.21846, 0.15598, 0.1183, 0.23568, 0.17549, 0.71832, 0.27258]
Predicted label: 8
Correct prediction
Energy consumption = 194.344609 pJ
sum error= 271
Actual label: 6
Output voltages: [0.28378, 0.23914, 0.35351, 0.066196, 0.34219, 0.2853, 0.75292, 0.075816, 0.37448, 0.14649]
Predicted label: 6
Correct prediction
Energy consumption = 185.666520 pJ
sum error= 271
Actual label: 3
Output voltages: [0.46233, 0.12183, 0.29783, 0.75146, 0.18675, 0.22052, 0.16801, 0.18999, 0.41353, 0.19714]
Predicted label: 3
Correct prediction
Energy consumption = 195.373096 pJ
sum error= 271
Actual label: 8
Output voltages: [0.26639, 0.21735, 0.30697, 0.19174, 0.19011, 0.2226, 0.26669, 0.097067, 0.73044, 0.28123]
Predicted label: 8
Correct prediction
Energy consumption = 189.848041 pJ
sum error= 271
Actual label: 0
Output voltages: [0.66518, 0.22706, 0.3074, 0.15997, 0.17695, 0.068772, 0.40619, 0.18089, 0.28137, 0.40073]
Predicted label: 0
Correct prediction
Energy consumption = 186.361492 pJ
sum error= 271
Actual label: 9
Output voltages: [0.3829, 0.11823, 0.20751, 0.22029, 0.26145, 0.18336, 0.088089, 0.21444, 0.43105, 0.67578]
Predicted label: 9
Correct prediction
Energy consumption = 184.522667 pJ
sum error= 271
Actual label: 6
Output voltages: [0.27209, 0.22672, 0.35144, 0.062629, 0.37065, 0.28842, 0.74543, 0.056488, 0.35344, 0.10238]
Predicted label: 6
Correct prediction
Energy consumption = 193.695313 pJ
sum error= 271
Actual label: 2
Output voltages: [0.41008, 0.10844, 0.64407, 0.40573, 0.15345, 0.046562, 0.2542, 0.19208, 0.53257, 0.25266]
Predicted label: 2
Correct prediction
Energy consumption = 194.793270 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 802 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 802 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 802 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.36312, 0.6627, 0.23897, 0.26367, 0.080547, 0.089826, 0.46696, 0.11383, 0.43413, 0.18667]
Predicted label: 1
Correct prediction
Energy consumption = 214.026700 pJ
sum error= 271
Actual label: 0
Output voltages: [0.71284, 0.22217, 0.2667, 0.16887, 0.15866, 0.16016, 0.45408, 0.1764, 0.25961, 0.28428]
Predicted label: 0
Correct prediction
Energy consumption = 189.451894 pJ
sum error= 271
Actual label: 1
Output voltages: [0.24906, 0.72218, 0.20282, 0.27758, 0.2742, 0.072712, 0.40749, 0.049077, 0.36705, 0.25942]
Predicted label: 1
Correct prediction
Energy consumption = 207.921447 pJ
sum error= 271
Actual label: 0
Output voltages: [0.69352, 0.25812, 0.22071, 0.21299, 0.15242, 0.091928, 0.31915, 0.17271, 0.37975, 0.29197]
Predicted label: 0
Correct prediction
Energy consumption = 189.729195 pJ
sum error= 271
Actual label: 6
Output voltages: [0.25708, 0.16584, 0.32312, 0.073563, 0.37805, 0.29517, 0.73329, 0.048903, 0.34764, 0.14007]
Predicted label: 6
Correct prediction
Energy consumption = 187.267619 pJ
sum error= 271
Actual label: 2
Output voltages: [0.377, 0.17063, 0.75089, 0.31025, 0.21974, 0.051152, 0.27732, 0.26396, 0.37086, 0.14905]
Predicted label: 2
Correct prediction
Energy consumption = 185.104599 pJ
sum error= 271
Actual label: 3
Output voltages: [0.37757, 0.1753, 0.34665, 0.75315, 0.22376, 0.13518, 0.1639, 0.11798, 0.45675, 0.2208]
Predicted label: 3
Correct prediction
Energy consumption = 177.411667 pJ
sum error= 271
Actual label: 8
Output voltages: [0.25527, 0.17655, 0.35637, 0.18579, 0.18368, 0.14874, 0.15829, 0.13837, 0.74388, 0.33766]
Predicted label: 8
Correct prediction
Energy consumption = 186.198185 pJ
sum error= 271
Actual label: 9
Output voltages: [0.35582, 0.12803, 0.20852, 0.17916, 0.25934, 0.13821, 0.070018, 0.21586, 0.44659, 0.66455]
Predicted label: 9
Correct prediction
Energy consumption = 194.083795 pJ
sum error= 271
Actual label: 0
Output voltages: [0.67967, 0.24372, 0.32779, 0.14685, 0.24806, 0.062833, 0.44765, 0.2222, 0.33287, 0.20409]
Predicted label: 0
Correct prediction
Energy consumption = 190.032988 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 803 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 803 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 803 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.41383, 0.11444, 0.45357, 0.27528, 0.11093, 0.065412, 0.072822, 0.66977, 0.37277, 0.32635]
Predicted label: 7
Correct prediction
Energy consumption = 199.667442 pJ
sum error= 271
Actual label: 2
Output voltages: [0.29731, 0.22491, 0.74546, 0.33712, 0.25709, 0.033467, 0.19459, 0.34753, 0.28666, 0.20206]
Predicted label: 2
Correct prediction
Energy consumption = 179.542653 pJ
sum error= 271
Actual label: 3
Output voltages: [0.25873, 0.14869, 0.29161, 0.74489, 0.22794, 0.15017, 0.12842, 0.21021, 0.47834, 0.26911]
Predicted label: 3
Correct prediction
Energy consumption = 183.957957 pJ
sum error= 271
Actual label: 4
Output voltages: [0.11499, 0.17341, 0.24247, 0.17597, 0.74667, 0.062889, 0.24077, 0.33881, 0.30247, 0.18604]
Predicted label: 4
Correct prediction
Energy consumption = 188.462634 pJ
sum error= 271
Actual label: 5
Output voltages: [0.19227, 0.053272, 0.12793, 0.38613, 0.17119, 0.61302, 0.25123, 0.15188, 0.56989, 0.2345]
Predicted label: 5
Correct prediction
Energy consumption = 193.362945 pJ
sum error= 271
Actual label: 5
Output voltages: [0.21315, 0.043417, 0.13324, 0.46286, 0.17521, 0.54107, 0.20085, 0.14501, 0.53678, 0.23194]
Predicted label: 5
Correct prediction
Energy consumption = 183.868757 pJ
sum error= 271
Actual label: 2
Output voltages: [0.35413, 0.22307, 0.72669, 0.34599, 0.3032, 0.041161, 0.2529, 0.29312, 0.29871, 0.15973]
Predicted label: 2
Correct prediction
Energy consumption = 191.585165 pJ
sum error= 271
Actual label: 8
Output voltages: [0.27292, 0.21877, 0.31873, 0.19771, 0.18198, 0.19081, 0.24825, 0.09272, 0.72931, 0.36961]
Predicted label: 8
Correct prediction
Energy consumption = 182.243361 pJ
sum error= 271
Actual label: 5
Output voltages: [0.2562, 0.06459, 0.10833, 0.33324, 0.21046, 0.71769, 0.36295, 0.15477, 0.50473, 0.17584]
Predicted label: 5
Correct prediction
Energy consumption = 188.947779 pJ
sum error= 271
Actual label: 4
Output voltages: [0.14542, 0.17626, 0.24337, 0.15444, 0.75385, 0.088409, 0.22012, 0.25244, 0.24752, 0.20657]
Predicted label: 4
Correct prediction
Energy consumption = 191.738160 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 804 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 804 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 804 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30257, 0.17436, 0.32237, 0.089205, 0.40607, 0.36561, 0.73336, 0.047703, 0.3728, 0.12298]
Predicted label: 6
Correct prediction
Energy consumption = 191.096703 pJ
sum error= 271
Actual label: 6
Output voltages: [0.30364, 0.18631, 0.23402, 0.15715, 0.31984, 0.39988, 0.72454, 0.068925, 0.41246, 0.155]
Predicted label: 6
Correct prediction
Energy consumption = 185.506628 pJ
sum error= 271
Actual label: 6
Output voltages: [0.28687, 0.20196, 0.27419, 0.14582, 0.32476, 0.37481, 0.73459, 0.071327, 0.39096, 0.1233]
Predicted label: 6
Correct prediction
Energy consumption = 187.764648 pJ
sum error= 271
Actual label: 7
Output voltages: [0.39325, 0.2372, 0.58437, 0.21366, 0.074064, 0.036043, 0.13049, 0.6335, 0.4022, 0.28093]
Predicted label: 7
Correct prediction
Energy consumption = 193.247679 pJ
sum error= 271
Actual label: 9
Output voltages: [0.36566, 0.12264, 0.22113, 0.2201, 0.28713, 0.097962, 0.053427, 0.24755, 0.43218, 0.59746]
Predicted label: 9
Correct prediction
Energy consumption = 199.309038 pJ
sum error= 271
Actual label: 1
Output voltages: [0.22638, 0.66229, 0.23731, 0.22233, 0.41064, 0.068675, 0.34028, 0.042784, 0.35602, 0.35843]
Predicted label: 1
Correct prediction
Energy consumption = 206.989797 pJ
sum error= 271
Actual label: 8
Output voltages: [0.25394, 0.27118, 0.3165, 0.19174, 0.21598, 0.11277, 0.20581, 0.14093, 0.74264, 0.33043]
Predicted label: 8
Correct prediction
Energy consumption = 187.410736 pJ
sum error= 271
Actual label: 2
Output voltages: [0.47317, 0.14398, 0.66393, 0.36564, 0.14265, 0.075679, 0.26841, 0.27168, 0.47814, 0.18879]
Predicted label: 2
Correct prediction
Energy consumption = 194.158010 pJ
sum error= 271
Actual label: 1
Output voltages: [0.24454, 0.75288, 0.24588, 0.25352, 0.24796, 0.095681, 0.40767, 0.12132, 0.35125, 0.18636]
Predicted label: 1
Correct prediction
Energy consumption = 209.629558 pJ
sum error= 271
Actual label: 5
Output voltages: [0.26741, 0.04884, 0.10061, 0.29934, 0.23913, 0.70946, 0.37016, 0.1676, 0.52328, 0.23006]
Predicted label: 5
Correct prediction
Energy consumption = 182.810826 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 805 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 805 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 805 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.43502, 0.10395, 0.35674, 0.7408, 0.19829, 0.14038, 0.13631, 0.15027, 0.42993, 0.16667]
Predicted label: 3
Correct prediction
Energy consumption = 193.979135 pJ
sum error= 271
Actual label: 4
Output voltages: [0.20309, 0.13896, 0.25436, 0.24264, 0.7321, 0.069129, 0.23433, 0.26625, 0.27669, 0.169]
Predicted label: 4
Correct prediction
Energy consumption = 192.437005 pJ
sum error= 271
Actual label: 7
Output voltages: [0.33791, 0.18156, 0.34356, 0.23317, 0.14089, 0.060824, 0.047362, 0.74577, 0.37633, 0.36142]
Predicted label: 7
Correct prediction
Energy consumption = 198.933282 pJ
sum error= 271
Actual label: 9
Output voltages: [0.31551, 0.10095, 0.19004, 0.2495, 0.26237, 0.14048, 0.05847, 0.31908, 0.45488, 0.65347]
Predicted label: 9
Correct prediction
Energy consumption = 183.902443 pJ
sum error= 271
Actual label: 4
Output voltages: [0.13027, 0.15931, 0.226, 0.1249, 0.75305, 0.089591, 0.29258, 0.32393, 0.2695, 0.14021]
Predicted label: 4
Correct prediction
Energy consumption = 189.144943 pJ
sum error= 271
Actual label: 0
Output voltages: [0.73343, 0.2405, 0.27215, 0.16552, 0.2227, 0.10515, 0.40067, 0.16359, 0.3359, 0.21472]
Predicted label: 0
Correct prediction
Energy consumption = 193.814208 pJ
sum error= 271
Actual label: 0
Output voltages: [0.73811, 0.26762, 0.2528, 0.19285, 0.1674, 0.15055, 0.36743, 0.23107, 0.31055, 0.25739]
Predicted label: 0
Correct prediction
Energy consumption = 185.273362 pJ
sum error= 271
Actual label: 0
Output voltages: [0.73745, 0.27014, 0.27858, 0.1263, 0.15692, 0.096967, 0.36215, 0.23373, 0.30184, 0.33469]
Predicted label: 0
Correct prediction
Energy consumption = 182.659061 pJ
sum error= 271
Actual label: 1
Output voltages: [0.22008, 0.75119, 0.22393, 0.29074, 0.24871, 0.071012, 0.42254, 0.080229, 0.34963, 0.18624]
Predicted label: 1
Correct prediction
Energy consumption = 210.152337 pJ
sum error= 271
Actual label: 2
Output voltages: [0.23885, 0.5307, 0.55415, 0.33147, 0.11655, 0.039032, 0.32285, 0.090022, 0.42016, 0.25006]
Predicted label: 2
Correct prediction
Energy consumption = 195.218055 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 806 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 806 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 806 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.3669, 0.18796, 0.27719, 0.73793, 0.14189, 0.15605, 0.074676, 0.13486, 0.48186, 0.31236]
Predicted label: 3
Correct prediction
Energy consumption = 193.239813 pJ
sum error= 271
Actual label: 4
Output voltages: [0.37988, 0.21776, 0.3024, 0.18334, 0.66991, 0.038595, 0.26424, 0.13491, 0.24245, 0.35393]
Predicted label: 4
Correct prediction
Energy consumption = 198.634731 pJ
sum error= 271
Actual label: 5
Output voltages: [0.29046, 0.17786, 0.12253, 0.37805, 0.090592, 0.5829, 0.29785, 0.051055, 0.61316, 0.17259]
Predicted label: 8
Wrong prediction!
Energy consumption = 198.472838 pJ
sum error= 272
Actual label: 6
Output voltages: [0.29485, 0.31884, 0.26369, 0.24066, 0.2878, 0.32375, 0.6985, 0.064437, 0.42876, 0.069151]
Predicted label: 6
Correct prediction
Energy consumption = 200.814579 pJ
sum error= 272
Actual label: 7
Output voltages: [0.36947, 0.24009, 0.29568, 0.34203, 0.096061, 0.10799, 0.03317, 0.65009, 0.52522, 0.32822]
Predicted label: 7
Correct prediction
Energy consumption = 202.626698 pJ
sum error= 272
Actual label: 8
Output voltages: [0.28825, 0.30201, 0.22093, 0.44689, 0.11143, 0.13303, 0.2376, 0.070143, 0.68633, 0.31333]
Predicted label: 8
Correct prediction
Energy consumption = 205.043361 pJ
sum error= 272
Actual label: 9
Output voltages: [0.28891, 0.15048, 0.18649, 0.20992, 0.25154, 0.12582, 0.065485, 0.14478, 0.48175, 0.61848]
Predicted label: 9
Correct prediction
Energy consumption = 197.149220 pJ
sum error= 272
Actual label: 0
Output voltages: [0.72811, 0.2348, 0.302, 0.13726, 0.14913, 0.16794, 0.35825, 0.17915, 0.34211, 0.19677]
Predicted label: 0
Correct prediction
Energy consumption = 193.214368 pJ
sum error= 272
Actual label: 1
Output voltages: [0.21891, 0.75341, 0.26685, 0.27616, 0.2722, 0.051209, 0.36852, 0.09903, 0.32034, 0.26565]
Predicted label: 1
Correct prediction
Energy consumption = 213.148821 pJ
sum error= 272
Actual label: 2
Output voltages: [0.25505, 0.5961, 0.54785, 0.37869, 0.14893, 0.03568, 0.3354, 0.12341, 0.34661, 0.17772]
Predicted label: 1
Wrong prediction!
Energy consumption = 190.434897 pJ
sum error= 273
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 807 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 807 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 807 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34365, 0.18263, 0.30508, 0.76216, 0.22282, 0.21084, 0.15934, 0.17197, 0.40782, 0.27391]
Predicted label: 3
Correct prediction
Energy consumption = 189.451628 pJ
sum error= 273
Actual label: 4
Output voltages: [0.26644, 0.28063, 0.088555, 0.30727, 0.67949, 0.1753, 0.32582, 0.1784, 0.22336, 0.34183]
Predicted label: 4
Correct prediction
Energy consumption = 200.834567 pJ
sum error= 273
Actual label: 5
Output voltages: [0.21744, 0.13335, 0.064441, 0.44599, 0.24064, 0.75162, 0.29996, 0.1971, 0.44013, 0.19871]
Predicted label: 5
Correct prediction
Energy consumption = 189.619113 pJ
sum error= 273
Actual label: 6
Output voltages: [0.3177, 0.25394, 0.24173, 0.16066, 0.28973, 0.41075, 0.72569, 0.13093, 0.44637, 0.085732]
Predicted label: 6
Correct prediction
Energy consumption = 190.128327 pJ
sum error= 273
Actual label: 7
Output voltages: [0.25338, 0.26701, 0.26473, 0.21311, 0.16761, 0.059906, 0.036485, 0.74147, 0.38964, 0.31035]
Predicted label: 7
Correct prediction
Energy consumption = 200.814561 pJ
sum error= 273
Actual label: 8
Output voltages: [0.36645, 0.33086, 0.20541, 0.40736, 0.070881, 0.16923, 0.27291, 0.058998, 0.70506, 0.31585]
Predicted label: 8
Correct prediction
Energy consumption = 200.342937 pJ
sum error= 273
Actual label: 9
Output voltages: [0.36222, 0.1443, 0.20585, 0.22535, 0.29883, 0.13151, 0.056955, 0.17514, 0.41303, 0.67176]
Predicted label: 9
Correct prediction
Energy consumption = 190.706994 pJ
sum error= 273
Actual label: 0
Output voltages: [0.73703, 0.19777, 0.33344, 0.17398, 0.23165, 0.12654, 0.367, 0.19502, 0.37267, 0.23901]
Predicted label: 0
Correct prediction
Energy consumption = 195.191947 pJ
sum error= 273
Actual label: 1
Output voltages: [0.3061, 0.7548, 0.2347, 0.29819, 0.20313, 0.076705, 0.39916, 0.12907, 0.2972, 0.21376]
Predicted label: 1
Correct prediction
Energy consumption = 212.472905 pJ
sum error= 273
Actual label: 2
Output voltages: [0.30507, 0.45416, 0.61918, 0.3712, 0.15966, 0.033587, 0.28508, 0.13148, 0.37977, 0.21581]
Predicted label: 2
Correct prediction
Energy consumption = 186.603838 pJ
sum error= 273
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 808 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 808 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 808 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.39436, 0.17071, 0.30806, 0.75808, 0.21678, 0.17329, 0.13964, 0.18018, 0.45401, 0.22703]
Predicted label: 3
Correct prediction
Energy consumption = 187.400409 pJ
sum error= 273
Actual label: 4
Output voltages: [0.30593, 0.21302, 0.22697, 0.17523, 0.61461, 0.093123, 0.54443, 0.1147, 0.21617, 0.19341]
Predicted label: 4
Correct prediction
Energy consumption = 196.301996 pJ
sum error= 273
Actual label: 5
Output voltages: [0.26204, 0.050503, 0.057814, 0.30582, 0.27824, 0.67835, 0.33858, 0.20508, 0.50546, 0.294]
Predicted label: 5
Correct prediction
Energy consumption = 191.180350 pJ
sum error= 273
Actual label: 6
Output voltages: [0.30195, 0.26711, 0.28624, 0.15663, 0.28792, 0.37649, 0.74665, 0.092822, 0.36667, 0.13046]
Predicted label: 6
Correct prediction
Energy consumption = 192.859338 pJ
sum error= 273
Actual label: 9
Output voltages: [0.33721, 0.12119, 0.24208, 0.23848, 0.38978, 0.1298, 0.094115, 0.19796, 0.34914, 0.65001]
Predicted label: 9
Correct prediction
Energy consumption = 198.146258 pJ
sum error= 273
Actual label: 0
Output voltages: [0.6858, 0.20549, 0.2893, 0.13963, 0.20212, 0.14115, 0.45651, 0.17162, 0.36455, 0.22784]
Predicted label: 0
Correct prediction
Energy consumption = 195.167125 pJ
sum error= 273
Actual label: 1
Output voltages: [0.25549, 0.73816, 0.24118, 0.29516, 0.31649, 0.059451, 0.41078, 0.099218, 0.30233, 0.21329]
Predicted label: 1
Correct prediction
Energy consumption = 213.248279 pJ
sum error= 273
Actual label: 3
Output voltages: [0.34226, 0.17348, 0.29014, 0.74563, 0.1584, 0.098009, 0.1124, 0.19272, 0.49368, 0.20276]
Predicted label: 3
Correct prediction
Energy consumption = 181.428030 pJ
sum error= 273
Actual label: 1
Output voltages: [0.29978, 0.67548, 0.27666, 0.29528, 0.15732, 0.066731, 0.32928, 0.062141, 0.49318, 0.23468]
Predicted label: 1
Correct prediction
Energy consumption = 206.630059 pJ
sum error= 273
Actual label: 5
Output voltages: [0.20071, 0.054273, 0.072254, 0.34398, 0.24214, 0.71483, 0.27154, 0.19343, 0.51793, 0.2523]
Predicted label: 5
Correct prediction
Energy consumption = 196.358858 pJ
sum error= 273
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 809 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 809 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 809 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.25068, 0.75038, 0.21642, 0.28679, 0.15643, 0.085961, 0.47227, 0.13843, 0.34679, 0.14124]
Predicted label: 1
Correct prediction
Energy consumption = 213.865623 pJ
sum error= 273
Actual label: 2
Output voltages: [0.33333, 0.40705, 0.56147, 0.36365, 0.11664, 0.030487, 0.33051, 0.25533, 0.39317, 0.13346]
Predicted label: 2
Correct prediction
Energy consumption = 204.715139 pJ
sum error= 273
Actual label: 4
Output voltages: [0.22604, 0.19247, 0.20165, 0.15463, 0.74183, 0.11053, 0.38484, 0.17414, 0.2786, 0.21366]
Predicted label: 4
Correct prediction
Energy consumption = 200.810988 pJ
sum error= 273
Actual label: 9
Output voltages: [0.28322, 0.13233, 0.21997, 0.20881, 0.28011, 0.13958, 0.073086, 0.18982, 0.46883, 0.6131]
Predicted label: 9
Correct prediction
Energy consumption = 192.208520 pJ
sum error= 273
Actual label: 2
Output voltages: [0.21394, 0.33877, 0.48849, 0.33613, 0.21474, 0.044998, 0.21199, 0.18077, 0.54658, 0.2423]
Predicted label: 8
Wrong prediction!
Energy consumption = 202.698866 pJ
sum error= 274
Actual label: 4
Output voltages: [0.22287, 0.23212, 0.12003, 0.27712, 0.64065, 0.12497, 0.45563, 0.16792, 0.31232, 0.15129]
Predicted label: 4
Correct prediction
Energy consumption = 207.379010 pJ
sum error= 274
Actual label: 6
Output voltages: [0.34453, 0.29561, 0.27064, 0.17145, 0.33575, 0.3098, 0.73761, 0.077195, 0.38756, 0.091964]
Predicted label: 6
Correct prediction
Energy consumption = 193.543634 pJ
sum error= 274
Actual label: 8
Output voltages: [0.42661, 0.1233, 0.3519, 0.37177, 0.12273, 0.15974, 0.17723, 0.071149, 0.67234, 0.30572]
Predicted label: 8
Correct prediction
Energy consumption = 194.122234 pJ
sum error= 274
Actual label: 0
Output voltages: [0.72116, 0.23691, 0.32001, 0.13268, 0.17774, 0.078531, 0.42001, 0.20798, 0.32331, 0.28124]
Predicted label: 0
Correct prediction
Energy consumption = 185.362687 pJ
sum error= 274
Actual label: 1
Output voltages: [0.17336, 0.76284, 0.26425, 0.19827, 0.24031, 0.089267, 0.38653, 0.17053, 0.3271, 0.20987]
Predicted label: 1
Correct prediction
Energy consumption = 203.959440 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 810 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 810 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 810 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17203, 0.75789, 0.21173, 0.27262, 0.19476, 0.078264, 0.42546, 0.10312, 0.39321, 0.19631]
Predicted label: 1
Correct prediction
Energy consumption = 211.960589 pJ
sum error= 274
Actual label: 9
Output voltages: [0.30613, 0.15947, 0.18601, 0.25785, 0.3634, 0.15917, 0.12823, 0.18308, 0.34774, 0.67149]
Predicted label: 9
Correct prediction
Energy consumption = 192.259910 pJ
sum error= 274
Actual label: 2
Output voltages: [0.27599, 0.43787, 0.56872, 0.42964, 0.099052, 0.039171, 0.26247, 0.17891, 0.42903, 0.11989]
Predicted label: 2
Correct prediction
Energy consumption = 197.447708 pJ
sum error= 274
Actual label: 6
Output voltages: [0.29991, 0.31526, 0.26698, 0.21313, 0.3442, 0.27811, 0.73846, 0.070045, 0.38371, 0.099138]
Predicted label: 6
Correct prediction
Energy consumption = 197.311635 pJ
sum error= 274
Actual label: 6
Output voltages: [0.28612, 0.17442, 0.27016, 0.21118, 0.35105, 0.20779, 0.6729, 0.051324, 0.48058, 0.13985]
Predicted label: 6
Correct prediction
Energy consumption = 197.696521 pJ
sum error= 274
Actual label: 8
Output voltages: [0.28595, 0.23858, 0.20758, 0.36055, 0.15406, 0.17494, 0.27457, 0.074955, 0.67676, 0.30778]
Predicted label: 8
Correct prediction
Energy consumption = 197.457229 pJ
sum error= 274
Actual label: 7
Output voltages: [0.35182, 0.32064, 0.35068, 0.24633, 0.1051, 0.04729, 0.055234, 0.51721, 0.50332, 0.34629]
Predicted label: 7
Correct prediction
Energy consumption = 200.453433 pJ
sum error= 274
Actual label: 4
Output voltages: [0.31351, 0.21369, 0.23157, 0.16797, 0.69029, 0.060617, 0.33229, 0.12173, 0.2859, 0.29399]
Predicted label: 4
Correct prediction
Energy consumption = 200.499358 pJ
sum error= 274
Actual label: 2
Output voltages: [0.30306, 0.26466, 0.74189, 0.26246, 0.17059, 0.032546, 0.25474, 0.34503, 0.42238, 0.12109]
Predicted label: 2
Correct prediction
Energy consumption = 196.427826 pJ
sum error= 274
Actual label: 9
Output voltages: [0.34658, 0.13185, 0.20093, 0.24046, 0.3083, 0.093868, 0.078242, 0.24743, 0.39497, 0.65458]
Predicted label: 9
Correct prediction
Energy consumption = 192.930708 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 811 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 811 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 811 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25382, 0.32041, 0.31969, 0.20919, 0.17589, 0.034179, 0.040536, 0.65036, 0.36114, 0.37592]
Predicted label: 7
Correct prediction
Energy consumption = 202.819456 pJ
sum error= 274
Actual label: 0
Output voltages: [0.71849, 0.26753, 0.301, 0.16633, 0.1593, 0.092129, 0.4106, 0.19793, 0.3407, 0.24814]
Predicted label: 0
Correct prediction
Energy consumption = 191.924876 pJ
sum error= 274
Actual label: 2
Output voltages: [0.36089, 0.22903, 0.69561, 0.36996, 0.16232, 0.031898, 0.28106, 0.24215, 0.4383, 0.19526]
Predicted label: 2
Correct prediction
Energy consumption = 196.069587 pJ
sum error= 274
Actual label: 1
Output voltages: [0.2605, 0.75148, 0.26856, 0.27913, 0.27524, 0.05501, 0.4057, 0.14857, 0.26517, 0.21721]
Predicted label: 1
Correct prediction
Energy consumption = 210.407687 pJ
sum error= 274
Actual label: 0
Output voltages: [0.74857, 0.23279, 0.20349, 0.18897, 0.18824, 0.20049, 0.34133, 0.21323, 0.3136, 0.23117]
Predicted label: 0
Correct prediction
Energy consumption = 192.094806 pJ
sum error= 274
Actual label: 3
Output voltages: [0.40508, 0.083864, 0.23264, 0.65568, 0.15085, 0.25041, 0.12951, 0.21921, 0.51217, 0.24051]
Predicted label: 3
Correct prediction
Energy consumption = 198.314478 pJ
sum error= 274
Actual label: 6
Output voltages: [0.27159, 0.17321, 0.34389, 0.058397, 0.34842, 0.27393, 0.72931, 0.050905, 0.43875, 0.11671]
Predicted label: 6
Correct prediction
Energy consumption = 184.846550 pJ
sum error= 274
Actual label: 0
Output voltages: [0.72679, 0.25617, 0.32155, 0.19581, 0.10752, 0.13435, 0.43183, 0.18288, 0.26929, 0.22403]
Predicted label: 0
Correct prediction
Energy consumption = 189.170474 pJ
sum error= 274
Actual label: 1
Output voltages: [0.19235, 0.74346, 0.27887, 0.15188, 0.27696, 0.081614, 0.40766, 0.061137, 0.35927, 0.26768]
Predicted label: 1
Correct prediction
Energy consumption = 200.830627 pJ
sum error= 274
Actual label: 2
Output voltages: [0.2823, 0.17925, 0.7505, 0.27299, 0.22602, 0.039011, 0.21263, 0.36213, 0.37693, 0.19768]
Predicted label: 2
Correct prediction
Energy consumption = 176.059910 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 812 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 812 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 812 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.27547, 0.1412, 0.38026, 0.72386, 0.1063, 0.20154, 0.10518, 0.16642, 0.52622, 0.25412]
Predicted label: 3
Correct prediction
Energy consumption = 185.402894 pJ
sum error= 274
Actual label: 4
Output voltages: [0.17209, 0.18985, 0.31524, 0.1744, 0.75938, 0.073692, 0.27017, 0.31305, 0.20583, 0.19441]
Predicted label: 4
Correct prediction
Energy consumption = 192.033659 pJ
sum error= 274
Actual label: 5
Output voltages: [0.26857, 0.056667, 0.07346, 0.32108, 0.16684, 0.72502, 0.32175, 0.23671, 0.49711, 0.26709]
Predicted label: 5
Correct prediction
Energy consumption = 193.424953 pJ
sum error= 274
Actual label: 6
Output voltages: [0.24679, 0.15706, 0.35557, 0.063751, 0.38043, 0.30308, 0.72939, 0.052543, 0.34075, 0.18309]
Predicted label: 6
Correct prediction
Energy consumption = 185.907366 pJ
sum error= 274
Actual label: 7
Output voltages: [0.33256, 0.2458, 0.3123, 0.35302, 0.14342, 0.05711, 0.046476, 0.75214, 0.29537, 0.34091]
Predicted label: 7
Correct prediction
Energy consumption = 200.654230 pJ
sum error= 274
Actual label: 8
Output voltages: [0.18633, 0.18752, 0.42851, 0.12291, 0.23116, 0.13289, 0.27716, 0.094375, 0.73344, 0.34167]
Predicted label: 8
Correct prediction
Energy consumption = 190.562793 pJ
sum error= 274
Actual label: 9
Output voltages: [0.2998, 0.1185, 0.10496, 0.26115, 0.30168, 0.40231, 0.11647, 0.27536, 0.36231, 0.59253]
Predicted label: 9
Correct prediction
Energy consumption = 188.691144 pJ
sum error= 274
Actual label: 0
Output voltages: [0.73472, 0.25104, 0.208, 0.1748, 0.18937, 0.17318, 0.43755, 0.16269, 0.30762, 0.22792]
Predicted label: 0
Correct prediction
Energy consumption = 190.996057 pJ
sum error= 274
Actual label: 1
Output voltages: [0.27621, 0.60912, 0.28089, 0.30725, 0.26605, 0.18407, 0.58123, 0.046015, 0.36696, 0.12599]
Predicted label: 1
Correct prediction
Energy consumption = 202.595535 pJ
sum error= 274
Actual label: 2
Output voltages: [0.3276, 0.24204, 0.74311, 0.38216, 0.23412, 0.041378, 0.20945, 0.29176, 0.36685, 0.24939]
Predicted label: 2
Correct prediction
Energy consumption = 181.122854 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 813 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 813 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 813 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36365, 0.15005, 0.31303, 0.75097, 0.16356, 0.21421, 0.083572, 0.24528, 0.4224, 0.25284]
Predicted label: 3
Correct prediction
Energy consumption = 187.491002 pJ
sum error= 274
Actual label: 4
Output voltages: [0.11621, 0.13171, 0.26931, 0.19396, 0.7585, 0.12478, 0.22445, 0.26118, 0.24573, 0.21193]
Predicted label: 4
Correct prediction
Energy consumption = 191.624209 pJ
sum error= 274
Actual label: 5
Output voltages: [0.35353, 0.047661, 0.056809, 0.35977, 0.23368, 0.73683, 0.33173, 0.18963, 0.49538, 0.11666]
Predicted label: 5
Correct prediction
Energy consumption = 189.736027 pJ
sum error= 274
Actual label: 6
Output voltages: [0.28363, 0.20879, 0.33895, 0.11601, 0.31861, 0.3075, 0.74093, 0.050023, 0.38891, 0.18994]
Predicted label: 6
Correct prediction
Energy consumption = 180.740790 pJ
sum error= 274
Actual label: 7
Output voltages: [0.27088, 0.24722, 0.35711, 0.1869, 0.16662, 0.048367, 0.067623, 0.76568, 0.32763, 0.30632]
Predicted label: 7
Correct prediction
Energy consumption = 199.547595 pJ
sum error= 274
Actual label: 8
Output voltages: [0.18029, 0.14025, 0.34155, 0.17635, 0.24457, 0.2268, 0.29059, 0.072989, 0.71643, 0.30162]
Predicted label: 8
Correct prediction
Energy consumption = 195.232911 pJ
sum error= 274
Actual label: 9
Output voltages: [0.33914, 0.089448, 0.19881, 0.26937, 0.34404, 0.18679, 0.10356, 0.30964, 0.40065, 0.63741]
Predicted label: 9
Correct prediction
Energy consumption = 184.543753 pJ
sum error= 274
Actual label: 0
Output voltages: [0.72235, 0.27835, 0.23666, 0.20013, 0.13062, 0.11886, 0.3862, 0.18205, 0.32656, 0.30555]
Predicted label: 0
Correct prediction
Energy consumption = 183.533768 pJ
sum error= 274
Actual label: 1
Output voltages: [0.26339, 0.73748, 0.25484, 0.26869, 0.26668, 0.062686, 0.40551, 0.040403, 0.3324, 0.27246]
Predicted label: 1
Correct prediction
Energy consumption = 198.490005 pJ
sum error= 274
Actual label: 2
Output voltages: [0.28041, 0.11882, 0.72012, 0.32685, 0.12364, 0.043, 0.12844, 0.42559, 0.49829, 0.13869]
Predicted label: 2
Correct prediction
Energy consumption = 181.007500 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 814 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 814 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 814 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.37366, 0.11141, 0.34699, 0.73994, 0.16456, 0.23668, 0.1238, 0.19007, 0.55813, 0.16892]
Predicted label: 3
Correct prediction
Energy consumption = 185.789227 pJ
sum error= 274
Actual label: 4
Output voltages: [0.22916, 0.10808, 0.33777, 0.24654, 0.74008, 0.052859, 0.17491, 0.18716, 0.25976, 0.24914]
Predicted label: 4
Correct prediction
Energy consumption = 186.630866 pJ
sum error= 274
Actual label: 5
Output voltages: [0.27494, 0.098016, 0.047839, 0.37075, 0.27579, 0.73952, 0.3458, 0.13092, 0.38789, 0.21192]
Predicted label: 5
Correct prediction
Energy consumption = 189.476029 pJ
sum error= 274
Actual label: 6
Output voltages: [0.30365, 0.15266, 0.1795, 0.22026, 0.27876, 0.46834, 0.66063, 0.049268, 0.35051, 0.11866]
Predicted label: 6
Correct prediction
Energy consumption = 184.893243 pJ
sum error= 274
Actual label: 7
Output voltages: [0.29962, 0.27343, 0.44511, 0.32945, 0.13603, 0.036567, 0.044047, 0.69721, 0.33289, 0.3121]
Predicted label: 7
Correct prediction
Energy consumption = 195.830737 pJ
sum error= 274
Actual label: 8
Output voltages: [0.22145, 0.18026, 0.24557, 0.33543, 0.1189, 0.35659, 0.3126, 0.090367, 0.73462, 0.20066]
Predicted label: 8
Correct prediction
Energy consumption = 187.303707 pJ
sum error= 274
Actual label: 9
Output voltages: [0.30857, 0.17174, 0.18837, 0.22126, 0.26334, 0.14727, 0.058777, 0.13889, 0.43781, 0.67894]
Predicted label: 9
Correct prediction
Energy consumption = 185.309014 pJ
sum error= 274
Actual label: 8
Output voltages: [0.21502, 0.21896, 0.30605, 0.2262, 0.21308, 0.17834, 0.20115, 0.097908, 0.73619, 0.28748]
Predicted label: 8
Correct prediction
Energy consumption = 188.593046 pJ
sum error= 274
Actual label: 6
Output voltages: [0.26706, 0.1731, 0.26424, 0.15791, 0.31737, 0.38164, 0.73348, 0.052261, 0.41415, 0.1979]
Predicted label: 6
Correct prediction
Energy consumption = 186.423850 pJ
sum error= 274
Actual label: 5
Output voltages: [0.21827, 0.060509, 0.060072, 0.29537, 0.25504, 0.7349, 0.26146, 0.19768, 0.51711, 0.25142]
Predicted label: 5
Correct prediction
Energy consumption = 184.548104 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 815 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 815 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 815 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30441, 0.098748, 0.18087, 0.25689, 0.26692, 0.18768, 0.067211, 0.34861, 0.47795, 0.5948]
Predicted label: 9
Correct prediction
Energy consumption = 194.351810 pJ
sum error= 274
Actual label: 7
Output voltages: [0.33503, 0.30434, 0.47438, 0.2526, 0.10809, 0.04725, 0.046244, 0.72252, 0.33966, 0.3469]
Predicted label: 7
Correct prediction
Energy consumption = 194.040270 pJ
sum error= 274
Actual label: 0
Output voltages: [0.73765, 0.25181, 0.28419, 0.18709, 0.13438, 0.15387, 0.40799, 0.16821, 0.27834, 0.23494]
Predicted label: 0
Correct prediction
Energy consumption = 190.334117 pJ
sum error= 274
Actual label: 2
Output voltages: [0.32141, 0.18673, 0.75046, 0.32999, 0.18472, 0.037914, 0.22273, 0.23327, 0.43474, 0.18008]
Predicted label: 2
Correct prediction
Energy consumption = 184.113499 pJ
sum error= 274
Actual label: 3
Output voltages: [0.32128, 0.17131, 0.29788, 0.75716, 0.18168, 0.2065, 0.10691, 0.2436, 0.4585, 0.26597]
Predicted label: 3
Correct prediction
Energy consumption = 181.017696 pJ
sum error= 274
Actual label: 4
Output voltages: [0.13674, 0.23132, 0.30377, 0.20429, 0.75915, 0.080989, 0.30152, 0.29534, 0.15361, 0.2169]
Predicted label: 4
Correct prediction
Energy consumption = 192.268589 pJ
sum error= 274
Actual label: 3
Output voltages: [0.26358, 0.18804, 0.25384, 0.65059, 0.1252, 0.2174, 0.074053, 0.20865, 0.48685, 0.40658]
Predicted label: 3
Correct prediction
Energy consumption = 180.676626 pJ
sum error= 274
Actual label: 8
Output voltages: [0.15998, 0.22622, 0.28812, 0.20353, 0.17491, 0.21878, 0.24799, 0.14423, 0.74869, 0.29537]
Predicted label: 8
Correct prediction
Energy consumption = 182.350396 pJ
sum error= 274
Actual label: 5
Output voltages: [0.36447, 0.048328, 0.068201, 0.31069, 0.23504, 0.69481, 0.37494, 0.1168, 0.42822, 0.1549]
Predicted label: 5
Correct prediction
Energy consumption = 192.115946 pJ
sum error= 274
Actual label: 1
Output voltages: [0.16853, 0.71895, 0.27662, 0.31453, 0.30049, 0.040184, 0.27045, 0.32217, 0.23709, 0.24019]
Predicted label: 1
Correct prediction
Energy consumption = 204.757034 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 816 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 816 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 816 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.42588, 0.06628, 0.04309, 0.40768, 0.24062, 0.62911, 0.30905, 0.11204, 0.39462, 0.28621]
Predicted label: 5
Correct prediction
Energy consumption = 195.649434 pJ
sum error= 274
Actual label: 2
Output voltages: [0.3354, 0.20094, 0.75367, 0.32913, 0.19205, 0.037161, 0.22247, 0.29386, 0.42462, 0.2328]
Predicted label: 2
Correct prediction
Energy consumption = 184.569428 pJ
sum error= 274
Actual label: 3
Output voltages: [0.3026, 0.11675, 0.40552, 0.74653, 0.12938, 0.14935, 0.13627, 0.20706, 0.4982, 0.23186]
Predicted label: 3
Correct prediction
Energy consumption = 180.215292 pJ
sum error= 274
Actual label: 0
Output voltages: [0.69137, 0.25319, 0.32594, 0.14957, 0.14617, 0.12989, 0.46264, 0.22315, 0.24132, 0.30008]
Predicted label: 0
Correct prediction
Energy consumption = 184.299729 pJ
sum error= 274
Actual label: 1
Output voltages: [0.27193, 0.68606, 0.3194, 0.18914, 0.347, 0.076641, 0.34079, 0.11773, 0.30938, 0.18049]
Predicted label: 1
Correct prediction
Energy consumption = 199.800640 pJ
sum error= 274
Actual label: 2
Output voltages: [0.26121, 0.25904, 0.72533, 0.37634, 0.26741, 0.030979, 0.17454, 0.38514, 0.26999, 0.21686]
Predicted label: 2
Correct prediction
Energy consumption = 183.546906 pJ
sum error= 274
Actual label: 1
Output voltages: [0.27561, 0.7432, 0.28346, 0.20064, 0.23617, 0.12595, 0.37913, 0.058095, 0.36587, 0.21419]
Predicted label: 1
Correct prediction
Energy consumption = 202.272846 pJ
sum error= 274
Actual label: 3
Output voltages: [0.28095, 0.15278, 0.3388, 0.75061, 0.17836, 0.21693, 0.11337, 0.22992, 0.48777, 0.26156]
Predicted label: 3
Correct prediction
Energy consumption = 185.904455 pJ
sum error= 274
Actual label: 2
Output voltages: [0.35078, 0.30278, 0.73508, 0.43313, 0.19914, 0.031543, 0.22883, 0.18961, 0.33386, 0.17661]
Predicted label: 2
Correct prediction
Energy consumption = 181.994726 pJ
sum error= 274
Actual label: 6
Output voltages: [0.31038, 0.20739, 0.3137, 0.18244, 0.25907, 0.32221, 0.73844, 0.04818, 0.40138, 0.21446]
Predicted label: 6
Correct prediction
Energy consumption = 182.094744 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 817 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 817 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 817 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.37229, 0.088757, 0.047832, 0.34605, 0.23344, 0.73072, 0.35828, 0.19475, 0.37543, 0.14073]
Predicted label: 5
Correct prediction
Energy consumption = 186.839331 pJ
sum error= 274
Actual label: 3
Output voltages: [0.2774, 0.12824, 0.2847, 0.73542, 0.20605, 0.25843, 0.089502, 0.23434, 0.49548, 0.18813]
Predicted label: 3
Correct prediction
Energy consumption = 188.097057 pJ
sum error= 274
Actual label: 0
Output voltages: [0.72715, 0.26662, 0.28801, 0.14875, 0.13204, 0.10916, 0.40709, 0.2283, 0.28308, 0.26248]
Predicted label: 0
Correct prediction
Energy consumption = 186.824364 pJ
sum error= 274
Actual label: 7
Output voltages: [0.29351, 0.2842, 0.38978, 0.25616, 0.13613, 0.055343, 0.049895, 0.75773, 0.3488, 0.32749]
Predicted label: 7
Correct prediction
Energy consumption = 189.118820 pJ
sum error= 274
Actual label: 2
Output voltages: [0.38161, 0.13505, 0.6997, 0.39343, 0.2191, 0.035148, 0.22278, 0.24792, 0.45767, 0.22751]
Predicted label: 2
Correct prediction
Energy consumption = 180.673559 pJ
sum error= 274
Actual label: 7
Output voltages: [0.31434, 0.31331, 0.39676, 0.26163, 0.12596, 0.059458, 0.047367, 0.7317, 0.32591, 0.37206]
Predicted label: 7
Correct prediction
Energy consumption = 193.773520 pJ
sum error= 274
Actual label: 4
Output voltages: [0.1562, 0.13507, 0.26127, 0.075215, 0.75251, 0.10479, 0.28324, 0.28392, 0.29975, 0.18749]
Predicted label: 4
Correct prediction
Energy consumption = 190.603733 pJ
sum error= 274
Actual label: 6
Output voltages: [0.2873, 0.17168, 0.2941, 0.14929, 0.31876, 0.30228, 0.73265, 0.046904, 0.37191, 0.21253]
Predicted label: 6
Correct prediction
Energy consumption = 183.723140 pJ
sum error= 274
Actual label: 4
Output voltages: [0.22488, 0.16946, 0.32088, 0.12417, 0.75872, 0.10723, 0.29587, 0.20372, 0.261, 0.19686]
Predicted label: 4
Correct prediction
Energy consumption = 187.534153 pJ
sum error= 274
Actual label: 0
Output voltages: [0.73639, 0.22793, 0.32748, 0.18809, 0.10542, 0.18013, 0.39414, 0.18172, 0.29828, 0.22491]
Predicted label: 0
Correct prediction
Energy consumption = 189.286621 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 818 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 818 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 818 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25592, 0.065674, 0.052771, 0.30229, 0.19352, 0.72816, 0.34578, 0.21444, 0.44181, 0.2058]
Predicted label: 5
Correct prediction
Energy consumption = 192.909901 pJ
sum error= 274
Actual label: 9
Output voltages: [0.30696, 0.058874, 0.17822, 0.1891, 0.27043, 0.40445, 0.14279, 0.22115, 0.45804, 0.52946]
Predicted label: 9
Correct prediction
Energy consumption = 190.928906 pJ
sum error= 274
Actual label: 9
Output voltages: [0.49332, 0.070381, 0.1842, 0.19244, 0.39279, 0.17439, 0.19055, 0.16379, 0.32851, 0.57784]
Predicted label: 9
Correct prediction
Energy consumption = 192.282665 pJ
sum error= 274
Actual label: 8
Output voltages: [0.2675, 0.076406, 0.084568, 0.41251, 0.16823, 0.4773, 0.357, 0.071634, 0.59278, 0.14024]
Predicted label: 8
Correct prediction
Energy consumption = 188.664993 pJ
sum error= 274
Actual label: 9
Output voltages: [0.3355, 0.097323, 0.18813, 0.21001, 0.33433, 0.19398, 0.06316, 0.19569, 0.4285, 0.61586]
Predicted label: 9
Correct prediction
Energy consumption = 188.632815 pJ
sum error= 274
Actual label: 5
Output voltages: [0.27577, 0.056873, 0.12473, 0.42799, 0.17941, 0.61896, 0.30971, 0.089631, 0.44487, 0.3235]
Predicted label: 5
Correct prediction
Energy consumption = 193.994872 pJ
sum error= 274
Actual label: 3
Output voltages: [0.24296, 0.14845, 0.26181, 0.73448, 0.17534, 0.27779, 0.071105, 0.25339, 0.5493, 0.2299]
Predicted label: 3
Correct prediction
Energy consumption = 172.559292 pJ
sum error= 274
Actual label: 1
Output voltages: [0.2174, 0.71348, 0.25718, 0.21344, 0.367, 0.052936, 0.27024, 0.16236, 0.32806, 0.21707]
Predicted label: 1
Correct prediction
Energy consumption = 197.604672 pJ
sum error= 274
Actual label: 7
Output voltages: [0.31549, 0.24539, 0.36751, 0.21073, 0.10364, 0.06164, 0.070708, 0.75287, 0.33856, 0.28167]
Predicted label: 7
Correct prediction
Energy consumption = 198.989257 pJ
sum error= 274
Actual label: 4
Output voltages: [0.12741, 0.20929, 0.2683, 0.15032, 0.75551, 0.1019, 0.31343, 0.33274, 0.17081, 0.20695]
Predicted label: 4
Correct prediction
Energy consumption = 186.043360 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 819 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 819 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 819 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.36518, 0.27204, 0.41187, 0.24835, 0.15509, 0.051206, 0.056635, 0.74024, 0.28671, 0.39406]
Predicted label: 7
Correct prediction
Energy consumption = 193.934016 pJ
sum error= 274
Actual label: 6
Output voltages: [0.27201, 0.20228, 0.36043, 0.065779, 0.31897, 0.32943, 0.74048, 0.054442, 0.40143, 0.13667]
Predicted label: 6
Correct prediction
Energy consumption = 187.487680 pJ
sum error= 274
Actual label: 5
Output voltages: [0.25591, 0.046311, 0.12067, 0.35641, 0.22415, 0.68855, 0.3727, 0.17163, 0.46541, 0.19086]
Predicted label: 5
Correct prediction
Energy consumption = 188.661793 pJ
sum error= 274
Actual label: 4
Output voltages: [0.20674, 0.13048, 0.31526, 0.12542, 0.73786, 0.082781, 0.30909, 0.26457, 0.27526, 0.17061]
Predicted label: 4
Correct prediction
Energy consumption = 191.286372 pJ
sum error= 274
Actual label: 0
Output voltages: [0.67057, 0.21017, 0.35744, 0.18581, 0.25327, 0.057471, 0.40737, 0.21341, 0.36125, 0.17343]
Predicted label: 0
Correct prediction
Energy consumption = 190.766702 pJ
sum error= 274
Actual label: 0
Output voltages: [0.72558, 0.23926, 0.27525, 0.16944, 0.16343, 0.12874, 0.44833, 0.15265, 0.30069, 0.27029]
Predicted label: 0
Correct prediction
Energy consumption = 183.028633 pJ
sum error= 274
Actual label: 6
Output voltages: [0.35047, 0.20227, 0.30261, 0.078804, 0.25084, 0.38235, 0.66946, 0.042839, 0.2888, 0.18868]
Predicted label: 6
Correct prediction
Energy consumption = 182.408074 pJ
sum error= 274
Actual label: 6
Output voltages: [0.29069, 0.14312, 0.21894, 0.16988, 0.27382, 0.43714, 0.67413, 0.040121, 0.4654, 0.19944]
Predicted label: 6
Correct prediction
Energy consumption = 183.019015 pJ
sum error= 274
Actual label: 2
Output voltages: [0.24257, 0.12455, 0.74035, 0.31479, 0.30084, 0.053236, 0.20699, 0.25028, 0.35974, 0.25378]
Predicted label: 2
Correct prediction
Energy consumption = 187.299691 pJ
sum error= 274
Actual label: 0
Output voltages: [0.73711, 0.23842, 0.26261, 0.15818, 0.13385, 0.14067, 0.43215, 0.26826, 0.27381, 0.26449]
Predicted label: 0
Correct prediction
Energy consumption = 184.041798 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 820 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 820 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 820 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31602, 0.15398, 0.35409, 0.084004, 0.31192, 0.28903, 0.67925, 0.045182, 0.45516, 0.17516]
Predicted label: 6
Correct prediction
Energy consumption = 189.951908 pJ
sum error= 274
Actual label: 3
Output voltages: [0.34673, 0.090803, 0.29717, 0.72247, 0.18421, 0.30649, 0.074394, 0.19471, 0.50921, 0.27424]
Predicted label: 3
Correct prediction
Energy consumption = 187.219936 pJ
sum error= 274
Actual label: 7
Output voltages: [0.26694, 0.31688, 0.42433, 0.28078, 0.21017, 0.053487, 0.037362, 0.72317, 0.23118, 0.31119]
Predicted label: 7
Correct prediction
Energy consumption = 197.094445 pJ
sum error= 274
Actual label: 7
Output voltages: [0.43946, 0.23865, 0.19509, 0.20852, 0.25183, 0.18332, 0.048523, 0.74308, 0.30851, 0.31117]
Predicted label: 7
Correct prediction
Energy consumption = 183.712691 pJ
sum error= 274
Actual label: 4
Output voltages: [0.24682, 0.16615, 0.41609, 0.19374, 0.73991, 0.038553, 0.24314, 0.25137, 0.18797, 0.2543]
Predicted label: 4
Correct prediction
Energy consumption = 191.997035 pJ
sum error= 274
Actual label: 4
Output voltages: [0.13612, 0.1724, 0.33222, 0.21367, 0.73476, 0.065194, 0.30163, 0.33844, 0.18946, 0.18941]
Predicted label: 4
Correct prediction
Energy consumption = 187.388756 pJ
sum error= 274
Actual label: 3
Output voltages: [0.36539, 0.15413, 0.3197, 0.75803, 0.17295, 0.19009, 0.12488, 0.25511, 0.46887, 0.21448]
Predicted label: 3
Correct prediction
Energy consumption = 180.959313 pJ
sum error= 274
Actual label: 9
Output voltages: [0.34175, 0.096114, 0.17254, 0.31198, 0.34858, 0.19658, 0.1151, 0.23412, 0.41779, 0.61601]
Predicted label: 9
Correct prediction
Energy consumption = 188.657960 pJ
sum error= 274
Actual label: 2
Output voltages: [0.36893, 0.1309, 0.75073, 0.29285, 0.16756, 0.052071, 0.2173, 0.32156, 0.47899, 0.14961]
Predicted label: 2
Correct prediction
Energy consumption = 185.722781 pJ
sum error= 274
Actual label: 8
Output voltages: [0.27665, 0.11662, 0.31607, 0.25556, 0.22853, 0.25433, 0.29779, 0.082069, 0.73709, 0.19926]
Predicted label: 8
Correct prediction
Energy consumption = 196.880607 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 821 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 821 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 821 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3575, 0.12233, 0.16605, 0.30081, 0.45546, 0.26971, 0.27148, 0.12167, 0.25412, 0.65872]
Predicted label: 9
Correct prediction
Energy consumption = 196.916045 pJ
sum error= 274
Actual label: 6
Output voltages: [0.27369, 0.19176, 0.31083, 0.099993, 0.34975, 0.34446, 0.73759, 0.046632, 0.40094, 0.16983]
Predicted label: 6
Correct prediction
Energy consumption = 183.102420 pJ
sum error= 274
Actual label: 0
Output voltages: [0.65973, 0.26028, 0.25529, 0.08845, 0.20674, 0.095669, 0.43355, 0.2881, 0.20192, 0.30957]
Predicted label: 0
Correct prediction
Energy consumption = 189.297619 pJ
sum error= 274
Actual label: 9
Output voltages: [0.41018, 0.12209, 0.25007, 0.29012, 0.37306, 0.18525, 0.19245, 0.15758, 0.26161, 0.6897]
Predicted label: 9
Correct prediction
Energy consumption = 186.910618 pJ
sum error= 274
Actual label: 5
Output voltages: [0.2284, 0.044401, 0.05629, 0.31471, 0.26198, 0.68912, 0.38726, 0.12996, 0.51375, 0.24849]
Predicted label: 5
Correct prediction
Energy consumption = 183.386394 pJ
sum error= 274
Actual label: 3
Output voltages: [0.30769, 0.090341, 0.25935, 0.71444, 0.18223, 0.32186, 0.102, 0.22124, 0.49119, 0.25599]
Predicted label: 3
Correct prediction
Energy consumption = 177.590633 pJ
sum error= 274
Actual label: 8
Output voltages: [0.21229, 0.1774, 0.31015, 0.34902, 0.17154, 0.17894, 0.29076, 0.082873, 0.70851, 0.23814]
Predicted label: 8
Correct prediction
Energy consumption = 195.139472 pJ
sum error= 274
Actual label: 8
Output voltages: [0.25049, 0.14415, 0.27178, 0.29014, 0.1656, 0.27489, 0.17802, 0.071043, 0.68641, 0.37331]
Predicted label: 8
Correct prediction
Energy consumption = 189.319985 pJ
sum error= 274
Actual label: 7
Output voltages: [0.35339, 0.26952, 0.47266, 0.3183, 0.1383, 0.031618, 0.055224, 0.68966, 0.27684, 0.30239]
Predicted label: 7
Correct prediction
Energy consumption = 198.663784 pJ
sum error= 274
Actual label: 1
Output voltages: [0.23376, 0.75718, 0.28887, 0.18303, 0.31738, 0.068427, 0.38702, 0.097923, 0.264, 0.27254]
Predicted label: 1
Correct prediction
Energy consumption = 196.128624 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 822 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 822 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 822 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15224, 0.13692, 0.27329, 0.18457, 0.75065, 0.073108, 0.25017, 0.36773, 0.25109, 0.11576]
Predicted label: 4
Correct prediction
Energy consumption = 193.545203 pJ
sum error= 274
Actual label: 0
Output voltages: [0.74084, 0.22884, 0.28531, 0.16812, 0.17809, 0.11158, 0.4207, 0.21092, 0.28107, 0.26069]
Predicted label: 0
Correct prediction
Energy consumption = 192.287126 pJ
sum error= 274
Actual label: 4
Output voltages: [0.13154, 0.19378, 0.31175, 0.22219, 0.75456, 0.068349, 0.22589, 0.29191, 0.18963, 0.22245]
Predicted label: 4
Correct prediction
Energy consumption = 191.678944 pJ
sum error= 274
Actual label: 8
Output voltages: [0.20004, 0.16753, 0.38452, 0.24006, 0.19013, 0.17229, 0.29696, 0.10315, 0.72882, 0.25443]
Predicted label: 8
Correct prediction
Energy consumption = 187.236673 pJ
sum error= 274
Actual label: 5
Output voltages: [0.28673, 0.055339, 0.088922, 0.36881, 0.21512, 0.71281, 0.36231, 0.16838, 0.4929, 0.2061]
Predicted label: 5
Correct prediction
Energy consumption = 182.305703 pJ
sum error= 274
Actual label: 2
Output voltages: [0.32221, 0.19318, 0.74433, 0.33268, 0.12784, 0.037854, 0.18862, 0.29753, 0.42183, 0.15055]
Predicted label: 2
Correct prediction
Energy consumption = 179.647586 pJ
sum error= 274
Actual label: 3
Output voltages: [0.35618, 0.11852, 0.39648, 0.73252, 0.13628, 0.11791, 0.1144, 0.16588, 0.4993, 0.22191]
Predicted label: 3
Correct prediction
Energy consumption = 184.560585 pJ
sum error= 274
Actual label: 9
Output voltages: [0.41978, 0.084855, 0.20798, 0.16603, 0.34065, 0.17102, 0.13647, 0.19438, 0.43346, 0.61671]
Predicted label: 9
Correct prediction
Energy consumption = 186.666031 pJ
sum error= 274
Actual label: 0
Output voltages: [0.59057, 0.1428, 0.32181, 0.15182, 0.44002, 0.061384, 0.48335, 0.23874, 0.2675, 0.22611]
Predicted label: 0
Correct prediction
Energy consumption = 198.713565 pJ
sum error= 274
Actual label: 1
Output voltages: [0.28498, 0.61354, 0.24792, 0.13028, 0.4279, 0.10625, 0.31391, 0.047907, 0.38437, 0.2501]
Predicted label: 1
Correct prediction
Energy consumption = 195.272623 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 823 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 823 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 823 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39991, 0.08155, 0.19669, 0.2918, 0.34652, 0.19581, 0.11819, 0.26327, 0.32963, 0.58446]
Predicted label: 9
Correct prediction
Energy consumption = 198.500724 pJ
sum error= 274
Actual label: 1
Output voltages: [0.19716, 0.69772, 0.29851, 0.21971, 0.33345, 0.071581, 0.32935, 0.080062, 0.37386, 0.22264]
Predicted label: 1
Correct prediction
Energy consumption = 195.440178 pJ
sum error= 274
Actual label: 5
Output voltages: [0.39373, 0.070017, 0.057807, 0.4651, 0.19348, 0.73596, 0.26027, 0.13571, 0.38685, 0.22456]
Predicted label: 5
Correct prediction
Energy consumption = 189.931995 pJ
sum error= 274
Actual label: 1
Output voltages: [0.25281, 0.68726, 0.22512, 0.13873, 0.36453, 0.1531, 0.38752, 0.069241, 0.40218, 0.201]
Predicted label: 1
Correct prediction
Energy consumption = 199.852205 pJ
sum error= 274
Actual label: 7
Output voltages: [0.26496, 0.28027, 0.35804, 0.26902, 0.13114, 0.056321, 0.037724, 0.73707, 0.37576, 0.36893]
Predicted label: 7
Correct prediction
Energy consumption = 195.047199 pJ
sum error= 274
Actual label: 4
Output voltages: [0.17338, 0.13302, 0.3441, 0.13462, 0.7519, 0.057408, 0.30283, 0.32212, 0.20055, 0.23578]
Predicted label: 4
Correct prediction
Energy consumption = 183.267512 pJ
sum error= 274
Actual label: 8
Output voltages: [0.19106, 0.23408, 0.23641, 0.20768, 0.29064, 0.28468, 0.45641, 0.1009, 0.66095, 0.21141]
Predicted label: 8
Correct prediction
Energy consumption = 189.480831 pJ
sum error= 274
Actual label: 6
Output voltages: [0.31119, 0.19725, 0.30913, 0.13291, 0.31757, 0.36701, 0.73135, 0.048366, 0.42936, 0.19477]
Predicted label: 6
Correct prediction
Energy consumption = 180.205417 pJ
sum error= 274
Actual label: 2
Output voltages: [0.3134, 0.13728, 0.75044, 0.29005, 0.15881, 0.044414, 0.23268, 0.3028, 0.44447, 0.18992]
Predicted label: 2
Correct prediction
Energy consumption = 178.493713 pJ
sum error= 274
Actual label: 1
Output voltages: [0.24623, 0.66753, 0.20277, 0.23418, 0.33875, 0.13228, 0.42056, 0.041388, 0.41316, 0.23586]
Predicted label: 1
Correct prediction
Energy consumption = 195.861977 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 824 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 824 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 824 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.28975, 0.097981, 0.23467, 0.1284, 0.339, 0.40055, 0.69183, 0.054182, 0.47081, 0.15378]
Predicted label: 6
Correct prediction
Energy consumption = 185.793527 pJ
sum error= 274
Actual label: 8
Output voltages: [0.3164, 0.22676, 0.38419, 0.19651, 0.27845, 0.113, 0.30675, 0.059824, 0.70036, 0.26698]
Predicted label: 8
Correct prediction
Energy consumption = 195.504957 pJ
sum error= 274
Actual label: 8
Output voltages: [0.2009, 0.21786, 0.24328, 0.17877, 0.30026, 0.28336, 0.32577, 0.12161, 0.69687, 0.18615]
Predicted label: 8
Correct prediction
Energy consumption = 195.266059 pJ
sum error= 274
Actual label: 0
Output voltages: [0.66259, 0.090119, 0.29171, 0.089411, 0.30655, 0.19925, 0.4874, 0.25699, 0.25104, 0.1709]
Predicted label: 0
Correct prediction
Energy consumption = 196.667664 pJ
sum error= 274
Actual label: 1
Output voltages: [0.23025, 0.62693, 0.19426, 0.27352, 0.38239, 0.11654, 0.30697, 0.067473, 0.33461, 0.23744]
Predicted label: 1
Correct prediction
Energy consumption = 199.474016 pJ
sum error= 274
Actual label: 2
Output voltages: [0.29326, 0.21201, 0.75152, 0.25694, 0.26778, 0.034057, 0.1878, 0.3451, 0.28982, 0.24288]
Predicted label: 2
Correct prediction
Energy consumption = 187.806529 pJ
sum error= 274
Actual label: 3
Output voltages: [0.29151, 0.11712, 0.22217, 0.51897, 0.20692, 0.3761, 0.13823, 0.098282, 0.53553, 0.37289]
Predicted label: 8
Wrong prediction!
Energy consumption = 189.604509 pJ
sum error= 275
Actual label: 4
Output voltages: [0.13257, 0.13137, 0.31157, 0.10102, 0.71347, 0.10256, 0.28877, 0.22401, 0.37191, 0.17758]
Predicted label: 4
Correct prediction
Energy consumption = 182.180693 pJ
sum error= 275
Actual label: 7
Output voltages: [0.34537, 0.23352, 0.3453, 0.32427, 0.090495, 0.048536, 0.047579, 0.7483, 0.42146, 0.24073]
Predicted label: 7
Correct prediction
Energy consumption = 195.321928 pJ
sum error= 275
Actual label: 8
Output voltages: [0.27268, 0.2219, 0.29918, 0.20591, 0.15561, 0.18611, 0.22747, 0.14288, 0.74282, 0.32347]
Predicted label: 8
Correct prediction
Energy consumption = 176.333111 pJ
sum error= 275
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 825 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 825 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 825 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36836, 0.12568, 0.20945, 0.27401, 0.3243, 0.19241, 0.13394, 0.15458, 0.38734, 0.68504]
Predicted label: 9
Correct prediction
Energy consumption = 186.008939 pJ
sum error= 275
Actual label: 0
Output voltages: [0.73035, 0.23403, 0.25127, 0.21372, 0.17657, 0.16265, 0.41078, 0.127, 0.29776, 0.25204]
Predicted label: 0
Correct prediction
Energy consumption = 193.871597 pJ
sum error= 275
Actual label: 1
Output voltages: [0.26081, 0.73855, 0.2299, 0.17685, 0.41843, 0.065745, 0.28527, 0.19566, 0.22193, 0.2806]
Predicted label: 1
Correct prediction
Energy consumption = 200.580775 pJ
sum error= 275
Actual label: 2
Output voltages: [0.28898, 0.13926, 0.74377, 0.28799, 0.3011, 0.03505, 0.18199, 0.2385, 0.38746, 0.30084]
Predicted label: 2
Correct prediction
Energy consumption = 181.390796 pJ
sum error= 275
Actual label: 3
Output voltages: [0.34688, 0.17391, 0.29875, 0.73361, 0.13862, 0.23314, 0.1341, 0.22012, 0.51357, 0.15263]
Predicted label: 3
Correct prediction
Energy consumption = 192.573268 pJ
sum error= 275
Actual label: 4
Output voltages: [0.22668, 0.07277, 0.28162, 0.19239, 0.68318, 0.11926, 0.27716, 0.16864, 0.40727, 0.1541]
Predicted label: 4
Correct prediction
Energy consumption = 194.375489 pJ
sum error= 275
Actual label: 6
Output voltages: [0.25814, 0.16975, 0.36878, 0.092833, 0.48869, 0.29408, 0.72003, 0.094102, 0.30887, 0.085571]
Predicted label: 6
Correct prediction
Energy consumption = 186.736863 pJ
sum error= 275
Actual label: 7
Output voltages: [0.24081, 0.28148, 0.49395, 0.24808, 0.091751, 0.045287, 0.05529, 0.73425, 0.43824, 0.24734]
Predicted label: 7
Correct prediction
Energy consumption = 200.231656 pJ
sum error= 275
Actual label: 8
Output voltages: [0.20054, 0.16181, 0.2284, 0.26479, 0.14129, 0.28661, 0.19681, 0.14458, 0.75016, 0.26494]
Predicted label: 8
Correct prediction
Energy consumption = 186.678291 pJ
sum error= 275
Actual label: 9
Output voltages: [0.2826, 0.053453, 0.1872, 0.21259, 0.2768, 0.30072, 0.14089, 0.29533, 0.46731, 0.57666]
Predicted label: 9
Correct prediction
Energy consumption = 185.447074 pJ
sum error= 275
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 826 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 826 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 826 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.67044, 0.13848, 0.25347, 0.10646, 0.23062, 0.19654, 0.46295, 0.1752, 0.21057, 0.36717]
Predicted label: 0
Correct prediction
Energy consumption = 190.538731 pJ
sum error= 275
Actual label: 1
Output voltages: [0.23192, 0.72165, 0.30812, 0.17583, 0.3276, 0.083459, 0.43156, 0.061396, 0.31034, 0.18557]
Predicted label: 1
Correct prediction
Energy consumption = 201.188019 pJ
sum error= 275
Actual label: 2
Output voltages: [0.24746, 0.22798, 0.7397, 0.34645, 0.21522, 0.039795, 0.21997, 0.29497, 0.33578, 0.14631]
Predicted label: 2
Correct prediction
Energy consumption = 181.868115 pJ
sum error= 275
Actual label: 3
Output voltages: [0.2801, 0.22652, 0.28531, 0.75281, 0.18935, 0.18884, 0.09966, 0.22767, 0.43842, 0.29214]
Predicted label: 3
Correct prediction
Energy consumption = 190.000546 pJ
sum error= 275
Actual label: 4
Output voltages: [0.21926, 0.12949, 0.38038, 0.23487, 0.70536, 0.038191, 0.17718, 0.21917, 0.30555, 0.20275]
Predicted label: 4
Correct prediction
Energy consumption = 182.886994 pJ
sum error= 275
Actual label: 7
Output voltages: [0.40951, 0.10758, 0.29725, 0.34678, 0.052026, 0.20837, 0.067441, 0.68089, 0.47913, 0.2899]
Predicted label: 7
Correct prediction
Energy consumption = 198.139443 pJ
sum error= 275
Actual label: 8
Output voltages: [0.17805, 0.19391, 0.24564, 0.2332, 0.16816, 0.29815, 0.18589, 0.15315, 0.75765, 0.27266]
Predicted label: 8
Correct prediction
Energy consumption = 189.755386 pJ
sum error= 275
Actual label: 9
Output voltages: [0.33175, 0.065315, 0.21622, 0.15008, 0.35914, 0.23953, 0.17654, 0.20422, 0.43944, 0.59854]
Predicted label: 9
Correct prediction
Energy consumption = 187.585187 pJ
sum error= 275
Actual label: 1
Output voltages: [0.15169, 0.74186, 0.28789, 0.22945, 0.32481, 0.050095, 0.29854, 0.1493, 0.27185, 0.21027]
Predicted label: 1
Correct prediction
Energy consumption = 194.817178 pJ
sum error= 275
Actual label: 4
Output voltages: [0.13543, 0.18874, 0.30576, 0.24608, 0.75262, 0.069983, 0.15726, 0.24706, 0.22202, 0.25574]
Predicted label: 4
Correct prediction
Energy consumption = 190.430671 pJ
sum error= 275
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 827 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 827 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 827 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.37941, 0.10667, 0.045285, 0.21292, 0.25512, 0.68845, 0.37938, 0.18664, 0.43244, 0.24055]
Predicted label: 5
Correct prediction
Energy consumption = 196.890630 pJ
sum error= 275
Actual label: 3
Output voltages: [0.20862, 0.14381, 0.27955, 0.73516, 0.16039, 0.30339, 0.097337, 0.27696, 0.48896, 0.22487]
Predicted label: 3
Correct prediction
Energy consumption = 181.904569 pJ
sum error= 275
Actual label: 3
Output voltages: [0.24152, 0.20898, 0.29589, 0.73138, 0.14477, 0.15695, 0.10642, 0.15959, 0.52137, 0.21048]
Predicted label: 3
Correct prediction
Energy consumption = 182.768025 pJ
sum error= 275
Actual label: 0
Output voltages: [0.69719, 0.11451, 0.31243, 0.13773, 0.19573, 0.085217, 0.35368, 0.32853, 0.216, 0.37917]
Predicted label: 0
Correct prediction
Energy consumption = 188.077836 pJ
sum error= 275
Actual label: 9
Output voltages: [0.36303, 0.09638, 0.16262, 0.20944, 0.27127, 0.24195, 0.10256, 0.25013, 0.48309, 0.63669]
Predicted label: 9
Correct prediction
Energy consumption = 182.876893 pJ
sum error= 275
Actual label: 5
Output voltages: [0.44537, 0.07395, 0.095091, 0.32845, 0.14441, 0.71825, 0.42187, 0.13754, 0.43332, 0.11618]
Predicted label: 5
Correct prediction
Energy consumption = 191.092739 pJ
sum error= 275
Actual label: 4
Output voltages: [0.23265, 0.16239, 0.38776, 0.11982, 0.74898, 0.056903, 0.28146, 0.19803, 0.30271, 0.20152]
Predicted label: 4
Correct prediction
Energy consumption = 193.461841 pJ
sum error= 275
Actual label: 3
Output voltages: [0.22866, 0.16698, 0.21913, 0.70583, 0.29027, 0.26812, 0.19706, 0.060281, 0.42283, 0.27675]
Predicted label: 3
Correct prediction
Energy consumption = 192.467746 pJ
sum error= 275
Actual label: 0
Output voltages: [0.68454, 0.096016, 0.32113, 0.25951, 0.32528, 0.17265, 0.31583, 0.21048, 0.16626, 0.33856]
Predicted label: 0
Correct prediction
Energy consumption = 192.440020 pJ
sum error= 275
Actual label: 8
Output voltages: [0.24424, 0.055152, 0.24729, 0.14736, 0.19689, 0.21619, 0.24115, 0.39161, 0.65721, 0.25606]
Predicted label: 8
Correct prediction
Energy consumption = 192.652706 pJ
sum error= 275
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 828 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 828 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 828 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13609, 0.22734, 0.26057, 0.16376, 0.74193, 0.14521, 0.2776, 0.19186, 0.30099, 0.19727]
Predicted label: 4
Correct prediction
Energy consumption = 196.575616 pJ
sum error= 275
Actual label: 6
Output voltages: [0.34238, 0.30288, 0.29009, 0.18469, 0.26571, 0.29954, 0.67542, 0.11932, 0.38164, 0.055019]
Predicted label: 6
Correct prediction
Energy consumption = 190.415537 pJ
sum error= 275
Actual label: 7
Output voltages: [0.30096, 0.24929, 0.45237, 0.29452, 0.074752, 0.043018, 0.04872, 0.71859, 0.45498, 0.29447]
Predicted label: 7
Correct prediction
Energy consumption = 190.338540 pJ
sum error= 275
Actual label: 0
Output voltages: [0.70181, 0.17827, 0.34142, 0.14067, 0.26654, 0.16604, 0.43234, 0.23817, 0.19644, 0.22914]
Predicted label: 0
Correct prediction
Energy consumption = 192.364726 pJ
sum error= 275
Actual label: 7
Output voltages: [0.46563, 0.15707, 0.095422, 0.42258, 0.050449, 0.27357, 0.069349, 0.65407, 0.45666, 0.29756]
Predicted label: 7
Correct prediction
Energy consumption = 191.933423 pJ
sum error= 275
Actual label: 7
Output voltages: [0.26289, 0.31236, 0.42714, 0.24025, 0.12906, 0.047175, 0.043963, 0.74918, 0.33049, 0.34282]
Predicted label: 7
Correct prediction
Energy consumption = 187.685571 pJ
sum error= 275
Actual label: 1
Output voltages: [0.22638, 0.71312, 0.26286, 0.23587, 0.25614, 0.057758, 0.2218, 0.16935, 0.40301, 0.27184]
Predicted label: 1
Correct prediction
Energy consumption = 195.916814 pJ
sum error= 275
Actual label: 6
Output voltages: [0.34112, 0.21099, 0.21335, 0.22234, 0.27243, 0.3505, 0.64656, 0.16393, 0.45491, 0.052394]
Predicted label: 6
Correct prediction
Energy consumption = 194.134182 pJ
sum error= 275
Actual label: 9
Output voltages: [0.2543, 0.10365, 0.14278, 0.17235, 0.29407, 0.35745, 0.23376, 0.28416, 0.37991, 0.57121]
Predicted label: 9
Correct prediction
Energy consumption = 189.964664 pJ
sum error= 275
Actual label: 1
Output voltages: [0.23672, 0.71702, 0.20651, 0.21544, 0.39503, 0.059821, 0.26719, 0.18119, 0.26564, 0.28458]
Predicted label: 1
Correct prediction
Energy consumption = 200.411211 pJ
sum error= 275
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 829 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 829 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 829 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34311, 0.20475, 0.33, 0.7557, 0.12773, 0.18881, 0.15509, 0.17301, 0.4597, 0.16699]
Predicted label: 3
Correct prediction
Energy consumption = 194.795839 pJ
sum error= 275
Actual label: 6
Output voltages: [0.27004, 0.1946, 0.37327, 0.057547, 0.35989, 0.30721, 0.72083, 0.095255, 0.40164, 0.056831]
Predicted label: 6
Correct prediction
Energy consumption = 188.697631 pJ
sum error= 275
Actual label: 2
Output voltages: [0.39381, 0.22996, 0.71642, 0.30168, 0.17682, 0.028576, 0.27874, 0.38217, 0.31935, 0.11997]
Predicted label: 2
Correct prediction
Energy consumption = 196.021860 pJ
sum error= 275
Actual label: 3
Output voltages: [0.23578, 0.23043, 0.24546, 0.73554, 0.13931, 0.22232, 0.097366, 0.19913, 0.45562, 0.31466]
Predicted label: 3
Correct prediction
Energy consumption = 186.590047 pJ
sum error= 275
Actual label: 8
Output voltages: [0.2194, 0.13244, 0.30461, 0.22778, 0.18711, 0.1747, 0.13579, 0.16288, 0.73865, 0.29081]
Predicted label: 8
Correct prediction
Energy consumption = 190.045875 pJ
sum error= 275
Actual label: 2
Output voltages: [0.37744, 0.13086, 0.71917, 0.31385, 0.1287, 0.0402, 0.22756, 0.36797, 0.52408, 0.15801]
Predicted label: 2
Correct prediction
Energy consumption = 179.469920 pJ
sum error= 275
Actual label: 3
Output voltages: [0.24495, 0.15177, 0.30168, 0.64406, 0.17122, 0.33141, 0.12825, 0.18908, 0.53318, 0.18556]
Predicted label: 3
Correct prediction
Energy consumption = 188.845222 pJ
sum error= 275
Actual label: 8
Output voltages: [0.20097, 0.2296, 0.33661, 0.18739, 0.19274, 0.14217, 0.20918, 0.12809, 0.71941, 0.36184]
Predicted label: 8
Correct prediction
Energy consumption = 185.037020 pJ
sum error= 275
Actual label: 9
Output voltages: [0.28281, 0.084937, 0.12614, 0.22518, 0.38282, 0.32456, 0.21293, 0.1894, 0.33711, 0.60552]
Predicted label: 9
Correct prediction
Energy consumption = 186.854163 pJ
sum error= 275
Actual label: 5
Output voltages: [0.31337, 0.052614, 0.072771, 0.23316, 0.24042, 0.67408, 0.41986, 0.13718, 0.57506, 0.1315]
Predicted label: 5
Correct prediction
Energy consumption = 188.656578 pJ
sum error= 275
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 830 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 830 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 830 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18105, 0.099926, 0.27452, 0.30646, 0.18175, 0.21183, 0.15889, 0.16541, 0.74971, 0.2584]
Predicted label: 8
Correct prediction
Energy consumption = 192.717324 pJ
sum error= 275
Actual label: 8
Output voltages: [0.21461, 0.15361, 0.2525, 0.2421, 0.18729, 0.26696, 0.23179, 0.099183, 0.74689, 0.27693]
Predicted label: 8
Correct prediction
Energy consumption = 184.777913 pJ
sum error= 275
Actual label: 7
Output voltages: [0.43582, 0.13518, 0.29856, 0.39946, 0.10699, 0.11856, 0.044464, 0.73483, 0.38761, 0.35732]
Predicted label: 7
Correct prediction
Energy consumption = 193.055436 pJ
sum error= 275
Actual label: 1
Output voltages: [0.2198, 0.72811, 0.24989, 0.14793, 0.36542, 0.089997, 0.3171, 0.10495, 0.35639, 0.29066]
Predicted label: 1
Correct prediction
Energy consumption = 196.908331 pJ
sum error= 275
Actual label: 7
Output voltages: [0.51845, 0.16043, 0.31735, 0.38662, 0.033715, 0.26478, 0.056824, 0.55316, 0.4845, 0.29938]
Predicted label: 7
Correct prediction
Energy consumption = 195.529149 pJ
sum error= 275
Actual label: 1
Output voltages: [0.16474, 0.72731, 0.28335, 0.16425, 0.30978, 0.093234, 0.3261, 0.11422, 0.3625, 0.2225]
Predicted label: 1
Correct prediction
Energy consumption = 193.234906 pJ
sum error= 275
Actual label: 1
Output voltages: [0.284, 0.6792, 0.25646, 0.15655, 0.39848, 0.10673, 0.33933, 0.062064, 0.3532, 0.23293]
Predicted label: 1
Correct prediction
Energy consumption = 190.071880 pJ
sum error= 275
Actual label: 0
Output voltages: [0.73202, 0.25928, 0.29684, 0.16366, 0.12435, 0.12672, 0.41996, 0.20928, 0.27721, 0.24462]
Predicted label: 0
Correct prediction
Energy consumption = 189.800479 pJ
sum error= 275
Actual label: 3
Output voltages: [0.27838, 0.15806, 0.27263, 0.74929, 0.21104, 0.21259, 0.17683, 0.20129, 0.46506, 0.2639]
Predicted label: 3
Correct prediction
Energy consumption = 186.781734 pJ
sum error= 275
Actual label: 4
Output voltages: [0.13644, 0.1739, 0.3579, 0.16774, 0.66712, 0.062048, 0.21088, 0.10232, 0.43744, 0.19392]
Predicted label: 4
Correct prediction
Energy consumption = 182.459463 pJ
sum error= 275
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 831 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 831 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 831 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.26979, 0.24095, 0.74615, 0.3134, 0.18944, 0.032724, 0.30187, 0.24407, 0.35273, 0.14146]
Predicted label: 2
Correct prediction
Energy consumption = 185.317987 pJ
sum error= 275
Actual label: 6
Output voltages: [0.22488, 0.2145, 0.46929, 0.056824, 0.5331, 0.20646, 0.63913, 0.095129, 0.27733, 0.11384]
Predicted label: 6
Correct prediction
Energy consumption = 185.121339 pJ
sum error= 275
Actual label: 4
Output voltages: [0.11333, 0.19585, 0.24624, 0.081721, 0.7447, 0.11944, 0.20376, 0.26937, 0.30732, 0.22906]
Predicted label: 4
Correct prediction
Energy consumption = 191.573346 pJ
sum error= 275
Actual label: 7
Output voltages: [0.37339, 0.22298, 0.26235, 0.32245, 0.12981, 0.10388, 0.049752, 0.75698, 0.29075, 0.31534]
Predicted label: 7
Correct prediction
Energy consumption = 198.602975 pJ
sum error= 275
Actual label: 4
Output voltages: [0.16255, 0.19857, 0.28472, 0.20105, 0.75178, 0.065565, 0.22412, 0.26026, 0.23425, 0.23854]
Predicted label: 4
Correct prediction
Energy consumption = 194.240236 pJ
sum error= 275
Actual label: 2
Output voltages: [0.29844, 0.15809, 0.74074, 0.2664, 0.15929, 0.042256, 0.20345, 0.38395, 0.45934, 0.20385]
Predicted label: 2
Correct prediction
Energy consumption = 186.608980 pJ
sum error= 275
Actual label: 7
Output voltages: [0.40547, 0.23315, 0.55682, 0.23699, 0.052395, 0.091981, 0.10954, 0.53966, 0.49445, 0.22039]
Predicted label: 2
Wrong prediction!
Energy consumption = 188.544457 pJ
sum error= 276
Actual label: 4
Output voltages: [0.19598, 0.15953, 0.32711, 0.14346, 0.7185, 0.052124, 0.16542, 0.17928, 0.36379, 0.21633]
Predicted label: 4
Correct prediction
Energy consumption = 187.304513 pJ
sum error= 276
Actual label: 2
Output voltages: [0.3773, 0.12269, 0.68273, 0.28436, 0.16885, 0.036135, 0.2063, 0.27741, 0.50109, 0.18059]
Predicted label: 2
Correct prediction
Energy consumption = 191.221884 pJ
sum error= 276
Actual label: 9
Output voltages: [0.30464, 0.11727, 0.12319, 0.25705, 0.32517, 0.28385, 0.23673, 0.12531, 0.38021, 0.60396]
Predicted label: 9
Correct prediction
Energy consumption = 191.085764 pJ
sum error= 276
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 832 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 832 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 832 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32136, 0.14069, 0.69834, 0.32165, 0.15723, 0.029159, 0.17204, 0.45918, 0.43397, 0.1865]
Predicted label: 2
Correct prediction
Energy consumption = 185.519659 pJ
sum error= 276
Actual label: 7
Output voltages: [0.44136, 0.12722, 0.21498, 0.46208, 0.083099, 0.25121, 0.040981, 0.70356, 0.43051, 0.3829]
Predicted label: 7
Correct prediction
Energy consumption = 191.913811 pJ
sum error= 276
Actual label: 9
Output voltages: [0.30109, 0.068515, 0.12685, 0.21632, 0.41777, 0.30322, 0.25411, 0.23132, 0.26841, 0.57558]
Predicted label: 9
Correct prediction
Energy consumption = 188.699175 pJ
sum error= 276
Actual label: 2
Output voltages: [0.4504, 0.17492, 0.67639, 0.34315, 0.095138, 0.056043, 0.25754, 0.1522, 0.50857, 0.28912]
Predicted label: 2
Correct prediction
Energy consumption = 185.812075 pJ
sum error= 276
Actual label: 1
Output voltages: [0.18616, 0.70609, 0.27395, 0.23085, 0.36279, 0.067307, 0.31291, 0.11422, 0.33729, 0.20442]
Predicted label: 1
Correct prediction
Energy consumption = 196.946249 pJ
sum error= 276
Actual label: 0
Output voltages: [0.50612, 0.30446, 0.28429, 0.15153, 0.32397, 0.18459, 0.59336, 0.10015, 0.26089, 0.094759]
Predicted label: 6
Wrong prediction!
Energy consumption = 200.635165 pJ
sum error= 277
Actual label: 6
Output voltages: [0.31437, 0.28111, 0.41018, 0.047803, 0.42307, 0.31383, 0.623, 0.17024, 0.29463, 0.049352]
Predicted label: 6
Correct prediction
Energy consumption = 182.771739 pJ
sum error= 277
Actual label: 5
Output voltages: [0.27572, 0.044117, 0.12085, 0.34514, 0.15967, 0.70732, 0.26728, 0.17275, 0.58009, 0.14483]
Predicted label: 5
Correct prediction
Energy consumption = 186.996788 pJ
sum error= 277
Actual label: 3
Output voltages: [0.36974, 0.17704, 0.33997, 0.75564, 0.17104, 0.18029, 0.15293, 0.15584, 0.42858, 0.21969]
Predicted label: 3
Correct prediction
Energy consumption = 183.182292 pJ
sum error= 277
Actual label: 4
Output voltages: [0.24837, 0.15771, 0.34513, 0.13645, 0.73981, 0.057199, 0.32319, 0.18035, 0.27668, 0.19122]
Predicted label: 4
Correct prediction
Energy consumption = 188.125997 pJ
sum error= 277
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 833 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 833 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 833 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.36516, 0.062974, 0.30767, 0.24135, 0.10281, 0.30683, 0.17433, 0.17499, 0.73394, 0.25503]
Predicted label: 8
Correct prediction
Energy consumption = 188.926093 pJ
sum error= 277
Actual label: 5
Output voltages: [0.38202, 0.064533, 0.049225, 0.3109, 0.2122, 0.74306, 0.41273, 0.14353, 0.39231, 0.13254]
Predicted label: 5
Correct prediction
Energy consumption = 189.227916 pJ
sum error= 277
Actual label: 9
Output voltages: [0.33162, 0.065732, 0.16565, 0.38244, 0.20725, 0.21282, 0.04468, 0.3223, 0.47727, 0.52696]
Predicted label: 9
Correct prediction
Energy consumption = 192.778054 pJ
sum error= 277
Actual label: 6
Output voltages: [0.31981, 0.23857, 0.34461, 0.061594, 0.3711, 0.27234, 0.74483, 0.063516, 0.36501, 0.146]
Predicted label: 6
Correct prediction
Energy consumption = 190.400985 pJ
sum error= 277
Actual label: 9
Output voltages: [0.27588, 0.079825, 0.13687, 0.19052, 0.40141, 0.24442, 0.15788, 0.23682, 0.40823, 0.57573]
Predicted label: 9
Correct prediction
Energy consumption = 190.777252 pJ
sum error= 277
Actual label: 0
Output voltages: [0.6283, 0.1441, 0.20331, 0.11492, 0.26754, 0.33451, 0.57659, 0.25207, 0.30021, 0.13313]
Predicted label: 0
Correct prediction
Energy consumption = 192.482176 pJ
sum error= 277
Actual label: 6
Output voltages: [0.29136, 0.18549, 0.38275, 0.076226, 0.41853, 0.21796, 0.7389, 0.064148, 0.31094, 0.15515]
Predicted label: 6
Correct prediction
Energy consumption = 183.759956 pJ
sum error= 277
Actual label: 3
Output voltages: [0.21884, 0.20028, 0.29416, 0.74608, 0.15789, 0.19253, 0.12565, 0.20511, 0.51603, 0.22013]
Predicted label: 3
Correct prediction
Energy consumption = 186.255632 pJ
sum error= 277
Actual label: 0
Output voltages: [0.68571, 0.25912, 0.31931, 0.18714, 0.11582, 0.10681, 0.46719, 0.17701, 0.34087, 0.24129]
Predicted label: 0
Correct prediction
Energy consumption = 194.080190 pJ
sum error= 277
Actual label: 8
Output voltages: [0.2782, 0.1672, 0.41037, 0.14731, 0.29982, 0.11117, 0.49, 0.14285, 0.46729, 0.21495]
Predicted label: 6
Wrong prediction!
Energy consumption = 185.187514 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 834 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 834 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 834 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.20791, 0.73719, 0.29534, 0.29338, 0.22322, 0.075549, 0.32115, 0.21462, 0.33173, 0.20077]
Predicted label: 1
Correct prediction
Energy consumption = 207.974520 pJ
sum error= 278
Actual label: 6
Output voltages: [0.27177, 0.20576, 0.36248, 0.093736, 0.28245, 0.30353, 0.73353, 0.052424, 0.41762, 0.14422]
Predicted label: 6
Correct prediction
Energy consumption = 187.757325 pJ
sum error= 278
Actual label: 0
Output voltages: [0.71127, 0.17857, 0.31248, 0.13699, 0.27011, 0.094508, 0.45703, 0.22107, 0.27896, 0.22004]
Predicted label: 0
Correct prediction
Energy consumption = 186.170012 pJ
sum error= 278
Actual label: 0
Output voltages: [0.72885, 0.24025, 0.26795, 0.19557, 0.19151, 0.093889, 0.42952, 0.16693, 0.31825, 0.24068]
Predicted label: 0
Correct prediction
Energy consumption = 188.799056 pJ
sum error= 278
Actual label: 1
Output voltages: [0.21033, 0.72387, 0.29894, 0.20706, 0.38701, 0.050309, 0.34917, 0.10623, 0.29508, 0.25065]
Predicted label: 1
Correct prediction
Energy consumption = 209.873027 pJ
sum error= 278
Actual label: 2
Output voltages: [0.33008, 0.18772, 0.7468, 0.31493, 0.23126, 0.035385, 0.21998, 0.33845, 0.36196, 0.2005]
Predicted label: 2
Correct prediction
Energy consumption = 186.632212 pJ
sum error= 278
Actual label: 3
Output voltages: [0.32478, 0.09542, 0.32694, 0.73784, 0.21185, 0.24224, 0.068214, 0.28377, 0.45341, 0.25945]
Predicted label: 3
Correct prediction
Energy consumption = 186.961944 pJ
sum error= 278
Actual label: 4
Output voltages: [0.14667, 0.17793, 0.3027, 0.18642, 0.7563, 0.078871, 0.24349, 0.25987, 0.20176, 0.26275]
Predicted label: 4
Correct prediction
Energy consumption = 186.167104 pJ
sum error= 278
Actual label: 5
Output voltages: [0.26538, 0.04788, 0.18174, 0.31801, 0.23616, 0.61715, 0.45338, 0.092695, 0.50661, 0.21002]
Predicted label: 5
Correct prediction
Energy consumption = 187.278267 pJ
sum error= 278
Actual label: 6
Output voltages: [0.28345, 0.18232, 0.39437, 0.042562, 0.47329, 0.2194, 0.72596, 0.052478, 0.28497, 0.13037]
Predicted label: 6
Correct prediction
Energy consumption = 179.006068 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 835 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 835 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 835 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33442, 0.27985, 0.21589, 0.21072, 0.18152, 0.11545, 0.040012, 0.74538, 0.31364, 0.3155]
Predicted label: 7
Correct prediction
Energy consumption = 196.527871 pJ
sum error= 278
Actual label: 0
Output voltages: [0.70398, 0.24842, 0.34604, 0.19042, 0.072167, 0.10933, 0.38383, 0.23648, 0.27807, 0.31226]
Predicted label: 0
Correct prediction
Energy consumption = 188.033967 pJ
sum error= 278
Actual label: 1
Output voltages: [0.13609, 0.75442, 0.19092, 0.24905, 0.21094, 0.092042, 0.36856, 0.13584, 0.41612, 0.22934]
Predicted label: 1
Correct prediction
Energy consumption = 210.389510 pJ
sum error= 278
Actual label: 2
Output voltages: [0.28472, 0.17722, 0.64932, 0.17382, 0.58783, 0.026794, 0.30132, 0.17174, 0.27112, 0.29441]
Predicted label: 2
Correct prediction
Energy consumption = 178.422018 pJ
sum error= 278
Actual label: 3
Output voltages: [0.34668, 0.11508, 0.15376, 0.73071, 0.18947, 0.41323, 0.1874, 0.25592, 0.35984, 0.15375]
Predicted label: 3
Correct prediction
Energy consumption = 194.262167 pJ
sum error= 278
Actual label: 4
Output voltages: [0.12963, 0.12667, 0.34059, 0.14538, 0.74287, 0.055864, 0.2558, 0.24751, 0.24723, 0.24164]
Predicted label: 4
Correct prediction
Energy consumption = 196.748976 pJ
sum error= 278
Actual label: 7
Output voltages: [0.33206, 0.25021, 0.24912, 0.28293, 0.1447, 0.09338, 0.046795, 0.76448, 0.304, 0.2477]
Predicted label: 7
Correct prediction
Energy consumption = 189.516525 pJ
sum error= 278
Actual label: 8
Output voltages: [0.2512, 0.18079, 0.26713, 0.30208, 0.13245, 0.28166, 0.31746, 0.099868, 0.72343, 0.20876]
Predicted label: 8
Correct prediction
Energy consumption = 189.365149 pJ
sum error= 278
Actual label: 9
Output voltages: [0.31755, 0.13002, 0.14737, 0.27182, 0.31018, 0.18044, 0.065238, 0.20094, 0.40976, 0.63037]
Predicted label: 9
Correct prediction
Energy consumption = 192.442068 pJ
sum error= 278
Actual label: 0
Output voltages: [0.72708, 0.17815, 0.25426, 0.14241, 0.14621, 0.15442, 0.45738, 0.24585, 0.29317, 0.26223]
Predicted label: 0
Correct prediction
Energy consumption = 184.127920 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 836 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 836 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 836 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23558, 0.71075, 0.25433, 0.21825, 0.31963, 0.086425, 0.42818, 0.06118, 0.35059, 0.26333]
Predicted label: 1
Correct prediction
Energy consumption = 204.152816 pJ
sum error= 278
Actual label: 2
Output voltages: [0.31169, 0.13435, 0.74712, 0.27864, 0.26154, 0.036519, 0.23942, 0.26842, 0.4227, 0.1923]
Predicted label: 2
Correct prediction
Energy consumption = 180.682944 pJ
sum error= 278
Actual label: 3
Output voltages: [0.301, 0.072505, 0.29992, 0.7204, 0.28248, 0.27943, 0.19681, 0.17068, 0.42631, 0.11366]
Predicted label: 3
Correct prediction
Energy consumption = 188.394465 pJ
sum error= 278
Actual label: 4
Output voltages: [0.17684, 0.11766, 0.3415, 0.21088, 0.7414, 0.056046, 0.24952, 0.20345, 0.22936, 0.26059]
Predicted label: 4
Correct prediction
Energy consumption = 188.378620 pJ
sum error= 278
Actual label: 7
Output voltages: [0.34095, 0.24612, 0.43022, 0.28886, 0.11437, 0.051495, 0.045968, 0.75222, 0.33667, 0.32418]
Predicted label: 7
Correct prediction
Energy consumption = 195.213800 pJ
sum error= 278
Actual label: 2
Output voltages: [0.308, 0.21412, 0.7552, 0.28109, 0.18222, 0.047394, 0.22122, 0.21207, 0.45939, 0.16841]
Predicted label: 2
Correct prediction
Energy consumption = 184.535674 pJ
sum error= 278
Actual label: 5
Output voltages: [0.24207, 0.054321, 0.10701, 0.31655, 0.23944, 0.71988, 0.3017, 0.19266, 0.5149, 0.26697]
Predicted label: 5
Correct prediction
Energy consumption = 186.416415 pJ
sum error= 278
Actual label: 1
Output voltages: [0.16416, 0.7508, 0.30033, 0.19462, 0.29191, 0.080121, 0.38602, 0.16457, 0.2991, 0.16095]
Predicted label: 1
Correct prediction
Energy consumption = 202.634118 pJ
sum error= 278
Actual label: 6
Output voltages: [0.31285, 0.17872, 0.32664, 0.050308, 0.37991, 0.32514, 0.7438, 0.081478, 0.31594, 0.11718]
Predicted label: 6
Correct prediction
Energy consumption = 186.142418 pJ
sum error= 278
Actual label: 4
Output voltages: [0.19655, 0.17417, 0.26678, 0.079998, 0.74324, 0.09854, 0.30319, 0.25335, 0.2927, 0.20849]
Predicted label: 4
Correct prediction
Energy consumption = 192.389659 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 837 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 837 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 837 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.3879, 0.14027, 0.31614, 0.75302, 0.17709, 0.21032, 0.13316, 0.21823, 0.41559, 0.22541]
Predicted label: 3
Correct prediction
Energy consumption = 188.560451 pJ
sum error= 278
Actual label: 9
Output voltages: [0.33598, 0.09255, 0.20122, 0.28828, 0.23777, 0.24781, 0.10378, 0.20537, 0.48299, 0.59616]
Predicted label: 9
Correct prediction
Energy consumption = 188.854052 pJ
sum error= 278
Actual label: 9
Output voltages: [0.40591, 0.08992, 0.24139, 0.23146, 0.32923, 0.10313, 0.074578, 0.21005, 0.42283, 0.61489]
Predicted label: 9
Correct prediction
Energy consumption = 183.678357 pJ
sum error= 278
Actual label: 0
Output voltages: [0.70649, 0.1942, 0.2734, 0.12424, 0.20916, 0.13962, 0.49586, 0.22055, 0.28916, 0.21126]
Predicted label: 0
Correct prediction
Energy consumption = 186.486369 pJ
sum error= 278
Actual label: 9
Output voltages: [0.34034, 0.12687, 0.21667, 0.18832, 0.19427, 0.19449, 0.09423, 0.24409, 0.58158, 0.54807]
Predicted label: 8
Wrong prediction!
Energy consumption = 189.630241 pJ
sum error= 279
Actual label: 7
Output voltages: [0.33362, 0.24421, 0.19885, 0.24674, 0.26569, 0.13619, 0.044484, 0.71519, 0.30281, 0.30641]
Predicted label: 7
Correct prediction
Energy consumption = 198.538719 pJ
sum error= 279
Actual label: 1
Output voltages: [0.28062, 0.70558, 0.2047, 0.30867, 0.37068, 0.11873, 0.38603, 0.14617, 0.211, 0.22264]
Predicted label: 1
Correct prediction
Energy consumption = 214.274676 pJ
sum error= 279
Actual label: 6
Output voltages: [0.28875, 0.17025, 0.32792, 0.056333, 0.43436, 0.31418, 0.73068, 0.088266, 0.31039, 0.067458]
Predicted label: 6
Correct prediction
Energy consumption = 186.698333 pJ
sum error= 279
Actual label: 4
Output voltages: [0.16864, 0.18407, 0.30869, 0.092368, 0.75027, 0.059828, 0.22412, 0.20161, 0.27143, 0.24326]
Predicted label: 4
Correct prediction
Energy consumption = 195.309433 pJ
sum error= 279
Actual label: 3
Output voltages: [0.30917, 0.1116, 0.26987, 0.72058, 0.20523, 0.23225, 0.097015, 0.23346, 0.43755, 0.31838]
Predicted label: 3
Correct prediction
Energy consumption = 185.225358 pJ
sum error= 279
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 838 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 838 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 838 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.24499, 0.21016, 0.35777, 0.062952, 0.40861, 0.29862, 0.74225, 0.061229, 0.32647, 0.10254]
Predicted label: 6
Correct prediction
Energy consumption = 189.778688 pJ
sum error= 279
Actual label: 2
Output voltages: [0.29034, 0.1897, 0.74343, 0.31517, 0.19879, 0.032554, 0.17121, 0.34363, 0.38171, 0.20275]
Predicted label: 2
Correct prediction
Energy consumption = 181.711616 pJ
sum error= 279
Actual label: 0
Output voltages: [0.6515, 0.059928, 0.4348, 0.38606, 0.089625, 0.19139, 0.27998, 0.26437, 0.3676, 0.13678]
Predicted label: 0
Correct prediction
Energy consumption = 189.810280 pJ
sum error= 279
Actual label: 9
Output voltages: [0.2276, 0.12638, 0.20506, 0.29949, 0.23977, 0.31264, 0.15772, 0.13641, 0.53641, 0.53057]
Predicted label: 8
Wrong prediction!
Energy consumption = 189.351940 pJ
sum error= 280
Actual label: 8
Output voltages: [0.23879, 0.18443, 0.28286, 0.25781, 0.16534, 0.28895, 0.18761, 0.17819, 0.75881, 0.19249]
Predicted label: 8
Correct prediction
Energy consumption = 186.168559 pJ
sum error= 280
Actual label: 6
Output voltages: [0.25422, 0.20944, 0.36493, 0.071783, 0.3828, 0.28705, 0.7441, 0.096996, 0.37061, 0.092275]
Predicted label: 6
Correct prediction
Energy consumption = 189.403115 pJ
sum error= 280
Actual label: 5
Output voltages: [0.25731, 0.057823, 0.12791, 0.29129, 0.28914, 0.6775, 0.3767, 0.062824, 0.55242, 0.20738]
Predicted label: 5
Correct prediction
Energy consumption = 183.521055 pJ
sum error= 280
Actual label: 7
Output voltages: [0.30358, 0.25927, 0.24166, 0.26239, 0.25879, 0.07213, 0.029488, 0.69537, 0.35692, 0.32478]
Predicted label: 7
Correct prediction
Energy consumption = 191.950623 pJ
sum error= 280
Actual label: 0
Output voltages: [0.74272, 0.17439, 0.30453, 0.13253, 0.22162, 0.10125, 0.41911, 0.32535, 0.26341, 0.26531]
Predicted label: 0
Correct prediction
Energy consumption = 187.451659 pJ
sum error= 280
Actual label: 0
Output voltages: [0.65579, 0.19546, 0.34525, 0.16286, 0.23405, 0.05837, 0.48323, 0.16451, 0.36142, 0.2555]
Predicted label: 0
Correct prediction
Energy consumption = 179.395766 pJ
sum error= 280
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 839 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 839 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 839 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.27423, 0.75262, 0.18095, 0.19033, 0.38498, 0.14931, 0.34866, 0.17238, 0.22852, 0.26665]
Predicted label: 1
Correct prediction
Energy consumption = 206.458135 pJ
sum error= 280
Actual label: 7
Output voltages: [0.35474, 0.22631, 0.22685, 0.1992, 0.20437, 0.23401, 0.058586, 0.7374, 0.37775, 0.19132]
Predicted label: 7
Correct prediction
Energy consumption = 193.171179 pJ
sum error= 280
Actual label: 4
Output voltages: [0.14403, 0.15242, 0.29327, 0.076326, 0.72488, 0.15808, 0.43696, 0.22617, 0.37043, 0.10569]
Predicted label: 4
Correct prediction
Energy consumption = 197.509186 pJ
sum error= 280
Actual label: 3
Output voltages: [0.34222, 0.11304, 0.31231, 0.74264, 0.17974, 0.15103, 0.078626, 0.2396, 0.47551, 0.24364]
Predicted label: 3
Correct prediction
Energy consumption = 186.241995 pJ
sum error= 280
Actual label: 2
Output voltages: [0.35332, 0.10842, 0.74994, 0.27409, 0.14, 0.0418, 0.22779, 0.33207, 0.46409, 0.12616]
Predicted label: 2
Correct prediction
Energy consumption = 182.617167 pJ
sum error= 280
Actual label: 4
Output voltages: [0.16497, 0.12727, 0.30686, 0.20137, 0.75047, 0.074469, 0.23883, 0.25008, 0.20489, 0.20337]
Predicted label: 4
Correct prediction
Energy consumption = 188.594777 pJ
sum error= 280
Actual label: 1
Output voltages: [0.25732, 0.70668, 0.28336, 0.1944, 0.31467, 0.16519, 0.45327, 0.04107, 0.39595, 0.21036]
Predicted label: 1
Correct prediction
Energy consumption = 204.296647 pJ
sum error= 280
Actual label: 3
Output voltages: [0.5128, 0.18545, 0.37488, 0.66073, 0.069772, 0.36518, 0.17046, 0.13004, 0.40925, 0.17373]
Predicted label: 3
Correct prediction
Energy consumption = 202.202564 pJ
sum error= 280
Actual label: 7
Output voltages: [0.24496, 0.29217, 0.3166, 0.2643, 0.13651, 0.059672, 0.044514, 0.75997, 0.33314, 0.30569]
Predicted label: 7
Correct prediction
Energy consumption = 193.625348 pJ
sum error= 280
Actual label: 6
Output voltages: [0.26604, 0.2087, 0.25811, 0.11766, 0.36568, 0.34645, 0.74338, 0.097021, 0.36378, 0.14073]
Predicted label: 6
Correct prediction
Energy consumption = 193.454897 pJ
sum error= 280
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 840 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 840 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 840 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15715, 0.14991, 0.32261, 0.13908, 0.75534, 0.06983, 0.24415, 0.217, 0.23642, 0.27921]
Predicted label: 4
Correct prediction
Energy consumption = 193.853256 pJ
sum error= 280
Actual label: 7
Output voltages: [0.34145, 0.24065, 0.21862, 0.19233, 0.17647, 0.093842, 0.052624, 0.75525, 0.34027, 0.33789]
Predicted label: 7
Correct prediction
Energy consumption = 197.712802 pJ
sum error= 280
Actual label: 7
Output voltages: [0.33278, 0.22945, 0.27116, 0.13188, 0.20418, 0.14483, 0.046817, 0.76076, 0.38371, 0.19131]
Predicted label: 7
Correct prediction
Energy consumption = 189.501880 pJ
sum error= 280
Actual label: 7
Output voltages: [0.3622, 0.20316, 0.19622, 0.2401, 0.22188, 0.19717, 0.048314, 0.76293, 0.26603, 0.29592]
Predicted label: 7
Correct prediction
Energy consumption = 182.846285 pJ
sum error= 280
Actual label: 9
Output voltages: [0.4057, 0.093474, 0.19307, 0.23429, 0.33934, 0.20727, 0.095886, 0.24888, 0.3764, 0.65331]
Predicted label: 9
Correct prediction
Energy consumption = 191.243161 pJ
sum error= 280
Actual label: 8
Output voltages: [0.23173, 0.17759, 0.28326, 0.15296, 0.22854, 0.19796, 0.26644, 0.07741, 0.70312, 0.32109]
Predicted label: 8
Correct prediction
Energy consumption = 189.560134 pJ
sum error= 280
Actual label: 4
Output voltages: [0.18671, 0.10323, 0.33491, 0.16068, 0.68952, 0.063707, 0.13869, 0.15811, 0.27948, 0.3995]
Predicted label: 4
Correct prediction
Energy consumption = 192.082890 pJ
sum error= 280
Actual label: 3
Output voltages: [0.27262, 0.13027, 0.33216, 0.73498, 0.18436, 0.26458, 0.082612, 0.18353, 0.51704, 0.19926]
Predicted label: 3
Correct prediction
Energy consumption = 184.882491 pJ
sum error= 280
Actual label: 8
Output voltages: [0.29576, 0.20062, 0.25216, 0.30623, 0.20304, 0.43627, 0.54611, 0.061257, 0.48524, 0.151]
Predicted label: 6
Wrong prediction!
Energy consumption = 187.837917 pJ
sum error= 281
Actual label: 2
Output voltages: [0.25804, 0.19383, 0.75615, 0.30065, 0.17126, 0.042138, 0.22153, 0.29659, 0.44097, 0.16286]
Predicted label: 2
Correct prediction
Energy consumption = 181.726481 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 841 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 841 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 841 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.29681, 0.076465, 0.29268, 0.33782, 0.06009, 0.36825, 0.3307, 0.063292, 0.60428, 0.2339]
Predicted label: 8
Correct prediction
Energy consumption = 195.956857 pJ
sum error= 281
Actual label: 3
Output voltages: [0.30244, 0.18591, 0.28676, 0.7532, 0.10844, 0.19323, 0.11652, 0.22013, 0.49094, 0.23292]
Predicted label: 3
Correct prediction
Energy consumption = 188.660619 pJ
sum error= 281
Actual label: 5
Output voltages: [0.34619, 0.045365, 0.054793, 0.4384, 0.23554, 0.73402, 0.24354, 0.23685, 0.42849, 0.168]
Predicted label: 5
Correct prediction
Energy consumption = 184.467905 pJ
sum error= 281
Actual label: 8
Output voltages: [0.29817, 0.15804, 0.13262, 0.3658, 0.1734, 0.35492, 0.35822, 0.13708, 0.69389, 0.076711]
Predicted label: 8
Correct prediction
Energy consumption = 193.033001 pJ
sum error= 281
Actual label: 0
Output voltages: [0.69743, 0.21916, 0.29572, 0.12541, 0.22265, 0.087288, 0.46466, 0.19335, 0.34115, 0.21168]
Predicted label: 0
Correct prediction
Energy consumption = 189.057904 pJ
sum error= 281
Actual label: 5
Output voltages: [0.26067, 0.0555, 0.054064, 0.34773, 0.34102, 0.74379, 0.34536, 0.13021, 0.42014, 0.24523]
Predicted label: 5
Correct prediction
Energy consumption = 187.163999 pJ
sum error= 281
Actual label: 4
Output voltages: [0.11361, 0.24494, 0.18077, 0.10429, 0.72926, 0.11881, 0.30667, 0.23284, 0.3673, 0.21927]
Predicted label: 4
Correct prediction
Energy consumption = 205.670476 pJ
sum error= 281
Actual label: 7
Output voltages: [0.42603, 0.17737, 0.10662, 0.14158, 0.19254, 0.27944, 0.067505, 0.75348, 0.35941, 0.29]
Predicted label: 7
Correct prediction
Energy consumption = 191.697777 pJ
sum error= 281
Actual label: 1
Output voltages: [0.20957, 0.75906, 0.223, 0.2232, 0.26793, 0.13285, 0.407, 0.063806, 0.36654, 0.2179]
Predicted label: 1
Correct prediction
Energy consumption = 210.742784 pJ
sum error= 281
Actual label: 3
Output voltages: [0.1648, 0.11074, 0.24681, 0.64673, 0.2633, 0.25521, 0.1241, 0.16423, 0.49272, 0.34426]
Predicted label: 3
Correct prediction
Energy consumption = 188.954283 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 842 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 842 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 842 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.11361, 0.76075, 0.24615, 0.25376, 0.2403, 0.10627, 0.42288, 0.16048, 0.34171, 0.21928]
Predicted label: 1
Correct prediction
Energy consumption = 208.011551 pJ
sum error= 281
Actual label: 7
Output voltages: [0.36043, 0.31767, 0.28231, 0.18449, 0.10855, 0.079589, 0.055115, 0.74565, 0.42589, 0.3269]
Predicted label: 7
Correct prediction
Energy consumption = 197.504975 pJ
sum error= 281
Actual label: 9
Output voltages: [0.29765, 0.062528, 0.14502, 0.30229, 0.26497, 0.34739, 0.061752, 0.30113, 0.4835, 0.60926]
Predicted label: 9
Correct prediction
Energy consumption = 181.796596 pJ
sum error= 281
Actual label: 6
Output voltages: [0.27637, 0.19934, 0.35854, 0.049022, 0.35761, 0.29499, 0.73601, 0.10548, 0.38938, 0.081444]
Predicted label: 6
Correct prediction
Energy consumption = 185.393121 pJ
sum error= 281
Actual label: 2
Output voltages: [0.33282, 0.25893, 0.76343, 0.2677, 0.17299, 0.045997, 0.24302, 0.22312, 0.37806, 0.20213]
Predicted label: 2
Correct prediction
Energy consumption = 187.015816 pJ
sum error= 281
Actual label: 0
Output voltages: [0.73359, 0.232, 0.26248, 0.1408, 0.21125, 0.14712, 0.48159, 0.21639, 0.23697, 0.23459]
Predicted label: 0
Correct prediction
Energy consumption = 191.683932 pJ
sum error= 281
Actual label: 9
Output voltages: [0.4512, 0.12286, 0.16525, 0.23266, 0.29857, 0.23102, 0.18252, 0.22458, 0.3335, 0.62291]
Predicted label: 9
Correct prediction
Energy consumption = 194.324985 pJ
sum error= 281
Actual label: 1
Output voltages: [0.18103, 0.74394, 0.25079, 0.22647, 0.24658, 0.14547, 0.50613, 0.078943, 0.33493, 0.15347]
Predicted label: 1
Correct prediction
Energy consumption = 206.188555 pJ
sum error= 281
Actual label: 7
Output voltages: [0.4578, 0.1679, 0.14699, 0.25223, 0.2379, 0.18694, 0.051924, 0.74797, 0.33337, 0.30841]
Predicted label: 7
Correct prediction
Energy consumption = 199.117978 pJ
sum error= 281
Actual label: 3
Output voltages: [0.25741, 0.1715, 0.27289, 0.74681, 0.17263, 0.30828, 0.073711, 0.24367, 0.44429, 0.27641]
Predicted label: 3
Correct prediction
Energy consumption = 181.941912 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 843 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 843 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 843 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.24102, 0.12762, 0.26471, 0.6864, 0.13845, 0.29923, 0.083674, 0.22698, 0.57105, 0.23663]
Predicted label: 3
Correct prediction
Energy consumption = 193.084858 pJ
sum error= 281
Actual label: 9
Output voltages: [0.32767, 0.057927, 0.11939, 0.21938, 0.2948, 0.34204, 0.095139, 0.29299, 0.48893, 0.56108]
Predicted label: 9
Correct prediction
Energy consumption = 190.358418 pJ
sum error= 281
Actual label: 1
Output voltages: [0.18725, 0.751, 0.24129, 0.178, 0.34251, 0.1011, 0.40559, 0.089566, 0.27564, 0.28186]
Predicted label: 1
Correct prediction
Energy consumption = 209.539416 pJ
sum error= 281
Actual label: 6
Output voltages: [0.27958, 0.18928, 0.36059, 0.047701, 0.40513, 0.29851, 0.74141, 0.074843, 0.33977, 0.080829]
Predicted label: 6
Correct prediction
Energy consumption = 183.911791 pJ
sum error= 281
Actual label: 4
Output voltages: [0.15634, 0.09814, 0.2937, 0.13499, 0.75179, 0.052542, 0.30951, 0.27687, 0.22502, 0.1981]
Predicted label: 4
Correct prediction
Energy consumption = 188.330278 pJ
sum error= 281
Actual label: 3
Output voltages: [0.39286, 0.062272, 0.227, 0.72088, 0.16654, 0.35136, 0.20555, 0.16143, 0.35969, 0.23172]
Predicted label: 3
Correct prediction
Energy consumption = 189.650270 pJ
sum error= 281
Actual label: 9
Output voltages: [0.32929, 0.10735, 0.19901, 0.26789, 0.27406, 0.20079, 0.066125, 0.28913, 0.41255, 0.64498]
Predicted label: 9
Correct prediction
Energy consumption = 187.720834 pJ
sum error= 281
Actual label: 8
Output voltages: [0.19616, 0.16735, 0.23867, 0.2466, 0.17254, 0.31618, 0.29544, 0.1471, 0.74915, 0.24303]
Predicted label: 8
Correct prediction
Energy consumption = 181.479864 pJ
sum error= 281
Actual label: 2
Output voltages: [0.34762, 0.13583, 0.75119, 0.32517, 0.16447, 0.044287, 0.22843, 0.25464, 0.43895, 0.1876]
Predicted label: 2
Correct prediction
Energy consumption = 182.729906 pJ
sum error= 281
Actual label: 1
Output voltages: [0.16869, 0.73926, 0.28832, 0.2332, 0.32851, 0.10079, 0.34106, 0.24295, 0.32152, 0.084534]
Predicted label: 1
Correct prediction
Energy consumption = 203.529629 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 844 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 844 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 844 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20227, 0.22901, 0.25405, 0.19707, 0.17629, 0.23094, 0.26608, 0.18317, 0.75222, 0.26838]
Predicted label: 8
Correct prediction
Energy consumption = 191.970833 pJ
sum error= 281
Actual label: 6
Output voltages: [0.28307, 0.22773, 0.35228, 0.053476, 0.39938, 0.30186, 0.74219, 0.092037, 0.33177, 0.14423]
Predicted label: 6
Correct prediction
Energy consumption = 185.544689 pJ
sum error= 281
Actual label: 4
Output voltages: [0.24679, 0.16358, 0.28092, 0.10636, 0.66368, 0.087096, 0.55175, 0.15116, 0.26207, 0.18908]
Predicted label: 4
Correct prediction
Energy consumption = 188.420680 pJ
sum error= 281
Actual label: 1
Output voltages: [0.25156, 0.7608, 0.29399, 0.24709, 0.23374, 0.060833, 0.4115, 0.095941, 0.28038, 0.20136]
Predicted label: 1
Correct prediction
Energy consumption = 207.601401 pJ
sum error= 281
Actual label: 5
Output voltages: [0.33383, 0.055646, 0.038623, 0.35237, 0.325, 0.70157, 0.30566, 0.18254, 0.38758, 0.23725]
Predicted label: 5
Correct prediction
Energy consumption = 187.222550 pJ
sum error= 281
Actual label: 5
Output voltages: [0.33222, 0.054513, 0.04819, 0.33678, 0.22787, 0.7503, 0.30703, 0.26241, 0.47401, 0.18504]
Predicted label: 5
Correct prediction
Energy consumption = 181.616981 pJ
sum error= 281
Actual label: 6
Output voltages: [0.27236, 0.21841, 0.35282, 0.10048, 0.29583, 0.31282, 0.74011, 0.049717, 0.41768, 0.16119]
Predicted label: 6
Correct prediction
Energy consumption = 176.758998 pJ
sum error= 281
Actual label: 5
Output voltages: [0.24738, 0.08335, 0.1025, 0.38661, 0.18624, 0.69935, 0.23157, 0.15405, 0.54802, 0.2435]
Predicted label: 5
Correct prediction
Energy consumption = 180.632835 pJ
sum error= 281
Actual label: 0
Output voltages: [0.71962, 0.21039, 0.14972, 0.13424, 0.17706, 0.29133, 0.40477, 0.15454, 0.29307, 0.29435]
Predicted label: 0
Correct prediction
Energy consumption = 195.705204 pJ
sum error= 281
Actual label: 1
Output voltages: [0.19825, 0.7461, 0.11012, 0.24352, 0.20793, 0.26698, 0.37422, 0.15216, 0.39466, 0.17244]
Predicted label: 1
Correct prediction
Energy consumption = 205.186844 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 845 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 845 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 845 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33284, 0.37083, 0.74204, 0.31534, 0.2166, 0.024979, 0.27466, 0.2602, 0.26284, 0.22241]
Predicted label: 2
Correct prediction
Energy consumption = 193.884258 pJ
sum error= 281
Actual label: 3
Output voltages: [0.33984, 0.17903, 0.32064, 0.75594, 0.18541, 0.16884, 0.18246, 0.17064, 0.4043, 0.24128]
Predicted label: 3
Correct prediction
Energy consumption = 185.286208 pJ
sum error= 281
Actual label: 4
Output voltages: [0.17562, 0.17663, 0.25615, 0.16975, 0.76384, 0.092918, 0.28498, 0.33982, 0.21363, 0.25444]
Predicted label: 4
Correct prediction
Energy consumption = 196.607509 pJ
sum error= 281
Actual label: 5
Output voltages: [0.2623, 0.053587, 0.077527, 0.43568, 0.22185, 0.61784, 0.29999, 0.066768, 0.51362, 0.17795]
Predicted label: 5
Correct prediction
Energy consumption = 190.172104 pJ
sum error= 281
Actual label: 6
Output voltages: [0.29526, 0.22435, 0.37786, 0.072132, 0.35312, 0.34128, 0.7509, 0.06028, 0.36109, 0.15824]
Predicted label: 6
Correct prediction
Energy consumption = 180.493919 pJ
sum error= 281
Actual label: 7
Output voltages: [0.29906, 0.26861, 0.31239, 0.27167, 0.076033, 0.077389, 0.055726, 0.76036, 0.39032, 0.32812]
Predicted label: 7
Correct prediction
Energy consumption = 204.614141 pJ
sum error= 281
Actual label: 8
Output voltages: [0.36935, 0.1005, 0.3873, 0.31084, 0.15661, 0.15829, 0.2936, 0.075057, 0.70068, 0.27973]
Predicted label: 8
Correct prediction
Energy consumption = 195.947028 pJ
sum error= 281
Actual label: 9
Output voltages: [0.36722, 0.073122, 0.17193, 0.31539, 0.19114, 0.20835, 0.055732, 0.21377, 0.50097, 0.60632]
Predicted label: 9
Correct prediction
Energy consumption = 184.673669 pJ
sum error= 281
Actual label: 0
Output voltages: [0.72717, 0.20553, 0.20669, 0.18759, 0.13051, 0.2595, 0.40174, 0.16293, 0.30699, 0.22896]
Predicted label: 0
Correct prediction
Energy consumption = 189.084163 pJ
sum error= 281
Actual label: 1
Output voltages: [0.23678, 0.74829, 0.23444, 0.28687, 0.25832, 0.074366, 0.30702, 0.1053, 0.39176, 0.263]
Predicted label: 1
Correct prediction
Energy consumption = 205.668754 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 846 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 846 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 846 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40767, 0.15756, 0.70199, 0.39711, 0.21635, 0.040198, 0.24681, 0.2421, 0.38952, 0.18781]
Predicted label: 2
Correct prediction
Energy consumption = 191.534337 pJ
sum error= 281
Actual label: 3
Output voltages: [0.39182, 0.22592, 0.32316, 0.76072, 0.15716, 0.18535, 0.13293, 0.18515, 0.42037, 0.23504]
Predicted label: 3
Correct prediction
Energy consumption = 186.759164 pJ
sum error= 281
Actual label: 4
Output voltages: [0.064921, 0.20321, 0.17206, 0.049109, 0.70981, 0.20781, 0.31874, 0.31797, 0.39918, 0.22901]
Predicted label: 4
Correct prediction
Energy consumption = 202.185504 pJ
sum error= 281
Actual label: 5
Output voltages: [0.3278, 0.074045, 0.07875, 0.44393, 0.17935, 0.74276, 0.30079, 0.15756, 0.44692, 0.20303]
Predicted label: 5
Correct prediction
Energy consumption = 188.890398 pJ
sum error= 281
Actual label: 6
Output voltages: [0.32752, 0.24065, 0.31748, 0.072843, 0.34416, 0.31406, 0.74283, 0.058316, 0.31977, 0.19106]
Predicted label: 6
Correct prediction
Energy consumption = 186.121302 pJ
sum error= 281
Actual label: 7
Output voltages: [0.28494, 0.27021, 0.35052, 0.32687, 0.07133, 0.061669, 0.049862, 0.70487, 0.51869, 0.26475]
Predicted label: 7
Correct prediction
Energy consumption = 204.604612 pJ
sum error= 281
Actual label: 8
Output voltages: [0.2941, 0.20023, 0.37204, 0.31508, 0.13333, 0.1844, 0.1997, 0.0804, 0.74344, 0.33665]
Predicted label: 8
Correct prediction
Energy consumption = 189.167230 pJ
sum error= 281
Actual label: 9
Output voltages: [0.35347, 0.08994, 0.17484, 0.32325, 0.2686, 0.2965, 0.14214, 0.34783, 0.33304, 0.67888]
Predicted label: 9
Correct prediction
Energy consumption = 193.839934 pJ
sum error= 281
Actual label: 0
Output voltages: [0.68171, 0.20733, 0.30239, 0.16016, 0.11308, 0.17989, 0.46107, 0.11885, 0.31639, 0.25498]
Predicted label: 0
Correct prediction
Energy consumption = 188.041621 pJ
sum error= 281
Actual label: 1
Output voltages: [0.22485, 0.74694, 0.27039, 0.35982, 0.22626, 0.066261, 0.33296, 0.13007, 0.37893, 0.16886]
Predicted label: 1
Correct prediction
Energy consumption = 201.057383 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 847 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 847 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 847 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35162, 0.27854, 0.68744, 0.36665, 0.31513, 0.037306, 0.26437, 0.20257, 0.36433, 0.16689]
Predicted label: 2
Correct prediction
Energy consumption = 190.466453 pJ
sum error= 281
Actual label: 3
Output voltages: [0.35847, 0.1528, 0.32249, 0.75686, 0.22554, 0.15544, 0.14076, 0.1732, 0.45748, 0.24161]
Predicted label: 3
Correct prediction
Energy consumption = 177.368965 pJ
sum error= 281
Actual label: 4
Output voltages: [0.30855, 0.10245, 0.34513, 0.12361, 0.70935, 0.043384, 0.24424, 0.17363, 0.32858, 0.321]
Predicted label: 4
Correct prediction
Energy consumption = 196.330271 pJ
sum error= 281
Actual label: 5
Output voltages: [0.29685, 0.076155, 0.067626, 0.51305, 0.20256, 0.69664, 0.27942, 0.14333, 0.43399, 0.21978]
Predicted label: 5
Correct prediction
Energy consumption = 193.993847 pJ
sum error= 281
Actual label: 6
Output voltages: [0.29455, 0.16279, 0.27612, 0.1146, 0.37082, 0.37613, 0.72851, 0.062831, 0.37219, 0.14919]
Predicted label: 6
Correct prediction
Energy consumption = 186.919278 pJ
sum error= 281
Actual label: 7
Output voltages: [0.31003, 0.2584, 0.32577, 0.2494, 0.058908, 0.073261, 0.04909, 0.72553, 0.46174, 0.31084]
Predicted label: 7
Correct prediction
Energy consumption = 204.549643 pJ
sum error= 281
Actual label: 8
Output voltages: [0.29498, 0.10565, 0.26341, 0.28644, 0.20343, 0.29108, 0.2767, 0.051853, 0.68155, 0.27781]
Predicted label: 8
Correct prediction
Energy consumption = 189.282843 pJ
sum error= 281
Actual label: 9
Output voltages: [0.36043, 0.086221, 0.25493, 0.29414, 0.22279, 0.11575, 0.072871, 0.24697, 0.45507, 0.5756]
Predicted label: 9
Correct prediction
Energy consumption = 184.971924 pJ
sum error= 281
Actual label: 6
Output voltages: [0.38542, 0.23824, 0.21422, 0.19597, 0.27799, 0.43652, 0.73721, 0.083045, 0.33376, 0.22563]
Predicted label: 6
Correct prediction
Energy consumption = 191.010077 pJ
sum error= 281
Actual label: 9
Output voltages: [0.34809, 0.11379, 0.21722, 0.30218, 0.28539, 0.14014, 0.073266, 0.29111, 0.36204, 0.64582]
Predicted label: 9
Correct prediction
Energy consumption = 193.040535 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 848 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 848 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 848 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.27848, 0.24449, 0.23992, 0.21751, 0.13326, 0.1224, 0.043105, 0.75067, 0.4469, 0.31509]
Predicted label: 7
Correct prediction
Energy consumption = 203.653540 pJ
sum error= 281
Actual label: 0
Output voltages: [0.74542, 0.24461, 0.22129, 0.23197, 0.12722, 0.25531, 0.34048, 0.15016, 0.26649, 0.30787]
Predicted label: 0
Correct prediction
Energy consumption = 198.440499 pJ
sum error= 281
Actual label: 2
Output voltages: [0.42531, 0.14654, 0.70919, 0.34968, 0.22464, 0.036582, 0.23172, 0.2445, 0.39028, 0.1865]
Predicted label: 2
Correct prediction
Energy consumption = 188.840250 pJ
sum error= 281
Actual label: 3
Output voltages: [0.39003, 0.16952, 0.34746, 0.75256, 0.15669, 0.12865, 0.15933, 0.15018, 0.44555, 0.23573]
Predicted label: 3
Correct prediction
Energy consumption = 179.423811 pJ
sum error= 281
Actual label: 4
Output voltages: [0.13334, 0.18546, 0.26236, 0.061165, 0.76024, 0.15592, 0.29349, 0.29518, 0.2967, 0.23224]
Predicted label: 4
Correct prediction
Energy consumption = 197.581802 pJ
sum error= 281
Actual label: 3
Output voltages: [0.32243, 0.15491, 0.32714, 0.74458, 0.15943, 0.14121, 0.18689, 0.167, 0.47041, 0.25911]
Predicted label: 3
Correct prediction
Energy consumption = 192.889359 pJ
sum error= 281
Actual label: 8
Output voltages: [0.36877, 0.18387, 0.375, 0.28645, 0.15656, 0.11484, 0.22359, 0.064457, 0.68672, 0.36062]
Predicted label: 8
Correct prediction
Energy consumption = 190.523889 pJ
sum error= 281
Actual label: 5
Output voltages: [0.2892, 0.037677, 0.053009, 0.36666, 0.26154, 0.68126, 0.3053, 0.1786, 0.52706, 0.20091]
Predicted label: 5
Correct prediction
Energy consumption = 182.516482 pJ
sum error= 281
Actual label: 1
Output voltages: [0.22887, 0.74374, 0.2518, 0.29993, 0.26952, 0.072762, 0.38289, 0.13055, 0.36048, 0.15238]
Predicted label: 1
Correct prediction
Energy consumption = 209.508290 pJ
sum error= 281
Actual label: 3
Output voltages: [0.40803, 0.12801, 0.33508, 0.74904, 0.16662, 0.163, 0.14373, 0.17458, 0.41448, 0.23846]
Predicted label: 3
Correct prediction
Energy consumption = 189.701146 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 849 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 849 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 849 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69953, 0.16777, 0.22779, 0.17108, 0.14541, 0.21664, 0.40245, 0.2424, 0.268, 0.32249]
Predicted label: 0
Correct prediction
Energy consumption = 191.742227 pJ
sum error= 281
Actual label: 1
Output voltages: [0.25111, 0.74803, 0.25098, 0.4002, 0.073115, 0.085207, 0.36306, 0.13493, 0.38757, 0.18906]
Predicted label: 1
Correct prediction
Energy consumption = 210.200893 pJ
sum error= 281
Actual label: 2
Output voltages: [0.31424, 0.20468, 0.73554, 0.34142, 0.24057, 0.027843, 0.27705, 0.35887, 0.31984, 0.23624]
Predicted label: 2
Correct prediction
Energy consumption = 184.518813 pJ
sum error= 281
Actual label: 1
Output voltages: [0.2436, 0.72399, 0.29283, 0.27221, 0.23153, 0.056657, 0.28125, 0.080335, 0.43975, 0.21928]
Predicted label: 1
Correct prediction
Energy consumption = 208.023312 pJ
sum error= 281
Actual label: 3
Output voltages: [0.40763, 0.13417, 0.26987, 0.75271, 0.12746, 0.23299, 0.13093, 0.22183, 0.42649, 0.21671]
Predicted label: 3
Correct prediction
Energy consumption = 189.965268 pJ
sum error= 281
Actual label: 2
Output voltages: [0.36475, 0.22687, 0.65741, 0.45332, 0.19439, 0.033854, 0.31365, 0.15872, 0.42063, 0.14615]
Predicted label: 2
Correct prediction
Energy consumption = 180.260298 pJ
sum error= 281
Actual label: 0
Output voltages: [0.67282, 0.19726, 0.29052, 0.11825, 0.11002, 0.17629, 0.45516, 0.12568, 0.29263, 0.30592]
Predicted label: 0
Correct prediction
Energy consumption = 185.277870 pJ
sum error= 281
Actual label: 7
Output voltages: [0.25038, 0.36406, 0.34855, 0.41555, 0.092959, 0.038564, 0.055414, 0.64892, 0.46387, 0.26257]
Predicted label: 7
Correct prediction
Energy consumption = 202.818457 pJ
sum error= 281
Actual label: 2
Output voltages: [0.33891, 0.31405, 0.67517, 0.38997, 0.16087, 0.030238, 0.29348, 0.19801, 0.43792, 0.20856]
Predicted label: 2
Correct prediction
Energy consumption = 187.391125 pJ
sum error= 281
Actual label: 6
Output voltages: [0.27383, 0.18476, 0.31166, 0.076778, 0.35369, 0.35317, 0.73931, 0.062217, 0.35448, 0.097461]
Predicted label: 6
Correct prediction
Energy consumption = 184.793032 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 850 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 850 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 850 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.12252, 0.17661, 0.27496, 0.15456, 0.7661, 0.11363, 0.298, 0.34244, 0.23151, 0.26535]
Predicted label: 4
Correct prediction
Energy consumption = 193.198468 pJ
sum error= 281
Actual label: 0
Output voltages: [0.73385, 0.19014, 0.22168, 0.17592, 0.2229, 0.12906, 0.41879, 0.20534, 0.32496, 0.25157]
Predicted label: 0
Correct prediction
Energy consumption = 192.560093 pJ
sum error= 281
Actual label: 5
Output voltages: [0.29594, 0.058141, 0.081163, 0.54202, 0.15631, 0.5708, 0.17176, 0.15055, 0.45258, 0.25521]
Predicted label: 5
Correct prediction
Energy consumption = 195.918647 pJ
sum error= 281
Actual label: 9
Output voltages: [0.32198, 0.097154, 0.19131, 0.26948, 0.22748, 0.36429, 0.12674, 0.34533, 0.40433, 0.56351]
Predicted label: 9
Correct prediction
Energy consumption = 193.391874 pJ
sum error= 281
Actual label: 9
Output voltages: [0.25761, 0.064963, 0.16516, 0.30055, 0.18956, 0.48014, 0.13114, 0.30496, 0.46611, 0.50504]
Predicted label: 9
Correct prediction
Energy consumption = 189.394433 pJ
sum error= 281
Actual label: 8
Output voltages: [0.36686, 0.15164, 0.26048, 0.31775, 0.13804, 0.29122, 0.25336, 0.10242, 0.71143, 0.26207]
Predicted label: 8
Correct prediction
Energy consumption = 193.515239 pJ
sum error= 281
Actual label: 9
Output voltages: [0.38251, 0.13618, 0.18155, 0.20807, 0.31044, 0.18042, 0.10452, 0.21391, 0.39384, 0.69409]
Predicted label: 9
Correct prediction
Energy consumption = 196.935016 pJ
sum error= 281
Actual label: 5
Output voltages: [0.35265, 0.042924, 0.059299, 0.3099, 0.1887, 0.73277, 0.35142, 0.1685, 0.52792, 0.10975]
Predicted label: 5
Correct prediction
Energy consumption = 183.434376 pJ
sum error= 281
Actual label: 3
Output voltages: [0.4325, 0.18638, 0.277, 0.74941, 0.13641, 0.22552, 0.14883, 0.13867, 0.39907, 0.19163]
Predicted label: 3
Correct prediction
Energy consumption = 195.088735 pJ
sum error= 281
Actual label: 1
Output voltages: [0.28788, 0.7084, 0.24924, 0.25026, 0.22007, 0.056753, 0.35959, 0.082465, 0.40371, 0.16262]
Predicted label: 1
Correct prediction
Energy consumption = 209.395193 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 851 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 851 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 851 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26457, 0.34974, 0.35954, 0.33158, 0.098553, 0.043655, 0.061647, 0.68389, 0.4666, 0.2163]
Predicted label: 7
Correct prediction
Energy consumption = 206.781894 pJ
sum error= 281
Actual label: 4
Output voltages: [0.22531, 0.151, 0.33278, 0.1159, 0.74468, 0.051924, 0.26593, 0.22671, 0.23515, 0.27995]
Predicted label: 4
Correct prediction
Energy consumption = 198.981692 pJ
sum error= 281
Actual label: 7
Output voltages: [0.30788, 0.2939, 0.41062, 0.35268, 0.097884, 0.038563, 0.062571, 0.70073, 0.43231, 0.20856]
Predicted label: 7
Correct prediction
Energy consumption = 202.011467 pJ
sum error= 281
Actual label: 0
Output voltages: [0.72928, 0.10255, 0.21723, 0.22817, 0.1147, 0.25015, 0.36571, 0.23096, 0.29846, 0.31437]
Predicted label: 0
Correct prediction
Energy consumption = 185.328074 pJ
sum error= 281
Actual label: 0
Output voltages: [0.74014, 0.24108, 0.24101, 0.19193, 0.12585, 0.12052, 0.39563, 0.20389, 0.30615, 0.33541]
Predicted label: 0
Correct prediction
Energy consumption = 186.094006 pJ
sum error= 281
Actual label: 6
Output voltages: [0.27438, 0.2208, 0.33908, 0.075998, 0.32394, 0.36426, 0.74052, 0.10429, 0.41664, 0.093609]
Predicted label: 6
Correct prediction
Energy consumption = 190.153577 pJ
sum error= 281
Actual label: 6
Output voltages: [0.29923, 0.19279, 0.31049, 0.055879, 0.36426, 0.32845, 0.73736, 0.056126, 0.3804, 0.11496]
Predicted label: 6
Correct prediction
Energy consumption = 180.795194 pJ
sum error= 281
Actual label: 6
Output voltages: [0.2498, 0.19133, 0.32097, 0.054505, 0.36519, 0.41974, 0.71561, 0.087798, 0.42172, 0.082845]
Predicted label: 6
Correct prediction
Energy consumption = 183.448973 pJ
sum error= 281
Actual label: 3
Output voltages: [0.35841, 0.17103, 0.30697, 0.76036, 0.20773, 0.19326, 0.15768, 0.20099, 0.40548, 0.23686]
Predicted label: 3
Correct prediction
Energy consumption = 192.190380 pJ
sum error= 281
Actual label: 7
Output voltages: [0.34463, 0.41426, 0.36739, 0.46097, 0.068938, 0.031772, 0.11728, 0.59358, 0.30143, 0.27113]
Predicted label: 7
Correct prediction
Energy consumption = 196.079903 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 852 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 852 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 852 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.070527, 0.2731, 0.24394, 0.14322, 0.51527, 0.081948, 0.15722, 0.19333, 0.44516, 0.42847]
Predicted label: 4
Correct prediction
Energy consumption = 203.245359 pJ
sum error= 281
Actual label: 2
Output voltages: [0.37349, 0.34911, 0.71247, 0.38465, 0.1957, 0.027202, 0.24036, 0.19645, 0.33922, 0.30079]
Predicted label: 2
Correct prediction
Energy consumption = 195.181574 pJ
sum error= 281
Actual label: 8
Output voltages: [0.27261, 0.060157, 0.45744, 0.2712, 0.176, 0.14969, 0.37847, 0.15511, 0.64386, 0.20497]
Predicted label: 8
Correct prediction
Energy consumption = 189.354218 pJ
sum error= 281
Actual label: 9
Output voltages: [0.22584, 0.057355, 0.2026, 0.2584, 0.36352, 0.25146, 0.12023, 0.37306, 0.34482, 0.5734]
Predicted label: 9
Correct prediction
Energy consumption = 204.983671 pJ
sum error= 281
Actual label: 8
Output voltages: [0.2845, 0.20586, 0.43149, 0.22828, 0.16336, 0.097356, 0.29132, 0.12897, 0.69483, 0.26529]
Predicted label: 8
Correct prediction
Energy consumption = 198.596530 pJ
sum error= 281
Actual label: 7
Output voltages: [0.30429, 0.33781, 0.32103, 0.45649, 0.10732, 0.043904, 0.048296, 0.62758, 0.3958, 0.25235]
Predicted label: 7
Correct prediction
Energy consumption = 204.097659 pJ
sum error= 281
Actual label: 1
Output voltages: [0.2724, 0.76314, 0.28933, 0.30413, 0.16238, 0.069063, 0.36719, 0.10149, 0.30137, 0.21625]
Predicted label: 1
Correct prediction
Energy consumption = 205.743906 pJ
sum error= 281
Actual label: 4
Output voltages: [0.27418, 0.10864, 0.23355, 0.2315, 0.52229, 0.17916, 0.23501, 0.3031, 0.2479, 0.49888]
Predicted label: 4
Correct prediction
Energy consumption = 207.941943 pJ
sum error= 281
Actual label: 0
Output voltages: [0.73705, 0.1971, 0.21923, 0.14513, 0.17262, 0.28327, 0.39613, 0.13848, 0.23813, 0.29322]
Predicted label: 0
Correct prediction
Energy consumption = 192.546156 pJ
sum error= 281
Actual label: 4
Output voltages: [0.2819, 0.13838, 0.25344, 0.070582, 0.75418, 0.21099, 0.33137, 0.20549, 0.24651, 0.31439]
Predicted label: 4
Correct prediction
Energy consumption = 193.027166 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 853 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 853 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 853 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.33572, 0.083558, 0.32352, 0.30909, 0.22118, 0.15935, 0.28119, 0.1195, 0.71371, 0.1855]
Predicted label: 8
Correct prediction
Energy consumption = 190.127710 pJ
sum error= 281
Actual label: 5
Output voltages: [0.2051, 0.067474, 0.10723, 0.37337, 0.1948, 0.72429, 0.29029, 0.14347, 0.55125, 0.19642]
Predicted label: 5
Correct prediction
Energy consumption = 193.130778 pJ
sum error= 281
Actual label: 2
Output voltages: [0.39841, 0.26082, 0.70368, 0.37666, 0.15532, 0.029588, 0.34429, 0.18478, 0.42209, 0.17637]
Predicted label: 2
Correct prediction
Energy consumption = 183.805252 pJ
sum error= 281
Actual label: 3
Output voltages: [0.38687, 0.12207, 0.38418, 0.72243, 0.12465, 0.12572, 0.12769, 0.1481, 0.50388, 0.21906]
Predicted label: 3
Correct prediction
Energy consumption = 188.165640 pJ
sum error= 281
Actual label: 9
Output voltages: [0.375, 0.10089, 0.19322, 0.27506, 0.35421, 0.20588, 0.19686, 0.30656, 0.26171, 0.63923]
Predicted label: 9
Correct prediction
Energy consumption = 197.991158 pJ
sum error= 281
Actual label: 0
Output voltages: [0.71689, 0.23165, 0.26293, 0.15298, 0.11783, 0.17312, 0.40964, 0.16161, 0.33331, 0.26707]
Predicted label: 0
Correct prediction
Energy consumption = 193.721980 pJ
sum error= 281
Actual label: 1
Output voltages: [0.20538, 0.70189, 0.18916, 0.38088, 0.28467, 0.16469, 0.19503, 0.23654, 0.25241, 0.26177]
Predicted label: 1
Correct prediction
Energy consumption = 213.436695 pJ
sum error= 281
Actual label: 9
Output voltages: [0.37691, 0.11769, 0.17642, 0.25648, 0.36862, 0.21443, 0.15862, 0.31383, 0.34492, 0.66911]
Predicted label: 9
Correct prediction
Energy consumption = 199.624323 pJ
sum error= 281
Actual label: 1
Output voltages: [0.22932, 0.72476, 0.23383, 0.33525, 0.13806, 0.11235, 0.24145, 0.20887, 0.42193, 0.232]
Predicted label: 1
Correct prediction
Energy consumption = 212.684564 pJ
sum error= 281
Actual label: 5
Output voltages: [0.446, 0.106, 0.051891, 0.34862, 0.16431, 0.69438, 0.29063, 0.20347, 0.38189, 0.26496]
Predicted label: 5
Correct prediction
Energy consumption = 201.060545 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 854 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 854 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 854 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.18663, 0.74823, 0.29387, 0.45451, 0.25473, 0.061435, 0.23874, 0.2064, 0.28255, 0.24176]
Predicted label: 1
Correct prediction
Energy consumption = 209.808841 pJ
sum error= 281
Actual label: 7
Output voltages: [0.2644, 0.2955, 0.3838, 0.34958, 0.073249, 0.038858, 0.049736, 0.65663, 0.44833, 0.35092]
Predicted label: 7
Correct prediction
Energy consumption = 203.811005 pJ
sum error= 281
Actual label: 6
Output voltages: [0.3366, 0.28129, 0.24646, 0.22337, 0.25592, 0.40611, 0.72459, 0.098921, 0.47202, 0.095584]
Predicted label: 6
Correct prediction
Energy consumption = 207.114298 pJ
sum error= 281
Actual label: 1
Output voltages: [0.25445, 0.74902, 0.19363, 0.413, 0.21799, 0.16203, 0.23935, 0.18218, 0.20194, 0.31647]
Predicted label: 1
Correct prediction
Energy consumption = 210.577946 pJ
sum error= 281
Actual label: 2
Output voltages: [0.46967, 0.18122, 0.71508, 0.34426, 0.10268, 0.055002, 0.27053, 0.19409, 0.41438, 0.14668]
Predicted label: 2
Correct prediction
Energy consumption = 194.106440 pJ
sum error= 281
Actual label: 1
Output voltages: [0.20768, 0.74838, 0.25756, 0.32558, 0.27201, 0.10864, 0.26329, 0.28827, 0.26355, 0.23647]
Predicted label: 1
Correct prediction
Energy consumption = 212.227388 pJ
sum error= 281
Actual label: 6
Output voltages: [0.27505, 0.29416, 0.23529, 0.17703, 0.29776, 0.40465, 0.73483, 0.12275, 0.43815, 0.082878]
Predicted label: 6
Correct prediction
Energy consumption = 202.014856 pJ
sum error= 281
Actual label: 8
Output voltages: [0.30033, 0.15077, 0.28782, 0.28662, 0.15419, 0.27295, 0.24679, 0.09128, 0.73904, 0.23104]
Predicted label: 8
Correct prediction
Energy consumption = 186.199296 pJ
sum error= 281
Actual label: 0
Output voltages: [0.69599, 0.21856, 0.17298, 0.16857, 0.15858, 0.30031, 0.39752, 0.11961, 0.29793, 0.31566]
Predicted label: 0
Correct prediction
Energy consumption = 196.489179 pJ
sum error= 281
Actual label: 1
Output voltages: [0.19164, 0.77096, 0.2463, 0.28419, 0.18008, 0.10695, 0.42779, 0.13036, 0.30144, 0.22608]
Predicted label: 1
Correct prediction
Energy consumption = 201.425254 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 855 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 855 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 855 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.30136, 0.26393, 0.73691, 0.34123, 0.18351, 0.027978, 0.18219, 0.39664, 0.33326, 0.19628]
Predicted label: 2
Correct prediction
Energy consumption = 187.065400 pJ
sum error= 281
Actual label: 3
Output voltages: [0.32694, 0.15826, 0.33851, 0.74417, 0.20549, 0.19734, 0.13955, 0.18428, 0.41292, 0.16838]
Predicted label: 3
Correct prediction
Energy consumption = 181.309930 pJ
sum error= 281
Actual label: 4
Output voltages: [0.11001, 0.15729, 0.29226, 0.14619, 0.76012, 0.064385, 0.23831, 0.30561, 0.22362, 0.25917]
Predicted label: 4
Correct prediction
Energy consumption = 196.915288 pJ
sum error= 281
Actual label: 5
Output voltages: [0.30197, 0.19037, 0.11589, 0.38869, 0.15971, 0.74807, 0.30055, 0.23074, 0.40034, 0.17966]
Predicted label: 5
Correct prediction
Energy consumption = 192.242677 pJ
sum error= 281
Actual label: 6
Output voltages: [0.32765, 0.27118, 0.32165, 0.11441, 0.34068, 0.25121, 0.74905, 0.059271, 0.32797, 0.209]
Predicted label: 6
Correct prediction
Energy consumption = 190.425700 pJ
sum error= 281
Actual label: 7
Output voltages: [0.29719, 0.18402, 0.25739, 0.32994, 0.11772, 0.10493, 0.05127, 0.76212, 0.31595, 0.31739]
Predicted label: 7
Correct prediction
Energy consumption = 201.083528 pJ
sum error= 281
Actual label: 8
Output voltages: [0.19202, 0.17922, 0.28212, 0.29461, 0.15907, 0.25631, 0.17515, 0.1141, 0.74907, 0.29816]
Predicted label: 8
Correct prediction
Energy consumption = 190.272853 pJ
sum error= 281
Actual label: 9
Output voltages: [0.33596, 0.14324, 0.19652, 0.32038, 0.31078, 0.28395, 0.17495, 0.23166, 0.31561, 0.71917]
Predicted label: 9
Correct prediction
Energy consumption = 189.101558 pJ
sum error= 281
Actual label: 0
Output voltages: [0.63383, 0.23643, 0.18265, 0.14125, 0.1308, 0.36012, 0.48029, 0.18879, 0.36044, 0.17775]
Predicted label: 0
Correct prediction
Energy consumption = 203.674256 pJ
sum error= 281
Actual label: 1
Output voltages: [0.17811, 0.75645, 0.12229, 0.24602, 0.25357, 0.21442, 0.43108, 0.1583, 0.35202, 0.20082]
Predicted label: 1
Correct prediction
Energy consumption = 210.351026 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 856 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 856 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 856 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.39021, 0.17287, 0.72999, 0.41026, 0.19291, 0.04013, 0.192, 0.21964, 0.40056, 0.14674]
Predicted label: 2
Correct prediction
Energy consumption = 191.533371 pJ
sum error= 281
Actual label: 3
Output voltages: [0.16269, 0.19045, 0.27708, 0.70417, 0.14715, 0.29973, 0.062592, 0.26109, 0.56174, 0.25299]
Predicted label: 3
Correct prediction
Energy consumption = 179.434160 pJ
sum error= 281
Actual label: 4
Output voltages: [0.20375, 0.16489, 0.29304, 0.16997, 0.7648, 0.11803, 0.29401, 0.29974, 0.19269, 0.26095]
Predicted label: 4
Correct prediction
Energy consumption = 194.587523 pJ
sum error= 281
Actual label: 5
Output voltages: [0.22951, 0.068857, 0.13586, 0.43727, 0.19189, 0.72207, 0.24253, 0.23882, 0.52075, 0.27981]
Predicted label: 5
Correct prediction
Energy consumption = 184.868269 pJ
sum error= 281
Actual label: 6
Output voltages: [0.34968, 0.30328, 0.2911, 0.091164, 0.31116, 0.31536, 0.73677, 0.096441, 0.31339, 0.13796]
Predicted label: 6
Correct prediction
Energy consumption = 196.100470 pJ
sum error= 281
Actual label: 7
Output voltages: [0.33247, 0.39462, 0.38127, 0.40577, 0.070185, 0.03567, 0.097087, 0.65, 0.29587, 0.33717]
Predicted label: 7
Correct prediction
Energy consumption = 206.713950 pJ
sum error= 281
Actual label: 8
Output voltages: [0.19192, 0.15891, 0.27571, 0.26927, 0.21561, 0.28689, 0.22126, 0.11957, 0.74924, 0.25828]
Predicted label: 8
Correct prediction
Energy consumption = 191.986614 pJ
sum error= 281
Actual label: 0
Output voltages: [0.72427, 0.23417, 0.23866, 0.22456, 0.11205, 0.25597, 0.33724, 0.081102, 0.34835, 0.25321]
Predicted label: 0
Correct prediction
Energy consumption = 192.534633 pJ
sum error= 281
Actual label: 1
Output voltages: [0.1659, 0.77444, 0.24665, 0.28467, 0.21854, 0.12305, 0.3956, 0.16802, 0.28603, 0.21286]
Predicted label: 1
Correct prediction
Energy consumption = 203.495264 pJ
sum error= 281
Actual label: 2
Output voltages: [0.40391, 0.11455, 0.74332, 0.37593, 0.14931, 0.051887, 0.22955, 0.29308, 0.38724, 0.17269]
Predicted label: 2
Correct prediction
Energy consumption = 183.792097 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 857 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 857 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 857 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.28491, 0.20114, 0.28695, 0.7495, 0.15092, 0.29713, 0.088266, 0.18326, 0.51003, 0.18808]
Predicted label: 3
Correct prediction
Energy consumption = 190.505285 pJ
sum error= 281
Actual label: 5
Output voltages: [0.29413, 0.11745, 0.10629, 0.29936, 0.16475, 0.75082, 0.29438, 0.26877, 0.44753, 0.27147]
Predicted label: 5
Correct prediction
Energy consumption = 183.582113 pJ
sum error= 281
Actual label: 6
Output voltages: [0.28114, 0.2847, 0.32727, 0.063534, 0.31233, 0.32853, 0.75016, 0.080134, 0.35337, 0.098648]
Predicted label: 6
Correct prediction
Energy consumption = 193.084328 pJ
sum error= 281
Actual label: 7
Output voltages: [0.35715, 0.29276, 0.18423, 0.33968, 0.12244, 0.16777, 0.042411, 0.75017, 0.25891, 0.37941]
Predicted label: 7
Correct prediction
Energy consumption = 202.686805 pJ
sum error= 281
Actual label: 8
Output voltages: [0.22277, 0.18119, 0.29777, 0.25081, 0.17008, 0.23205, 0.1689, 0.17476, 0.7561, 0.26217]
Predicted label: 8
Correct prediction
Energy consumption = 185.379592 pJ
sum error= 281
Actual label: 1
Output voltages: [0.17992, 0.76351, 0.31347, 0.28889, 0.14959, 0.075809, 0.32772, 0.17965, 0.33952, 0.24401]
Predicted label: 1
Correct prediction
Energy consumption = 213.355816 pJ
sum error= 281
Actual label: 0
Output voltages: [0.72773, 0.23013, 0.19181, 0.16422, 0.21667, 0.23878, 0.50588, 0.13789, 0.25896, 0.26899]
Predicted label: 0
Correct prediction
Energy consumption = 199.130860 pJ
sum error= 281
Actual label: 4
Output voltages: [0.16408, 0.18226, 0.30125, 0.18276, 0.76113, 0.055379, 0.21881, 0.33093, 0.20706, 0.28141]
Predicted label: 4
Correct prediction
Energy consumption = 197.819952 pJ
sum error= 281
Actual label: 5
Output voltages: [0.38861, 0.085104, 0.12786, 0.33838, 0.17234, 0.67686, 0.38249, 0.21969, 0.39608, 0.26609]
Predicted label: 5
Correct prediction
Energy consumption = 196.114648 pJ
sum error= 281
Actual label: 6
Output voltages: [0.3359, 0.25127, 0.30221, 0.095905, 0.30897, 0.30791, 0.74711, 0.088027, 0.33626, 0.18854]
Predicted label: 6
Correct prediction
Energy consumption = 187.721168 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 858 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 858 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 858 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.33087, 0.32789, 0.30964, 0.12877, 0.32439, 0.36417, 0.75114, 0.10781, 0.31283, 0.10738]
Predicted label: 6
Correct prediction
Energy consumption = 194.646813 pJ
sum error= 281
Actual label: 3
Output voltages: [0.29769, 0.20164, 0.33452, 0.74594, 0.1631, 0.11006, 0.15344, 0.12277, 0.48238, 0.2896]
Predicted label: 3
Correct prediction
Energy consumption = 185.758727 pJ
sum error= 281
Actual label: 4
Output voltages: [0.15289, 0.15484, 0.31886, 0.20842, 0.763, 0.11449, 0.28569, 0.25478, 0.18631, 0.27173]
Predicted label: 4
Correct prediction
Energy consumption = 192.362466 pJ
sum error= 281
Actual label: 4
Output voltages: [0.17957, 0.12421, 0.36797, 0.18389, 0.75726, 0.075603, 0.26265, 0.25721, 0.1916, 0.3]
Predicted label: 4
Correct prediction
Energy consumption = 187.313931 pJ
sum error= 281
Actual label: 2
Output voltages: [0.44738, 0.21629, 0.70419, 0.3993, 0.077749, 0.059121, 0.28098, 0.11454, 0.37801, 0.21224]
Predicted label: 2
Correct prediction
Energy consumption = 195.186382 pJ
sum error= 281
Actual label: 8
Output voltages: [0.20353, 0.24097, 0.28655, 0.32297, 0.10196, 0.24551, 0.20232, 0.14607, 0.75648, 0.29331]
Predicted label: 8
Correct prediction
Energy consumption = 192.058335 pJ
sum error= 281
Actual label: 1
Output voltages: [0.17294, 0.76728, 0.25985, 0.28115, 0.31083, 0.070404, 0.38082, 0.17119, 0.27549, 0.24939]
Predicted label: 1
Correct prediction
Energy consumption = 206.623370 pJ
sum error= 281
Actual label: 0
Output voltages: [0.68808, 0.24901, 0.20363, 0.12668, 0.20377, 0.19052, 0.50193, 0.10641, 0.28952, 0.21703]
Predicted label: 0
Correct prediction
Energy consumption = 199.731376 pJ
sum error= 281
Actual label: 6
Output voltages: [0.31453, 0.25231, 0.30358, 0.085772, 0.32391, 0.34132, 0.75414, 0.077779, 0.33204, 0.16709]
Predicted label: 6
Correct prediction
Energy consumption = 185.587598 pJ
sum error= 281
Actual label: 4
Output voltages: [0.1407, 0.14802, 0.31277, 0.15724, 0.75631, 0.070979, 0.2659, 0.25642, 0.24731, 0.24684]
Predicted label: 4
Correct prediction
Energy consumption = 193.797415 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 859 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 859 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 859 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33509, 0.12927, 0.26214, 0.34595, 0.28559, 0.21388, 0.13776, 0.32926, 0.30139, 0.66469]
Predicted label: 9
Correct prediction
Energy consumption = 198.795098 pJ
sum error= 281
Actual label: 7
Output voltages: [0.30068, 0.41123, 0.24927, 0.42949, 0.10099, 0.042922, 0.052937, 0.71135, 0.25649, 0.34675]
Predicted label: 7
Correct prediction
Energy consumption = 205.376466 pJ
sum error= 281
Actual label: 2
Output voltages: [0.36077, 0.23243, 0.7333, 0.42157, 0.13308, 0.048051, 0.23034, 0.20199, 0.36994, 0.1048]
Predicted label: 2
Correct prediction
Energy consumption = 189.686241 pJ
sum error= 281
Actual label: 9
Output voltages: [0.34648, 0.15896, 0.21496, 0.17027, 0.47976, 0.13543, 0.20981, 0.28798, 0.22737, 0.62481]
Predicted label: 9
Correct prediction
Energy consumption = 202.290009 pJ
sum error= 281
Actual label: 2
Output voltages: [0.41198, 0.18411, 0.71975, 0.42988, 0.17966, 0.041301, 0.21927, 0.21227, 0.40717, 0.21118]
Predicted label: 2
Correct prediction
Energy consumption = 196.674228 pJ
sum error= 281
Actual label: 0
Output voltages: [0.73176, 0.21735, 0.23195, 0.14422, 0.19111, 0.22982, 0.44628, 0.15072, 0.28369, 0.24296]
Predicted label: 0
Correct prediction
Energy consumption = 191.037934 pJ
sum error= 281
Actual label: 9
Output voltages: [0.3706, 0.14179, 0.21125, 0.25189, 0.41519, 0.20075, 0.23685, 0.23074, 0.24931, 0.66837]
Predicted label: 9
Correct prediction
Energy consumption = 198.648610 pJ
sum error= 281
Actual label: 3
Output voltages: [0.2142, 0.19041, 0.34337, 0.72155, 0.090296, 0.21204, 0.098768, 0.19943, 0.55577, 0.23346]
Predicted label: 3
Correct prediction
Energy consumption = 186.504384 pJ
sum error= 281
Actual label: 3
Output voltages: [0.37874, 0.13406, 0.35251, 0.74855, 0.15549, 0.14157, 0.15114, 0.15986, 0.44603, 0.26055]
Predicted label: 3
Correct prediction
Energy consumption = 184.675068 pJ
sum error= 281
Actual label: 9
Output voltages: [0.29608, 0.11833, 0.22693, 0.28709, 0.35075, 0.2062, 0.14721, 0.18817, 0.36934, 0.68233]
Predicted label: 9
Correct prediction
Energy consumption = 186.533497 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 860 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 860 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 860 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.17585, 0.7553, 0.33912, 0.24482, 0.2541, 0.053477, 0.3099, 0.098571, 0.31376, 0.2453]
Predicted label: 1
Correct prediction
Energy consumption = 208.828510 pJ
sum error= 281
Actual label: 5
Output voltages: [0.21755, 0.075453, 0.08259, 0.39971, 0.25088, 0.66793, 0.2394, 0.19232, 0.52545, 0.31589]
Predicted label: 5
Correct prediction
Energy consumption = 193.319976 pJ
sum error= 281
Actual label: 2
Output voltages: [0.3954, 0.13106, 0.71844, 0.39795, 0.14952, 0.051212, 0.17793, 0.17282, 0.42568, 0.18758]
Predicted label: 2
Correct prediction
Energy consumption = 194.162224 pJ
sum error= 281
Actual label: 3
Output voltages: [0.47636, 0.10233, 0.33946, 0.74213, 0.14785, 0.22041, 0.13783, 0.1829, 0.43778, 0.16056]
Predicted label: 3
Correct prediction
Energy consumption = 183.693619 pJ
sum error= 281
Actual label: 1
Output voltages: [0.14326, 0.76591, 0.2234, 0.24403, 0.25514, 0.086422, 0.32197, 0.15472, 0.34125, 0.29608]
Predicted label: 1
Correct prediction
Energy consumption = 213.775382 pJ
sum error= 281
Actual label: 6
Output voltages: [0.35877, 0.30801, 0.28272, 0.13809, 0.30624, 0.32921, 0.74475, 0.11205, 0.32774, 0.117]
Predicted label: 6
Correct prediction
Energy consumption = 197.110661 pJ
sum error= 281
Actual label: 7
Output voltages: [0.34466, 0.3338, 0.37238, 0.38389, 0.12429, 0.038167, 0.049325, 0.69751, 0.2515, 0.39148]
Predicted label: 7
Correct prediction
Energy consumption = 206.376259 pJ
sum error= 281
Actual label: 3
Output voltages: [0.28207, 0.16034, 0.25309, 0.67557, 0.079666, 0.272, 0.11175, 0.16084, 0.57836, 0.28605]
Predicted label: 3
Correct prediction
Energy consumption = 182.995286 pJ
sum error= 281
Actual label: 7
Output voltages: [0.29528, 0.21949, 0.27239, 0.41914, 0.085602, 0.086125, 0.045137, 0.74729, 0.30146, 0.4173]
Predicted label: 7
Correct prediction
Energy consumption = 199.359264 pJ
sum error= 281
Actual label: 8
Output voltages: [0.18827, 0.21273, 0.33135, 0.24206, 0.16474, 0.19184, 0.16379, 0.15008, 0.74046, 0.34561]
Predicted label: 8
Correct prediction
Energy consumption = 190.321803 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 861 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 861 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 861 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19757, 0.099767, 0.2979, 0.13182, 0.7413, 0.051553, 0.27673, 0.33597, 0.34146, 0.15034]
Predicted label: 4
Correct prediction
Energy consumption = 197.403593 pJ
sum error= 281
Actual label: 0
Output voltages: [0.73649, 0.22838, 0.14983, 0.23181, 0.12655, 0.25463, 0.40087, 0.12743, 0.27231, 0.28022]
Predicted label: 0
Correct prediction
Energy consumption = 202.604460 pJ
sum error= 281
Actual label: 2
Output voltages: [0.36955, 0.21207, 0.76105, 0.29844, 0.19543, 0.044151, 0.24369, 0.30554, 0.38163, 0.15263]
Predicted label: 2
Correct prediction
Energy consumption = 185.897267 pJ
sum error= 281
Actual label: 4
Output voltages: [0.13625, 0.12678, 0.31622, 0.23717, 0.74706, 0.05305, 0.19136, 0.27174, 0.24602, 0.28228]
Predicted label: 4
Correct prediction
Energy consumption = 196.414830 pJ
sum error= 281
Actual label: 0
Output voltages: [0.72759, 0.23634, 0.24289, 0.16032, 0.22329, 0.13775, 0.43227, 0.16316, 0.31136, 0.19158]
Predicted label: 0
Correct prediction
Energy consumption = 201.288059 pJ
sum error= 281
Actual label: 2
Output voltages: [0.35224, 0.15659, 0.58098, 0.58519, 0.15524, 0.049062, 0.18336, 0.13267, 0.45929, 0.15893]
Predicted label: 3
Wrong prediction!
Energy consumption = 190.593426 pJ
sum error= 282
Actual label: 4
Output voltages: [0.20825, 0.25619, 0.18442, 0.20351, 0.73833, 0.16076, 0.28707, 0.23299, 0.21806, 0.35936]
Predicted label: 4
Correct prediction
Energy consumption = 207.635268 pJ
sum error= 282
Actual label: 7
Output voltages: [0.32644, 0.26903, 0.21302, 0.30986, 0.18705, 0.085124, 0.048322, 0.75518, 0.23076, 0.34365]
Predicted label: 7
Correct prediction
Energy consumption = 191.559305 pJ
sum error= 282
Actual label: 8
Output voltages: [0.19213, 0.27181, 0.29069, 0.34102, 0.11278, 0.22073, 0.22731, 0.18744, 0.74667, 0.29741]
Predicted label: 8
Correct prediction
Energy consumption = 190.513631 pJ
sum error= 282
Actual label: 0
Output voltages: [0.74126, 0.25045, 0.2881, 0.17563, 0.16171, 0.15196, 0.37569, 0.15169, 0.2858, 0.2568]
Predicted label: 0
Correct prediction
Energy consumption = 188.010422 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 862 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 862 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 862 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32195, 0.24031, 0.2193, 0.27584, 0.17648, 0.15201, 0.047518, 0.76446, 0.26068, 0.34635]
Predicted label: 7
Correct prediction
Energy consumption = 201.217248 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71983, 0.32405, 0.19179, 0.18197, 0.19495, 0.16602, 0.46684, 0.15078, 0.27566, 0.18555]
Predicted label: 0
Correct prediction
Energy consumption = 202.247611 pJ
sum error= 282
Actual label: 6
Output voltages: [0.30482, 0.28597, 0.30298, 0.089499, 0.2908, 0.33987, 0.74913, 0.099551, 0.3469, 0.13051]
Predicted label: 6
Correct prediction
Energy consumption = 190.561179 pJ
sum error= 282
Actual label: 9
Output voltages: [0.4085, 0.17151, 0.18194, 0.29134, 0.38606, 0.25253, 0.14414, 0.32848, 0.26151, 0.66445]
Predicted label: 9
Correct prediction
Energy consumption = 201.130375 pJ
sum error= 282
Actual label: 3
Output voltages: [0.43186, 0.15483, 0.2632, 0.75331, 0.12824, 0.26387, 0.13721, 0.20004, 0.38769, 0.19869]
Predicted label: 3
Correct prediction
Energy consumption = 190.670211 pJ
sum error= 282
Actual label: 2
Output voltages: [0.37058, 0.18278, 0.75464, 0.31522, 0.2463, 0.050632, 0.21293, 0.22023, 0.4461, 0.19998]
Predicted label: 2
Correct prediction
Energy consumption = 185.825820 pJ
sum error= 282
Actual label: 4
Output voltages: [0.15809, 0.14679, 0.2869, 0.16808, 0.76484, 0.049279, 0.2693, 0.28496, 0.2063, 0.2484]
Predicted label: 4
Correct prediction
Energy consumption = 187.510426 pJ
sum error= 282
Actual label: 8
Output voltages: [0.18532, 0.23372, 0.2741, 0.21466, 0.20079, 0.23464, 0.16611, 0.1676, 0.75297, 0.30456]
Predicted label: 8
Correct prediction
Energy consumption = 193.978351 pJ
sum error= 282
Actual label: 6
Output voltages: [0.34901, 0.27995, 0.27251, 0.10393, 0.26199, 0.34475, 0.74042, 0.11299, 0.34264, 0.1606]
Predicted label: 6
Correct prediction
Energy consumption = 199.770682 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71113, 0.25411, 0.22496, 0.13711, 0.19668, 0.14841, 0.47373, 0.14521, 0.29941, 0.20258]
Predicted label: 0
Correct prediction
Energy consumption = 193.642555 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 863 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 863 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 863 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.23844, 0.12094, 0.15491, 0.45534, 0.15607, 0.71108, 0.26369, 0.15372, 0.47634, 0.25277]
Predicted label: 5
Correct prediction
Energy consumption = 191.223855 pJ
sum error= 282
Actual label: 7
Output voltages: [0.32322, 0.22751, 0.26014, 0.31932, 0.11884, 0.10124, 0.057215, 0.75866, 0.29722, 0.32522]
Predicted label: 7
Correct prediction
Energy consumption = 198.580631 pJ
sum error= 282
Actual label: 5
Output voltages: [0.26835, 0.16395, 0.14219, 0.47723, 0.17769, 0.64811, 0.42361, 0.17133, 0.32923, 0.1903]
Predicted label: 5
Correct prediction
Energy consumption = 192.025116 pJ
sum error= 282
Actual label: 1
Output voltages: [0.16591, 0.75688, 0.31543, 0.35317, 0.2164, 0.047762, 0.27398, 0.22206, 0.29538, 0.25798]
Predicted label: 1
Correct prediction
Energy consumption = 215.943104 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73701, 0.23477, 0.23103, 0.19607, 0.22483, 0.16778, 0.44504, 0.15897, 0.30992, 0.24089]
Predicted label: 0
Correct prediction
Energy consumption = 205.831728 pJ
sum error= 282
Actual label: 8
Output voltages: [0.18317, 0.24132, 0.29167, 0.20595, 0.17031, 0.18458, 0.22589, 0.212, 0.74651, 0.31246]
Predicted label: 8
Correct prediction
Energy consumption = 200.837835 pJ
sum error= 282
Actual label: 1
Output voltages: [0.25264, 0.7627, 0.294, 0.27299, 0.22529, 0.061904, 0.36909, 0.086948, 0.3201, 0.23153]
Predicted label: 1
Correct prediction
Energy consumption = 203.786775 pJ
sum error= 282
Actual label: 6
Output voltages: [0.38393, 0.16248, 0.30909, 0.064912, 0.30794, 0.20674, 0.68111, 0.11569, 0.34525, 0.15539]
Predicted label: 6
Correct prediction
Energy consumption = 196.622643 pJ
sum error= 282
Actual label: 7
Output voltages: [0.26906, 0.2537, 0.2869, 0.25721, 0.15105, 0.087938, 0.049656, 0.76744, 0.25734, 0.31076]
Predicted label: 7
Correct prediction
Energy consumption = 198.394197 pJ
sum error= 282
Actual label: 2
Output voltages: [0.43848, 0.10798, 0.72294, 0.39258, 0.11878, 0.062437, 0.20513, 0.2321, 0.462, 0.18938]
Predicted label: 2
Correct prediction
Energy consumption = 185.320224 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 864 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 864 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 864 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3428, 0.16023, 0.25747, 0.28786, 0.30561, 0.18847, 0.15124, 0.21887, 0.34672, 0.69156]
Predicted label: 9
Correct prediction
Energy consumption = 196.747362 pJ
sum error= 282
Actual label: 7
Output voltages: [0.29815, 0.22887, 0.27886, 0.21869, 0.13135, 0.055486, 0.05118, 0.75238, 0.36917, 0.36568]
Predicted label: 7
Correct prediction
Energy consumption = 195.409705 pJ
sum error= 282
Actual label: 9
Output voltages: [0.38177, 0.16597, 0.21505, 0.29518, 0.3291, 0.22864, 0.17355, 0.22, 0.31508, 0.70175]
Predicted label: 9
Correct prediction
Energy consumption = 188.827842 pJ
sum error= 282
Actual label: 5
Output voltages: [0.25024, 0.086516, 0.11538, 0.43414, 0.17957, 0.73941, 0.2541, 0.21488, 0.46836, 0.28183]
Predicted label: 5
Correct prediction
Energy consumption = 184.810525 pJ
sum error= 282
Actual label: 6
Output voltages: [0.29989, 0.25143, 0.29866, 0.098929, 0.32199, 0.35479, 0.7454, 0.081946, 0.39528, 0.13589]
Predicted label: 6
Correct prediction
Energy consumption = 192.225808 pJ
sum error= 282
Actual label: 5
Output voltages: [0.34135, 0.075562, 0.10399, 0.41609, 0.14687, 0.70117, 0.2629, 0.21925, 0.50144, 0.26729]
Predicted label: 5
Correct prediction
Energy consumption = 191.952938 pJ
sum error= 282
Actual label: 2
Output voltages: [0.41342, 0.20337, 0.74659, 0.3079, 0.17029, 0.03468, 0.26014, 0.26225, 0.35219, 0.17578]
Predicted label: 2
Correct prediction
Energy consumption = 185.315710 pJ
sum error= 282
Actual label: 6
Output voltages: [0.31238, 0.29632, 0.24145, 0.17355, 0.25659, 0.37391, 0.74711, 0.12884, 0.36059, 0.10888]
Predicted label: 6
Correct prediction
Energy consumption = 199.198966 pJ
sum error= 282
Actual label: 2
Output voltages: [0.38205, 0.1894, 0.72647, 0.41574, 0.13434, 0.04005, 0.24068, 0.18298, 0.40022, 0.16416]
Predicted label: 2
Correct prediction
Energy consumption = 188.122372 pJ
sum error= 282
Actual label: 8
Output voltages: [0.17674, 0.20784, 0.2674, 0.30962, 0.12228, 0.26424, 0.17353, 0.14504, 0.75399, 0.30866]
Predicted label: 8
Correct prediction
Energy consumption = 187.650362 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 865 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 865 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 865 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.1993, 0.76084, 0.20161, 0.24512, 0.32515, 0.088434, 0.36066, 0.083014, 0.29006, 0.27188]
Predicted label: 1
Correct prediction
Energy consumption = 208.683907 pJ
sum error= 282
Actual label: 7
Output voltages: [0.33508, 0.261, 0.24736, 0.31418, 0.15207, 0.073178, 0.048778, 0.76163, 0.22907, 0.34693]
Predicted label: 7
Correct prediction
Energy consumption = 193.469276 pJ
sum error= 282
Actual label: 5
Output voltages: [0.30824, 0.067713, 0.072049, 0.42741, 0.18546, 0.73668, 0.28293, 0.24479, 0.47387, 0.27925]
Predicted label: 5
Correct prediction
Energy consumption = 187.005317 pJ
sum error= 282
Actual label: 5
Output voltages: [0.29019, 0.15884, 0.18651, 0.46427, 0.083853, 0.66833, 0.33602, 0.25714, 0.42144, 0.16207]
Predicted label: 5
Correct prediction
Energy consumption = 179.124422 pJ
sum error= 282
Actual label: 7
Output voltages: [0.34983, 0.23895, 0.24598, 0.39195, 0.14401, 0.084522, 0.052184, 0.7545, 0.22493, 0.37951]
Predicted label: 7
Correct prediction
Energy consumption = 194.669946 pJ
sum error= 282
Actual label: 3
Output voltages: [0.48149, 0.24509, 0.26818, 0.76003, 0.10918, 0.25295, 0.14161, 0.18959, 0.36962, 0.17308]
Predicted label: 3
Correct prediction
Energy consumption = 188.347428 pJ
sum error= 282
Actual label: 5
Output voltages: [0.3049, 0.10173, 0.14324, 0.40373, 0.14384, 0.69486, 0.30756, 0.18796, 0.48163, 0.2567]
Predicted label: 5
Correct prediction
Energy consumption = 182.416673 pJ
sum error= 282
Actual label: 0
Output voltages: [0.74913, 0.2842, 0.24986, 0.2425, 0.127, 0.2316, 0.37542, 0.15779, 0.27148, 0.2245]
Predicted label: 0
Correct prediction
Energy consumption = 185.192159 pJ
sum error= 282
Actual label: 1
Output voltages: [0.16289, 0.7584, 0.27169, 0.22569, 0.26205, 0.081753, 0.40556, 0.090512, 0.3282, 0.19593]
Predicted label: 1
Correct prediction
Energy consumption = 211.175135 pJ
sum error= 282
Actual label: 1
Output voltages: [0.18824, 0.76653, 0.26508, 0.26009, 0.24926, 0.077788, 0.38964, 0.15491, 0.29765, 0.22368]
Predicted label: 1
Correct prediction
Energy consumption = 203.628917 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 866 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 866 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 866 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.2423, 0.17803, 0.30308, 0.75071, 0.15976, 0.21619, 0.10164, 0.21097, 0.45911, 0.24286]
Predicted label: 3
Correct prediction
Energy consumption = 183.964697 pJ
sum error= 282
Actual label: 8
Output voltages: [0.18196, 0.14687, 0.29052, 0.29474, 0.15395, 0.26901, 0.19305, 0.10214, 0.74253, 0.33109]
Predicted label: 8
Correct prediction
Energy consumption = 190.005226 pJ
sum error= 282
Actual label: 4
Output voltages: [0.14441, 0.1397, 0.33717, 0.16225, 0.75757, 0.074271, 0.29159, 0.26496, 0.22707, 0.24937]
Predicted label: 4
Correct prediction
Energy consumption = 193.936963 pJ
sum error= 282
Actual label: 9
Output voltages: [0.35646, 0.13157, 0.18979, 0.30488, 0.31799, 0.18551, 0.096842, 0.23858, 0.35827, 0.67565]
Predicted label: 9
Correct prediction
Energy consumption = 184.626619 pJ
sum error= 282
Actual label: 4
Output voltages: [0.18301, 0.10707, 0.32417, 0.13849, 0.7465, 0.052589, 0.26836, 0.25884, 0.29454, 0.24836]
Predicted label: 4
Correct prediction
Energy consumption = 189.427296 pJ
sum error= 282
Actual label: 5
Output voltages: [0.29723, 0.065275, 0.060044, 0.42674, 0.27033, 0.74409, 0.28523, 0.28345, 0.43548, 0.22472]
Predicted label: 5
Correct prediction
Energy consumption = 193.041772 pJ
sum error= 282
Actual label: 1
Output voltages: [0.17184, 0.76547, 0.16515, 0.33863, 0.25477, 0.096793, 0.27563, 0.15082, 0.31419, 0.27627]
Predicted label: 1
Correct prediction
Energy consumption = 215.500546 pJ
sum error= 282
Actual label: 8
Output voltages: [0.23104, 0.17292, 0.27257, 0.36538, 0.076596, 0.25245, 0.22644, 0.11455, 0.74149, 0.25775]
Predicted label: 8
Correct prediction
Energy consumption = 192.531332 pJ
sum error= 282
Actual label: 6
Output voltages: [0.2905, 0.25859, 0.32869, 0.10313, 0.27465, 0.31731, 0.74825, 0.085224, 0.33952, 0.18073]
Predicted label: 6
Correct prediction
Energy consumption = 194.182600 pJ
sum error= 282
Actual label: 8
Output voltages: [0.21356, 0.20068, 0.30271, 0.18698, 0.18541, 0.14808, 0.15802, 0.18271, 0.73855, 0.35062]
Predicted label: 8
Correct prediction
Energy consumption = 189.193071 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 867 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 867 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 867 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36509, 0.1029, 0.17543, 0.29255, 0.27326, 0.26738, 0.13196, 0.25186, 0.41798, 0.61685]
Predicted label: 9
Correct prediction
Energy consumption = 191.405485 pJ
sum error= 282
Actual label: 0
Output voltages: [0.72516, 0.27588, 0.34114, 0.21967, 0.12116, 0.11486, 0.36432, 0.17803, 0.26411, 0.28395]
Predicted label: 0
Correct prediction
Energy consumption = 191.818744 pJ
sum error= 282
Actual label: 1
Output voltages: [0.17183, 0.74925, 0.25384, 0.27515, 0.29934, 0.051839, 0.35141, 0.11077, 0.25279, 0.24411]
Predicted label: 1
Correct prediction
Energy consumption = 208.940496 pJ
sum error= 282
Actual label: 2
Output voltages: [0.37733, 0.20102, 0.7436, 0.32802, 0.14725, 0.035009, 0.24921, 0.28667, 0.41858, 0.16843]
Predicted label: 2
Correct prediction
Energy consumption = 188.989810 pJ
sum error= 282
Actual label: 3
Output voltages: [0.39414, 0.13085, 0.34806, 0.74648, 0.12327, 0.13027, 0.19747, 0.17609, 0.44594, 0.20361]
Predicted label: 3
Correct prediction
Energy consumption = 188.403899 pJ
sum error= 282
Actual label: 4
Output voltages: [0.10923, 0.13374, 0.25512, 0.19094, 0.75121, 0.062744, 0.24743, 0.2868, 0.24328, 0.21179]
Predicted label: 4
Correct prediction
Energy consumption = 186.935274 pJ
sum error= 282
Actual label: 5
Output voltages: [0.22202, 0.048409, 0.098263, 0.35148, 0.20059, 0.7, 0.32967, 0.12661, 0.54218, 0.19205]
Predicted label: 5
Correct prediction
Energy consumption = 191.041758 pJ
sum error= 282
Actual label: 6
Output voltages: [0.27148, 0.23085, 0.33538, 0.068755, 0.36219, 0.28941, 0.74349, 0.069795, 0.33248, 0.10121]
Predicted label: 6
Correct prediction
Energy consumption = 189.240512 pJ
sum error= 282
Actual label: 7
Output voltages: [0.35845, 0.2251, 0.25221, 0.32857, 0.12591, 0.14098, 0.039816, 0.72471, 0.30959, 0.38188]
Predicted label: 7
Correct prediction
Energy consumption = 199.725415 pJ
sum error= 282
Actual label: 8
Output voltages: [0.20327, 0.20523, 0.2439, 0.35503, 0.092684, 0.23179, 0.19321, 0.11019, 0.7435, 0.26889]
Predicted label: 8
Correct prediction
Energy consumption = 185.172541 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 868 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 868 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 868 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33005, 0.1063, 0.23562, 0.2507, 0.26722, 0.14223, 0.062912, 0.26682, 0.4356, 0.64162]
Predicted label: 9
Correct prediction
Energy consumption = 194.741812 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71918, 0.26492, 0.27171, 0.14015, 0.14831, 0.093377, 0.39629, 0.24543, 0.31086, 0.31327]
Predicted label: 0
Correct prediction
Energy consumption = 187.329209 pJ
sum error= 282
Actual label: 1
Output voltages: [0.15164, 0.76379, 0.19071, 0.24363, 0.3055, 0.085074, 0.34502, 0.12532, 0.33846, 0.28746]
Predicted label: 1
Correct prediction
Energy consumption = 207.913031 pJ
sum error= 282
Actual label: 2
Output voltages: [0.32771, 0.2433, 0.74499, 0.29257, 0.14336, 0.039199, 0.23339, 0.33455, 0.43926, 0.17062]
Predicted label: 2
Correct prediction
Energy consumption = 189.280660 pJ
sum error= 282
Actual label: 3
Output voltages: [0.34565, 0.21456, 0.37357, 0.69644, 0.11342, 0.12543, 0.15867, 0.065182, 0.56787, 0.29114]
Predicted label: 3
Correct prediction
Energy consumption = 187.121852 pJ
sum error= 282
Actual label: 4
Output voltages: [0.14177, 0.18841, 0.31525, 0.1426, 0.75309, 0.061827, 0.31516, 0.32307, 0.18723, 0.19315]
Predicted label: 4
Correct prediction
Energy consumption = 190.158208 pJ
sum error= 282
Actual label: 5
Output voltages: [0.23572, 0.0742, 0.05544, 0.40286, 0.2783, 0.70989, 0.37642, 0.093361, 0.49397, 0.18694]
Predicted label: 5
Correct prediction
Energy consumption = 186.910148 pJ
sum error= 282
Actual label: 6
Output voltages: [0.29726, 0.18134, 0.31103, 0.059836, 0.36703, 0.31182, 0.73799, 0.087095, 0.32015, 0.10241]
Predicted label: 6
Correct prediction
Energy consumption = 186.331361 pJ
sum error= 282
Actual label: 7
Output voltages: [0.29312, 0.27652, 0.29958, 0.2449, 0.12631, 0.047436, 0.044037, 0.74778, 0.37488, 0.31778]
Predicted label: 7
Correct prediction
Energy consumption = 204.543285 pJ
sum error= 282
Actual label: 8
Output voltages: [0.23402, 0.1828, 0.3412, 0.34318, 0.10809, 0.19632, 0.21311, 0.1358, 0.74186, 0.26189]
Predicted label: 8
Correct prediction
Energy consumption = 187.319800 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 869 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 869 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 869 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36179, 0.14603, 0.21708, 0.23847, 0.27052, 0.11051, 0.057761, 0.22501, 0.40315, 0.65828]
Predicted label: 9
Correct prediction
Energy consumption = 199.643550 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71523, 0.22669, 0.29058, 0.1911, 0.18096, 0.069443, 0.33852, 0.26065, 0.36213, 0.27821]
Predicted label: 0
Correct prediction
Energy consumption = 194.301123 pJ
sum error= 282
Actual label: 1
Output voltages: [0.20833, 0.75151, 0.24412, 0.22287, 0.29587, 0.12609, 0.43605, 0.075304, 0.31488, 0.18422]
Predicted label: 1
Correct prediction
Energy consumption = 207.745620 pJ
sum error= 282
Actual label: 2
Output voltages: [0.36019, 0.17952, 0.74173, 0.31066, 0.21257, 0.038828, 0.2654, 0.2189, 0.43042, 0.19955]
Predicted label: 2
Correct prediction
Energy consumption = 186.159223 pJ
sum error= 282
Actual label: 3
Output voltages: [0.33287, 0.18999, 0.34046, 0.75071, 0.19754, 0.1204, 0.1506, 0.13245, 0.45911, 0.26938]
Predicted label: 3
Correct prediction
Energy consumption = 186.681294 pJ
sum error= 282
Actual label: 4
Output voltages: [0.14929, 0.16944, 0.26867, 0.17662, 0.74806, 0.053593, 0.22535, 0.24437, 0.23801, 0.23326]
Predicted label: 4
Correct prediction
Energy consumption = 186.828243 pJ
sum error= 282
Actual label: 5
Output voltages: [0.30034, 0.094422, 0.058097, 0.28664, 0.18898, 0.75846, 0.30784, 0.17887, 0.51523, 0.15002]
Predicted label: 5
Correct prediction
Energy consumption = 194.594121 pJ
sum error= 282
Actual label: 6
Output voltages: [0.2983, 0.24437, 0.29041, 0.086468, 0.32899, 0.37366, 0.73981, 0.091549, 0.33188, 0.12777]
Predicted label: 6
Correct prediction
Energy consumption = 192.332528 pJ
sum error= 282
Actual label: 7
Output voltages: [0.32511, 0.24883, 0.25538, 0.18628, 0.21943, 0.089196, 0.037033, 0.75145, 0.28665, 0.27112]
Predicted label: 7
Correct prediction
Energy consumption = 196.543732 pJ
sum error= 282
Actual label: 8
Output voltages: [0.20247, 0.14364, 0.23789, 0.39399, 0.14129, 0.22858, 0.18953, 0.16599, 0.73747, 0.21529]
Predicted label: 8
Correct prediction
Energy consumption = 192.510253 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 870 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 870 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 870 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32155, 0.12389, 0.19827, 0.23472, 0.32211, 0.11214, 0.072333, 0.20166, 0.42008, 0.64393]
Predicted label: 9
Correct prediction
Energy consumption = 193.210991 pJ
sum error= 282
Actual label: 3
Output voltages: [0.37196, 0.1743, 0.31879, 0.75519, 0.14925, 0.20225, 0.1522, 0.17653, 0.4155, 0.25837]
Predicted label: 3
Correct prediction
Energy consumption = 189.147935 pJ
sum error= 282
Actual label: 5
Output voltages: [0.20865, 0.084127, 0.10933, 0.34677, 0.19257, 0.67715, 0.31342, 0.070092, 0.5396, 0.21895]
Predicted label: 5
Correct prediction
Energy consumption = 184.920192 pJ
sum error= 282
Actual label: 3
Output voltages: [0.46141, 0.16186, 0.41723, 0.73503, 0.091252, 0.11825, 0.15045, 0.16441, 0.40599, 0.23336]
Predicted label: 3
Correct prediction
Energy consumption = 191.121725 pJ
sum error= 282
Actual label: 2
Output voltages: [0.34414, 0.28422, 0.74282, 0.32378, 0.15942, 0.027616, 0.24083, 0.32745, 0.37627, 0.22422]
Predicted label: 2
Correct prediction
Energy consumption = 178.730317 pJ
sum error= 282
Actual label: 9
Output voltages: [0.3233, 0.093837, 0.21834, 0.25105, 0.35151, 0.17655, 0.089874, 0.29577, 0.40042, 0.64518]
Predicted label: 9
Correct prediction
Energy consumption = 189.397197 pJ
sum error= 282
Actual label: 3
Output voltages: [0.37078, 0.17436, 0.35459, 0.7521, 0.19278, 0.085436, 0.18512, 0.16595, 0.4423, 0.22095]
Predicted label: 3
Correct prediction
Energy consumption = 183.219023 pJ
sum error= 282
Actual label: 2
Output voltages: [0.35709, 0.18376, 0.75348, 0.26561, 0.20566, 0.042484, 0.23484, 0.30448, 0.414, 0.15541]
Predicted label: 2
Correct prediction
Energy consumption = 181.631884 pJ
sum error= 282
Actual label: 1
Output voltages: [0.15461, 0.73305, 0.29576, 0.22925, 0.30929, 0.068533, 0.36226, 0.19426, 0.35917, 0.12426]
Predicted label: 1
Correct prediction
Energy consumption = 206.338877 pJ
sum error= 282
Actual label: 4
Output voltages: [0.15417, 0.15122, 0.27418, 0.073476, 0.75139, 0.15454, 0.23069, 0.25344, 0.29066, 0.28079]
Predicted label: 4
Correct prediction
Energy consumption = 189.022518 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 871 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 871 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 871 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.15839, 0.044773, 0.067835, 0.27223, 0.26092, 0.67996, 0.35413, 0.10528, 0.56491, 0.22334]
Predicted label: 5
Correct prediction
Energy consumption = 188.597205 pJ
sum error= 282
Actual label: 5
Output voltages: [0.17358, 0.059961, 0.11229, 0.38897, 0.21314, 0.63471, 0.28339, 0.10508, 0.55444, 0.21025]
Predicted label: 5
Correct prediction
Energy consumption = 181.731530 pJ
sum error= 282
Actual label: 2
Output voltages: [0.33469, 0.24387, 0.75092, 0.31512, 0.18106, 0.036303, 0.25132, 0.25267, 0.39867, 0.17137]
Predicted label: 2
Correct prediction
Energy consumption = 184.844136 pJ
sum error= 282
Actual label: 3
Output voltages: [0.39201, 0.16925, 0.32981, 0.75381, 0.15556, 0.14945, 0.19675, 0.16882, 0.39055, 0.2093]
Predicted label: 3
Correct prediction
Energy consumption = 183.015360 pJ
sum error= 282
Actual label: 2
Output voltages: [0.35528, 0.33431, 0.73947, 0.30335, 0.20612, 0.027682, 0.25142, 0.29039, 0.34208, 0.21197]
Predicted label: 2
Correct prediction
Energy consumption = 181.645189 pJ
sum error= 282
Actual label: 1
Output voltages: [0.22792, 0.74164, 0.28055, 0.30935, 0.23662, 0.08159, 0.39234, 0.054433, 0.39236, 0.23251]
Predicted label: 1
Correct prediction
Energy consumption = 213.080718 pJ
sum error= 282
Actual label: 3
Output voltages: [0.46436, 0.14048, 0.33085, 0.74848, 0.12925, 0.1625, 0.095766, 0.2377, 0.37716, 0.22135]
Predicted label: 3
Correct prediction
Energy consumption = 186.597881 pJ
sum error= 282
Actual label: 9
Output voltages: [0.36341, 0.095387, 0.21621, 0.26795, 0.33505, 0.19881, 0.091298, 0.29109, 0.36825, 0.65178]
Predicted label: 9
Correct prediction
Energy consumption = 186.846414 pJ
sum error= 282
Actual label: 7
Output voltages: [0.2826, 0.29643, 0.43456, 0.25332, 0.11999, 0.039082, 0.048431, 0.74442, 0.37356, 0.29048]
Predicted label: 7
Correct prediction
Energy consumption = 188.927315 pJ
sum error= 282
Actual label: 2
Output voltages: [0.35423, 0.26615, 0.74533, 0.32405, 0.23719, 0.034158, 0.22586, 0.28928, 0.36586, 0.18684]
Predicted label: 2
Correct prediction
Energy consumption = 179.552533 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 872 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 872 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 872 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16516, 0.75489, 0.29054, 0.24234, 0.3329, 0.10059, 0.39323, 0.14694, 0.27254, 0.17002]
Predicted label: 1
Correct prediction
Energy consumption = 205.416843 pJ
sum error= 282
Actual label: 2
Output voltages: [0.36367, 0.24623, 0.73974, 0.35287, 0.17699, 0.031722, 0.22676, 0.33809, 0.38765, 0.20094]
Predicted label: 2
Correct prediction
Energy consumption = 185.557899 pJ
sum error= 282
Actual label: 8
Output voltages: [0.21345, 0.16772, 0.29869, 0.44496, 0.063851, 0.24826, 0.17195, 0.1393, 0.72415, 0.22262]
Predicted label: 8
Correct prediction
Energy consumption = 195.253631 pJ
sum error= 282
Actual label: 9
Output voltages: [0.30607, 0.12843, 0.20868, 0.22429, 0.24933, 0.14861, 0.059766, 0.2356, 0.45122, 0.66324]
Predicted label: 9
Correct prediction
Energy consumption = 183.024948 pJ
sum error= 282
Actual label: 1
Output voltages: [0.17251, 0.76489, 0.31203, 0.21064, 0.23116, 0.069693, 0.40211, 0.16071, 0.32325, 0.18877]
Predicted label: 1
Correct prediction
Energy consumption = 204.827199 pJ
sum error= 282
Actual label: 8
Output voltages: [0.21167, 0.18605, 0.26394, 0.35232, 0.10132, 0.22448, 0.17159, 0.13952, 0.7401, 0.30891]
Predicted label: 8
Correct prediction
Energy consumption = 196.460674 pJ
sum error= 282
Actual label: 8
Output voltages: [0.20413, 0.16874, 0.25016, 0.26633, 0.128, 0.25843, 0.19046, 0.12586, 0.73709, 0.32871]
Predicted label: 8
Correct prediction
Energy consumption = 190.967245 pJ
sum error= 282
Actual label: 7
Output voltages: [0.25265, 0.31096, 0.27072, 0.28582, 0.14838, 0.074359, 0.042931, 0.75242, 0.25328, 0.33939]
Predicted label: 7
Correct prediction
Energy consumption = 196.346414 pJ
sum error= 282
Actual label: 8
Output voltages: [0.16089, 0.1724, 0.21264, 0.31982, 0.1273, 0.282, 0.16977, 0.11957, 0.72377, 0.30031]
Predicted label: 8
Correct prediction
Energy consumption = 198.322451 pJ
sum error= 282
Actual label: 1
Output voltages: [0.22681, 0.74657, 0.27253, 0.23242, 0.2009, 0.087022, 0.50169, 0.058203, 0.31491, 0.22362]
Predicted label: 1
Correct prediction
Energy consumption = 202.465354 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 873 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 873 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 873 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74045, 0.22359, 0.26398, 0.21552, 0.18322, 0.12948, 0.38982, 0.20492, 0.32741, 0.27014]
Predicted label: 0
Correct prediction
Energy consumption = 193.822111 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73079, 0.26906, 0.26379, 0.19091, 0.15794, 0.1127, 0.39405, 0.16723, 0.29449, 0.27992]
Predicted label: 0
Correct prediction
Energy consumption = 188.343837 pJ
sum error= 282
Actual label: 6
Output voltages: [0.2899, 0.23184, 0.34838, 0.058923, 0.36341, 0.28076, 0.74518, 0.091078, 0.31572, 0.13409]
Predicted label: 6
Correct prediction
Energy consumption = 188.292061 pJ
sum error= 282
Actual label: 7
Output voltages: [0.26652, 0.31146, 0.28821, 0.30457, 0.12284, 0.053597, 0.042487, 0.74962, 0.28, 0.31468]
Predicted label: 7
Correct prediction
Energy consumption = 201.389846 pJ
sum error= 282
Actual label: 7
Output voltages: [0.30888, 0.24171, 0.33686, 0.22766, 0.11807, 0.057888, 0.05315, 0.76011, 0.43501, 0.30249]
Predicted label: 7
Correct prediction
Energy consumption = 196.122509 pJ
sum error= 282
Actual label: 8
Output voltages: [0.20215, 0.19871, 0.23164, 0.32728, 0.10751, 0.22899, 0.13048, 0.16646, 0.73715, 0.308]
Predicted label: 8
Correct prediction
Energy consumption = 189.170333 pJ
sum error= 282
Actual label: 7
Output voltages: [0.3305, 0.22276, 0.18579, 0.25231, 0.21962, 0.13609, 0.040331, 0.71192, 0.3722, 0.39956]
Predicted label: 7
Correct prediction
Energy consumption = 196.924248 pJ
sum error= 282
Actual label: 5
Output voltages: [0.25957, 0.085852, 0.095251, 0.43019, 0.20282, 0.72326, 0.3436, 0.083191, 0.47549, 0.21583]
Predicted label: 5
Correct prediction
Energy consumption = 188.431041 pJ
sum error= 282
Actual label: 0
Output voltages: [0.6944, 0.1771, 0.27153, 0.14085, 0.29215, 0.14102, 0.47198, 0.21745, 0.29098, 0.19248]
Predicted label: 0
Correct prediction
Energy consumption = 194.616139 pJ
sum error= 282
Actual label: 6
Output voltages: [0.3029, 0.23123, 0.29233, 0.14546, 0.30567, 0.35801, 0.74687, 0.065145, 0.37399, 0.20042]
Predicted label: 6
Correct prediction
Energy consumption = 188.548281 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 874 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 874 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 874 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.11403, 0.76537, 0.24286, 0.20061, 0.1979, 0.11134, 0.39979, 0.15399, 0.398, 0.19587]
Predicted label: 1
Correct prediction
Energy consumption = 204.172299 pJ
sum error= 282
Actual label: 5
Output voltages: [0.20196, 0.047999, 0.074419, 0.38008, 0.26326, 0.70521, 0.32505, 0.13593, 0.49977, 0.24463]
Predicted label: 5
Correct prediction
Energy consumption = 190.950056 pJ
sum error= 282
Actual label: 7
Output voltages: [0.24977, 0.3863, 0.40558, 0.19568, 0.094029, 0.042897, 0.053311, 0.65463, 0.39288, 0.2274]
Predicted label: 7
Correct prediction
Energy consumption = 207.558848 pJ
sum error= 282
Actual label: 4
Output voltages: [0.14614, 0.14021, 0.21384, 0.091292, 0.75338, 0.099819, 0.29926, 0.26407, 0.33023, 0.14203]
Predicted label: 4
Correct prediction
Energy consumption = 191.472839 pJ
sum error= 282
Actual label: 6
Output voltages: [0.33839, 0.20815, 0.27253, 0.14994, 0.29531, 0.38011, 0.72143, 0.090026, 0.43786, 0.13388]
Predicted label: 6
Correct prediction
Energy consumption = 187.865775 pJ
sum error= 282
Actual label: 1
Output voltages: [0.18368, 0.75335, 0.27006, 0.25207, 0.29073, 0.05682, 0.40097, 0.094227, 0.25869, 0.27933]
Predicted label: 1
Correct prediction
Energy consumption = 208.443600 pJ
sum error= 282
Actual label: 2
Output voltages: [0.36945, 0.16456, 0.73633, 0.35941, 0.20468, 0.046544, 0.23827, 0.25839, 0.41028, 0.16307]
Predicted label: 2
Correct prediction
Energy consumption = 186.073526 pJ
sum error= 282
Actual label: 5
Output voltages: [0.21251, 0.045057, 0.086475, 0.3408, 0.29991, 0.68902, 0.34406, 0.13547, 0.48892, 0.25774]
Predicted label: 5
Correct prediction
Energy consumption = 183.873954 pJ
sum error= 282
Actual label: 0
Output voltages: [0.72837, 0.25579, 0.202, 0.20858, 0.16211, 0.16221, 0.40858, 0.18223, 0.35129, 0.20337]
Predicted label: 0
Correct prediction
Energy consumption = 193.471901 pJ
sum error= 282
Actual label: 7
Output voltages: [0.27959, 0.28749, 0.25054, 0.27491, 0.14013, 0.11217, 0.038846, 0.75506, 0.28995, 0.37285]
Predicted label: 7
Correct prediction
Energy consumption = 191.061183 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 875 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 875 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 875 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34353, 0.089834, 0.20388, 0.22411, 0.35779, 0.19868, 0.089374, 0.23169, 0.3939, 0.66697]
Predicted label: 9
Correct prediction
Energy consumption = 197.595255 pJ
sum error= 282
Actual label: 9
Output voltages: [0.37513, 0.11351, 0.22184, 0.25569, 0.2807, 0.16143, 0.075792, 0.25763, 0.40083, 0.65977]
Predicted label: 9
Correct prediction
Energy consumption = 183.546163 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73268, 0.27003, 0.25301, 0.20556, 0.11565, 0.17134, 0.36329, 0.2449, 0.32167, 0.21243]
Predicted label: 0
Correct prediction
Energy consumption = 202.941949 pJ
sum error= 282
Actual label: 3
Output voltages: [0.44596, 0.16004, 0.34956, 0.74568, 0.10132, 0.18516, 0.10575, 0.18398, 0.41157, 0.19562]
Predicted label: 3
Correct prediction
Energy consumption = 194.653067 pJ
sum error= 282
Actual label: 4
Output voltages: [0.14602, 0.11958, 0.31819, 0.16637, 0.75041, 0.054103, 0.30148, 0.28483, 0.21642, 0.19867]
Predicted label: 4
Correct prediction
Energy consumption = 188.057282 pJ
sum error= 282
Actual label: 4
Output voltages: [0.16119, 0.12874, 0.25803, 0.12779, 0.74996, 0.067801, 0.24191, 0.31795, 0.33361, 0.20362]
Predicted label: 4
Correct prediction
Energy consumption = 187.803713 pJ
sum error= 282
Actual label: 8
Output voltages: [0.20306, 0.20773, 0.29433, 0.21407, 0.17385, 0.11621, 0.17939, 0.14298, 0.73029, 0.35258]
Predicted label: 8
Correct prediction
Energy consumption = 196.741931 pJ
sum error= 282
Actual label: 4
Output voltages: [0.19198, 0.13834, 0.27504, 0.13243, 0.75202, 0.056952, 0.25613, 0.2665, 0.25623, 0.22173]
Predicted label: 4
Correct prediction
Energy consumption = 185.837413 pJ
sum error= 282
Actual label: 1
Output voltages: [0.17743, 0.74915, 0.23119, 0.33278, 0.21336, 0.085517, 0.41083, 0.16849, 0.3118, 0.15108]
Predicted label: 1
Correct prediction
Energy consumption = 204.964359 pJ
sum error= 282
Actual label: 8
Output voltages: [0.33644, 0.26155, 0.31036, 0.23314, 0.16182, 0.065406, 0.26941, 0.16849, 0.66293, 0.31066]
Predicted label: 8
Correct prediction
Energy consumption = 204.686733 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 876 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 876 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 876 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29752, 0.23863, 0.29906, 0.099558, 0.3036, 0.30723, 0.73921, 0.083295, 0.37643, 0.11624]
Predicted label: 6
Correct prediction
Energy consumption = 195.294400 pJ
sum error= 282
Actual label: 5
Output voltages: [0.25844, 0.080771, 0.083624, 0.37233, 0.18102, 0.72244, 0.33026, 0.10863, 0.5121, 0.15839]
Predicted label: 5
Correct prediction
Energy consumption = 190.632378 pJ
sum error= 282
Actual label: 9
Output voltages: [0.34143, 0.16632, 0.2012, 0.25846, 0.29873, 0.13288, 0.067556, 0.18428, 0.39652, 0.66999]
Predicted label: 9
Correct prediction
Energy consumption = 190.760032 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71401, 0.2688, 0.31647, 0.21623, 0.17348, 0.078822, 0.42721, 0.1811, 0.34414, 0.2456]
Predicted label: 0
Correct prediction
Energy consumption = 198.075350 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73931, 0.27413, 0.25708, 0.14506, 0.15074, 0.11934, 0.39067, 0.23138, 0.25887, 0.31689]
Predicted label: 0
Correct prediction
Energy consumption = 186.070739 pJ
sum error= 282
Actual label: 0
Output voltages: [0.72822, 0.27532, 0.28963, 0.13182, 0.13634, 0.10062, 0.36346, 0.23664, 0.28746, 0.29971]
Predicted label: 0
Correct prediction
Energy consumption = 185.105595 pJ
sum error= 282
Actual label: 3
Output voltages: [0.49534, 0.10746, 0.29979, 0.73853, 0.21035, 0.30396, 0.12788, 0.20391, 0.39351, 0.11336]
Predicted label: 3
Correct prediction
Energy consumption = 190.752744 pJ
sum error= 282
Actual label: 7
Output voltages: [0.302, 0.19972, 0.19972, 0.29267, 0.17724, 0.19757, 0.03936, 0.75014, 0.33839, 0.38609]
Predicted label: 7
Correct prediction
Energy consumption = 193.797874 pJ
sum error= 282
Actual label: 1
Output voltages: [0.17905, 0.75721, 0.27494, 0.20948, 0.34771, 0.10588, 0.40613, 0.1334, 0.21883, 0.22797]
Predicted label: 1
Correct prediction
Energy consumption = 205.531748 pJ
sum error= 282
Actual label: 6
Output voltages: [0.27372, 0.20609, 0.31732, 0.059157, 0.36247, 0.30432, 0.73713, 0.086175, 0.35168, 0.099334]
Predicted label: 6
Correct prediction
Energy consumption = 186.286546 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 877 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 877 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 877 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13975, 0.10519, 0.29485, 0.23405, 0.74304, 0.051379, 0.27751, 0.28553, 0.20013, 0.26599]
Predicted label: 4
Correct prediction
Energy consumption = 192.899669 pJ
sum error= 282
Actual label: 6
Output voltages: [0.3047, 0.21655, 0.32096, 0.061892, 0.38641, 0.30174, 0.74621, 0.059595, 0.35533, 0.12098]
Predicted label: 6
Correct prediction
Energy consumption = 189.773614 pJ
sum error= 282
Actual label: 0
Output voltages: [0.74162, 0.2599, 0.20961, 0.18694, 0.15584, 0.13143, 0.39498, 0.17674, 0.30664, 0.2583]
Predicted label: 0
Correct prediction
Energy consumption = 191.104848 pJ
sum error= 282
Actual label: 4
Output voltages: [0.12523, 0.14942, 0.23631, 0.15273, 0.75413, 0.078768, 0.32793, 0.29849, 0.2427, 0.14709]
Predicted label: 4
Correct prediction
Energy consumption = 192.129840 pJ
sum error= 282
Actual label: 5
Output voltages: [0.20714, 0.044286, 0.10062, 0.32285, 0.24922, 0.69261, 0.34028, 0.12606, 0.52279, 0.20568]
Predicted label: 5
Correct prediction
Energy consumption = 192.079027 pJ
sum error= 282
Actual label: 4
Output voltages: [0.16677, 0.080323, 0.2729, 0.12244, 0.74394, 0.10614, 0.29626, 0.22306, 0.34132, 0.13438]
Predicted label: 4
Correct prediction
Energy consumption = 195.363728 pJ
sum error= 282
Actual label: 1
Output voltages: [0.19743, 0.75857, 0.24172, 0.20012, 0.2653, 0.12153, 0.39532, 0.11405, 0.34316, 0.18716]
Predicted label: 1
Correct prediction
Energy consumption = 202.249734 pJ
sum error= 282
Actual label: 3
Output voltages: [0.30166, 0.20768, 0.30485, 0.76067, 0.15443, 0.15001, 0.13967, 0.21453, 0.41727, 0.26782]
Predicted label: 3
Correct prediction
Energy consumption = 180.272124 pJ
sum error= 282
Actual label: 8
Output voltages: [0.18078, 0.22004, 0.22203, 0.35876, 0.14221, 0.29853, 0.13248, 0.1804, 0.73808, 0.32617]
Predicted label: 8
Correct prediction
Energy consumption = 194.363804 pJ
sum error= 282
Actual label: 6
Output voltages: [0.27102, 0.18854, 0.30356, 0.097658, 0.40669, 0.33495, 0.73882, 0.064502, 0.34571, 0.12245]
Predicted label: 6
Correct prediction
Energy consumption = 190.871903 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 878 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 878 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 878 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30106, 0.19727, 0.29748, 0.7598, 0.20959, 0.13303, 0.15053, 0.17257, 0.44258, 0.26078]
Predicted label: 3
Correct prediction
Energy consumption = 182.602206 pJ
sum error= 282
Actual label: 9
Output voltages: [0.32857, 0.14029, 0.22192, 0.28595, 0.31335, 0.14999, 0.13952, 0.1977, 0.37891, 0.63544]
Predicted label: 9
Correct prediction
Energy consumption = 190.772425 pJ
sum error= 282
Actual label: 9
Output voltages: [0.33269, 0.10171, 0.207, 0.17996, 0.20679, 0.22131, 0.095312, 0.26355, 0.533, 0.58997]
Predicted label: 9
Correct prediction
Energy consumption = 187.118807 pJ
sum error= 282
Actual label: 5
Output voltages: [0.18345, 0.10158, 0.096416, 0.34112, 0.24691, 0.69501, 0.33331, 0.080401, 0.48921, 0.24871]
Predicted label: 5
Correct prediction
Energy consumption = 176.304491 pJ
sum error= 282
Actual label: 9
Output voltages: [0.34757, 0.14564, 0.23838, 0.24903, 0.23488, 0.16218, 0.075345, 0.24302, 0.43017, 0.66705]
Predicted label: 9
Correct prediction
Energy consumption = 190.366555 pJ
sum error= 282
Actual label: 3
Output voltages: [0.4497, 0.14597, 0.41011, 0.73499, 0.13886, 0.15598, 0.15713, 0.17503, 0.35501, 0.1748]
Predicted label: 3
Correct prediction
Energy consumption = 202.519765 pJ
sum error= 282
Actual label: 7
Output voltages: [0.35628, 0.19091, 0.18665, 0.29501, 0.13489, 0.14814, 0.041629, 0.75097, 0.40703, 0.39509]
Predicted label: 7
Correct prediction
Energy consumption = 196.779495 pJ
sum error= 282
Actual label: 8
Output voltages: [0.28827, 0.15198, 0.28444, 0.37911, 0.12397, 0.14978, 0.13478, 0.10075, 0.70666, 0.33145]
Predicted label: 8
Correct prediction
Energy consumption = 193.632845 pJ
sum error= 282
Actual label: 5
Output voltages: [0.21766, 0.049511, 0.093468, 0.37626, 0.2179, 0.68889, 0.28004, 0.18696, 0.53317, 0.2754]
Predicted label: 5
Correct prediction
Energy consumption = 188.596451 pJ
sum error= 282
Actual label: 6
Output voltages: [0.30508, 0.24051, 0.30788, 0.11572, 0.32449, 0.32939, 0.74577, 0.06401, 0.34111, 0.16214]
Predicted label: 6
Correct prediction
Energy consumption = 189.070818 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 879 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 879 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 879 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.14904, 0.11643, 0.29741, 0.15053, 0.75046, 0.088676, 0.31851, 0.23853, 0.24271, 0.1519]
Predicted label: 4
Correct prediction
Energy consumption = 193.583750 pJ
sum error= 282
Actual label: 7
Output voltages: [0.31183, 0.16927, 0.25129, 0.30036, 0.10855, 0.076808, 0.038485, 0.72501, 0.4831, 0.39561]
Predicted label: 7
Correct prediction
Energy consumption = 200.745434 pJ
sum error= 282
Actual label: 6
Output voltages: [0.30553, 0.19846, 0.31466, 0.068422, 0.38557, 0.27584, 0.73043, 0.063949, 0.33742, 0.16225]
Predicted label: 6
Correct prediction
Energy consumption = 191.896070 pJ
sum error= 282
Actual label: 2
Output voltages: [0.40558, 0.19688, 0.74121, 0.32425, 0.15412, 0.038775, 0.27109, 0.28597, 0.41959, 0.17117]
Predicted label: 2
Correct prediction
Energy consumption = 185.693187 pJ
sum error= 282
Actual label: 2
Output voltages: [0.31809, 0.22201, 0.74536, 0.31687, 0.17046, 0.031381, 0.21949, 0.34209, 0.38892, 0.20899]
Predicted label: 2
Correct prediction
Energy consumption = 181.483777 pJ
sum error= 282
Actual label: 0
Output voltages: [0.70374, 0.23513, 0.28721, 0.21369, 0.20027, 0.068005, 0.38223, 0.16277, 0.33669, 0.29915]
Predicted label: 0
Correct prediction
Energy consumption = 195.999749 pJ
sum error= 282
Actual label: 9
Output voltages: [0.38287, 0.1196, 0.21936, 0.25371, 0.36584, 0.17292, 0.099047, 0.22955, 0.33763, 0.6869]
Predicted label: 9
Correct prediction
Energy consumption = 191.474276 pJ
sum error= 282
Actual label: 4
Output voltages: [0.17781, 0.13867, 0.2742, 0.14864, 0.74739, 0.071883, 0.30237, 0.26038, 0.23815, 0.17263]
Predicted label: 4
Correct prediction
Energy consumption = 187.575388 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71093, 0.26774, 0.33391, 0.18395, 0.13337, 0.10754, 0.39816, 0.1629, 0.29896, 0.32648]
Predicted label: 0
Correct prediction
Energy consumption = 196.697965 pJ
sum error= 282
Actual label: 1
Output voltages: [0.21106, 0.75087, 0.27781, 0.2375, 0.29532, 0.10933, 0.48876, 0.06609, 0.30182, 0.19608]
Predicted label: 1
Correct prediction
Energy consumption = 199.621904 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 880 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 880 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 880 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.41104, 0.15486, 0.75392, 0.30697, 0.19092, 0.051131, 0.26141, 0.3003, 0.41422, 0.15788]
Predicted label: 2
Correct prediction
Energy consumption = 185.111618 pJ
sum error= 282
Actual label: 3
Output voltages: [0.31703, 0.18758, 0.31398, 0.75959, 0.20063, 0.22222, 0.11969, 0.19555, 0.45346, 0.26517]
Predicted label: 3
Correct prediction
Energy consumption = 181.299084 pJ
sum error= 282
Actual label: 4
Output voltages: [0.20217, 0.17116, 0.32599, 0.11649, 0.75452, 0.05189, 0.3044, 0.26047, 0.18939, 0.23334]
Predicted label: 4
Correct prediction
Energy consumption = 190.419053 pJ
sum error= 282
Actual label: 5
Output voltages: [0.26423, 0.059588, 0.088636, 0.30523, 0.21593, 0.69111, 0.37363, 0.065071, 0.54683, 0.19059]
Predicted label: 5
Correct prediction
Energy consumption = 189.982389 pJ
sum error= 282
Actual label: 6
Output voltages: [0.2776, 0.25165, 0.30359, 0.093006, 0.36613, 0.32806, 0.75021, 0.10463, 0.35166, 0.10806]
Predicted label: 6
Correct prediction
Energy consumption = 191.268598 pJ
sum error= 282
Actual label: 7
Output voltages: [0.29511, 0.29956, 0.46903, 0.19158, 0.17902, 0.041478, 0.051499, 0.74959, 0.29152, 0.3027]
Predicted label: 7
Correct prediction
Energy consumption = 198.549803 pJ
sum error= 282
Actual label: 8
Output voltages: [0.19907, 0.31422, 0.2057, 0.21532, 0.15084, 0.24156, 0.22632, 0.17958, 0.74039, 0.25382]
Predicted label: 8
Correct prediction
Energy consumption = 189.969791 pJ
sum error= 282
Actual label: 9
Output voltages: [0.323, 0.10213, 0.18201, 0.3226, 0.29046, 0.22165, 0.1161, 0.27082, 0.36106, 0.63143]
Predicted label: 9
Correct prediction
Energy consumption = 192.915403 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71896, 0.28891, 0.2235, 0.17625, 0.16507, 0.16325, 0.42821, 0.19783, 0.30185, 0.19426]
Predicted label: 0
Correct prediction
Energy consumption = 192.978529 pJ
sum error= 282
Actual label: 1
Output voltages: [0.30364, 0.68708, 0.2892, 0.18726, 0.44181, 0.050472, 0.28535, 0.16876, 0.21867, 0.24623]
Predicted label: 1
Correct prediction
Energy consumption = 195.692531 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 881 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 881 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 881 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31198, 0.26731, 0.74315, 0.36569, 0.16799, 0.032853, 0.21048, 0.28574, 0.36979, 0.1443]
Predicted label: 2
Correct prediction
Energy consumption = 186.733486 pJ
sum error= 282
Actual label: 3
Output voltages: [0.36193, 0.13702, 0.32412, 0.75829, 0.24052, 0.23956, 0.15292, 0.19526, 0.41113, 0.2193]
Predicted label: 3
Correct prediction
Energy consumption = 181.902527 pJ
sum error= 282
Actual label: 4
Output voltages: [0.17788, 0.17131, 0.32313, 0.1533, 0.75207, 0.058642, 0.27291, 0.30762, 0.18491, 0.21978]
Predicted label: 4
Correct prediction
Energy consumption = 185.836023 pJ
sum error= 282
Actual label: 5
Output voltages: [0.24899, 0.053265, 0.064352, 0.38821, 0.26917, 0.70148, 0.24437, 0.13433, 0.53564, 0.23968]
Predicted label: 5
Correct prediction
Energy consumption = 190.710891 pJ
sum error= 282
Actual label: 6
Output voltages: [0.27155, 0.25595, 0.3152, 0.26784, 0.38722, 0.29579, 0.6934, 0.17585, 0.30701, 0.049435]
Predicted label: 6
Correct prediction
Energy consumption = 200.786749 pJ
sum error= 282
Actual label: 7
Output voltages: [0.40038, 0.20655, 0.31396, 0.30902, 0.116, 0.086125, 0.041716, 0.74294, 0.36783, 0.35917]
Predicted label: 7
Correct prediction
Energy consumption = 198.682077 pJ
sum error= 282
Actual label: 8
Output voltages: [0.20447, 0.32514, 0.22524, 0.32678, 0.18821, 0.2919, 0.34992, 0.081033, 0.6501, 0.23949]
Predicted label: 8
Correct prediction
Energy consumption = 197.324683 pJ
sum error= 282
Actual label: 9
Output voltages: [0.29294, 0.10276, 0.19071, 0.2635, 0.23712, 0.19848, 0.10684, 0.24968, 0.47582, 0.62073]
Predicted label: 9
Correct prediction
Energy consumption = 193.749539 pJ
sum error= 282
Actual label: 0
Output voltages: [0.74056, 0.24519, 0.27673, 0.15534, 0.15918, 0.11228, 0.37147, 0.23608, 0.2506, 0.28018]
Predicted label: 0
Correct prediction
Energy consumption = 187.260032 pJ
sum error= 282
Actual label: 1
Output voltages: [0.17171, 0.71702, 0.28269, 0.19668, 0.40083, 0.070509, 0.30499, 0.22146, 0.30523, 0.20274]
Predicted label: 1
Correct prediction
Energy consumption = 197.268080 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 882 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 882 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 882 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32327, 0.13707, 0.74053, 0.32539, 0.15782, 0.040068, 0.19494, 0.27666, 0.50184, 0.17908]
Predicted label: 2
Correct prediction
Energy consumption = 185.014330 pJ
sum error= 282
Actual label: 3
Output voltages: [0.39755, 0.13668, 0.25925, 0.74642, 0.18921, 0.28431, 0.17252, 0.24538, 0.384, 0.16297]
Predicted label: 3
Correct prediction
Energy consumption = 184.931706 pJ
sum error= 282
Actual label: 4
Output voltages: [0.16271, 0.20091, 0.21775, 0.17719, 0.73665, 0.19848, 0.2569, 0.2044, 0.21606, 0.26065]
Predicted label: 4
Correct prediction
Energy consumption = 186.644914 pJ
sum error= 282
Actual label: 5
Output voltages: [0.34361, 0.066881, 0.073122, 0.36338, 0.1512, 0.75621, 0.26702, 0.24218, 0.5277, 0.1815]
Predicted label: 5
Correct prediction
Energy consumption = 193.347125 pJ
sum error= 282
Actual label: 6
Output voltages: [0.28485, 0.19267, 0.32129, 0.056418, 0.34092, 0.32442, 0.73887, 0.092699, 0.3851, 0.080396]
Predicted label: 6
Correct prediction
Energy consumption = 186.456213 pJ
sum error= 282
Actual label: 7
Output voltages: [0.32695, 0.30634, 0.42396, 0.2514, 0.19045, 0.045571, 0.047795, 0.74922, 0.25187, 0.30721]
Predicted label: 7
Correct prediction
Energy consumption = 197.218884 pJ
sum error= 282
Actual label: 8
Output voltages: [0.35187, 0.25496, 0.3201, 0.24058, 0.18591, 0.10282, 0.36154, 0.081226, 0.6951, 0.28354]
Predicted label: 8
Correct prediction
Energy consumption = 190.009787 pJ
sum error= 282
Actual label: 9
Output voltages: [0.2823, 0.10309, 0.19833, 0.23854, 0.22716, 0.26254, 0.12, 0.20251, 0.48934, 0.5899]
Predicted label: 9
Correct prediction
Energy consumption = 186.446283 pJ
sum error= 282
Actual label: 6
Output voltages: [0.3096, 0.19543, 0.22939, 0.16396, 0.31525, 0.40209, 0.73677, 0.073733, 0.36497, 0.18321]
Predicted label: 6
Correct prediction
Energy consumption = 187.749335 pJ
sum error= 282
Actual label: 4
Output voltages: [0.16786, 0.14628, 0.31236, 0.20142, 0.7519, 0.096709, 0.25903, 0.22259, 0.21167, 0.29667]
Predicted label: 4
Correct prediction
Energy consumption = 196.549898 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 883 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 883 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 883 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.30475, 0.23909, 0.75456, 0.29452, 0.21797, 0.049159, 0.2199, 0.18916, 0.4209, 0.19349]
Predicted label: 2
Correct prediction
Energy consumption = 186.984621 pJ
sum error= 282
Actual label: 6
Output voltages: [0.27494, 0.19399, 0.25372, 0.14209, 0.3303, 0.35043, 0.73201, 0.0912, 0.4259, 0.12605]
Predicted label: 6
Correct prediction
Energy consumption = 194.834399 pJ
sum error= 282
Actual label: 4
Output voltages: [0.19187, 0.17927, 0.27356, 0.18385, 0.75189, 0.063587, 0.30899, 0.29887, 0.18944, 0.18923]
Predicted label: 4
Correct prediction
Energy consumption = 200.727336 pJ
sum error= 282
Actual label: 7
Output voltages: [0.31505, 0.22508, 0.18819, 0.32406, 0.20981, 0.17419, 0.044915, 0.75611, 0.30345, 0.39124]
Predicted label: 7
Correct prediction
Energy consumption = 188.293157 pJ
sum error= 282
Actual label: 5
Output voltages: [0.27415, 0.055302, 0.077849, 0.35373, 0.21832, 0.69079, 0.36536, 0.090305, 0.51618, 0.2433]
Predicted label: 5
Correct prediction
Energy consumption = 187.779250 pJ
sum error= 282
Actual label: 5
Output voltages: [0.2566, 0.040728, 0.080948, 0.30955, 0.24127, 0.65342, 0.3932, 0.1028, 0.53535, 0.24435]
Predicted label: 5
Correct prediction
Energy consumption = 177.887974 pJ
sum error= 282
Actual label: 4
Output voltages: [0.12867, 0.1871, 0.28468, 0.18389, 0.74869, 0.077538, 0.36705, 0.30186, 0.21161, 0.17607]
Predicted label: 4
Correct prediction
Energy consumption = 197.007453 pJ
sum error= 282
Actual label: 7
Output voltages: [0.31586, 0.22907, 0.22759, 0.30586, 0.15705, 0.09925, 0.045974, 0.75668, 0.26297, 0.33158]
Predicted label: 7
Correct prediction
Energy consumption = 193.802223 pJ
sum error= 282
Actual label: 2
Output voltages: [0.30143, 0.24228, 0.76369, 0.27885, 0.20857, 0.050089, 0.23616, 0.29479, 0.36017, 0.17806]
Predicted label: 2
Correct prediction
Energy consumption = 179.992636 pJ
sum error= 282
Actual label: 9
Output voltages: [0.36178, 0.13936, 0.21385, 0.22659, 0.25443, 0.17203, 0.073966, 0.23295, 0.41389, 0.67011]
Predicted label: 9
Correct prediction
Energy consumption = 195.344355 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 884 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 884 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 884 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36042, 0.19468, 0.31902, 0.76537, 0.19372, 0.16544, 0.14299, 0.20464, 0.44209, 0.23374]
Predicted label: 3
Correct prediction
Energy consumption = 179.735616 pJ
sum error= 282
Actual label: 9
Output voltages: [0.32456, 0.10863, 0.20908, 0.21018, 0.22994, 0.22918, 0.10958, 0.22929, 0.50187, 0.63477]
Predicted label: 9
Correct prediction
Energy consumption = 188.337477 pJ
sum error= 282
Actual label: 3
Output voltages: [0.30414, 0.093324, 0.27767, 0.74909, 0.22288, 0.27161, 0.1585, 0.18644, 0.39345, 0.23092]
Predicted label: 3
Correct prediction
Energy consumption = 184.992729 pJ
sum error= 282
Actual label: 8
Output voltages: [0.25282, 0.23239, 0.23203, 0.23935, 0.18428, 0.28708, 0.27854, 0.11308, 0.72937, 0.27113]
Predicted label: 8
Correct prediction
Energy consumption = 189.328705 pJ
sum error= 282
Actual label: 2
Output voltages: [0.36711, 0.18936, 0.7484, 0.2888, 0.22488, 0.045, 0.24818, 0.19034, 0.42631, 0.18656]
Predicted label: 2
Correct prediction
Energy consumption = 185.710740 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71713, 0.2652, 0.31104, 0.21507, 0.16803, 0.084487, 0.37383, 0.18424, 0.32867, 0.25709]
Predicted label: 0
Correct prediction
Energy consumption = 201.945227 pJ
sum error= 282
Actual label: 9
Output voltages: [0.3646, 0.16681, 0.20832, 0.22567, 0.36732, 0.15004, 0.11729, 0.19413, 0.323, 0.70171]
Predicted label: 9
Correct prediction
Energy consumption = 193.540681 pJ
sum error= 282
Actual label: 5
Output voltages: [0.36385, 0.066783, 0.055194, 0.32448, 0.24704, 0.70627, 0.41279, 0.16249, 0.37792, 0.3133]
Predicted label: 5
Correct prediction
Energy consumption = 190.686529 pJ
sum error= 282
Actual label: 6
Output voltages: [0.27456, 0.17063, 0.27795, 0.11718, 0.38159, 0.29817, 0.72134, 0.086779, 0.39189, 0.12682]
Predicted label: 6
Correct prediction
Energy consumption = 191.119691 pJ
sum error= 282
Actual label: 0
Output voltages: [0.6931, 0.25676, 0.33161, 0.1638, 0.1774, 0.070487, 0.43587, 0.18458, 0.275, 0.30316]
Predicted label: 0
Correct prediction
Energy consumption = 200.223777 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 885 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 885 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 885 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.14494, 0.76187, 0.30054, 0.26801, 0.22409, 0.054734, 0.40262, 0.13658, 0.32144, 0.2301]
Predicted label: 1
Correct prediction
Energy consumption = 205.295553 pJ
sum error= 282
Actual label: 0
Output voltages: [0.7386, 0.24256, 0.28667, 0.17086, 0.17558, 0.10855, 0.33715, 0.24909, 0.29431, 0.28046]
Predicted label: 0
Correct prediction
Energy consumption = 195.628500 pJ
sum error= 282
Actual label: 6
Output voltages: [0.29426, 0.19226, 0.28777, 0.082303, 0.38634, 0.35276, 0.73913, 0.067706, 0.38312, 0.10219]
Predicted label: 6
Correct prediction
Energy consumption = 188.167403 pJ
sum error= 282
Actual label: 5
Output voltages: [0.32783, 0.065114, 0.068221, 0.30834, 0.18568, 0.74331, 0.38325, 0.14666, 0.5578, 0.1278]
Predicted label: 5
Correct prediction
Energy consumption = 192.276183 pJ
sum error= 282
Actual label: 3
Output voltages: [0.37576, 0.13892, 0.31511, 0.75971, 0.20561, 0.24836, 0.11715, 0.19579, 0.43379, 0.24479]
Predicted label: 3
Correct prediction
Energy consumption = 181.446776 pJ
sum error= 282
Actual label: 5
Output voltages: [0.28008, 0.048287, 0.074249, 0.31324, 0.27293, 0.69826, 0.36247, 0.10399, 0.52102, 0.21746]
Predicted label: 5
Correct prediction
Energy consumption = 184.432652 pJ
sum error= 282
Actual label: 3
Output voltages: [0.37668, 0.11419, 0.31275, 0.75507, 0.20784, 0.21965, 0.15943, 0.20611, 0.42461, 0.22828]
Predicted label: 3
Correct prediction
Energy consumption = 179.038742 pJ
sum error= 282
Actual label: 8
Output voltages: [0.21521, 0.29889, 0.34158, 0.1714, 0.19233, 0.14501, 0.26099, 0.1599, 0.7206, 0.27954]
Predicted label: 8
Correct prediction
Energy consumption = 195.640265 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71759, 0.26516, 0.31728, 0.18989, 0.18447, 0.078267, 0.39882, 0.17002, 0.33541, 0.22313]
Predicted label: 0
Correct prediction
Energy consumption = 192.566370 pJ
sum error= 282
Actual label: 0
Output voltages: [0.70296, 0.15928, 0.24142, 0.12043, 0.25277, 0.16626, 0.47191, 0.23207, 0.29821, 0.22671]
Predicted label: 0
Correct prediction
Energy consumption = 185.327796 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 886 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 886 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 886 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.42433, 0.14636, 0.29497, 0.76011, 0.18676, 0.20481, 0.1315, 0.22718, 0.38851, 0.22398]
Predicted label: 3
Correct prediction
Energy consumption = 186.926416 pJ
sum error= 282
Actual label: 4
Output voltages: [0.15381, 0.15609, 0.26565, 0.14717, 0.74848, 0.071747, 0.28441, 0.31044, 0.22728, 0.18276]
Predicted label: 4
Correct prediction
Energy consumption = 195.031266 pJ
sum error= 282
Actual label: 1
Output voltages: [0.19329, 0.75189, 0.2838, 0.22349, 0.36122, 0.075555, 0.38823, 0.17351, 0.23502, 0.20713]
Predicted label: 1
Correct prediction
Energy consumption = 207.615839 pJ
sum error= 282
Actual label: 5
Output voltages: [0.2369, 0.051182, 0.13578, 0.25134, 0.21866, 0.66301, 0.39539, 0.12368, 0.60268, 0.20474]
Predicted label: 5
Correct prediction
Energy consumption = 194.528491 pJ
sum error= 282
Actual label: 3
Output voltages: [0.40283, 0.15681, 0.27417, 0.75234, 0.16144, 0.27233, 0.20934, 0.19517, 0.36153, 0.18816]
Predicted label: 3
Correct prediction
Energy consumption = 187.060780 pJ
sum error= 282
Actual label: 0
Output voltages: [0.72762, 0.28731, 0.28593, 0.1511, 0.13198, 0.11697, 0.39893, 0.18015, 0.27787, 0.30526]
Predicted label: 0
Correct prediction
Energy consumption = 192.253522 pJ
sum error= 282
Actual label: 8
Output voltages: [0.24309, 0.33774, 0.24251, 0.3097, 0.17563, 0.13041, 0.1682, 0.15982, 0.71134, 0.29597]
Predicted label: 8
Correct prediction
Energy consumption = 196.009381 pJ
sum error= 282
Actual label: 3
Output voltages: [0.46667, 0.1022, 0.31448, 0.73502, 0.23651, 0.25791, 0.18308, 0.22469, 0.33031, 0.10839]
Predicted label: 3
Correct prediction
Energy consumption = 187.887948 pJ
sum error= 282
Actual label: 0
Output voltages: [0.71692, 0.18847, 0.28716, 0.14218, 0.12578, 0.19508, 0.41877, 0.16792, 0.2936, 0.26973]
Predicted label: 0
Correct prediction
Energy consumption = 190.645668 pJ
sum error= 282
Actual label: 6
Output voltages: [0.34979, 0.25897, 0.29685, 0.10016, 0.31545, 0.30542, 0.73691, 0.083095, 0.31885, 0.14886]
Predicted label: 6
Correct prediction
Energy consumption = 182.117420 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 887 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 887 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 887 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33265, 0.22518, 0.7442, 0.28836, 0.25217, 0.043498, 0.22933, 0.16051, 0.4438, 0.24388]
Predicted label: 2
Correct prediction
Energy consumption = 186.895854 pJ
sum error= 282
Actual label: 7
Output voltages: [0.31957, 0.20096, 0.28274, 0.29353, 0.10883, 0.093163, 0.046868, 0.75552, 0.38682, 0.3449]
Predicted label: 7
Correct prediction
Energy consumption = 193.472979 pJ
sum error= 282
Actual label: 8
Output voltages: [0.30068, 0.24518, 0.30252, 0.26233, 0.19023, 0.20245, 0.25296, 0.11115, 0.74231, 0.25841]
Predicted label: 8
Correct prediction
Energy consumption = 190.192529 pJ
sum error= 282
Actual label: 1
Output voltages: [0.1605, 0.74043, 0.23311, 0.21907, 0.37148, 0.068398, 0.3476, 0.11416, 0.26829, 0.29641]
Predicted label: 1
Correct prediction
Energy consumption = 204.702799 pJ
sum error= 282
Actual label: 7
Output voltages: [0.30077, 0.19229, 0.28459, 0.36302, 0.074195, 0.066442, 0.045548, 0.74711, 0.40806, 0.32703]
Predicted label: 7
Correct prediction
Energy consumption = 196.121671 pJ
sum error= 282
Actual label: 1
Output voltages: [0.25928, 0.72771, 0.37347, 0.20011, 0.35822, 0.064313, 0.48805, 0.057613, 0.21123, 0.20249]
Predicted label: 1
Correct prediction
Energy consumption = 200.495191 pJ
sum error= 282
Actual label: 3
Output voltages: [0.34051, 0.15931, 0.27026, 0.75641, 0.21051, 0.30325, 0.16516, 0.14339, 0.38569, 0.21426]
Predicted label: 3
Correct prediction
Energy consumption = 192.806700 pJ
sum error= 282
Actual label: 8
Output voltages: [0.25408, 0.2217, 0.31473, 0.27188, 0.18727, 0.23896, 0.18789, 0.13497, 0.74887, 0.28985]
Predicted label: 8
Correct prediction
Energy consumption = 191.435974 pJ
sum error= 282
Actual label: 5
Output voltages: [0.26288, 0.060446, 0.061873, 0.31809, 0.21395, 0.74184, 0.34356, 0.18756, 0.46413, 0.22071]
Predicted label: 5
Correct prediction
Energy consumption = 190.504146 pJ
sum error= 282
Actual label: 4
Output voltages: [0.085655, 0.17996, 0.26542, 0.224, 0.7522, 0.057231, 0.26032, 0.34856, 0.19423, 0.18434]
Predicted label: 4
Correct prediction
Energy consumption = 187.981489 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 888 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 888 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 888 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36311, 0.26306, 0.74765, 0.3502, 0.20976, 0.037528, 0.19696, 0.20503, 0.38962, 0.20344]
Predicted label: 2
Correct prediction
Energy consumption = 189.433477 pJ
sum error= 282
Actual label: 0
Output voltages: [0.65903, 0.29115, 0.30797, 0.13938, 0.18678, 0.079004, 0.367, 0.19683, 0.32722, 0.1851]
Predicted label: 0
Correct prediction
Energy consumption = 205.762344 pJ
sum error= 282
Actual label: 9
Output voltages: [0.28918, 0.16786, 0.27224, 0.27051, 0.44705, 0.10622, 0.14253, 0.16111, 0.30731, 0.6483]
Predicted label: 9
Correct prediction
Energy consumption = 200.851448 pJ
sum error= 282
Actual label: 7
Output voltages: [0.32588, 0.22726, 0.28747, 0.31571, 0.14392, 0.088879, 0.038287, 0.74813, 0.39457, 0.33784]
Predicted label: 7
Correct prediction
Energy consumption = 193.651739 pJ
sum error= 282
Actual label: 6
Output voltages: [0.30231, 0.2463, 0.30321, 0.074287, 0.36217, 0.30283, 0.74388, 0.09037, 0.28347, 0.18594]
Predicted label: 6
Correct prediction
Energy consumption = 195.006455 pJ
sum error= 282
Actual label: 7
Output voltages: [0.23391, 0.27464, 0.39455, 0.34422, 0.11601, 0.053165, 0.034053, 0.73489, 0.3639, 0.40968]
Predicted label: 7
Correct prediction
Energy consumption = 192.840430 pJ
sum error= 282
Actual label: 4
Output voltages: [0.20584, 0.1242, 0.34166, 0.19868, 0.74084, 0.053174, 0.1827, 0.18691, 0.23879, 0.28893]
Predicted label: 4
Correct prediction
Energy consumption = 195.736298 pJ
sum error= 282
Actual label: 1
Output voltages: [0.17602, 0.6843, 0.29333, 0.18517, 0.41952, 0.045741, 0.2581, 0.14993, 0.29053, 0.23776]
Predicted label: 1
Correct prediction
Energy consumption = 197.066854 pJ
sum error= 282
Actual label: 6
Output voltages: [0.26113, 0.17613, 0.30491, 0.068241, 0.38023, 0.32701, 0.74201, 0.07944, 0.36179, 0.10751]
Predicted label: 6
Correct prediction
Energy consumption = 188.785157 pJ
sum error= 282
Actual label: 2
Output voltages: [0.4286, 0.15663, 0.69647, 0.4063, 0.11237, 0.048298, 0.26186, 0.20023, 0.41094, 0.19806]
Predicted label: 2
Correct prediction
Energy consumption = 189.429662 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 889 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 889 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 889 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32751, 0.25866, 0.28526, 0.084835, 0.34449, 0.26453, 0.74438, 0.099528, 0.32032, 0.17666]
Predicted label: 6
Correct prediction
Energy consumption = 188.713878 pJ
sum error= 282
Actual label: 7
Output voltages: [0.30291, 0.21885, 0.36529, 0.26333, 0.16141, 0.084439, 0.037623, 0.75761, 0.35761, 0.36638]
Predicted label: 7
Correct prediction
Energy consumption = 197.138250 pJ
sum error= 282
Actual label: 1
Output voltages: [0.334, 0.72835, 0.2558, 0.18431, 0.42856, 0.063336, 0.27583, 0.17444, 0.20467, 0.318]
Predicted label: 1
Correct prediction
Energy consumption = 202.664986 pJ
sum error= 282
Actual label: 9
Output voltages: [0.37802, 0.13973, 0.1737, 0.29646, 0.35255, 0.18523, 0.090522, 0.15871, 0.34604, 0.68019]
Predicted label: 9
Correct prediction
Energy consumption = 187.982483 pJ
sum error= 282
Actual label: 8
Output voltages: [0.24942, 0.25131, 0.28828, 0.24942, 0.14188, 0.20881, 0.21227, 0.11949, 0.74605, 0.29121]
Predicted label: 8
Correct prediction
Energy consumption = 192.438793 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73136, 0.28215, 0.24075, 0.1409, 0.18106, 0.11099, 0.32219, 0.26018, 0.30238, 0.28158]
Predicted label: 0
Correct prediction
Energy consumption = 191.864657 pJ
sum error= 282
Actual label: 6
Output voltages: [0.26313, 0.18098, 0.26859, 0.097394, 0.37007, 0.30599, 0.73414, 0.11084, 0.38901, 0.13646]
Predicted label: 6
Correct prediction
Energy consumption = 189.283025 pJ
sum error= 282
Actual label: 9
Output voltages: [0.35715, 0.099432, 0.20969, 0.19842, 0.29975, 0.15968, 0.081372, 0.19507, 0.44473, 0.65077]
Predicted label: 9
Correct prediction
Energy consumption = 188.816959 pJ
sum error= 282
Actual label: 4
Output voltages: [0.14664, 0.16147, 0.26365, 0.18402, 0.75006, 0.065597, 0.22007, 0.21796, 0.20738, 0.25153]
Predicted label: 4
Correct prediction
Energy consumption = 193.803779 pJ
sum error= 282
Actual label: 9
Output voltages: [0.34164, 0.11446, 0.19567, 0.24195, 0.31068, 0.1711, 0.082093, 0.26595, 0.40111, 0.66165]
Predicted label: 9
Correct prediction
Energy consumption = 182.588023 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 890 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 890 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 890 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29504, 0.10192, 0.19724, 0.20484, 0.25739, 0.19042, 0.092144, 0.26214, 0.47988, 0.61916]
Predicted label: 9
Correct prediction
Energy consumption = 193.742722 pJ
sum error= 282
Actual label: 6
Output voltages: [0.37288, 0.28435, 0.25132, 0.11666, 0.28902, 0.34578, 0.73247, 0.094595, 0.38085, 0.11087]
Predicted label: 6
Correct prediction
Energy consumption = 195.624407 pJ
sum error= 282
Actual label: 2
Output voltages: [0.32261, 0.25735, 0.74299, 0.2823, 0.17803, 0.036886, 0.22367, 0.25286, 0.40811, 0.18943]
Predicted label: 2
Correct prediction
Energy consumption = 192.366793 pJ
sum error= 282
Actual label: 3
Output voltages: [0.40525, 0.13863, 0.28508, 0.75568, 0.18822, 0.25411, 0.16978, 0.19751, 0.41812, 0.23634]
Predicted label: 3
Correct prediction
Energy consumption = 181.293036 pJ
sum error= 282
Actual label: 7
Output voltages: [0.41694, 0.20681, 0.16435, 0.27647, 0.19628, 0.20711, 0.055203, 0.714, 0.27169, 0.40317]
Predicted label: 7
Correct prediction
Energy consumption = 190.968237 pJ
sum error= 282
Actual label: 1
Output voltages: [0.24905, 0.72376, 0.20022, 0.20654, 0.44195, 0.079051, 0.24394, 0.22107, 0.24161, 0.27514]
Predicted label: 1
Correct prediction
Energy consumption = 206.458867 pJ
sum error= 282
Actual label: 9
Output voltages: [0.30299, 0.076051, 0.13964, 0.23654, 0.34965, 0.26592, 0.12429, 0.15896, 0.397, 0.58599]
Predicted label: 9
Correct prediction
Energy consumption = 195.642356 pJ
sum error= 282
Actual label: 2
Output voltages: [0.40571, 0.14709, 0.74968, 0.32805, 0.16294, 0.045869, 0.26892, 0.24428, 0.42433, 0.14593]
Predicted label: 2
Correct prediction
Energy consumption = 186.125432 pJ
sum error= 282
Actual label: 2
Output voltages: [0.3161, 0.1733, 0.71094, 0.33477, 0.28658, 0.04368, 0.2744, 0.19797, 0.40483, 0.18439]
Predicted label: 2
Correct prediction
Energy consumption = 189.366670 pJ
sum error= 282
Actual label: 5
Output voltages: [0.2919, 0.051687, 0.11003, 0.41634, 0.12611, 0.63231, 0.31413, 0.13698, 0.52622, 0.19399]
Predicted label: 5
Correct prediction
Energy consumption = 187.123557 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 891 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 891 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 891 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34078, 0.11561, 0.31331, 0.75363, 0.24865, 0.24658, 0.1338, 0.16459, 0.42428, 0.22706]
Predicted label: 3
Correct prediction
Energy consumption = 191.215661 pJ
sum error= 282
Actual label: 7
Output voltages: [0.35219, 0.25243, 0.40742, 0.31524, 0.10769, 0.060257, 0.038963, 0.73917, 0.3709, 0.35638]
Predicted label: 7
Correct prediction
Energy consumption = 192.526769 pJ
sum error= 282
Actual label: 8
Output voltages: [0.2492, 0.33089, 0.23002, 0.32191, 0.21046, 0.229, 0.28504, 0.087949, 0.70836, 0.26895]
Predicted label: 8
Correct prediction
Energy consumption = 193.564641 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73044, 0.23905, 0.21678, 0.14859, 0.23582, 0.15823, 0.45338, 0.21866, 0.25978, 0.20118]
Predicted label: 0
Correct prediction
Energy consumption = 201.797765 pJ
sum error= 282
Actual label: 1
Output voltages: [0.18376, 0.76168, 0.23887, 0.22666, 0.25754, 0.11535, 0.38711, 0.14285, 0.29771, 0.21944]
Predicted label: 1
Correct prediction
Energy consumption = 204.288509 pJ
sum error= 282
Actual label: 2
Output voltages: [0.3244, 0.1838, 0.73144, 0.36553, 0.16557, 0.042301, 0.22173, 0.26843, 0.44238, 0.12697]
Predicted label: 2
Correct prediction
Energy consumption = 186.720134 pJ
sum error= 282
Actual label: 3
Output voltages: [0.28704, 0.15355, 0.34814, 0.74864, 0.16546, 0.15155, 0.11763, 0.19518, 0.42535, 0.24054]
Predicted label: 3
Correct prediction
Energy consumption = 181.510832 pJ
sum error= 282
Actual label: 4
Output voltages: [0.16373, 0.14174, 0.3247, 0.14999, 0.75258, 0.065135, 0.22344, 0.19457, 0.26797, 0.23656]
Predicted label: 4
Correct prediction
Energy consumption = 186.528840 pJ
sum error= 282
Actual label: 7
Output voltages: [0.36919, 0.19401, 0.1509, 0.32019, 0.21411, 0.23401, 0.040294, 0.73998, 0.3181, 0.34559]
Predicted label: 7
Correct prediction
Energy consumption = 194.778449 pJ
sum error= 282
Actual label: 8
Output voltages: [0.17149, 0.19733, 0.29696, 0.27969, 0.18022, 0.21038, 0.18686, 0.19056, 0.75244, 0.25279]
Predicted label: 8
Correct prediction
Energy consumption = 185.048912 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 892 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 892 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 892 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36917, 0.13754, 0.2163, 0.24924, 0.34174, 0.22117, 0.12679, 0.2313, 0.35942, 0.70071]
Predicted label: 9
Correct prediction
Energy consumption = 186.597727 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73734, 0.20736, 0.33131, 0.19073, 0.1806, 0.08173, 0.35891, 0.21133, 0.31831, 0.23233]
Predicted label: 0
Correct prediction
Energy consumption = 190.000603 pJ
sum error= 282
Actual label: 1
Output voltages: [0.22505, 0.68262, 0.29599, 0.111, 0.2399, 0.10054, 0.36299, 0.090998, 0.45163, 0.28485]
Predicted label: 1
Correct prediction
Energy consumption = 195.929160 pJ
sum error= 282
Actual label: 2
Output voltages: [0.34487, 0.15581, 0.72418, 0.40816, 0.12802, 0.045953, 0.24513, 0.20637, 0.41895, 0.16603]
Predicted label: 2
Correct prediction
Energy consumption = 189.020038 pJ
sum error= 282
Actual label: 3
Output voltages: [0.35004, 0.1822, 0.30405, 0.75769, 0.18269, 0.17567, 0.124, 0.22711, 0.47648, 0.22605]
Predicted label: 3
Correct prediction
Energy consumption = 183.068650 pJ
sum error= 282
Actual label: 4
Output voltages: [0.14743, 0.18627, 0.32716, 0.19434, 0.75513, 0.068765, 0.28308, 0.3393, 0.19217, 0.16442]
Predicted label: 4
Correct prediction
Energy consumption = 190.595994 pJ
sum error= 282
Actual label: 7
Output voltages: [0.35761, 0.16967, 0.23266, 0.19467, 0.24741, 0.21827, 0.04832, 0.75137, 0.2526, 0.35893]
Predicted label: 7
Correct prediction
Energy consumption = 197.215843 pJ
sum error= 282
Actual label: 8
Output voltages: [0.194, 0.2529, 0.34137, 0.25225, 0.14773, 0.18236, 0.16825, 0.12001, 0.74752, 0.27279]
Predicted label: 8
Correct prediction
Energy consumption = 188.141320 pJ
sum error= 282
Actual label: 9
Output voltages: [0.36578, 0.11634, 0.19906, 0.26662, 0.22463, 0.21316, 0.091561, 0.2512, 0.48847, 0.62554]
Predicted label: 9
Correct prediction
Energy consumption = 185.044208 pJ
sum error= 282
Actual label: 0
Output voltages: [0.74655, 0.23419, 0.20565, 0.17184, 0.17539, 0.19256, 0.40558, 0.23864, 0.28637, 0.2238]
Predicted label: 0
Correct prediction
Energy consumption = 183.846628 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 893 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 893 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 893 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23453, 0.74407, 0.21322, 0.1977, 0.37889, 0.13666, 0.3392, 0.11908, 0.3053, 0.23143]
Predicted label: 1
Correct prediction
Energy consumption = 199.758820 pJ
sum error= 282
Actual label: 7
Output voltages: [0.42985, 0.22018, 0.14822, 0.25706, 0.28251, 0.20131, 0.054435, 0.74894, 0.23297, 0.30408]
Predicted label: 7
Correct prediction
Energy consumption = 197.761813 pJ
sum error= 282
Actual label: 8
Output voltages: [0.23221, 0.26993, 0.35267, 0.21721, 0.14484, 0.084843, 0.15558, 0.16336, 0.72967, 0.34619]
Predicted label: 8
Correct prediction
Energy consumption = 184.797448 pJ
sum error= 282
Actual label: 9
Output voltages: [0.35681, 0.1047, 0.2238, 0.21467, 0.28472, 0.16104, 0.06444, 0.21783, 0.46562, 0.64432]
Predicted label: 9
Correct prediction
Energy consumption = 183.155351 pJ
sum error= 282
Actual label: 8
Output voltages: [0.17837, 0.25029, 0.29134, 0.24145, 0.18955, 0.20283, 0.1972, 0.1403, 0.74994, 0.2732]
Predicted label: 8
Correct prediction
Energy consumption = 194.277604 pJ
sum error= 282
Actual label: 9
Output voltages: [0.33059, 0.15505, 0.19561, 0.30328, 0.31011, 0.18282, 0.10389, 0.24648, 0.3657, 0.69534]
Predicted label: 9
Correct prediction
Energy consumption = 185.017877 pJ
sum error= 282
Actual label: 2
Output voltages: [0.34484, 0.20406, 0.75226, 0.30769, 0.16464, 0.050276, 0.24974, 0.22816, 0.4212, 0.14984]
Predicted label: 2
Correct prediction
Energy consumption = 186.000624 pJ
sum error= 282
Actual label: 6
Output voltages: [0.29055, 0.20026, 0.33474, 0.058506, 0.388, 0.28847, 0.7407, 0.078258, 0.38018, 0.091642]
Predicted label: 6
Correct prediction
Energy consumption = 188.097832 pJ
sum error= 282
Actual label: 1
Output voltages: [0.21626, 0.7355, 0.17575, 0.16091, 0.33603, 0.096204, 0.35085, 0.14675, 0.29806, 0.25582]
Predicted label: 1
Correct prediction
Energy consumption = 200.592979 pJ
sum error= 282
Actual label: 3
Output voltages: [0.35093, 0.21747, 0.336, 0.75668, 0.16202, 0.14435, 0.12793, 0.17777, 0.43695, 0.22105]
Predicted label: 3
Correct prediction
Energy consumption = 184.737443 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 894 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 894 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 894 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.29089, 0.045683, 0.10885, 0.3979, 0.31546, 0.71832, 0.3467, 0.095006, 0.45921, 0.17756]
Predicted label: 5
Correct prediction
Energy consumption = 187.954593 pJ
sum error= 282
Actual label: 4
Output voltages: [0.10285, 0.12386, 0.24725, 0.30862, 0.74304, 0.13681, 0.21181, 0.25721, 0.2454, 0.15366]
Predicted label: 4
Correct prediction
Energy consumption = 188.704829 pJ
sum error= 282
Actual label: 8
Output voltages: [0.212, 0.25695, 0.33971, 0.24284, 0.19283, 0.1135, 0.18778, 0.086805, 0.70995, 0.29623]
Predicted label: 8
Correct prediction
Energy consumption = 195.153015 pJ
sum error= 282
Actual label: 2
Output voltages: [0.31445, 0.24588, 0.70957, 0.40342, 0.11392, 0.056636, 0.21664, 0.27139, 0.3996, 0.12933]
Predicted label: 2
Correct prediction
Energy consumption = 186.934316 pJ
sum error= 282
Actual label: 6
Output voltages: [0.27161, 0.14692, 0.26766, 0.11789, 0.32532, 0.32988, 0.71881, 0.056591, 0.47549, 0.16151]
Predicted label: 6
Correct prediction
Energy consumption = 187.294160 pJ
sum error= 282
Actual label: 4
Output voltages: [0.12175, 0.14244, 0.2427, 0.24097, 0.75658, 0.12986, 0.21611, 0.25663, 0.26755, 0.17991]
Predicted label: 4
Correct prediction
Energy consumption = 192.341154 pJ
sum error= 282
Actual label: 3
Output voltages: [0.32633, 0.10297, 0.27256, 0.75495, 0.26623, 0.28815, 0.16632, 0.13845, 0.36206, 0.22579]
Predicted label: 3
Correct prediction
Energy consumption = 185.117891 pJ
sum error= 282
Actual label: 4
Output voltages: [0.11666, 0.19294, 0.2922, 0.18519, 0.7454, 0.065011, 0.2033, 0.30802, 0.22552, 0.20257]
Predicted label: 4
Correct prediction
Energy consumption = 182.295089 pJ
sum error= 282
Actual label: 5
Output voltages: [0.34076, 0.079631, 0.047162, 0.37509, 0.27328, 0.74682, 0.28002, 0.17551, 0.41227, 0.12644]
Predicted label: 5
Correct prediction
Energy consumption = 189.212001 pJ
sum error= 282
Actual label: 9
Output voltages: [0.37836, 0.11648, 0.19937, 0.27533, 0.3131, 0.21501, 0.076373, 0.22681, 0.41426, 0.67673]
Predicted label: 9
Correct prediction
Energy consumption = 183.799120 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 895 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 895 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 895 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31936, 0.27845, 0.75185, 0.31012, 0.19166, 0.043725, 0.24802, 0.22563, 0.38641, 0.17387]
Predicted label: 2
Correct prediction
Energy consumption = 186.705301 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73685, 0.21917, 0.27692, 0.2078, 0.16248, 0.13606, 0.33242, 0.18739, 0.35026, 0.21366]
Predicted label: 0
Correct prediction
Energy consumption = 193.833224 pJ
sum error= 282
Actual label: 3
Output voltages: [0.26775, 0.21944, 0.32883, 0.66672, 0.12136, 0.19289, 0.12137, 0.089134, 0.40419, 0.37522]
Predicted label: 3
Correct prediction
Energy consumption = 196.901684 pJ
sum error= 282
Actual label: 9
Output voltages: [0.32777, 0.13627, 0.23005, 0.25088, 0.26969, 0.1493, 0.089713, 0.17468, 0.41601, 0.68411]
Predicted label: 9
Correct prediction
Energy consumption = 180.950439 pJ
sum error= 282
Actual label: 4
Output voltages: [0.15082, 0.1468, 0.28416, 0.1855, 0.75468, 0.12623, 0.26941, 0.24132, 0.30017, 0.21402]
Predicted label: 4
Correct prediction
Energy consumption = 185.288588 pJ
sum error= 282
Actual label: 9
Output voltages: [0.35207, 0.098838, 0.17237, 0.28334, 0.27329, 0.2634, 0.10644, 0.24087, 0.37912, 0.64777]
Predicted label: 9
Correct prediction
Energy consumption = 185.231636 pJ
sum error= 282
Actual label: 7
Output voltages: [0.33922, 0.26778, 0.32827, 0.25087, 0.13255, 0.067431, 0.038457, 0.53959, 0.46701, 0.41308]
Predicted label: 7
Correct prediction
Energy consumption = 197.906093 pJ
sum error= 282
Actual label: 3
Output voltages: [0.30283, 0.16287, 0.32536, 0.75451, 0.18067, 0.28897, 0.16488, 0.17483, 0.44713, 0.2144]
Predicted label: 3
Correct prediction
Energy consumption = 190.050703 pJ
sum error= 282
Actual label: 8
Output voltages: [0.1518, 0.26278, 0.23008, 0.3737, 0.087368, 0.29555, 0.11312, 0.2528, 0.75399, 0.23047]
Predicted label: 8
Correct prediction
Energy consumption = 189.228863 pJ
sum error= 282
Actual label: 7
Output voltages: [0.33929, 0.29696, 0.27791, 0.27591, 0.25997, 0.094861, 0.039399, 0.73835, 0.25091, 0.3036]
Predicted label: 7
Correct prediction
Energy consumption = 189.626953 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 896 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 896 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 896 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.15953, 0.12517, 0.32483, 0.2306, 0.75034, 0.063245, 0.20905, 0.2202, 0.24765, 0.21048]
Predicted label: 4
Correct prediction
Energy consumption = 189.986344 pJ
sum error= 282
Actual label: 4
Output voltages: [0.17814, 0.16711, 0.32264, 0.17264, 0.7361, 0.069179, 0.26184, 0.24292, 0.32096, 0.15467]
Predicted label: 4
Correct prediction
Energy consumption = 181.068551 pJ
sum error= 282
Actual label: 9
Output voltages: [0.32805, 0.14451, 0.22463, 0.24879, 0.2901, 0.16968, 0.068329, 0.20924, 0.41797, 0.67936]
Predicted label: 9
Correct prediction
Energy consumption = 186.482774 pJ
sum error= 282
Actual label: 8
Output voltages: [0.15389, 0.23853, 0.31949, 0.2257, 0.16686, 0.17288, 0.15096, 0.21316, 0.74247, 0.29904]
Predicted label: 8
Correct prediction
Energy consumption = 187.714203 pJ
sum error= 282
Actual label: 5
Output voltages: [0.25062, 0.058304, 0.072246, 0.39365, 0.23645, 0.69222, 0.27483, 0.1373, 0.42602, 0.32728]
Predicted label: 5
Correct prediction
Energy consumption = 191.262930 pJ
sum error= 282
Actual label: 8
Output voltages: [0.1693, 0.20952, 0.29127, 0.27313, 0.1293, 0.20288, 0.21559, 0.17538, 0.75047, 0.23762]
Predicted label: 8
Correct prediction
Energy consumption = 188.942619 pJ
sum error= 282
Actual label: 2
Output voltages: [0.30601, 0.31525, 0.75374, 0.33096, 0.2128, 0.040924, 0.25587, 0.23096, 0.36534, 0.19434]
Predicted label: 2
Correct prediction
Energy consumption = 178.476142 pJ
sum error= 282
Actual label: 6
Output voltages: [0.25385, 0.14221, 0.21816, 0.17278, 0.28838, 0.42906, 0.69643, 0.093338, 0.50834, 0.12371]
Predicted label: 6
Correct prediction
Energy consumption = 190.889733 pJ
sum error= 282
Actual label: 6
Output voltages: [0.28637, 0.16838, 0.22661, 0.14921, 0.33195, 0.41551, 0.73171, 0.066089, 0.39386, 0.1643]
Predicted label: 6
Correct prediction
Energy consumption = 182.619749 pJ
sum error= 282
Actual label: 2
Output voltages: [0.3641, 0.19979, 0.75625, 0.30676, 0.18494, 0.046506, 0.25672, 0.26179, 0.36882, 0.19357]
Predicted label: 2
Correct prediction
Energy consumption = 186.443589 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 897 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 897 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 897 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.29036, 0.14136, 0.40531, 0.74565, 0.12566, 0.12869, 0.12818, 0.2116, 0.47536, 0.20928]
Predicted label: 3
Correct prediction
Energy consumption = 184.762249 pJ
sum error= 282
Actual label: 1
Output voltages: [0.19331, 0.72375, 0.21927, 0.16117, 0.34932, 0.13582, 0.39455, 0.091967, 0.33894, 0.17671]
Predicted label: 1
Correct prediction
Energy consumption = 197.025212 pJ
sum error= 282
Actual label: 3
Output voltages: [0.34086, 0.086472, 0.42208, 0.71186, 0.18011, 0.19385, 0.14533, 0.18031, 0.55393, 0.1763]
Predicted label: 3
Correct prediction
Energy consumption = 191.957885 pJ
sum error= 282
Actual label: 2
Output voltages: [0.21877, 0.24231, 0.73161, 0.31547, 0.17629, 0.044362, 0.25872, 0.20119, 0.44583, 0.18366]
Predicted label: 2
Correct prediction
Energy consumption = 183.629319 pJ
sum error= 282
Actual label: 7
Output voltages: [0.49998, 0.1755, 0.14346, 0.20596, 0.24026, 0.1691, 0.064636, 0.6976, 0.34857, 0.26754]
Predicted label: 7
Correct prediction
Energy consumption = 196.376219 pJ
sum error= 282
Actual label: 3
Output voltages: [0.38504, 0.12823, 0.25867, 0.71222, 0.18336, 0.31731, 0.11665, 0.096775, 0.45227, 0.28615]
Predicted label: 3
Correct prediction
Energy consumption = 185.259537 pJ
sum error= 282
Actual label: 1
Output voltages: [0.19078, 0.73839, 0.24041, 0.19879, 0.38795, 0.14875, 0.3873, 0.12496, 0.28653, 0.18111]
Predicted label: 1
Correct prediction
Energy consumption = 196.924343 pJ
sum error= 282
Actual label: 9
Output voltages: [0.39819, 0.12532, 0.20957, 0.27868, 0.35302, 0.12104, 0.07637, 0.17786, 0.37143, 0.67622]
Predicted label: 9
Correct prediction
Energy consumption = 192.653849 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73857, 0.24642, 0.2845, 0.16534, 0.13823, 0.12958, 0.41473, 0.20233, 0.2867, 0.27979]
Predicted label: 0
Correct prediction
Energy consumption = 183.047557 pJ
sum error= 282
Actual label: 1
Output voltages: [0.18526, 0.74796, 0.27109, 0.1577, 0.24385, 0.12029, 0.39249, 0.15085, 0.36874, 0.18747]
Predicted label: 1
Correct prediction
Energy consumption = 193.510177 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 898 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 898 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 898 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.25942, 0.68414, 0.37481, 0.18857, 0.41734, 0.040072, 0.26814, 0.24606, 0.17262, 0.24181]
Predicted label: 1
Correct prediction
Energy consumption = 198.014011 pJ
sum error= 282
Actual label: 3
Output voltages: [0.32992, 0.13735, 0.33073, 0.7075, 0.099666, 0.20972, 0.14947, 0.10499, 0.53701, 0.20042]
Predicted label: 3
Correct prediction
Energy consumption = 187.010749 pJ
sum error= 282
Actual label: 5
Output voltages: [0.35428, 0.088351, 0.055542, 0.39358, 0.28504, 0.74656, 0.27982, 0.15923, 0.37318, 0.14141]
Predicted label: 5
Correct prediction
Energy consumption = 186.977259 pJ
sum error= 282
Actual label: 0
Output voltages: [0.72904, 0.20757, 0.30498, 0.19691, 0.13568, 0.11727, 0.42547, 0.21989, 0.3104, 0.29808]
Predicted label: 0
Correct prediction
Energy consumption = 184.861325 pJ
sum error= 282
Actual label: 7
Output voltages: [0.35313, 0.29386, 0.27244, 0.24928, 0.25438, 0.092864, 0.04299, 0.73383, 0.26466, 0.29204]
Predicted label: 7
Correct prediction
Energy consumption = 205.780542 pJ
sum error= 282
Actual label: 8
Output voltages: [0.21106, 0.23864, 0.31531, 0.24972, 0.13388, 0.21723, 0.15792, 0.15619, 0.75362, 0.3215]
Predicted label: 8
Correct prediction
Energy consumption = 189.940528 pJ
sum error= 282
Actual label: 1
Output voltages: [0.23707, 0.71346, 0.23998, 0.21233, 0.43899, 0.065695, 0.31669, 0.12983, 0.28942, 0.25084]
Predicted label: 1
Correct prediction
Energy consumption = 195.204847 pJ
sum error= 282
Actual label: 5
Output voltages: [0.28156, 0.049742, 0.056848, 0.40648, 0.2452, 0.73032, 0.30982, 0.18419, 0.46798, 0.24262]
Predicted label: 5
Correct prediction
Energy consumption = 186.199575 pJ
sum error= 282
Actual label: 1
Output voltages: [0.20778, 0.72676, 0.20931, 0.12755, 0.33103, 0.099707, 0.35078, 0.12201, 0.37196, 0.22935]
Predicted label: 1
Correct prediction
Energy consumption = 202.155614 pJ
sum error= 282
Actual label: 4
Output voltages: [0.13107, 0.14041, 0.28049, 0.16073, 0.74713, 0.085559, 0.23027, 0.27391, 0.29044, 0.18491]
Predicted label: 4
Correct prediction
Energy consumption = 179.256444 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 899 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 899 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 899 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27578, 0.15144, 0.28294, 0.10751, 0.34886, 0.364, 0.73207, 0.047307, 0.37601, 0.16705]
Predicted label: 6
Correct prediction
Energy consumption = 186.793883 pJ
sum error= 282
Actual label: 0
Output voltages: [0.7486, 0.26254, 0.25268, 0.20182, 0.14062, 0.22252, 0.39611, 0.17868, 0.26672, 0.23733]
Predicted label: 0
Correct prediction
Energy consumption = 192.254374 pJ
sum error= 282
Actual label: 0
Output voltages: [0.73206, 0.24581, 0.31533, 0.1863, 0.14379, 0.16107, 0.40809, 0.1887, 0.28157, 0.17639]
Predicted label: 0
Correct prediction
Energy consumption = 184.036560 pJ
sum error= 282
Actual label: 4
Output voltages: [0.17611, 0.20929, 0.31989, 0.19981, 0.75808, 0.064085, 0.22803, 0.30084, 0.17777, 0.23095]
Predicted label: 4
Correct prediction
Energy consumption = 192.835536 pJ
sum error= 282
Actual label: 9
Output voltages: [0.35455, 0.11586, 0.20162, 0.29478, 0.35596, 0.18142, 0.10336, 0.23504, 0.34516, 0.65981]
Predicted label: 9
Correct prediction
Energy consumption = 185.998566 pJ
sum error= 282
Actual label: 1
Output voltages: [0.21638, 0.73613, 0.30395, 0.17831, 0.37495, 0.09268, 0.37202, 0.15556, 0.30782, 0.1753]
Predicted label: 1
Correct prediction
Energy consumption = 199.885782 pJ
sum error= 282
Actual label: 6
Output voltages: [0.31151, 0.17188, 0.33243, 0.06264, 0.35571, 0.28181, 0.73518, 0.054052, 0.40443, 0.12769]
Predicted label: 6
Correct prediction
Energy consumption = 179.914801 pJ
sum error= 282
Actual label: 6
Output voltages: [0.26466, 0.14675, 0.30709, 0.081986, 0.35729, 0.34633, 0.73213, 0.044523, 0.38296, 0.15805]
Predicted label: 6
Correct prediction
Energy consumption = 176.092768 pJ
sum error= 282
Actual label: 9
Output voltages: [0.32224, 0.078562, 0.27649, 0.17175, 0.35443, 0.10149, 0.075922, 0.19862, 0.49619, 0.57044]
Predicted label: 9
Correct prediction
Energy consumption = 186.995359 pJ
sum error= 282
Actual label: 0
Output voltages: [0.7322, 0.21719, 0.25859, 0.18537, 0.15405, 0.18032, 0.43798, 0.18444, 0.28469, 0.24187]
Predicted label: 0
Correct prediction
Energy consumption = 186.209602 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 900 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 900 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 900 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.36299, 0.20159, 0.29154, 0.33743, 0.1697, 0.15804, 0.035339, 0.73544, 0.31543, 0.39329]
Predicted label: 7
Correct prediction
Energy consumption = 197.311127 pJ
sum error= 282
Actual label: 6
Output voltages: [0.28102, 0.19951, 0.35367, 0.13116, 0.33217, 0.26583, 0.73555, 0.0452, 0.41179, 0.21567]
Predicted label: 6
Correct prediction
Energy consumption = 184.818327 pJ
sum error= 282
Actual label: 1
Output voltages: [0.22208, 0.73935, 0.24999, 0.16038, 0.28793, 0.13803, 0.36769, 0.12462, 0.39195, 0.18222]
Predicted label: 1
Correct prediction
Energy consumption = 198.111512 pJ
sum error= 282
Actual label: 1
Output voltages: [0.16706, 0.71002, 0.23914, 0.13218, 0.32631, 0.10454, 0.28847, 0.10883, 0.39916, 0.24052]
Predicted label: 1
Correct prediction
Energy consumption = 187.091475 pJ
sum error= 282
Actual label: 0
Output voltages: [0.72309, 0.23287, 0.28442, 0.14076, 0.16614, 0.10661, 0.40597, 0.24194, 0.35081, 0.21612]
Predicted label: 0
Correct prediction
Energy consumption = 193.345504 pJ
sum error= 282
Actual label: 1
Output voltages: [0.22086, 0.59839, 0.27042, 0.13811, 0.30328, 0.078055, 0.28839, 0.059023, 0.46999, 0.28841]
Predicted label: 1
Correct prediction
Energy consumption = 198.991608 pJ
sum error= 282
Actual label: 2
Output voltages: [0.37558, 0.15993, 0.72873, 0.30957, 0.11198, 0.039638, 0.19251, 0.30974, 0.51807, 0.15258]
Predicted label: 2
Correct prediction
Energy consumption = 183.679790 pJ
sum error= 282
Actual label: 3
Output voltages: [0.24375, 0.13334, 0.33836, 0.70472, 0.074506, 0.19461, 0.11309, 0.20915, 0.58826, 0.1536]
Predicted label: 3
Correct prediction
Energy consumption = 173.745780 pJ
sum error= 282
Actual label: 4
Output voltages: [0.24186, 0.18037, 0.25733, 0.13886, 0.72955, 0.077111, 0.39146, 0.22419, 0.19916, 0.17772]
Predicted label: 4
Correct prediction
Energy consumption = 192.539904 pJ
sum error= 282
Actual label: 7
Output voltages: [0.29353, 0.1814, 0.70789, 0.34845, 0.14994, 0.036435, 0.16665, 0.40314, 0.48115, 0.088783]
Predicted label: 2
Wrong prediction!
Energy consumption = 182.111538 pJ
sum error= 283
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 901 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 901 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 901 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.31414, 0.20602, 0.66148, 0.40679, 0.064308, 0.050892, 0.23132, 0.18571, 0.54083, 0.14373]
Predicted label: 2
Correct prediction
Energy consumption = 189.065277 pJ
sum error= 283
Actual label: 3
Output voltages: [0.34007, 0.059691, 0.33955, 0.67942, 0.13553, 0.27842, 0.12162, 0.19663, 0.55389, 0.12052]
Predicted label: 3
Correct prediction
Energy consumption = 179.621848 pJ
sum error= 283
Actual label: 4
Output voltages: [0.25982, 0.14236, 0.32932, 0.10404, 0.65211, 0.0388, 0.29189, 0.25704, 0.28407, 0.20219]
Predicted label: 4
Correct prediction
Energy consumption = 190.548843 pJ
sum error= 283
Actual label: 5
Output voltages: [0.33308, 0.075705, 0.11726, 0.36045, 0.17879, 0.6873, 0.40895, 0.14147, 0.5252, 0.07771]
Predicted label: 5
Correct prediction
Energy consumption = 186.479306 pJ
sum error= 283
Actual label: 6
Output voltages: [0.3086, 0.099973, 0.19245, 0.18346, 0.32127, 0.36007, 0.65178, 0.040969, 0.43931, 0.20461]
Predicted label: 6
Correct prediction
Energy consumption = 183.199384 pJ
sum error= 283
Actual label: 7
Output voltages: [0.2612, 0.1872, 0.60865, 0.36607, 0.14153, 0.035157, 0.12282, 0.52968, 0.42019, 0.15119]
Predicted label: 2
Wrong prediction!
Energy consumption = 189.512146 pJ
sum error= 284
Actual label: 0
Output voltages: [0.57575, 0.13411, 0.33157, 0.10372, 0.25868, 0.25179, 0.49738, 0.22553, 0.31514, 0.12814]
Predicted label: 0
Correct prediction
Energy consumption = 191.348276 pJ
sum error= 284
Actual label: 1
Output voltages: [0.14927, 0.71694, 0.23447, 0.23005, 0.2698, 0.083121, 0.22862, 0.13005, 0.40765, 0.23451]
Predicted label: 1
Correct prediction
Energy consumption = 194.942860 pJ
sum error= 284
Actual label: 2
Output voltages: [0.30608, 0.14706, 0.71731, 0.38642, 0.15216, 0.034397, 0.19463, 0.36243, 0.43415, 0.1516]
Predicted label: 2
Correct prediction
Energy consumption = 182.160370 pJ
sum error= 284
Actual label: 7
Output voltages: [0.21648, 0.12523, 0.54219, 0.35464, 0.15243, 0.049474, 0.090171, 0.60682, 0.49683, 0.10415]
Predicted label: 7
Correct prediction
Energy consumption = 182.168419 pJ
sum error= 284
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 902 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 902 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 902 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20424, 0.16241, 0.20671, 0.34047, 0.13506, 0.29023, 0.16745, 0.11528, 0.73881, 0.24033]
Predicted label: 8
Correct prediction
Energy consumption = 194.452958 pJ
sum error= 284
Actual label: 6
Output voltages: [0.26795, 0.1822, 0.38404, 0.042732, 0.41684, 0.20347, 0.72621, 0.052068, 0.32492, 0.16006]
Predicted label: 6
Correct prediction
Energy consumption = 181.448684 pJ
sum error= 284
Actual label: 3
Output voltages: [0.30478, 0.065249, 0.50799, 0.67474, 0.12241, 0.23067, 0.1934, 0.17714, 0.47798, 0.13367]
Predicted label: 3
Correct prediction
Energy consumption = 187.150031 pJ
sum error= 284
Actual label: 9
Output voltages: [0.37465, 0.099754, 0.13715, 0.32451, 0.3792, 0.18321, 0.060962, 0.30065, 0.31431, 0.56738]
Predicted label: 9
Correct prediction
Energy consumption = 187.508101 pJ
sum error= 284
Actual label: 7
Output voltages: [0.27737, 0.13955, 0.61821, 0.37844, 0.098806, 0.030455, 0.11122, 0.55045, 0.47041, 0.16359]
Predicted label: 2
Wrong prediction!
Energy consumption = 182.803653 pJ
sum error= 285
Actual label: 1
Output voltages: [0.18528, 0.67199, 0.18117, 0.19078, 0.30066, 0.18274, 0.43062, 0.063997, 0.43329, 0.16332]
Predicted label: 1
Correct prediction
Energy consumption = 199.727447 pJ
sum error= 285
Actual label: 9
Output voltages: [0.35501, 0.12103, 0.067749, 0.30489, 0.35078, 0.3006, 0.2104, 0.24692, 0.31778, 0.54289]
Predicted label: 9
Correct prediction
Energy consumption = 192.336177 pJ
sum error= 285
Actual label: 3
Output voltages: [0.2714, 0.14568, 0.33427, 0.72532, 0.11488, 0.25998, 0.11833, 0.17504, 0.54154, 0.16146]
Predicted label: 3
Correct prediction
Energy consumption = 183.310567 pJ
sum error= 285
Actual label: 9
Output voltages: [0.3487, 0.05552, 0.16335, 0.25372, 0.2856, 0.29453, 0.085469, 0.3428, 0.42625, 0.57718]
Predicted label: 9
Correct prediction
Energy consumption = 188.262978 pJ
sum error= 285
Actual label: 6
Output voltages: [0.28641, 0.10018, 0.251, 0.076385, 0.38323, 0.33181, 0.70198, 0.050314, 0.43161, 0.16354]
Predicted label: 6
Correct prediction
Energy consumption = 180.881165 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 903 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 903 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 903 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.31027, 0.7078, 0.2101, 0.16231, 0.44011, 0.058689, 0.28096, 0.19552, 0.21196, 0.2961]
Predicted label: 1
Correct prediction
Energy consumption = 205.556035 pJ
sum error= 285
Actual label: 7
Output voltages: [0.24996, 0.17961, 0.45845, 0.35134, 0.21502, 0.039937, 0.055944, 0.69472, 0.335, 0.25566]
Predicted label: 7
Correct prediction
Energy consumption = 189.574954 pJ
sum error= 285
Actual label: 2
Output voltages: [0.31972, 0.18175, 0.71246, 0.38576, 0.092418, 0.039488, 0.28811, 0.22656, 0.50793, 0.13244]
Predicted label: 2
Correct prediction
Energy consumption = 178.890913 pJ
sum error= 285
Actual label: 4
Output voltages: [0.14418, 0.15452, 0.2461, 0.1033, 0.74427, 0.14428, 0.25866, 0.27499, 0.3265, 0.20899]
Predicted label: 4
Correct prediction
Energy consumption = 186.169341 pJ
sum error= 285
Actual label: 4
Output voltages: [0.099615, 0.19915, 0.18663, 0.11923, 0.73888, 0.10127, 0.30263, 0.28859, 0.2992, 0.17528]
Predicted label: 4
Correct prediction
Energy consumption = 185.702715 pJ
sum error= 285
Actual label: 5
Output voltages: [0.27747, 0.15066, 0.049905, 0.30147, 0.30326, 0.74648, 0.27835, 0.13863, 0.52641, 0.11762]
Predicted label: 5
Correct prediction
Energy consumption = 193.035309 pJ
sum error= 285
Actual label: 7
Output voltages: [0.21483, 0.26878, 0.50208, 0.39622, 0.12457, 0.038667, 0.062563, 0.59689, 0.39646, 0.1801]
Predicted label: 7
Correct prediction
Energy consumption = 188.074456 pJ
sum error= 285
Actual label: 0
Output voltages: [0.70741, 0.16177, 0.29004, 0.11122, 0.20653, 0.18155, 0.48613, 0.23163, 0.22078, 0.29409]
Predicted label: 0
Correct prediction
Energy consumption = 186.046112 pJ
sum error= 285
Actual label: 0
Output voltages: [0.72134, 0.18135, 0.32137, 0.12805, 0.18128, 0.19559, 0.4694, 0.30503, 0.22353, 0.20755]
Predicted label: 0
Correct prediction
Energy consumption = 180.357858 pJ
sum error= 285
Actual label: 1
Output voltages: [0.24984, 0.72364, 0.28021, 0.12807, 0.33085, 0.087984, 0.33793, 0.086115, 0.3244, 0.27206]
Predicted label: 1
Correct prediction
Energy consumption = 200.823239 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 904 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 904 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 904 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32409, 0.088587, 0.22212, 0.14036, 0.35808, 0.44484, 0.68387, 0.046748, 0.4036, 0.19434]
Predicted label: 6
Correct prediction
Energy consumption = 183.771307 pJ
sum error= 285
Actual label: 6
Output voltages: [0.30794, 0.1614, 0.2332, 0.14112, 0.32681, 0.39429, 0.72448, 0.054739, 0.35128, 0.15443]
Predicted label: 6
Correct prediction
Energy consumption = 181.166475 pJ
sum error= 285
Actual label: 8
Output voltages: [0.17803, 0.24896, 0.29883, 0.20684, 0.16867, 0.21823, 0.17541, 0.11829, 0.75127, 0.34447]
Predicted label: 8
Correct prediction
Energy consumption = 189.374033 pJ
sum error= 285
Actual label: 2
Output voltages: [0.33977, 0.31254, 0.72414, 0.40455, 0.098582, 0.031303, 0.25327, 0.1707, 0.40271, 0.15639]
Predicted label: 2
Correct prediction
Energy consumption = 181.527353 pJ
sum error= 285
Actual label: 7
Output voltages: [0.23401, 0.2214, 0.5654, 0.26085, 0.21223, 0.029419, 0.1168, 0.6858, 0.32835, 0.25122]
Predicted label: 7
Correct prediction
Energy consumption = 188.012716 pJ
sum error= 285
Actual label: 7
Output voltages: [0.22035, 0.19122, 0.51381, 0.32524, 0.21608, 0.03652, 0.066314, 0.68089, 0.29958, 0.24733]
Predicted label: 7
Correct prediction
Energy consumption = 180.440949 pJ
sum error= 285
Actual label: 2
Output voltages: [0.26228, 0.13047, 0.68735, 0.38931, 0.067628, 0.050519, 0.16158, 0.38383, 0.54178, 0.10328]
Predicted label: 2
Correct prediction
Energy consumption = 177.485222 pJ
sum error= 285
Actual label: 4
Output voltages: [0.15113, 0.19637, 0.22189, 0.079068, 0.73743, 0.097844, 0.30218, 0.35085, 0.25672, 0.24028]
Predicted label: 4
Correct prediction
Energy consumption = 191.326516 pJ
sum error= 285
Actual label: 2
Output voltages: [0.36813, 0.23795, 0.73534, 0.3092, 0.19666, 0.031581, 0.29194, 0.28255, 0.46129, 0.19759]
Predicted label: 2
Correct prediction
Energy consumption = 189.349213 pJ
sum error= 285
Actual label: 1
Output voltages: [0.23104, 0.74108, 0.28703, 0.17811, 0.3045, 0.071543, 0.33386, 0.12961, 0.354, 0.21617]
Predicted label: 1
Correct prediction
Energy consumption = 192.516858 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 905 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 905 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 905 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.28648, 0.12135, 0.25028, 0.1177, 0.3764, 0.37413, 0.72457, 0.043305, 0.37728, 0.17815]
Predicted label: 6
Correct prediction
Energy consumption = 187.352224 pJ
sum error= 285
Actual label: 1
Output voltages: [0.22279, 0.62314, 0.15483, 0.32443, 0.33629, 0.063587, 0.30003, 0.12282, 0.41604, 0.18116]
Predicted label: 1
Correct prediction
Energy consumption = 216.054932 pJ
sum error= 285
Actual label: 0
Output voltages: [0.74134, 0.22754, 0.21605, 0.15711, 0.1734, 0.20765, 0.36846, 0.22578, 0.2956, 0.20344]
Predicted label: 0
Correct prediction
Energy consumption = 192.063382 pJ
sum error= 285
Actual label: 6
Output voltages: [0.25554, 0.1863, 0.35837, 0.067667, 0.35346, 0.31144, 0.74454, 0.050391, 0.33285, 0.14569]
Predicted label: 6
Correct prediction
Energy consumption = 183.177592 pJ
sum error= 285
Actual label: 9
Output voltages: [0.37743, 0.10482, 0.15755, 0.31648, 0.29193, 0.15704, 0.05165, 0.35956, 0.36953, 0.61663]
Predicted label: 9
Correct prediction
Energy consumption = 197.149572 pJ
sum error= 285
Actual label: 8
Output voltages: [0.2142, 0.17668, 0.27654, 0.35937, 0.076241, 0.3251, 0.20202, 0.15867, 0.7485, 0.24212]
Predicted label: 8
Correct prediction
Energy consumption = 188.635881 pJ
sum error= 285
Actual label: 3
Output voltages: [0.33966, 0.10472, 0.29713, 0.75018, 0.17709, 0.34795, 0.12633, 0.22331, 0.47452, 0.15817]
Predicted label: 3
Correct prediction
Energy consumption = 181.365816 pJ
sum error= 285
Actual label: 9
Output voltages: [0.30896, 0.085084, 0.23657, 0.36103, 0.20811, 0.19279, 0.06172, 0.19968, 0.48502, 0.56282]
Predicted label: 9
Correct prediction
Energy consumption = 183.144716 pJ
sum error= 285
Actual label: 6
Output voltages: [0.29429, 0.19705, 0.33656, 0.054414, 0.38054, 0.30144, 0.74297, 0.066704, 0.35103, 0.10742]
Predicted label: 6
Correct prediction
Energy consumption = 188.673304 pJ
sum error= 285
Actual label: 3
Output voltages: [0.29555, 0.11576, 0.29723, 0.74924, 0.19425, 0.35668, 0.14238, 0.1868, 0.46886, 0.18762]
Predicted label: 3
Correct prediction
Energy consumption = 178.379023 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 906 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 906 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 906 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7303, 0.23591, 0.32556, 0.15445, 0.074488, 0.18742, 0.36631, 0.16203, 0.29666, 0.25383]
Predicted label: 0
Correct prediction
Energy consumption = 192.004774 pJ
sum error= 285
Actual label: 1
Output voltages: [0.22104, 0.7642, 0.25831, 0.32071, 0.096407, 0.10383, 0.40303, 0.14556, 0.34007, 0.19937]
Predicted label: 1
Correct prediction
Energy consumption = 205.614028 pJ
sum error= 285
Actual label: 2
Output voltages: [0.2851, 0.30465, 0.71746, 0.23056, 0.15189, 0.028105, 0.28159, 0.26338, 0.44533, 0.19703]
Predicted label: 2
Correct prediction
Energy consumption = 198.384518 pJ
sum error= 285
Actual label: 3
Output voltages: [0.28374, 0.32239, 0.38844, 0.72144, 0.086767, 0.060054, 0.14033, 0.20954, 0.36068, 0.25882]
Predicted label: 3
Correct prediction
Energy consumption = 184.135270 pJ
sum error= 285
Actual label: 4
Output voltages: [0.15266, 0.1988, 0.26104, 0.058715, 0.7561, 0.1371, 0.3369, 0.23026, 0.29332, 0.23206]
Predicted label: 4
Correct prediction
Energy consumption = 195.803470 pJ
sum error= 285
Actual label: 5
Output voltages: [0.21857, 0.047305, 0.11509, 0.38907, 0.28201, 0.72957, 0.30618, 0.25001, 0.49234, 0.29143]
Predicted label: 5
Correct prediction
Energy consumption = 190.083461 pJ
sum error= 285
Actual label: 6
Output voltages: [0.30621, 0.21449, 0.2824, 0.10223, 0.29121, 0.44067, 0.73718, 0.12296, 0.44883, 0.12465]
Predicted label: 6
Correct prediction
Energy consumption = 180.749272 pJ
sum error= 285
Actual label: 7
Output voltages: [0.34814, 0.19688, 0.19343, 0.1039, 0.27471, 0.16446, 0.070478, 0.76627, 0.31373, 0.24901]
Predicted label: 7
Correct prediction
Energy consumption = 201.434498 pJ
sum error= 285
Actual label: 8
Output voltages: [0.18727, 0.20058, 0.2987, 0.22688, 0.17121, 0.20982, 0.19159, 0.16078, 0.74991, 0.32478]
Predicted label: 8
Correct prediction
Energy consumption = 191.857255 pJ
sum error= 285
Actual label: 9
Output voltages: [0.36754, 0.062335, 0.25635, 0.20472, 0.36955, 0.17532, 0.13246, 0.25534, 0.35068, 0.64164]
Predicted label: 9
Correct prediction
Energy consumption = 192.178869 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 907 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 907 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 907 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69808, 0.24592, 0.25985, 0.11317, 0.12775, 0.18003, 0.45698, 0.24585, 0.26583, 0.27338]
Predicted label: 0
Correct prediction
Energy consumption = 192.336964 pJ
sum error= 285
Actual label: 1
Output voltages: [0.1899, 0.60356, 0.31472, 0.19899, 0.27109, 0.057034, 0.32509, 0.1061, 0.47523, 0.28993]
Predicted label: 1
Correct prediction
Energy consumption = 208.157097 pJ
sum error= 285
Actual label: 2
Output voltages: [0.33661, 0.29352, 0.70399, 0.40898, 0.14959, 0.029006, 0.32176, 0.15219, 0.46552, 0.23456]
Predicted label: 2
Correct prediction
Energy consumption = 187.008562 pJ
sum error= 285
Actual label: 3
Output voltages: [0.37266, 0.13517, 0.30069, 0.74161, 0.10958, 0.21192, 0.15553, 0.34446, 0.51022, 0.20098]
Predicted label: 3
Correct prediction
Energy consumption = 184.820532 pJ
sum error= 285
Actual label: 4
Output voltages: [0.17708, 0.17338, 0.28423, 0.061818, 0.72925, 0.15559, 0.42341, 0.18356, 0.33587, 0.18838]
Predicted label: 4
Correct prediction
Energy consumption = 201.887347 pJ
sum error= 285
Actual label: 5
Output voltages: [0.25216, 0.051771, 0.069754, 0.31255, 0.29661, 0.73691, 0.31217, 0.19315, 0.51688, 0.29626]
Predicted label: 5
Correct prediction
Energy consumption = 183.821394 pJ
sum error= 285
Actual label: 6
Output voltages: [0.30044, 0.16353, 0.26466, 0.13733, 0.33874, 0.3704, 0.72142, 0.052989, 0.41915, 0.16206]
Predicted label: 6
Correct prediction
Energy consumption = 179.750148 pJ
sum error= 285
Actual label: 7
Output voltages: [0.35713, 0.27304, 0.22429, 0.32241, 0.13132, 0.10503, 0.045014, 0.75203, 0.37697, 0.34875]
Predicted label: 7
Correct prediction
Energy consumption = 202.688125 pJ
sum error= 285
Actual label: 8
Output voltages: [0.23551, 0.14681, 0.29252, 0.25558, 0.17421, 0.26754, 0.27783, 0.16501, 0.74755, 0.23387]
Predicted label: 8
Correct prediction
Energy consumption = 187.168538 pJ
sum error= 285
Actual label: 9
Output voltages: [0.32464, 0.10662, 0.28008, 0.26497, 0.36305, 0.22076, 0.2106, 0.10516, 0.36427, 0.67214]
Predicted label: 9
Correct prediction
Energy consumption = 191.808072 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 908 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 908 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 908 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72994, 0.26824, 0.30256, 0.14814, 0.12587, 0.11396, 0.38834, 0.19798, 0.32155, 0.26435]
Predicted label: 0
Correct prediction
Energy consumption = 188.591637 pJ
sum error= 285
Actual label: 1
Output voltages: [0.16795, 0.7554, 0.26221, 0.27742, 0.19874, 0.092493, 0.34305, 0.096161, 0.39823, 0.24224]
Predicted label: 1
Correct prediction
Energy consumption = 206.301365 pJ
sum error= 285
Actual label: 2
Output voltages: [0.315, 0.31323, 0.66882, 0.40539, 0.12188, 0.033198, 0.31434, 0.16335, 0.45865, 0.16506]
Predicted label: 2
Correct prediction
Energy consumption = 187.608470 pJ
sum error= 285
Actual label: 3
Output voltages: [0.36365, 0.18155, 0.28493, 0.76074, 0.27231, 0.17836, 0.1918, 0.18269, 0.44829, 0.22056]
Predicted label: 3
Correct prediction
Energy consumption = 177.828452 pJ
sum error= 285
Actual label: 4
Output voltages: [0.22114, 0.15123, 0.35105, 0.051846, 0.72022, 0.071687, 0.39932, 0.19419, 0.35643, 0.20262]
Predicted label: 4
Correct prediction
Energy consumption = 199.040350 pJ
sum error= 285
Actual label: 5
Output voltages: [0.22536, 0.045271, 0.12053, 0.28973, 0.2197, 0.69159, 0.2796, 0.22167, 0.54684, 0.31286]
Predicted label: 5
Correct prediction
Energy consumption = 189.501760 pJ
sum error= 285
Actual label: 6
Output voltages: [0.30684, 0.17314, 0.2813, 0.12225, 0.31626, 0.413, 0.73383, 0.050851, 0.37894, 0.20358]
Predicted label: 6
Correct prediction
Energy consumption = 177.114280 pJ
sum error= 285
Actual label: 7
Output voltages: [0.28177, 0.26517, 0.2391, 0.23284, 0.15759, 0.067527, 0.043938, 0.75287, 0.38591, 0.28839]
Predicted label: 7
Correct prediction
Energy consumption = 201.342704 pJ
sum error= 285
Actual label: 8
Output voltages: [0.22892, 0.19123, 0.24128, 0.3198, 0.14012, 0.25776, 0.30444, 0.095995, 0.73518, 0.28552]
Predicted label: 8
Correct prediction
Energy consumption = 198.175472 pJ
sum error= 285
Actual label: 9
Output voltages: [0.28249, 0.14594, 0.20866, 0.23379, 0.31977, 0.20517, 0.10964, 0.1885, 0.42653, 0.6611]
Predicted label: 9
Correct prediction
Energy consumption = 187.133951 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 909 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 909 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 909 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.13663, 0.75526, 0.26991, 0.33948, 0.27595, 0.067, 0.26933, 0.1649, 0.33154, 0.2702]
Predicted label: 1
Correct prediction
Energy consumption = 211.992359 pJ
sum error= 285
Actual label: 6
Output voltages: [0.31834, 0.21347, 0.28875, 0.093414, 0.34925, 0.37716, 0.74192, 0.079567, 0.39771, 0.12218]
Predicted label: 6
Correct prediction
Energy consumption = 193.846046 pJ
sum error= 285
Actual label: 8
Output voltages: [0.22037, 0.13013, 0.25298, 0.35697, 0.14333, 0.2479, 0.15141, 0.13641, 0.73441, 0.29423]
Predicted label: 8
Correct prediction
Energy consumption = 200.387522 pJ
sum error= 285
Actual label: 9
Output voltages: [0.37401, 0.089238, 0.2105, 0.32801, 0.43494, 0.19357, 0.19139, 0.2531, 0.26982, 0.61699]
Predicted label: 9
Correct prediction
Energy consumption = 195.760027 pJ
sum error= 285
Actual label: 9
Output voltages: [0.37628, 0.13296, 0.26112, 0.29375, 0.36169, 0.16188, 0.13969, 0.21225, 0.27696, 0.70624]
Predicted label: 9
Correct prediction
Energy consumption = 197.304728 pJ
sum error= 285
Actual label: 0
Output voltages: [0.66703, 0.15588, 0.2577, 0.15077, 0.069517, 0.26342, 0.4592, 0.15779, 0.31199, 0.28216]
Predicted label: 0
Correct prediction
Energy consumption = 191.495995 pJ
sum error= 285
Actual label: 1
Output voltages: [0.21751, 0.75541, 0.30366, 0.21587, 0.16667, 0.12559, 0.45866, 0.12413, 0.36841, 0.19618]
Predicted label: 1
Correct prediction
Energy consumption = 202.839475 pJ
sum error= 285
Actual label: 2
Output voltages: [0.34819, 0.30338, 0.67172, 0.33865, 0.19141, 0.032107, 0.3516, 0.15681, 0.43262, 0.15914]
Predicted label: 2
Correct prediction
Energy consumption = 187.209866 pJ
sum error= 285
Actual label: 4
Output voltages: [0.18231, 0.15388, 0.30303, 0.096156, 0.75473, 0.080288, 0.33151, 0.3024, 0.2313, 0.24376]
Predicted label: 4
Correct prediction
Energy consumption = 199.676943 pJ
sum error= 285
Actual label: 4
Output voltages: [0.15346, 0.12718, 0.26858, 0.098511, 0.75683, 0.12202, 0.3712, 0.26396, 0.2701, 0.23576]
Predicted label: 4
Correct prediction
Energy consumption = 190.136827 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 910 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 910 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 910 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33023, 0.19883, 0.32642, 0.75363, 0.17517, 0.11095, 0.13545, 0.1275, 0.45351, 0.2667]
Predicted label: 3
Correct prediction
Energy consumption = 184.910054 pJ
sum error= 285
Actual label: 7
Output voltages: [0.25962, 0.24808, 0.27476, 0.29963, 0.12585, 0.052084, 0.060746, 0.76285, 0.31666, 0.28145]
Predicted label: 7
Correct prediction
Energy consumption = 196.418961 pJ
sum error= 285
Actual label: 4
Output voltages: [0.16857, 0.17235, 0.19224, 0.12298, 0.74201, 0.11402, 0.36927, 0.25851, 0.24114, 0.21461]
Predicted label: 4
Correct prediction
Energy consumption = 197.354409 pJ
sum error= 285
Actual label: 4
Output voltages: [0.18667, 0.20211, 0.30275, 0.17962, 0.74473, 0.06255, 0.46435, 0.27174, 0.15443, 0.18216]
Predicted label: 4
Correct prediction
Energy consumption = 195.369042 pJ
sum error= 285
Actual label: 4
Output voltages: [0.077426, 0.17965, 0.20934, 0.13535, 0.75149, 0.078052, 0.3216, 0.31023, 0.25202, 0.24312]
Predicted label: 4
Correct prediction
Energy consumption = 194.044312 pJ
sum error= 285
Actual label: 0
Output voltages: [0.7143, 0.21134, 0.23892, 0.12209, 0.14201, 0.1593, 0.44886, 0.18268, 0.27556, 0.27626]
Predicted label: 0
Correct prediction
Energy consumption = 189.972938 pJ
sum error= 285
Actual label: 3
Output voltages: [0.34012, 0.19127, 0.34792, 0.75733, 0.24546, 0.10637, 0.14419, 0.16852, 0.4444, 0.19995]
Predicted label: 3
Correct prediction
Energy consumption = 184.406773 pJ
sum error= 285
Actual label: 8
Output voltages: [0.22067, 0.18453, 0.26433, 0.29969, 0.14512, 0.22697, 0.18995, 0.18871, 0.74516, 0.27125]
Predicted label: 8
Correct prediction
Energy consumption = 190.788690 pJ
sum error= 285
Actual label: 7
Output voltages: [0.42349, 0.17785, 0.10633, 0.1913, 0.2625, 0.30023, 0.048809, 0.75759, 0.31393, 0.3901]
Predicted label: 7
Correct prediction
Energy consumption = 193.117846 pJ
sum error= 285
Actual label: 5
Output voltages: [0.23806, 0.049804, 0.099025, 0.30814, 0.23439, 0.70186, 0.28936, 0.1832, 0.55866, 0.27405]
Predicted label: 5
Correct prediction
Energy consumption = 178.249228 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 911 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 911 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 911 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.19607, 0.20191, 0.37511, 0.28489, 0.23294, 0.12595, 0.20869, 0.13289, 0.6825, 0.30835]
Predicted label: 8
Correct prediction
Energy consumption = 198.958761 pJ
sum error= 285
Actual label: 2
Output voltages: [0.36567, 0.24535, 0.71219, 0.41643, 0.15919, 0.034054, 0.27849, 0.19212, 0.46053, 0.17941]
Predicted label: 2
Correct prediction
Energy consumption = 188.062365 pJ
sum error= 285
Actual label: 1
Output voltages: [0.18321, 0.71527, 0.18041, 0.22718, 0.39292, 0.26235, 0.46125, 0.064695, 0.29658, 0.22285]
Predicted label: 1
Correct prediction
Energy consumption = 208.936935 pJ
sum error= 285
Actual label: 7
Output voltages: [0.2922, 0.22748, 0.14119, 0.084502, 0.25836, 0.16017, 0.06981, 0.75112, 0.39504, 0.29774]
Predicted label: 7
Correct prediction
Energy consumption = 202.452659 pJ
sum error= 285
Actual label: 5
Output voltages: [0.2664, 0.044748, 0.07238, 0.32215, 0.26207, 0.72159, 0.34795, 0.16283, 0.52394, 0.23267]
Predicted label: 5
Correct prediction
Energy consumption = 182.958412 pJ
sum error= 285
Actual label: 3
Output voltages: [0.33408, 0.17585, 0.31225, 0.75154, 0.17566, 0.16008, 0.13904, 0.1581, 0.47639, 0.23717]
Predicted label: 3
Correct prediction
Energy consumption = 184.500995 pJ
sum error= 285
Actual label: 8
Output voltages: [0.3858, 0.16778, 0.31452, 0.15972, 0.17084, 0.16619, 0.28271, 0.1735, 0.67006, 0.33176]
Predicted label: 8
Correct prediction
Energy consumption = 198.379788 pJ
sum error= 285
Actual label: 5
Output voltages: [0.40046, 0.0794, 0.060483, 0.51832, 0.12918, 0.71306, 0.26214, 0.2141, 0.43467, 0.12493]
Predicted label: 5
Correct prediction
Energy consumption = 194.869577 pJ
sum error= 285
Actual label: 2
Output voltages: [0.33167, 0.29397, 0.72044, 0.38299, 0.1389, 0.034541, 0.28509, 0.15122, 0.42667, 0.19412]
Predicted label: 2
Correct prediction
Energy consumption = 187.114079 pJ
sum error= 285
Actual label: 5
Output voltages: [0.23167, 0.049329, 0.12059, 0.29632, 0.23567, 0.68153, 0.31764, 0.17424, 0.5329, 0.29454]
Predicted label: 5
Correct prediction
Energy consumption = 184.787171 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 912 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 912 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 912 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.18897, 0.74503, 0.31001, 0.24042, 0.24192, 0.059377, 0.40126, 0.089106, 0.3627, 0.2425]
Predicted label: 1
Correct prediction
Energy consumption = 214.409412 pJ
sum error= 285
Actual label: 1
Output voltages: [0.19453, 0.75325, 0.29051, 0.21057, 0.24251, 0.059914, 0.41695, 0.089106, 0.31056, 0.23052]
Predicted label: 1
Correct prediction
Energy consumption = 198.966892 pJ
sum error= 285
Actual label: 6
Output voltages: [0.27911, 0.1625, 0.28406, 0.083934, 0.34546, 0.36986, 0.72954, 0.064083, 0.35241, 0.11807]
Predicted label: 6
Correct prediction
Energy consumption = 187.510697 pJ
sum error= 285
Actual label: 2
Output voltages: [0.30616, 0.21596, 0.6991, 0.4047, 0.14641, 0.030758, 0.26596, 0.2253, 0.48367, 0.16992]
Predicted label: 2
Correct prediction
Energy consumption = 179.002605 pJ
sum error= 285
Actual label: 1
Output voltages: [0.2444, 0.75138, 0.30382, 0.25385, 0.26762, 0.093834, 0.38035, 0.12984, 0.31961, 0.19316]
Predicted label: 1
Correct prediction
Energy consumption = 212.084656 pJ
sum error= 285
Actual label: 3
Output voltages: [0.33117, 0.18877, 0.34361, 0.75991, 0.17103, 0.18623, 0.13472, 0.16016, 0.47045, 0.21232]
Predicted label: 3
Correct prediction
Energy consumption = 182.573931 pJ
sum error= 285
Actual label: 8
Output voltages: [0.28948, 0.20439, 0.30717, 0.31255, 0.19352, 0.14664, 0.34385, 0.076335, 0.71525, 0.2524]
Predicted label: 8
Correct prediction
Energy consumption = 190.887504 pJ
sum error= 285
Actual label: 6
Output voltages: [0.26175, 0.2192, 0.31855, 0.16241, 0.32702, 0.34759, 0.726, 0.13885, 0.38348, 0.07415]
Predicted label: 6
Correct prediction
Energy consumption = 199.159504 pJ
sum error= 285
Actual label: 4
Output voltages: [0.17472, 0.18464, 0.26104, 0.084964, 0.73866, 0.13511, 0.4528, 0.24086, 0.31032, 0.18376]
Predicted label: 4
Correct prediction
Energy consumption = 199.433667 pJ
sum error= 285
Actual label: 2
Output voltages: [0.35884, 0.27519, 0.65218, 0.4942, 0.14205, 0.033807, 0.26219, 0.13201, 0.46024, 0.23706]
Predicted label: 2
Correct prediction
Energy consumption = 187.285327 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 913 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 913 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 913 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.43277, 0.30647, 0.33962, 0.12055, 0.20176, 0.23543, 0.71396, 0.093709, 0.3733, 0.17802]
Predicted label: 6
Correct prediction
Energy consumption = 194.415213 pJ
sum error= 285
Actual label: 2
Output voltages: [0.33723, 0.31494, 0.74615, 0.26255, 0.14075, 0.025522, 0.26876, 0.28609, 0.36426, 0.23255]
Predicted label: 2
Correct prediction
Energy consumption = 187.485367 pJ
sum error= 285
Actual label: 5
Output voltages: [0.21005, 0.065922, 0.14512, 0.3335, 0.27245, 0.68977, 0.33769, 0.15585, 0.51347, 0.30552]
Predicted label: 5
Correct prediction
Energy consumption = 189.228831 pJ
sum error= 285
Actual label: 5
Output voltages: [0.21918, 0.051462, 0.090858, 0.32005, 0.25871, 0.68622, 0.31514, 0.14778, 0.54398, 0.24832]
Predicted label: 5
Correct prediction
Energy consumption = 180.561562 pJ
sum error= 285
Actual label: 0
Output voltages: [0.71926, 0.28555, 0.29527, 0.17069, 0.093862, 0.16673, 0.39491, 0.17676, 0.33207, 0.23342]
Predicted label: 0
Correct prediction
Energy consumption = 187.723875 pJ
sum error= 285
Actual label: 2
Output voltages: [0.3496, 0.3304, 0.73549, 0.33664, 0.14589, 0.0334, 0.29117, 0.13065, 0.3753, 0.2165]
Predicted label: 2
Correct prediction
Energy consumption = 184.110481 pJ
sum error= 285
Actual label: 8
Output voltages: [0.19666, 0.13442, 0.25643, 0.29913, 0.22877, 0.19322, 0.18004, 0.076729, 0.69749, 0.38558]
Predicted label: 8
Correct prediction
Energy consumption = 194.532944 pJ
sum error= 285
Actual label: 0
Output voltages: [0.71936, 0.24716, 0.30468, 0.16414, 0.11445, 0.17276, 0.39619, 0.18847, 0.30794, 0.23433]
Predicted label: 0
Correct prediction
Energy consumption = 194.588488 pJ
sum error= 285
Actual label: 6
Output voltages: [0.3284, 0.2489, 0.2741, 0.088595, 0.29938, 0.37418, 0.74296, 0.11617, 0.37874, 0.14074]
Predicted label: 6
Correct prediction
Energy consumption = 183.929934 pJ
sum error= 285
Actual label: 8
Output voltages: [0.11101, 0.24496, 0.26855, 0.31789, 0.36207, 0.1845, 0.39, 0.065022, 0.58433, 0.22616]
Predicted label: 8
Correct prediction
Energy consumption = 205.589061 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 914 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 914 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 914 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.24284, 0.75902, 0.29733, 0.23746, 0.27829, 0.059157, 0.39755, 0.073922, 0.26818, 0.21924]
Predicted label: 1
Correct prediction
Energy consumption = 208.687185 pJ
sum error= 285
Actual label: 7
Output voltages: [0.34248, 0.13435, 0.063552, 0.19, 0.345, 0.24817, 0.056705, 0.74138, 0.3478, 0.28388]
Predicted label: 7
Correct prediction
Energy consumption = 201.146899 pJ
sum error= 285
Actual label: 9
Output voltages: [0.34076, 0.15291, 0.21945, 0.28108, 0.37922, 0.14337, 0.12522, 0.22728, 0.31041, 0.69953]
Predicted label: 9
Correct prediction
Energy consumption = 190.891425 pJ
sum error= 285
Actual label: 1
Output voltages: [0.18092, 0.76033, 0.19474, 0.27397, 0.28993, 0.069933, 0.34671, 0.11727, 0.32793, 0.2692]
Predicted label: 1
Correct prediction
Energy consumption = 211.281177 pJ
sum error= 285
Actual label: 9
Output voltages: [0.36873, 0.1139, 0.21121, 0.31755, 0.31985, 0.23071, 0.12004, 0.29639, 0.34601, 0.66452]
Predicted label: 9
Correct prediction
Energy consumption = 199.888563 pJ
sum error= 285
Actual label: 2
Output voltages: [0.34208, 0.3538, 0.70956, 0.30574, 0.17177, 0.027448, 0.34892, 0.14998, 0.41816, 0.18606]
Predicted label: 2
Correct prediction
Energy consumption = 188.248551 pJ
sum error= 285
Actual label: 6
Output voltages: [0.38795, 0.2038, 0.24227, 0.18432, 0.29753, 0.41635, 0.71826, 0.05566, 0.39817, 0.21205]
Predicted label: 6
Correct prediction
Energy consumption = 188.101502 pJ
sum error= 285
Actual label: 7
Output voltages: [0.32597, 0.18417, 0.19031, 0.20646, 0.24607, 0.18374, 0.053335, 0.76985, 0.34055, 0.33104]
Predicted label: 7
Correct prediction
Energy consumption = 201.248971 pJ
sum error= 285
Actual label: 6
Output voltages: [0.32239, 0.16934, 0.2265, 0.16168, 0.33656, 0.3932, 0.71819, 0.095717, 0.4487, 0.16451]
Predicted label: 6
Correct prediction
Energy consumption = 193.247927 pJ
sum error= 285
Actual label: 6
Output voltages: [0.31872, 0.16998, 0.21771, 0.16977, 0.29606, 0.4141, 0.7117, 0.10028, 0.46246, 0.16101]
Predicted label: 6
Correct prediction
Energy consumption = 181.400667 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 915 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 915 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 915 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2329, 0.12111, 0.24279, 0.27817, 0.22713, 0.30188, 0.40506, 0.058986, 0.70067, 0.27443]
Predicted label: 8
Correct prediction
Energy consumption = 200.067394 pJ
sum error= 285
Actual label: 7
Output voltages: [0.36667, 0.12709, 0.11176, 0.19532, 0.25106, 0.26183, 0.052263, 0.7558, 0.36279, 0.35191]
Predicted label: 7
Correct prediction
Energy consumption = 203.372167 pJ
sum error= 285
Actual label: 4
Output voltages: [0.17866, 0.14421, 0.2819, 0.13477, 0.7582, 0.079204, 0.30968, 0.25943, 0.23975, 0.1889]
Predicted label: 4
Correct prediction
Energy consumption = 193.032689 pJ
sum error= 285
Actual label: 9
Output voltages: [0.32133, 0.13219, 0.12631, 0.23266, 0.32446, 0.23954, 0.15373, 0.17541, 0.37167, 0.63158]
Predicted label: 9
Correct prediction
Energy consumption = 197.684740 pJ
sum error= 285
Actual label: 2
Output voltages: [0.35309, 0.28683, 0.73738, 0.3703, 0.17189, 0.026051, 0.31312, 0.24721, 0.38349, 0.24385]
Predicted label: 2
Correct prediction
Energy consumption = 187.073688 pJ
sum error= 285
Actual label: 1
Output voltages: [0.16666, 0.76617, 0.2401, 0.25845, 0.23844, 0.092792, 0.43752, 0.11463, 0.3442, 0.21727]
Predicted label: 1
Correct prediction
Energy consumption = 195.363720 pJ
sum error= 285
Actual label: 3
Output voltages: [0.43328, 0.23126, 0.27139, 0.75412, 0.16978, 0.28649, 0.17676, 0.23059, 0.31386, 0.16746]
Predicted label: 3
Correct prediction
Energy consumption = 190.726861 pJ
sum error= 285
Actual label: 3
Output voltages: [0.35459, 0.18981, 0.31899, 0.75876, 0.15023, 0.1478, 0.13702, 0.13726, 0.45114, 0.21318]
Predicted label: 3
Correct prediction
Energy consumption = 170.174703 pJ
sum error= 285
Actual label: 0
Output voltages: [0.64797, 0.091011, 0.29157, 0.13401, 0.20141, 0.10483, 0.31135, 0.23384, 0.24681, 0.48061]
Predicted label: 0
Correct prediction
Energy consumption = 188.011124 pJ
sum error= 285
Actual label: 5
Output voltages: [0.25994, 0.048134, 0.11986, 0.36015, 0.20951, 0.70507, 0.33205, 0.19288, 0.55404, 0.25919]
Predicted label: 5
Correct prediction
Energy consumption = 177.942614 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 916 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 916 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 916 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.26195, 0.060862, 0.075972, 0.32134, 0.23635, 0.73411, 0.33478, 0.14396, 0.51786, 0.21221]
Predicted label: 5
Correct prediction
Energy consumption = 185.700476 pJ
sum error= 285
Actual label: 8
Output voltages: [0.25945, 0.12769, 0.30212, 0.29736, 0.19315, 0.33857, 0.33535, 0.067464, 0.72555, 0.24064]
Predicted label: 8
Correct prediction
Energy consumption = 191.189634 pJ
sum error= 285
Actual label: 0
Output voltages: [0.71958, 0.20817, 0.25324, 0.17904, 0.24694, 0.11106, 0.45423, 0.21717, 0.33087, 0.24816]
Predicted label: 0
Correct prediction
Energy consumption = 197.095869 pJ
sum error= 285
Actual label: 3
Output voltages: [0.3047, 0.1733, 0.40576, 0.67529, 0.12196, 0.058754, 0.18528, 0.15663, 0.59614, 0.22104]
Predicted label: 3
Correct prediction
Energy consumption = 188.659113 pJ
sum error= 285
Actual label: 7
Output voltages: [0.31906, 0.19291, 0.15678, 0.20425, 0.21841, 0.18363, 0.048668, 0.76697, 0.35916, 0.31762]
Predicted label: 7
Correct prediction
Energy consumption = 200.512562 pJ
sum error= 285
Actual label: 9
Output voltages: [0.28149, 0.15305, 0.11469, 0.28625, 0.40113, 0.29647, 0.2206, 0.20461, 0.31547, 0.63258]
Predicted label: 9
Correct prediction
Energy consumption = 190.622361 pJ
sum error= 285
Actual label: 7
Output voltages: [0.34206, 0.11859, 0.070938, 0.25231, 0.24442, 0.25215, 0.045391, 0.75269, 0.35081, 0.36074]
Predicted label: 7
Correct prediction
Energy consumption = 201.557492 pJ
sum error= 285
Actual label: 0
Output voltages: [0.74043, 0.27844, 0.24942, 0.20214, 0.079874, 0.22161, 0.39377, 0.2204, 0.29722, 0.23922]
Predicted label: 0
Correct prediction
Energy consumption = 191.855168 pJ
sum error= 285
Actual label: 2
Output voltages: [0.31498, 0.33736, 0.59525, 0.31608, 0.11052, 0.036275, 0.3323, 0.12049, 0.56341, 0.22102]
Predicted label: 2
Correct prediction
Energy consumption = 192.919607 pJ
sum error= 285
Actual label: 7
Output voltages: [0.27544, 0.15522, 0.1783, 0.19438, 0.25363, 0.17309, 0.04898, 0.76023, 0.41522, 0.34764]
Predicted label: 7
Correct prediction
Energy consumption = 200.524017 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 917 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 917 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 917 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.31574, 0.13182, 0.15589, 0.28155, 0.36677, 0.30737, 0.17375, 0.2117, 0.3325, 0.63405]
Predicted label: 9
Correct prediction
Energy consumption = 196.603119 pJ
sum error= 285
Actual label: 1
Output voltages: [0.15884, 0.76189, 0.18567, 0.23747, 0.21143, 0.16671, 0.42429, 0.12251, 0.38135, 0.16353]
Predicted label: 1
Correct prediction
Energy consumption = 209.548696 pJ
sum error= 285
Actual label: 7
Output voltages: [0.33711, 0.078826, 0.10458, 0.14352, 0.38664, 0.24466, 0.10655, 0.74973, 0.33539, 0.21213]
Predicted label: 7
Correct prediction
Energy consumption = 209.159706 pJ
sum error= 285
Actual label: 8
Output voltages: [0.1627, 0.2066, 0.29216, 0.25944, 0.19453, 0.13103, 0.2061, 0.18432, 0.73132, 0.25829]
Predicted label: 8
Correct prediction
Energy consumption = 192.550551 pJ
sum error= 285
Actual label: 0
Output voltages: [0.74055, 0.25652, 0.25406, 0.16648, 0.10013, 0.17622, 0.40552, 0.22045, 0.28699, 0.22213]
Predicted label: 0
Correct prediction
Energy consumption = 188.496804 pJ
sum error= 285
Actual label: 3
Output voltages: [0.40505, 0.18125, 0.34522, 0.75694, 0.16598, 0.11317, 0.14727, 0.16061, 0.44556, 0.20139]
Predicted label: 3
Correct prediction
Energy consumption = 186.336027 pJ
sum error= 285
Actual label: 5
Output voltages: [0.23021, 0.046757, 0.12746, 0.30327, 0.22603, 0.68293, 0.29492, 0.18391, 0.58204, 0.2626]
Predicted label: 5
Correct prediction
Energy consumption = 177.425882 pJ
sum error= 285
Actual label: 3
Output voltages: [0.37895, 0.16556, 0.35922, 0.75252, 0.23822, 0.11234, 0.16672, 0.12787, 0.44455, 0.22058]
Predicted label: 3
Correct prediction
Energy consumption = 179.405165 pJ
sum error= 285
Actual label: 6
Output voltages: [0.29757, 0.22475, 0.30623, 0.059005, 0.33365, 0.33638, 0.73934, 0.066564, 0.40009, 0.13127]
Predicted label: 6
Correct prediction
Energy consumption = 189.672296 pJ
sum error= 285
Actual label: 0
Output voltages: [0.67269, 0.28589, 0.25336, 0.17213, 0.10526, 0.11789, 0.41244, 0.19138, 0.38117, 0.31561]
Predicted label: 0
Correct prediction
Energy consumption = 181.424681 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 918 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 918 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 918 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.25884, 0.70795, 0.30019, 0.10238, 0.26778, 0.12087, 0.30928, 0.11712, 0.42348, 0.2527]
Predicted label: 1
Correct prediction
Energy consumption = 197.383279 pJ
sum error= 285
Actual label: 2
Output voltages: [0.2619, 0.28799, 0.7022, 0.40426, 0.10957, 0.036599, 0.22815, 0.24538, 0.45546, 0.15685]
Predicted label: 2
Correct prediction
Energy consumption = 193.481299 pJ
sum error= 285
Actual label: 3
Output voltages: [0.35592, 0.16679, 0.29921, 0.73906, 0.12694, 0.14858, 0.091313, 0.20265, 0.45215, 0.24766]
Predicted label: 3
Correct prediction
Energy consumption = 184.858559 pJ
sum error= 285
Actual label: 4
Output voltages: [0.1212, 0.14955, 0.18321, 0.23121, 0.74267, 0.17933, 0.23796, 0.23761, 0.32242, 0.304]
Predicted label: 4
Correct prediction
Energy consumption = 188.570927 pJ
sum error= 285
Actual label: 5
Output voltages: [0.23762, 0.073995, 0.069992, 0.38483, 0.19391, 0.7105, 0.3025, 0.11213, 0.48764, 0.1726]
Predicted label: 5
Correct prediction
Energy consumption = 192.244023 pJ
sum error= 285
Actual label: 6
Output voltages: [0.28534, 0.17901, 0.25143, 0.14992, 0.32539, 0.30711, 0.70955, 0.11539, 0.50212, 0.14777]
Predicted label: 6
Correct prediction
Energy consumption = 187.142535 pJ
sum error= 285
Actual label: 7
Output voltages: [0.34162, 0.24243, 0.24188, 0.14914, 0.38222, 0.10045, 0.042051, 0.7457, 0.30137, 0.27893]
Predicted label: 7
Correct prediction
Energy consumption = 194.590499 pJ
sum error= 285
Actual label: 8
Output voltages: [0.22094, 0.24351, 0.26325, 0.24377, 0.17791, 0.1861, 0.17951, 0.15424, 0.73394, 0.32827]
Predicted label: 8
Correct prediction
Energy consumption = 191.466428 pJ
sum error= 285
Actual label: 9
Output voltages: [0.38788, 0.13409, 0.23642, 0.28258, 0.35327, 0.10178, 0.067938, 0.1859, 0.37856, 0.63375]
Predicted label: 9
Correct prediction
Energy consumption = 190.687492 pJ
sum error= 285
Actual label: 0
Output voltages: [0.72565, 0.25027, 0.19603, 0.18962, 0.16131, 0.16619, 0.41337, 0.16991, 0.35789, 0.2049]
Predicted label: 0
Correct prediction
Energy consumption = 185.213677 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 919 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 919 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 919 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.18116, 0.72144, 0.24167, 0.13605, 0.23333, 0.12074, 0.35568, 0.1167, 0.43805, 0.22861]
Predicted label: 1
Correct prediction
Energy consumption = 200.494378 pJ
sum error= 285
Actual label: 2
Output voltages: [0.28223, 0.28962, 0.70808, 0.38417, 0.077996, 0.038734, 0.22926, 0.20495, 0.43157, 0.12483]
Predicted label: 2
Correct prediction
Energy consumption = 186.096358 pJ
sum error= 285
Actual label: 3
Output voltages: [0.28994, 0.093933, 0.2311, 0.73451, 0.21741, 0.29132, 0.10931, 0.21182, 0.45773, 0.26384]
Predicted label: 3
Correct prediction
Energy consumption = 183.943237 pJ
sum error= 285
Actual label: 4
Output voltages: [0.21126, 0.20407, 0.24765, 0.096169, 0.74703, 0.13751, 0.23733, 0.25112, 0.31751, 0.15767]
Predicted label: 4
Correct prediction
Energy consumption = 192.609783 pJ
sum error= 285
Actual label: 5
Output voltages: [0.3881, 0.09088, 0.062345, 0.31551, 0.25533, 0.65472, 0.34921, 0.094436, 0.35866, 0.18939]
Predicted label: 5
Correct prediction
Energy consumption = 195.833100 pJ
sum error= 285
Actual label: 6
Output voltages: [0.32509, 0.19141, 0.229, 0.14362, 0.29132, 0.39848, 0.72606, 0.097873, 0.46259, 0.16368]
Predicted label: 6
Correct prediction
Energy consumption = 181.687867 pJ
sum error= 285
Actual label: 7
Output voltages: [0.30134, 0.26179, 0.25787, 0.2323, 0.24107, 0.13122, 0.037455, 0.74035, 0.28769, 0.4045]
Predicted label: 7
Correct prediction
Energy consumption = 188.602335 pJ
sum error= 285
Actual label: 8
Output voltages: [0.29881, 0.18992, 0.27792, 0.17675, 0.19464, 0.24055, 0.1703, 0.19795, 0.73105, 0.27451]
Predicted label: 8
Correct prediction
Energy consumption = 188.360194 pJ
sum error= 285
Actual label: 9
Output voltages: [0.34759, 0.11535, 0.18903, 0.21832, 0.25179, 0.20306, 0.052731, 0.23868, 0.51128, 0.62159]
Predicted label: 9
Correct prediction
Energy consumption = 183.384700 pJ
sum error= 285
Actual label: 0
Output voltages: [0.73992, 0.22865, 0.25973, 0.12973, 0.15286, 0.136, 0.43255, 0.22447, 0.28739, 0.23919]
Predicted label: 0
Correct prediction
Energy consumption = 181.202649 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 920 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 920 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 920 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.14561, 0.71666, 0.27051, 0.19607, 0.36633, 0.14232, 0.321, 0.059558, 0.36578, 0.23554]
Predicted label: 1
Correct prediction
Energy consumption = 199.004186 pJ
sum error= 285
Actual label: 2
Output voltages: [0.28397, 0.23373, 0.72381, 0.37813, 0.12372, 0.039915, 0.24924, 0.25744, 0.45713, 0.18051]
Predicted label: 2
Correct prediction
Energy consumption = 187.728123 pJ
sum error= 285
Actual label: 3
Output voltages: [0.24383, 0.1576, 0.3473, 0.70157, 0.17685, 0.15189, 0.082601, 0.18767, 0.43223, 0.30141]
Predicted label: 3
Correct prediction
Energy consumption = 183.968649 pJ
sum error= 285
Actual label: 4
Output voltages: [0.13883, 0.17106, 0.24556, 0.13728, 0.7516, 0.145, 0.2106, 0.2397, 0.31502, 0.23082]
Predicted label: 4
Correct prediction
Energy consumption = 187.907413 pJ
sum error= 285
Actual label: 7
Output voltages: [0.36664, 0.18283, 0.2099, 0.36124, 0.1541, 0.19301, 0.035049, 0.74078, 0.27344, 0.39776]
Predicted label: 7
Correct prediction
Energy consumption = 198.187447 pJ
sum error= 285
Actual label: 8
Output voltages: [0.31849, 0.21474, 0.2862, 0.1731, 0.24468, 0.17328, 0.31587, 0.068066, 0.68473, 0.31278]
Predicted label: 8
Correct prediction
Energy consumption = 191.123631 pJ
sum error= 285
Actual label: 9
Output voltages: [0.37328, 0.10066, 0.16756, 0.25058, 0.32248, 0.21732, 0.086255, 0.16686, 0.47246, 0.62653]
Predicted label: 9
Correct prediction
Energy consumption = 186.378730 pJ
sum error= 285
Actual label: 6
Output voltages: [0.34199, 0.23146, 0.24768, 0.17448, 0.30047, 0.28027, 0.70607, 0.1133, 0.45485, 0.14306]
Predicted label: 6
Correct prediction
Energy consumption = 195.057433 pJ
sum error= 285
Actual label: 4
Output voltages: [0.13299, 0.18013, 0.24452, 0.23395, 0.73589, 0.058595, 0.12643, 0.22465, 0.26509, 0.31705]
Predicted label: 4
Correct prediction
Energy consumption = 201.045565 pJ
sum error= 285
Actual label: 2
Output voltages: [0.33816, 0.26395, 0.73873, 0.34086, 0.17471, 0.02712, 0.20068, 0.31188, 0.39432, 0.1906]
Predicted label: 2
Correct prediction
Energy consumption = 184.537335 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 921 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 921 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 921 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.41211, 0.23013, 0.30188, 0.10919, 0.34709, 0.15599, 0.71747, 0.1415, 0.33018, 0.20576]
Predicted label: 6
Correct prediction
Energy consumption = 200.597692 pJ
sum error= 285
Actual label: 4
Output voltages: [0.19022, 0.19591, 0.23035, 0.2397, 0.64533, 0.074348, 0.094756, 0.1939, 0.29906, 0.47315]
Predicted label: 4
Correct prediction
Energy consumption = 198.254991 pJ
sum error= 285
Actual label: 7
Output voltages: [0.39463, 0.20971, 0.2072, 0.1771, 0.27398, 0.23138, 0.03696, 0.73419, 0.28705, 0.34676]
Predicted label: 7
Correct prediction
Energy consumption = 191.944847 pJ
sum error= 285
Actual label: 8
Output voltages: [0.26231, 0.20489, 0.24994, 0.31841, 0.15491, 0.23891, 0.26777, 0.072153, 0.74341, 0.25861]
Predicted label: 8
Correct prediction
Energy consumption = 192.070269 pJ
sum error= 285
Actual label: 9
Output voltages: [0.34333, 0.1488, 0.20458, 0.22489, 0.37271, 0.079623, 0.056717, 0.25856, 0.40611, 0.55651]
Predicted label: 9
Correct prediction
Energy consumption = 192.827724 pJ
sum error= 285
Actual label: 2
Output voltages: [0.26845, 0.22257, 0.74943, 0.30575, 0.11539, 0.034988, 0.24019, 0.30435, 0.44052, 0.14647]
Predicted label: 2
Correct prediction
Energy consumption = 184.418146 pJ
sum error= 285
Actual label: 9
Output voltages: [0.23938, 0.14224, 0.18314, 0.24354, 0.24699, 0.15538, 0.055414, 0.24453, 0.52481, 0.62136]
Predicted label: 9
Correct prediction
Energy consumption = 188.776353 pJ
sum error= 285
Actual label: 3
Output voltages: [0.29874, 0.13014, 0.40762, 0.69028, 0.085246, 0.1563, 0.20637, 0.15682, 0.49466, 0.093322]
Predicted label: 3
Correct prediction
Energy consumption = 183.761321 pJ
sum error= 285
Actual label: 9
Output voltages: [0.42809, 0.1081, 0.24497, 0.17614, 0.41745, 0.088175, 0.072071, 0.15843, 0.39532, 0.62308]
Predicted label: 9
Correct prediction
Energy consumption = 189.912075 pJ
sum error= 285
Actual label: 3
Output voltages: [0.3016, 0.177, 0.30624, 0.75883, 0.16851, 0.26274, 0.11897, 0.15069, 0.42141, 0.20908]
Predicted label: 3
Correct prediction
Energy consumption = 183.747896 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 922 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 922 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 922 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.74506, 0.24272, 0.29832, 0.23078, 0.14896, 0.15405, 0.33719, 0.20774, 0.30522, 0.21536]
Predicted label: 0
Correct prediction
Energy consumption = 194.271633 pJ
sum error= 285
Actual label: 0
Output voltages: [0.66857, 0.21189, 0.28501, 0.23663, 0.17993, 0.059139, 0.25643, 0.15929, 0.42691, 0.31014]
Predicted label: 0
Correct prediction
Energy consumption = 188.764947 pJ
sum error= 285
Actual label: 1
Output voltages: [0.15095, 0.74357, 0.21345, 0.13374, 0.26499, 0.13472, 0.33654, 0.16533, 0.39881, 0.21569]
Predicted label: 1
Correct prediction
Energy consumption = 197.767786 pJ
sum error= 285
Actual label: 0
Output voltages: [0.65961, 0.24573, 0.31898, 0.1744, 0.12537, 0.069897, 0.4019, 0.16728, 0.39131, 0.32995]
Predicted label: 0
Correct prediction
Energy consumption = 184.581556 pJ
sum error= 285
Actual label: 4
Output voltages: [0.13056, 0.17122, 0.31333, 0.22653, 0.7556, 0.069991, 0.23438, 0.26443, 0.24909, 0.22456]
Predicted label: 4
Correct prediction
Energy consumption = 193.689491 pJ
sum error= 285
Actual label: 2
Output voltages: [0.2575, 0.34386, 0.69627, 0.30887, 0.078972, 0.038167, 0.19491, 0.27253, 0.48519, 0.1982]
Predicted label: 2
Correct prediction
Energy consumption = 184.234013 pJ
sum error= 285
Actual label: 6
Output voltages: [0.30245, 0.19268, 0.28323, 0.062069, 0.34209, 0.28446, 0.731, 0.071792, 0.43097, 0.098683]
Predicted label: 6
Correct prediction
Energy consumption = 183.802100 pJ
sum error= 285
Actual label: 3
Output voltages: [0.3004, 0.15277, 0.39509, 0.72835, 0.11211, 0.14847, 0.16042, 0.086187, 0.51946, 0.18441]
Predicted label: 3
Correct prediction
Energy consumption = 179.341207 pJ
sum error= 285
Actual label: 5
Output voltages: [0.31588, 0.063191, 0.065786, 0.42912, 0.23986, 0.73218, 0.26419, 0.17423, 0.39486, 0.28752]
Predicted label: 5
Correct prediction
Energy consumption = 187.124955 pJ
sum error= 285
Actual label: 3
Output voltages: [0.26445, 0.16975, 0.33675, 0.71866, 0.096429, 0.19384, 0.13539, 0.10836, 0.53639, 0.25002]
Predicted label: 3
Correct prediction
Energy consumption = 181.092962 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 923 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 923 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 923 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.73625, 0.2498, 0.25249, 0.18128, 0.14658, 0.20687, 0.38754, 0.14505, 0.2687, 0.28943]
Predicted label: 0
Correct prediction
Energy consumption = 192.471311 pJ
sum error= 285
Actual label: 3
Output voltages: [0.31559, 0.13074, 0.25996, 0.75318, 0.23382, 0.21238, 0.13894, 0.1716, 0.42218, 0.2241]
Predicted label: 3
Correct prediction
Energy consumption = 189.015483 pJ
sum error= 285
Actual label: 4
Output voltages: [0.12881, 0.18118, 0.33154, 0.14299, 0.75609, 0.12801, 0.26638, 0.33868, 0.25277, 0.18078]
Predicted label: 4
Correct prediction
Energy consumption = 188.400797 pJ
sum error= 285
Actual label: 1
Output voltages: [0.19985, 0.72022, 0.38012, 0.2687, 0.3693, 0.047877, 0.29473, 0.11467, 0.23232, 0.178]
Predicted label: 1
Correct prediction
Energy consumption = 194.569003 pJ
sum error= 285
Actual label: 5
Output voltages: [0.30649, 0.058094, 0.054666, 0.35158, 0.24152, 0.75117, 0.29405, 0.18405, 0.44097, 0.20615]
Predicted label: 5
Correct prediction
Energy consumption = 188.945850 pJ
sum error= 285
Actual label: 3
Output voltages: [0.34478, 0.13116, 0.30318, 0.74727, 0.16343, 0.23468, 0.11407, 0.17164, 0.49924, 0.19334]
Predicted label: 3
Correct prediction
Energy consumption = 178.368613 pJ
sum error= 285
Actual label: 0
Output voltages: [0.73087, 0.26302, 0.23876, 0.25738, 0.15402, 0.11883, 0.28447, 0.18659, 0.35908, 0.31198]
Predicted label: 0
Correct prediction
Energy consumption = 191.746110 pJ
sum error= 285
Actual label: 8
Output voltages: [0.23764, 0.1421, 0.29806, 0.22516, 0.17761, 0.17286, 0.2648, 0.10674, 0.69395, 0.25183]
Predicted label: 8
Correct prediction
Energy consumption = 191.140982 pJ
sum error= 285
Actual label: 3
Output voltages: [0.27977, 0.10414, 0.44933, 0.69623, 0.12847, 0.10899, 0.15662, 0.10357, 0.52761, 0.22079]
Predicted label: 3
Correct prediction
Energy consumption = 181.796648 pJ
sum error= 285
Actual label: 0
Output voltages: [0.73821, 0.28745, 0.2734, 0.16072, 0.14743, 0.10912, 0.39622, 0.17385, 0.29377, 0.2985]
Predicted label: 0
Correct prediction
Energy consumption = 186.526437 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 924 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 924 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 924 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32678, 0.20535, 0.23421, 0.13641, 0.29423, 0.36544, 0.72842, 0.094927, 0.43079, 0.16701]
Predicted label: 6
Correct prediction
Energy consumption = 191.066846 pJ
sum error= 285
Actual label: 1
Output voltages: [0.22672, 0.71782, 0.34291, 0.17042, 0.4081, 0.050188, 0.31471, 0.198, 0.25418, 0.23693]
Predicted label: 1
Correct prediction
Energy consumption = 195.717264 pJ
sum error= 285
Actual label: 7
Output voltages: [0.42095, 0.19953, 0.21199, 0.2454, 0.24885, 0.21857, 0.044034, 0.75222, 0.28168, 0.32124]
Predicted label: 7
Correct prediction
Energy consumption = 195.147805 pJ
sum error= 285
Actual label: 8
Output voltages: [0.36108, 0.23984, 0.30582, 0.16053, 0.2379, 0.095268, 0.20272, 0.15383, 0.68298, 0.36009]
Predicted label: 8
Correct prediction
Energy consumption = 195.905955 pJ
sum error= 285
Actual label: 0
Output voltages: [0.74454, 0.24185, 0.21285, 0.14413, 0.13539, 0.18128, 0.42102, 0.24135, 0.30554, 0.22348]
Predicted label: 0
Correct prediction
Energy consumption = 185.169096 pJ
sum error= 285
Actual label: 9
Output voltages: [0.42867, 0.082374, 0.17946, 0.25654, 0.40002, 0.18173, 0.1196, 0.25652, 0.31412, 0.60116]
Predicted label: 9
Correct prediction
Energy consumption = 192.794459 pJ
sum error= 285
Actual label: 2
Output voltages: [0.32663, 0.27258, 0.73067, 0.37548, 0.13531, 0.032365, 0.26535, 0.25914, 0.40117, 0.2007]
Predicted label: 2
Correct prediction
Energy consumption = 182.549532 pJ
sum error= 285
Actual label: 6
Output voltages: [0.29929, 0.18519, 0.29604, 0.083317, 0.34885, 0.33624, 0.73682, 0.057449, 0.37312, 0.16823]
Predicted label: 6
Correct prediction
Energy consumption = 183.554433 pJ
sum error= 285
Actual label: 7
Output voltages: [0.30522, 0.262, 0.17546, 0.25052, 0.33408, 0.13095, 0.042818, 0.73686, 0.28754, 0.27311]
Predicted label: 7
Correct prediction
Energy consumption = 203.070560 pJ
sum error= 285
Actual label: 1
Output voltages: [0.15921, 0.72006, 0.15958, 0.1314, 0.3374, 0.20061, 0.31414, 0.1169, 0.41001, 0.19975]
Predicted label: 1
Correct prediction
Energy consumption = 199.029801 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 925 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 925 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 925 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.40517, 0.16379, 0.22734, 0.25447, 0.31698, 0.085289, 0.090802, 0.15234, 0.47314, 0.60066]
Predicted label: 9
Correct prediction
Energy consumption = 193.036210 pJ
sum error= 285
Actual label: 6
Output voltages: [0.30509, 0.21581, 0.25765, 0.10809, 0.30111, 0.33941, 0.73746, 0.10777, 0.42837, 0.10291]
Predicted label: 6
Correct prediction
Energy consumption = 187.960171 pJ
sum error= 285
Actual label: 9
Output voltages: [0.44355, 0.1098, 0.21235, 0.26357, 0.45247, 0.15036, 0.11088, 0.16745, 0.30832, 0.60383]
Predicted label: 9
Correct prediction
Energy consumption = 196.800064 pJ
sum error= 285
Actual label: 4
Output voltages: [0.17095, 0.18582, 0.22808, 0.29807, 0.49875, 0.30266, 0.24215, 0.23611, 0.50762, 0.13545]
Predicted label: 8
Wrong prediction!
Energy consumption = 202.645735 pJ
sum error= 286
Actual label: 9
Output voltages: [0.31603, 0.13584, 0.1651, 0.22602, 0.29981, 0.1722, 0.05578, 0.20217, 0.47268, 0.63404]
Predicted label: 9
Correct prediction
Energy consumption = 193.903520 pJ
sum error= 286
Actual label: 9
Output voltages: [0.37589, 0.12166, 0.19119, 0.22553, 0.36903, 0.12934, 0.063077, 0.20424, 0.38423, 0.60472]
Predicted label: 9
Correct prediction
Energy consumption = 186.847886 pJ
sum error= 286
Actual label: 6
Output voltages: [0.27071, 0.15735, 0.31294, 0.056891, 0.35193, 0.29968, 0.72688, 0.096924, 0.4269, 0.086014]
Predicted label: 6
Correct prediction
Energy consumption = 191.490048 pJ
sum error= 286
Actual label: 7
Output voltages: [0.29974, 0.27024, 0.30946, 0.24389, 0.22392, 0.092529, 0.031546, 0.73392, 0.29731, 0.37357]
Predicted label: 7
Correct prediction
Energy consumption = 191.380750 pJ
sum error= 286
Actual label: 1
Output voltages: [0.19948, 0.71938, 0.3035, 0.18224, 0.31947, 0.074797, 0.30457, 0.10459, 0.39001, 0.22392]
Predicted label: 1
Correct prediction
Energy consumption = 193.970735 pJ
sum error= 286
Actual label: 2
Output voltages: [0.27778, 0.21209, 0.64016, 0.44974, 0.088334, 0.044824, 0.22961, 0.19489, 0.50811, 0.11312]
Predicted label: 2
Correct prediction
Energy consumption = 178.988502 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 926 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 926 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 926 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.31166, 0.050251, 0.050988, 0.38976, 0.25519, 0.72935, 0.25295, 0.12232, 0.46576, 0.15746]
Predicted label: 5
Correct prediction
Energy consumption = 189.170533 pJ
sum error= 286
Actual label: 3
Output voltages: [0.31431, 0.12543, 0.30017, 0.7438, 0.19425, 0.17228, 0.10241, 0.23767, 0.47327, 0.25437]
Predicted label: 3
Correct prediction
Energy consumption = 183.048246 pJ
sum error= 286
Actual label: 7
Output voltages: [0.30051, 0.27152, 0.23272, 0.26064, 0.25177, 0.12188, 0.030893, 0.73444, 0.27639, 0.37084]
Predicted label: 7
Correct prediction
Energy consumption = 189.741218 pJ
sum error= 286
Actual label: 8
Output voltages: [0.18509, 0.19889, 0.31815, 0.27021, 0.15694, 0.15983, 0.22569, 0.13006, 0.74006, 0.28705]
Predicted label: 8
Correct prediction
Energy consumption = 185.617947 pJ
sum error= 286
Actual label: 0
Output voltages: [0.74149, 0.27332, 0.24765, 0.17587, 0.14403, 0.21441, 0.37842, 0.19496, 0.2583, 0.25481]
Predicted label: 0
Correct prediction
Energy consumption = 189.581345 pJ
sum error= 286
Actual label: 1
Output voltages: [0.14471, 0.76037, 0.30593, 0.42154, 0.21841, 0.12048, 0.3246, 0.16951, 0.23116, 0.32427]
Predicted label: 1
Correct prediction
Energy consumption = 214.347327 pJ
sum error= 286
Actual label: 2
Output voltages: [0.41413, 0.17326, 0.73063, 0.35999, 0.13605, 0.039729, 0.257, 0.232, 0.444, 0.17841]
Predicted label: 2
Correct prediction
Energy consumption = 189.865109 pJ
sum error= 286
Actual label: 4
Output voltages: [0.15655, 0.17761, 0.23191, 0.13093, 0.75161, 0.21668, 0.23251, 0.25597, 0.2502, 0.3502]
Predicted label: 4
Correct prediction
Energy consumption = 199.835473 pJ
sum error= 286
Actual label: 5
Output voltages: [0.20337, 0.096702, 0.098616, 0.34774, 0.22307, 0.65923, 0.20475, 0.11489, 0.45536, 0.32358]
Predicted label: 5
Correct prediction
Energy consumption = 185.117397 pJ
sum error= 286
Actual label: 6
Output voltages: [0.29117, 0.20617, 0.28626, 0.08265, 0.33504, 0.41145, 0.73283, 0.10879, 0.37035, 0.089933]
Predicted label: 6
Correct prediction
Energy consumption = 189.283489 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 927 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 927 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 927 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24058, 0.30383, 0.28486, 0.25474, 0.10285, 0.064087, 0.048966, 0.75358, 0.38334, 0.34896]
Predicted label: 7
Correct prediction
Energy consumption = 201.472183 pJ
sum error= 286
Actual label: 8
Output voltages: [0.16318, 0.14334, 0.27388, 0.25032, 0.16336, 0.24454, 0.24096, 0.10339, 0.73985, 0.27972]
Predicted label: 8
Correct prediction
Energy consumption = 195.608350 pJ
sum error= 286
Actual label: 9
Output voltages: [0.35513, 0.18568, 0.16398, 0.35549, 0.29092, 0.18427, 0.090278, 0.26159, 0.30883, 0.7041]
Predicted label: 9
Correct prediction
Energy consumption = 195.920992 pJ
sum error= 286
Actual label: 0
Output voltages: [0.73507, 0.2951, 0.3035, 0.19519, 0.10199, 0.19276, 0.38439, 0.17126, 0.26566, 0.25592]
Predicted label: 0
Correct prediction
Energy consumption = 190.138776 pJ
sum error= 286
Actual label: 1
Output voltages: [0.22316, 0.77567, 0.17808, 0.3028, 0.15596, 0.18453, 0.35952, 0.11004, 0.30567, 0.26164]
Predicted label: 1
Correct prediction
Energy consumption = 209.690888 pJ
sum error= 286
Actual label: 3
Output voltages: [0.38066, 0.17565, 0.27241, 0.75656, 0.15463, 0.20192, 0.23296, 0.17451, 0.36103, 0.19398]
Predicted label: 3
Correct prediction
Energy consumption = 190.871927 pJ
sum error= 286
Actual label: 4
Output voltages: [0.17595, 0.14431, 0.30048, 0.12572, 0.76363, 0.11773, 0.32309, 0.22639, 0.23977, 0.27549]
Predicted label: 4
Correct prediction
Energy consumption = 194.248118 pJ
sum error= 286
Actual label: 5
Output voltages: [0.18953, 0.097515, 0.11933, 0.32709, 0.22053, 0.65645, 0.28504, 0.10686, 0.46749, 0.29952]
Predicted label: 5
Correct prediction
Energy consumption = 186.098189 pJ
sum error= 286
Actual label: 6
Output voltages: [0.27858, 0.25201, 0.32691, 0.10807, 0.32562, 0.33961, 0.75283, 0.11162, 0.31564, 0.17515]
Predicted label: 6
Correct prediction
Energy consumption = 189.057148 pJ
sum error= 286
Actual label: 7
Output voltages: [0.35409, 0.22961, 0.19954, 0.23805, 0.14452, 0.13332, 0.048547, 0.75144, 0.35274, 0.37081]
Predicted label: 7
Correct prediction
Energy consumption = 204.148512 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 928 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 928 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 928 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2604, 0.066056, 0.28105, 0.25899, 0.11026, 0.51893, 0.32078, 0.057259, 0.6511, 0.21837]
Predicted label: 8
Correct prediction
Energy consumption = 193.487831 pJ
sum error= 286
Actual label: 0
Output voltages: [0.72761, 0.24526, 0.25596, 0.25306, 0.073405, 0.24758, 0.34269, 0.23929, 0.31315, 0.24745]
Predicted label: 0
Correct prediction
Energy consumption = 189.935324 pJ
sum error= 286
Actual label: 1
Output voltages: [0.16137, 0.76055, 0.21353, 0.23389, 0.27658, 0.138, 0.41631, 0.093107, 0.33192, 0.22584]
Predicted label: 1
Correct prediction
Energy consumption = 215.658344 pJ
sum error= 286
Actual label: 3
Output voltages: [0.26313, 0.28159, 0.30376, 0.76473, 0.16536, 0.12708, 0.12527, 0.22592, 0.39069, 0.2675]
Predicted label: 3
Correct prediction
Energy consumption = 191.723988 pJ
sum error= 286
Actual label: 4
Output voltages: [0.10697, 0.15991, 0.32115, 0.11677, 0.7559, 0.15333, 0.29163, 0.34824, 0.22849, 0.29305]
Predicted label: 4
Correct prediction
Energy consumption = 197.370528 pJ
sum error= 286
Actual label: 7
Output voltages: [0.38689, 0.14093, 0.21319, 0.46268, 0.075801, 0.19031, 0.035375, 0.74261, 0.41392, 0.37964]
Predicted label: 7
Correct prediction
Energy consumption = 198.345699 pJ
sum error= 286
Actual label: 8
Output voltages: [0.19893, 0.12198, 0.28656, 0.33824, 0.10821, 0.3381, 0.17956, 0.08505, 0.72879, 0.25834]
Predicted label: 8
Correct prediction
Energy consumption = 186.881152 pJ
sum error= 286
Actual label: 9
Output voltages: [0.29084, 0.11678, 0.20505, 0.29464, 0.23712, 0.20937, 0.086414, 0.25241, 0.47824, 0.65316]
Predicted label: 9
Correct prediction
Energy consumption = 186.054302 pJ
sum error= 286
Actual label: 7
Output voltages: [0.3319, 0.21494, 0.31249, 0.26405, 0.10798, 0.068344, 0.041428, 0.74202, 0.47367, 0.37775]
Predicted label: 7
Correct prediction
Energy consumption = 193.124907 pJ
sum error= 286
Actual label: 5
Output voltages: [0.21309, 0.079413, 0.11641, 0.37066, 0.20159, 0.64228, 0.22778, 0.11144, 0.54638, 0.29369]
Predicted label: 5
Correct prediction
Energy consumption = 183.450604 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 929 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 929 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 929 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25643, 0.11973, 0.052288, 0.28531, 0.3332, 0.74152, 0.37129, 0.08951, 0.37189, 0.27041]
Predicted label: 5
Correct prediction
Energy consumption = 187.786608 pJ
sum error= 286
Actual label: 1
Output voltages: [0.26556, 0.73724, 0.40569, 0.34768, 0.25289, 0.041615, 0.24262, 0.14509, 0.27407, 0.20386]
Predicted label: 1
Correct prediction
Energy consumption = 217.546010 pJ
sum error= 286
Actual label: 9
Output voltages: [0.37118, 0.161, 0.18178, 0.26864, 0.2761, 0.1789, 0.128, 0.24781, 0.3583, 0.6894]
Predicted label: 9
Correct prediction
Energy consumption = 199.916623 pJ
sum error= 286
Actual label: 9
Output voltages: [0.29105, 0.13739, 0.20435, 0.30599, 0.27926, 0.074339, 0.089352, 0.26936, 0.42021, 0.6418]
Predicted label: 9
Correct prediction
Energy consumption = 188.438583 pJ
sum error= 286
Actual label: 7
Output voltages: [0.33412, 0.18817, 0.19996, 0.22006, 0.20177, 0.13339, 0.048749, 0.76532, 0.34999, 0.35568]
Predicted label: 7
Correct prediction
Energy consumption = 195.277671 pJ
sum error= 286
Actual label: 1
Output voltages: [0.25308, 0.75933, 0.25696, 0.21162, 0.34713, 0.082548, 0.41727, 0.11332, 0.25445, 0.22909]
Predicted label: 1
Correct prediction
Energy consumption = 208.714892 pJ
sum error= 286
Actual label: 0
Output voltages: [0.68058, 0.18755, 0.28048, 0.10118, 0.1645, 0.14914, 0.44391, 0.21803, 0.18875, 0.3468]
Predicted label: 0
Correct prediction
Energy consumption = 187.529089 pJ
sum error= 286
Actual label: 0
Output voltages: [0.6767, 0.24756, 0.3618, 0.14991, 0.074074, 0.10987, 0.41278, 0.18747, 0.32744, 0.2609]
Predicted label: 0
Correct prediction
Energy consumption = 183.583160 pJ
sum error= 286
Actual label: 5
Output voltages: [0.26155, 0.051052, 0.065101, 0.38816, 0.2064, 0.74248, 0.26947, 0.21646, 0.46351, 0.25105]
Predicted label: 5
Correct prediction
Energy consumption = 190.479998 pJ
sum error= 286
Actual label: 9
Output voltages: [0.35032, 0.14873, 0.23289, 0.24148, 0.29915, 0.16191, 0.068408, 0.21419, 0.39987, 0.6901]
Predicted label: 9
Correct prediction
Energy consumption = 180.864834 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 930 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 930 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 930 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34358, 0.20299, 0.16267, 0.29761, 0.1822, 0.17687, 0.042504, 0.75675, 0.29609, 0.40259]
Predicted label: 7
Correct prediction
Energy consumption = 198.994665 pJ
sum error= 286
Actual label: 1
Output voltages: [0.19827, 0.7686, 0.22002, 0.28504, 0.1862, 0.14347, 0.33608, 0.14664, 0.36914, 0.20165]
Predicted label: 1
Correct prediction
Energy consumption = 213.850769 pJ
sum error= 286
Actual label: 7
Output voltages: [0.37135, 0.23623, 0.17709, 0.32746, 0.14672, 0.10112, 0.040729, 0.74822, 0.31855, 0.38991]
Predicted label: 7
Correct prediction
Energy consumption = 204.908371 pJ
sum error= 286
Actual label: 2
Output voltages: [0.43368, 0.14082, 0.59097, 0.60349, 0.093356, 0.046023, 0.19353, 0.21125, 0.44237, 0.24788]
Predicted label: 3
Wrong prediction!
Energy consumption = 191.952431 pJ
sum error= 287
Actual label: 2
Output voltages: [0.39449, 0.19466, 0.69456, 0.37312, 0.14645, 0.032956, 0.27263, 0.26432, 0.45174, 0.1907]
Predicted label: 2
Correct prediction
Energy consumption = 188.068299 pJ
sum error= 287
Actual label: 3
Output voltages: [0.39214, 0.23273, 0.28576, 0.76369, 0.10747, 0.17662, 0.20463, 0.20523, 0.37942, 0.18687]
Predicted label: 3
Correct prediction
Energy consumption = 189.241623 pJ
sum error= 287
Actual label: 6
Output voltages: [0.29435, 0.21841, 0.38941, 0.068808, 0.32548, 0.28654, 0.75048, 0.065071, 0.36171, 0.20386]
Predicted label: 6
Correct prediction
Energy consumption = 180.113403 pJ
sum error= 287
Actual label: 8
Output voltages: [0.20142, 0.20199, 0.32777, 0.33774, 0.1385, 0.13584, 0.22816, 0.11227, 0.71012, 0.32998]
Predicted label: 8
Correct prediction
Energy consumption = 194.432094 pJ
sum error= 287
Actual label: 3
Output voltages: [0.44461, 0.18867, 0.30674, 0.75677, 0.085935, 0.20222, 0.13337, 0.24894, 0.36792, 0.23647]
Predicted label: 3
Correct prediction
Energy consumption = 193.307706 pJ
sum error= 287
Actual label: 2
Output voltages: [0.41754, 0.14465, 0.67579, 0.4639, 0.15261, 0.037343, 0.18579, 0.35439, 0.43482, 0.20408]
Predicted label: 2
Correct prediction
Energy consumption = 190.220799 pJ
sum error= 287
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 931 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 931 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 931 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.72285, 0.27264, 0.3253, 0.17875, 0.086161, 0.12254, 0.37086, 0.19561, 0.31139, 0.28065]
Predicted label: 0
Correct prediction
Energy consumption = 192.535955 pJ
sum error= 287
Actual label: 0
Output voltages: [0.66083, 0.26799, 0.34878, 0.18942, 0.10817, 0.095948, 0.43238, 0.17476, 0.33687, 0.25627]
Predicted label: 0
Correct prediction
Energy consumption = 187.913503 pJ
sum error= 287
Actual label: 6
Output voltages: [0.29861, 0.20541, 0.24279, 0.16244, 0.32144, 0.37752, 0.73996, 0.063797, 0.3667, 0.17797]
Predicted label: 6
Correct prediction
Energy consumption = 185.763076 pJ
sum error= 287
Actual label: 1
Output voltages: [0.25853, 0.76365, 0.30328, 0.27671, 0.15423, 0.068248, 0.41826, 0.095324, 0.30947, 0.23113]
Predicted label: 1
Correct prediction
Energy consumption = 211.215283 pJ
sum error= 287
Actual label: 7
Output voltages: [0.28242, 0.33329, 0.32587, 0.31439, 0.093762, 0.052372, 0.050615, 0.75076, 0.35689, 0.37909]
Predicted label: 7
Correct prediction
Energy consumption = 204.455711 pJ
sum error= 287
Actual label: 5
Output voltages: [0.18551, 0.095863, 0.10805, 0.31004, 0.19977, 0.68772, 0.19898, 0.14646, 0.54086, 0.2525]
Predicted label: 5
Correct prediction
Energy consumption = 189.911129 pJ
sum error= 287
Actual label: 8
Output voltages: [0.24707, 0.14406, 0.22127, 0.33773, 0.096044, 0.34274, 0.14006, 0.14505, 0.71282, 0.33563]
Predicted label: 8
Correct prediction
Energy consumption = 184.073113 pJ
sum error= 287
Actual label: 6
Output voltages: [0.3045, 0.16942, 0.27634, 0.12896, 0.3509, 0.34003, 0.71443, 0.13381, 0.34523, 0.23269]
Predicted label: 6
Correct prediction
Energy consumption = 185.200946 pJ
sum error= 287
Actual label: 2
Output voltages: [0.44721, 0.19043, 0.71314, 0.46535, 0.13534, 0.036474, 0.25875, 0.30967, 0.39694, 0.21587]
Predicted label: 2
Correct prediction
Energy consumption = 198.938984 pJ
sum error= 287
Actual label: 9
Output voltages: [0.38979, 0.16818, 0.19667, 0.26766, 0.29398, 0.18728, 0.10592, 0.24542, 0.34985, 0.71284]
Predicted label: 9
Correct prediction
Energy consumption = 195.526561 pJ
sum error= 287
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 932 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 932 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 932 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.20529, 0.16086, 0.29806, 0.18408, 0.74178, 0.047615, 0.17856, 0.29714, 0.24768, 0.34552]
Predicted label: 4
Correct prediction
Energy consumption = 200.436919 pJ
sum error= 287
Actual label: 8
Output voltages: [0.2215, 0.19175, 0.32412, 0.33397, 0.094828, 0.18973, 0.18674, 0.089065, 0.74366, 0.30227]
Predicted label: 8
Correct prediction
Energy consumption = 193.697505 pJ
sum error= 287
Actual label: 8
Output voltages: [0.22952, 0.20079, 0.31604, 0.27004, 0.1831, 0.19547, 0.24167, 0.094105, 0.73919, 0.30977]
Predicted label: 8
Correct prediction
Energy consumption = 190.596345 pJ
sum error= 287
Actual label: 7
Output voltages: [0.31113, 0.17835, 0.17278, 0.273, 0.18667, 0.13277, 0.040511, 0.75469, 0.40132, 0.37694]
Predicted label: 7
Correct prediction
Energy consumption = 200.424033 pJ
sum error= 287
Actual label: 1
Output voltages: [0.14269, 0.7642, 0.22643, 0.24484, 0.2305, 0.14001, 0.44404, 0.10639, 0.32394, 0.18457]
Predicted label: 1
Correct prediction
Energy consumption = 209.556510 pJ
sum error= 287
Actual label: 0
Output voltages: [0.6817, 0.28119, 0.37516, 0.20143, 0.062057, 0.10812, 0.38547, 0.17847, 0.31487, 0.31136]
Predicted label: 0
Correct prediction
Energy consumption = 195.322553 pJ
sum error= 287
Actual label: 8
Output voltages: [0.22197, 0.14138, 0.31141, 0.34238, 0.11104, 0.27275, 0.20682, 0.11238, 0.74267, 0.25878]
Predicted label: 8
Correct prediction
Energy consumption = 190.583063 pJ
sum error= 287
Actual label: 7
Output voltages: [0.34296, 0.17812, 0.14212, 0.2843, 0.16137, 0.15529, 0.045945, 0.75119, 0.38785, 0.40897]
Predicted label: 7
Correct prediction
Energy consumption = 196.702487 pJ
sum error= 287
Actual label: 7
Output voltages: [0.32265, 0.19471, 0.21217, 0.31003, 0.14091, 0.11843, 0.044343, 0.75282, 0.36264, 0.41719]
Predicted label: 7
Correct prediction
Energy consumption = 191.248667 pJ
sum error= 287
Actual label: 5
Output voltages: [0.25587, 0.071116, 0.10538, 0.37707, 0.16295, 0.70845, 0.19774, 0.20205, 0.56475, 0.26617]
Predicted label: 5
Correct prediction
Energy consumption = 181.439600 pJ
sum error= 287
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 933 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 933 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 933 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.22906, 0.1661, 0.31593, 0.32054, 0.13232, 0.23118, 0.25266, 0.10721, 0.73872, 0.28762]
Predicted label: 8
Correct prediction
Energy consumption = 194.004862 pJ
sum error= 287
Actual label: 5
Output voltages: [0.23502, 0.052456, 0.082842, 0.38656, 0.26157, 0.66493, 0.25729, 0.17858, 0.43909, 0.37316]
Predicted label: 5
Correct prediction
Energy consumption = 190.746815 pJ
sum error= 287
Actual label: 3
Output voltages: [0.41793, 0.21917, 0.35673, 0.76233, 0.11171, 0.16765, 0.18709, 0.20649, 0.34663, 0.21953]
Predicted label: 3
Correct prediction
Energy consumption = 192.687092 pJ
sum error= 287
Actual label: 4
Output voltages: [0.15935, 0.18706, 0.31759, 0.15187, 0.74903, 0.057511, 0.2128, 0.26493, 0.21708, 0.35472]
Predicted label: 4
Correct prediction
Energy consumption = 198.581171 pJ
sum error= 287
Actual label: 6
Output voltages: [0.28512, 0.21229, 0.28977, 0.10676, 0.36733, 0.34407, 0.7401, 0.085278, 0.36252, 0.083872]
Predicted label: 6
Correct prediction
Energy consumption = 192.371789 pJ
sum error= 287
Actual label: 1
Output voltages: [0.15239, 0.76106, 0.26681, 0.48138, 0.16851, 0.13389, 0.26889, 0.19196, 0.21375, 0.32233]
Predicted label: 1
Correct prediction
Energy consumption = 213.226436 pJ
sum error= 287
Actual label: 1
Output voltages: [0.21298, 0.77007, 0.30624, 0.3342, 0.18383, 0.079843, 0.35631, 0.21584, 0.24438, 0.24468]
Predicted label: 1
Correct prediction
Energy consumption = 204.717997 pJ
sum error= 287
Actual label: 5
Output voltages: [0.19455, 0.10231, 0.11835, 0.40533, 0.20315, 0.67294, 0.20487, 0.17373, 0.49788, 0.32663]
Predicted label: 5
Correct prediction
Energy consumption = 186.170962 pJ
sum error= 287
Actual label: 5
Output voltages: [0.23931, 0.18179, 0.1492, 0.43931, 0.10813, 0.58195, 0.11491, 0.15898, 0.58231, 0.28037]
Predicted label: 8
Wrong prediction!
Energy consumption = 184.793797 pJ
sum error= 288
Actual label: 0
Output voltages: [0.70972, 0.27728, 0.30368, 0.32839, 0.047438, 0.23349, 0.36755, 0.19637, 0.34596, 0.23511]
Predicted label: 0
Correct prediction
Energy consumption = 194.084729 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 934 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 934 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 934 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.29033, 0.27756, 0.23864, 0.35108, 0.089844, 0.067043, 0.040295, 0.74414, 0.37453, 0.41402]
Predicted label: 7
Correct prediction
Energy consumption = 205.001112 pJ
sum error= 288
Actual label: 2
Output voltages: [0.38681, 0.13273, 0.68475, 0.42485, 0.11506, 0.038214, 0.23641, 0.27598, 0.49231, 0.22798]
Predicted label: 2
Correct prediction
Energy consumption = 191.110934 pJ
sum error= 288
Actual label: 3
Output voltages: [0.46522, 0.23143, 0.34471, 0.70425, 0.071557, 0.29223, 0.19985, 0.22724, 0.27568, 0.15798]
Predicted label: 3
Correct prediction
Energy consumption = 191.803866 pJ
sum error= 288
Actual label: 6
Output voltages: [0.33047, 0.2305, 0.23671, 0.16473, 0.30647, 0.43344, 0.73821, 0.08257, 0.36694, 0.16789]
Predicted label: 6
Correct prediction
Energy consumption = 189.270959 pJ
sum error= 288
Actual label: 4
Output voltages: [0.15414, 0.13774, 0.3251, 0.13203, 0.74813, 0.090925, 0.22161, 0.22185, 0.22314, 0.38327]
Predicted label: 4
Correct prediction
Energy consumption = 196.964697 pJ
sum error= 288
Actual label: 1
Output voltages: [0.16626, 0.76301, 0.24977, 0.25809, 0.27626, 0.15878, 0.35734, 0.10589, 0.33616, 0.25627]
Predicted label: 1
Correct prediction
Energy consumption = 216.472899 pJ
sum error= 288
Actual label: 2
Output voltages: [0.46348, 0.1452, 0.63491, 0.4197, 0.1243, 0.046904, 0.21078, 0.21513, 0.52549, 0.22623]
Predicted label: 2
Correct prediction
Energy consumption = 189.939437 pJ
sum error= 288
Actual label: 4
Output voltages: [0.14537, 0.11719, 0.35786, 0.17453, 0.75019, 0.063645, 0.22432, 0.25831, 0.25074, 0.28548]
Predicted label: 4
Correct prediction
Energy consumption = 199.421817 pJ
sum error= 288
Actual label: 1
Output voltages: [0.24582, 0.75543, 0.32968, 0.28424, 0.26325, 0.055051, 0.30067, 0.12918, 0.32334, 0.2458]
Predicted label: 1
Correct prediction
Energy consumption = 213.792682 pJ
sum error= 288
Actual label: 5
Output voltages: [0.2713, 0.093248, 0.10346, 0.28336, 0.1882, 0.73488, 0.31271, 0.14225, 0.48186, 0.23355]
Predicted label: 5
Correct prediction
Energy consumption = 194.281410 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 935 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 935 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 935 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13747, 0.2229, 0.33261, 0.21216, 0.72916, 0.066352, 0.20201, 0.3305, 0.22213, 0.38008]
Predicted label: 4
Correct prediction
Energy consumption = 199.121629 pJ
sum error= 288
Actual label: 2
Output voltages: [0.38576, 0.2019, 0.6436, 0.42083, 0.17702, 0.02631, 0.27472, 0.29159, 0.4107, 0.18274]
Predicted label: 2
Correct prediction
Energy consumption = 194.383369 pJ
sum error= 288
Actual label: 0
Output voltages: [0.7143, 0.29342, 0.32895, 0.13796, 0.082696, 0.17153, 0.37892, 0.16609, 0.26058, 0.2778]
Predicted label: 0
Correct prediction
Energy consumption = 189.945280 pJ
sum error= 288
Actual label: 4
Output voltages: [0.17749, 0.12185, 0.3104, 0.16384, 0.74087, 0.066811, 0.20375, 0.29519, 0.26855, 0.33878]
Predicted label: 4
Correct prediction
Energy consumption = 200.755016 pJ
sum error= 288
Actual label: 8
Output voltages: [0.22579, 0.16987, 0.3287, 0.28073, 0.11697, 0.20626, 0.20932, 0.16206, 0.74727, 0.27605]
Predicted label: 8
Correct prediction
Energy consumption = 194.816385 pJ
sum error= 288
Actual label: 6
Output voltages: [0.2983, 0.22266, 0.2714, 0.1378, 0.33315, 0.38352, 0.74355, 0.098647, 0.35506, 0.16957]
Predicted label: 6
Correct prediction
Energy consumption = 189.043900 pJ
sum error= 288
Actual label: 1
Output voltages: [0.23302, 0.77438, 0.266, 0.2028, 0.17527, 0.12222, 0.36835, 0.18766, 0.31741, 0.23382]
Predicted label: 1
Correct prediction
Energy consumption = 212.509820 pJ
sum error= 288
Actual label: 9
Output voltages: [0.2759, 0.16341, 0.21556, 0.25097, 0.37612, 0.10118, 0.076007, 0.18542, 0.35314, 0.64952]
Predicted label: 9
Correct prediction
Energy consumption = 195.639214 pJ
sum error= 288
Actual label: 0
Output voltages: [0.72977, 0.25733, 0.29399, 0.20599, 0.095245, 0.17535, 0.41417, 0.17231, 0.28213, 0.23926]
Predicted label: 0
Correct prediction
Energy consumption = 195.458420 pJ
sum error= 288
Actual label: 2
Output voltages: [0.44455, 0.16789, 0.73354, 0.3033, 0.14119, 0.043565, 0.28204, 0.25766, 0.44701, 0.16978]
Predicted label: 2
Correct prediction
Energy consumption = 182.842354 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 936 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 936 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 936 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24674, 0.069057, 0.067255, 0.39306, 0.20921, 0.73443, 0.26706, 0.19685, 0.46632, 0.25884]
Predicted label: 5
Correct prediction
Energy consumption = 189.961363 pJ
sum error= 288
Actual label: 6
Output voltages: [0.26072, 0.26869, 0.30437, 0.081827, 0.31253, 0.37385, 0.74767, 0.10236, 0.3719, 0.1391]
Predicted label: 6
Correct prediction
Energy consumption = 186.349531 pJ
sum error= 288
Actual label: 9
Output voltages: [0.3443, 0.13093, 0.18789, 0.27085, 0.2743, 0.17032, 0.069034, 0.29433, 0.40449, 0.66436]
Predicted label: 9
Correct prediction
Energy consumption = 190.601812 pJ
sum error= 288
Actual label: 3
Output voltages: [0.36482, 0.19377, 0.30822, 0.75852, 0.14023, 0.22561, 0.16506, 0.21674, 0.40565, 0.23717]
Predicted label: 3
Correct prediction
Energy consumption = 191.071329 pJ
sum error= 288
Actual label: 6
Output voltages: [0.25833, 0.13394, 0.27378, 0.080339, 0.42826, 0.25394, 0.69417, 0.063337, 0.3934, 0.17847]
Predicted label: 6
Correct prediction
Energy consumption = 189.367665 pJ
sum error= 288
Actual label: 3
Output voltages: [0.38008, 0.20157, 0.31317, 0.7504, 0.13534, 0.23311, 0.12269, 0.20128, 0.37526, 0.24444]
Predicted label: 3
Correct prediction
Energy consumption = 197.843644 pJ
sum error= 288
Actual label: 6
Output voltages: [0.2246, 0.15259, 0.31661, 0.083886, 0.41276, 0.26786, 0.69502, 0.06068, 0.37861, 0.17598]
Predicted label: 6
Correct prediction
Energy consumption = 189.557440 pJ
sum error= 288
Actual label: 0
Output voltages: [0.74322, 0.26363, 0.26197, 0.16329, 0.13939, 0.15181, 0.40084, 0.18884, 0.26866, 0.25674]
Predicted label: 0
Correct prediction
Energy consumption = 187.564691 pJ
sum error= 288
Actual label: 1
Output voltages: [0.16818, 0.77069, 0.23933, 0.29948, 0.23557, 0.14761, 0.28686, 0.21974, 0.26498, 0.30903]
Predicted label: 1
Correct prediction
Energy consumption = 213.057964 pJ
sum error= 288
Actual label: 2
Output voltages: [0.32014, 0.11312, 0.70206, 0.42007, 0.17815, 0.045224, 0.19818, 0.25598, 0.45499, 0.23645]
Predicted label: 2
Correct prediction
Energy consumption = 185.281752 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 937 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 937 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 937 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.31807, 0.2395, 0.35652, 0.74633, 0.10204, 0.12459, 0.16843, 0.12477, 0.46053, 0.21081]
Predicted label: 3
Correct prediction
Energy consumption = 184.505537 pJ
sum error= 288
Actual label: 4
Output voltages: [0.14787, 0.18916, 0.31519, 0.15608, 0.75003, 0.11752, 0.21524, 0.20285, 0.22874, 0.39227]
Predicted label: 4
Correct prediction
Energy consumption = 195.505935 pJ
sum error= 288
Actual label: 5
Output voltages: [0.21081, 0.04433, 0.068181, 0.41067, 0.26659, 0.7066, 0.33658, 0.23571, 0.51839, 0.1951]
Predicted label: 5
Correct prediction
Energy consumption = 189.665679 pJ
sum error= 288
Actual label: 6
Output voltages: [0.26528, 0.23489, 0.31303, 0.092724, 0.34999, 0.30008, 0.75231, 0.1001, 0.29678, 0.19268]
Predicted label: 6
Correct prediction
Energy consumption = 187.634328 pJ
sum error= 288
Actual label: 7
Output voltages: [0.3229, 0.19985, 0.15515, 0.22954, 0.23841, 0.18657, 0.066225, 0.76953, 0.25173, 0.28838]
Predicted label: 7
Correct prediction
Energy consumption = 199.110389 pJ
sum error= 288
Actual label: 8
Output voltages: [0.28867, 0.16713, 0.30032, 0.36948, 0.089776, 0.20966, 0.31614, 0.060362, 0.70546, 0.2576]
Predicted label: 8
Correct prediction
Energy consumption = 192.497601 pJ
sum error= 288
Actual label: 9
Output voltages: [0.36059, 0.13694, 0.19462, 0.29786, 0.28275, 0.2669, 0.12377, 0.29732, 0.35027, 0.70784]
Predicted label: 9
Correct prediction
Energy consumption = 191.522482 pJ
sum error= 288
Actual label: 0
Output voltages: [0.69196, 0.14382, 0.25813, 0.16519, 0.13545, 0.23687, 0.44364, 0.15251, 0.26249, 0.30416]
Predicted label: 0
Correct prediction
Energy consumption = 189.462593 pJ
sum error= 288
Actual label: 1
Output voltages: [0.20779, 0.7434, 0.32878, 0.22867, 0.29627, 0.07756, 0.39463, 0.10454, 0.29426, 0.21354]
Predicted label: 1
Correct prediction
Energy consumption = 209.545419 pJ
sum error= 288
Actual label: 2
Output voltages: [0.36593, 0.13609, 0.72393, 0.31532, 0.088213, 0.058457, 0.27788, 0.22456, 0.50892, 0.14984]
Predicted label: 2
Correct prediction
Energy consumption = 189.610227 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 938 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 938 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 938 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33927, 0.19414, 0.34187, 0.75298, 0.14978, 0.16574, 0.20463, 0.24129, 0.39522, 0.22403]
Predicted label: 3
Correct prediction
Energy consumption = 182.686238 pJ
sum error= 288
Actual label: 4
Output voltages: [0.11065, 0.22996, 0.23104, 0.1117, 0.75619, 0.16004, 0.22259, 0.33441, 0.24022, 0.32125]
Predicted label: 4
Correct prediction
Energy consumption = 198.388976 pJ
sum error= 288
Actual label: 5
Output voltages: [0.17632, 0.08881, 0.060069, 0.33705, 0.44205, 0.52374, 0.34443, 0.069762, 0.37034, 0.31967]
Predicted label: 5
Correct prediction
Energy consumption = 192.555614 pJ
sum error= 288
Actual label: 6
Output voltages: [0.2817, 0.23992, 0.34453, 0.061855, 0.39099, 0.3389, 0.74799, 0.06254, 0.3554, 0.14307]
Predicted label: 6
Correct prediction
Energy consumption = 181.175745 pJ
sum error= 288
Actual label: 7
Output voltages: [0.298, 0.23959, 0.17497, 0.23886, 0.17789, 0.121, 0.050452, 0.76285, 0.33533, 0.34969]
Predicted label: 7
Correct prediction
Energy consumption = 192.226860 pJ
sum error= 288
Actual label: 8
Output voltages: [0.28623, 0.16163, 0.2726, 0.34958, 0.11971, 0.34148, 0.51174, 0.054133, 0.62614, 0.23655]
Predicted label: 8
Correct prediction
Energy consumption = 200.129963 pJ
sum error= 288
Actual label: 9
Output voltages: [0.29042, 0.11759, 0.24492, 0.24551, 0.22715, 0.18043, 0.071792, 0.24968, 0.46113, 0.61839]
Predicted label: 9
Correct prediction
Energy consumption = 188.756639 pJ
sum error= 288
Actual label: 0
Output voltages: [0.69906, 0.20342, 0.23586, 0.19343, 0.13726, 0.19025, 0.45116, 0.15692, 0.3014, 0.25262]
Predicted label: 0
Correct prediction
Energy consumption = 189.620408 pJ
sum error= 288
Actual label: 1
Output voltages: [0.17628, 0.77378, 0.22328, 0.29766, 0.20674, 0.13823, 0.39362, 0.15958, 0.28593, 0.25425]
Predicted label: 1
Correct prediction
Energy consumption = 208.903146 pJ
sum error= 288
Actual label: 2
Output voltages: [0.40442, 0.15808, 0.73813, 0.34592, 0.16983, 0.040561, 0.27729, 0.25977, 0.44958, 0.15698]
Predicted label: 2
Correct prediction
Energy consumption = 186.494868 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 939 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 939 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 939 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33953, 0.15566, 0.28992, 0.75921, 0.24039, 0.135, 0.17457, 0.22819, 0.42987, 0.26175]
Predicted label: 3
Correct prediction
Energy consumption = 184.889021 pJ
sum error= 288
Actual label: 5
Output voltages: [0.21711, 0.050042, 0.05193, 0.41704, 0.33566, 0.7123, 0.32667, 0.20804, 0.50083, 0.20623]
Predicted label: 5
Correct prediction
Energy consumption = 184.365050 pJ
sum error= 288
Actual label: 6
Output voltages: [0.27686, 0.14791, 0.33877, 0.07079, 0.41024, 0.27781, 0.71057, 0.072341, 0.3081, 0.21074]
Predicted label: 6
Correct prediction
Energy consumption = 182.028510 pJ
sum error= 288
Actual label: 7
Output voltages: [0.31078, 0.19459, 0.25572, 0.20527, 0.17922, 0.12889, 0.059612, 0.76975, 0.34099, 0.28563]
Predicted label: 7
Correct prediction
Energy consumption = 198.611428 pJ
sum error= 288
Actual label: 8
Output voltages: [0.15725, 0.14113, 0.2701, 0.2784, 0.12579, 0.38229, 0.2571, 0.13184, 0.70282, 0.28964]
Predicted label: 8
Correct prediction
Energy consumption = 194.776782 pJ
sum error= 288
Actual label: 1
Output voltages: [0.24253, 0.75753, 0.25896, 0.33379, 0.22714, 0.12843, 0.29533, 0.071566, 0.30531, 0.32777]
Predicted label: 1
Correct prediction
Energy consumption = 214.282439 pJ
sum error= 288
Actual label: 0
Output voltages: [0.74078, 0.20905, 0.2751, 0.16768, 0.15748, 0.12556, 0.43332, 0.2051, 0.26966, 0.27686]
Predicted label: 0
Correct prediction
Energy consumption = 188.500962 pJ
sum error= 288
Actual label: 9
Output voltages: [0.31171, 0.12879, 0.22643, 0.29032, 0.24526, 0.2248, 0.12767, 0.24194, 0.41747, 0.63666]
Predicted label: 9
Correct prediction
Energy consumption = 193.857946 pJ
sum error= 288
Actual label: 5
Output voltages: [0.24049, 0.04721, 0.093336, 0.47894, 0.30986, 0.69864, 0.31892, 0.23897, 0.45627, 0.23411]
Predicted label: 5
Correct prediction
Energy consumption = 183.763493 pJ
sum error= 288
Actual label: 7
Output voltages: [0.40825, 0.20189, 0.10578, 0.1556, 0.28162, 0.22474, 0.061693, 0.74391, 0.28286, 0.4034]
Predicted label: 7
Correct prediction
Energy consumption = 193.227440 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 940 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 940 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 940 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.19456, 0.045931, 0.082584, 0.43546, 0.2789, 0.64417, 0.3244, 0.17601, 0.51256, 0.22609]
Predicted label: 5
Correct prediction
Energy consumption = 195.646839 pJ
sum error= 288
Actual label: 1
Output voltages: [0.30515, 0.76475, 0.18237, 0.34012, 0.2313, 0.11428, 0.27811, 0.18529, 0.22284, 0.31639]
Predicted label: 1
Correct prediction
Energy consumption = 216.401975 pJ
sum error= 288
Actual label: 8
Output voltages: [0.26472, 0.14888, 0.27862, 0.33688, 0.08478, 0.41597, 0.20706, 0.12176, 0.73843, 0.19695]
Predicted label: 8
Correct prediction
Energy consumption = 193.399587 pJ
sum error= 288
Actual label: 6
Output voltages: [0.28146, 0.20706, 0.31104, 0.12409, 0.32963, 0.37204, 0.73967, 0.055656, 0.40291, 0.16482]
Predicted label: 6
Correct prediction
Energy consumption = 186.670786 pJ
sum error= 288
Actual label: 9
Output voltages: [0.36984, 0.089827, 0.16842, 0.21826, 0.34257, 0.22629, 0.10137, 0.26387, 0.33343, 0.68685]
Predicted label: 9
Correct prediction
Energy consumption = 196.767366 pJ
sum error= 288
Actual label: 0
Output voltages: [0.7076, 0.17782, 0.26087, 0.11364, 0.20124, 0.1819, 0.44429, 0.13923, 0.30669, 0.24658]
Predicted label: 0
Correct prediction
Energy consumption = 195.332096 pJ
sum error= 288
Actual label: 4
Output voltages: [0.13947, 0.21054, 0.29274, 0.17364, 0.74808, 0.091176, 0.22799, 0.26197, 0.21127, 0.34826]
Predicted label: 4
Correct prediction
Energy consumption = 196.628563 pJ
sum error= 288
Actual label: 1
Output voltages: [0.2409, 0.76274, 0.23415, 0.30093, 0.19276, 0.13906, 0.37783, 0.080162, 0.31227, 0.23941]
Predicted label: 1
Correct prediction
Energy consumption = 206.699352 pJ
sum error= 288
Actual label: 9
Output voltages: [0.38517, 0.062321, 0.2126, 0.28294, 0.38929, 0.25731, 0.18608, 0.23033, 0.29311, 0.66933]
Predicted label: 9
Correct prediction
Energy consumption = 198.441237 pJ
sum error= 288
Actual label: 3
Output voltages: [0.29029, 0.13426, 0.38517, 0.74543, 0.16862, 0.17294, 0.14869, 0.14063, 0.51895, 0.21092]
Predicted label: 3
Correct prediction
Energy consumption = 176.890472 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 941 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 941 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 941 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.29794, 0.13508, 0.25647, 0.38543, 0.057376, 0.36691, 0.24573, 0.11295, 0.72342, 0.30548]
Predicted label: 8
Correct prediction
Energy consumption = 193.611728 pJ
sum error= 288
Actual label: 4
Output voltages: [0.18359, 0.11395, 0.2984, 0.104, 0.73076, 0.055831, 0.26447, 0.22773, 0.26779, 0.27403]
Predicted label: 4
Correct prediction
Energy consumption = 198.456629 pJ
sum error= 288
Actual label: 4
Output voltages: [0.10708, 0.11696, 0.29345, 0.16233, 0.7553, 0.077124, 0.26387, 0.29152, 0.27813, 0.21278]
Predicted label: 4
Correct prediction
Energy consumption = 191.216444 pJ
sum error= 288
Actual label: 7
Output voltages: [0.30059, 0.28966, 0.43163, 0.32657, 0.10944, 0.030887, 0.059832, 0.69076, 0.33779, 0.31527]
Predicted label: 7
Correct prediction
Energy consumption = 197.897667 pJ
sum error= 288
Actual label: 0
Output voltages: [0.71536, 0.18771, 0.31949, 0.15337, 0.19266, 0.16324, 0.42152, 0.1794, 0.31014, 0.28508]
Predicted label: 0
Correct prediction
Energy consumption = 194.429164 pJ
sum error= 288
Actual label: 1
Output voltages: [0.14011, 0.76866, 0.25949, 0.27253, 0.15208, 0.096748, 0.28715, 0.22155, 0.37366, 0.23343]
Predicted label: 1
Correct prediction
Energy consumption = 210.758494 pJ
sum error= 288
Actual label: 9
Output voltages: [0.32002, 0.1283, 0.14609, 0.34639, 0.30076, 0.32249, 0.1317, 0.26, 0.3119, 0.68605]
Predicted label: 9
Correct prediction
Energy consumption = 199.056134 pJ
sum error= 288
Actual label: 2
Output voltages: [0.39495, 0.1977, 0.74314, 0.29095, 0.14296, 0.047178, 0.28915, 0.21925, 0.42895, 0.13672]
Predicted label: 2
Correct prediction
Energy consumption = 193.197804 pJ
sum error= 288
Actual label: 8
Output voltages: [0.25064, 0.16411, 0.32106, 0.28384, 0.14933, 0.15816, 0.18042, 0.078698, 0.73163, 0.33127]
Predicted label: 8
Correct prediction
Energy consumption = 193.040478 pJ
sum error= 288
Actual label: 7
Output voltages: [0.34143, 0.27672, 0.14455, 0.27951, 0.17156, 0.18587, 0.052468, 0.75879, 0.264, 0.35179]
Predicted label: 7
Correct prediction
Energy consumption = 195.509129 pJ
sum error= 288
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 942 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 942 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 942 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.20844, 0.21854, 0.34239, 0.3123, 0.12616, 0.14735, 0.1807, 0.15398, 0.7476, 0.31565]
Predicted label: 8
Correct prediction
Energy consumption = 191.051796 pJ
sum error= 288
Actual label: 2
Output voltages: [0.45057, 0.16528, 0.71258, 0.41058, 0.063561, 0.074117, 0.19293, 0.31963, 0.37825, 0.1634]
Predicted label: 2
Correct prediction
Energy consumption = 192.328816 pJ
sum error= 288
Actual label: 5
Output voltages: [0.21375, 0.059562, 0.18174, 0.51554, 0.31158, 0.48003, 0.38144, 0.13855, 0.46656, 0.16753]
Predicted label: 3
Wrong prediction!
Energy consumption = 198.509664 pJ
sum error= 289
Actual label: 9
Output voltages: [0.31875, 0.08921, 0.19288, 0.28968, 0.36761, 0.22837, 0.15129, 0.34967, 0.33312, 0.59714]
Predicted label: 9
Correct prediction
Energy consumption = 194.895426 pJ
sum error= 289
Actual label: 6
Output voltages: [0.26175, 0.17615, 0.27715, 0.090012, 0.39746, 0.39696, 0.73673, 0.062021, 0.36365, 0.13153]
Predicted label: 6
Correct prediction
Energy consumption = 190.468725 pJ
sum error= 289
Actual label: 0
Output voltages: [0.57043, 0.12703, 0.33008, 0.094016, 0.16755, 0.24218, 0.54544, 0.13395, 0.33602, 0.19948]
Predicted label: 0
Correct prediction
Energy consumption = 195.747513 pJ
sum error= 289
Actual label: 6
Output voltages: [0.25458, 0.14531, 0.29047, 0.074327, 0.43587, 0.2265, 0.67531, 0.1126, 0.28579, 0.26678]
Predicted label: 6
Correct prediction
Energy consumption = 182.168841 pJ
sum error= 289
Actual label: 5
Output voltages: [0.25247, 0.050867, 0.054692, 0.37707, 0.30448, 0.68914, 0.41383, 0.079258, 0.46337, 0.21655]
Predicted label: 5
Correct prediction
Energy consumption = 190.749695 pJ
sum error= 289
Actual label: 5
Output voltages: [0.23426, 0.048333, 0.09481, 0.40869, 0.3149, 0.67332, 0.31359, 0.12132, 0.45359, 0.25405]
Predicted label: 5
Correct prediction
Energy consumption = 186.226317 pJ
sum error= 289
Actual label: 3
Output voltages: [0.28284, 0.18521, 0.32997, 0.75406, 0.16437, 0.16501, 0.12765, 0.15539, 0.50326, 0.22714]
Predicted label: 3
Correct prediction
Energy consumption = 172.420449 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 943 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 943 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 943 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.41, 0.17049, 0.3363, 0.73998, 0.12634, 0.26917, 0.16046, 0.21231, 0.37648, 0.14495]
Predicted label: 3
Correct prediction
Energy consumption = 186.820479 pJ
sum error= 289
Actual label: 3
Output voltages: [0.32726, 0.18826, 0.34762, 0.75556, 0.14198, 0.17402, 0.137, 0.13358, 0.46704, 0.20193]
Predicted label: 3
Correct prediction
Energy consumption = 178.369328 pJ
sum error= 289
Actual label: 9
Output voltages: [0.34676, 0.14317, 0.19817, 0.29842, 0.33099, 0.23108, 0.14877, 0.27269, 0.29288, 0.71371]
Predicted label: 9
Correct prediction
Energy consumption = 191.325119 pJ
sum error= 289
Actual label: 8
Output voltages: [0.27225, 0.16684, 0.31594, 0.085688, 0.1213, 0.19762, 0.30819, 0.19082, 0.70041, 0.33181]
Predicted label: 8
Correct prediction
Energy consumption = 194.482103 pJ
sum error= 289
Actual label: 1
Output voltages: [0.20663, 0.76343, 0.30212, 0.27647, 0.29782, 0.057356, 0.35018, 0.15353, 0.24833, 0.24408]
Predicted label: 1
Correct prediction
Energy consumption = 211.163368 pJ
sum error= 289
Actual label: 1
Output voltages: [0.19341, 0.76859, 0.14717, 0.3544, 0.14885, 0.17301, 0.41013, 0.15664, 0.30923, 0.20993]
Predicted label: 1
Correct prediction
Energy consumption = 211.174996 pJ
sum error= 289
Actual label: 0
Output voltages: [0.74117, 0.29785, 0.27359, 0.25105, 0.13177, 0.18381, 0.35835, 0.18803, 0.3343, 0.34479]
Predicted label: 0
Correct prediction
Energy consumption = 200.457542 pJ
sum error= 289
Actual label: 6
Output voltages: [0.3049, 0.20616, 0.27597, 0.11643, 0.35352, 0.32108, 0.73433, 0.082077, 0.33521, 0.14254]
Predicted label: 6
Correct prediction
Energy consumption = 188.386972 pJ
sum error= 289
Actual label: 1
Output voltages: [0.21313, 0.76792, 0.2572, 0.20286, 0.25036, 0.10404, 0.38465, 0.088267, 0.3403, 0.22437]
Predicted label: 1
Correct prediction
Energy consumption = 207.921071 pJ
sum error= 289
Actual label: 0
Output voltages: [0.70004, 0.22991, 0.26714, 0.14179, 0.14548, 0.15513, 0.41326, 0.19593, 0.30306, 0.3062]
Predicted label: 0
Correct prediction
Energy consumption = 193.001861 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 944 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 944 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 944 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.69897, 0.17491, 0.27356, 0.1933, 0.082647, 0.21951, 0.4433, 0.14818, 0.33256, 0.25025]
Predicted label: 0
Correct prediction
Energy consumption = 191.612564 pJ
sum error= 289
Actual label: 6
Output voltages: [0.33893, 0.24641, 0.2765, 0.12583, 0.29545, 0.32864, 0.73997, 0.10433, 0.29799, 0.22377]
Predicted label: 6
Correct prediction
Energy consumption = 192.838538 pJ
sum error= 289
Actual label: 2
Output voltages: [0.33447, 0.093631, 0.71287, 0.4017, 0.23759, 0.040983, 0.18599, 0.2935, 0.45099, 0.22919]
Predicted label: 2
Correct prediction
Energy consumption = 186.309229 pJ
sum error= 289
Actual label: 1
Output voltages: [0.18233, 0.76945, 0.23031, 0.32802, 0.21544, 0.1822, 0.33243, 0.12732, 0.31558, 0.303]
Predicted label: 1
Correct prediction
Energy consumption = 212.467996 pJ
sum error= 289
Actual label: 1
Output voltages: [0.21618, 0.76682, 0.23832, 0.34872, 0.29445, 0.18211, 0.30278, 0.12213, 0.19103, 0.31657]
Predicted label: 1
Correct prediction
Energy consumption = 209.119343 pJ
sum error= 289
Actual label: 3
Output voltages: [0.32582, 0.2045, 0.26994, 0.76567, 0.19733, 0.16514, 0.16007, 0.23296, 0.41934, 0.23303]
Predicted label: 3
Correct prediction
Energy consumption = 181.805772 pJ
sum error= 289
Actual label: 2
Output voltages: [0.20256, 0.16245, 0.72985, 0.35492, 0.197, 0.042659, 0.26275, 0.32789, 0.34261, 0.25924]
Predicted label: 2
Correct prediction
Energy consumption = 183.090187 pJ
sum error= 289
Actual label: 7
Output voltages: [0.37201, 0.17072, 0.16372, 0.25586, 0.22774, 0.1646, 0.054733, 0.76063, 0.30248, 0.28396]
Predicted label: 7
Correct prediction
Energy consumption = 201.458754 pJ
sum error= 289
Actual label: 7
Output voltages: [0.27524, 0.32167, 0.26985, 0.2466, 0.19432, 0.058182, 0.067549, 0.74387, 0.2216, 0.40362]
Predicted label: 7
Correct prediction
Energy consumption = 195.532556 pJ
sum error= 289
Actual label: 8
Output voltages: [0.16574, 0.13714, 0.24764, 0.25939, 0.13686, 0.31129, 0.1665, 0.17239, 0.7388, 0.32078]
Predicted label: 8
Correct prediction
Energy consumption = 190.637307 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 945 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 945 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 945 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.28372, 0.17965, 0.30834, 0.28196, 0.064375, 0.31355, 0.34196, 0.11094, 0.6765, 0.22494]
Predicted label: 8
Correct prediction
Energy consumption = 192.670801 pJ
sum error= 289
Actual label: 7
Output voltages: [0.28175, 0.21352, 0.17277, 0.26426, 0.18114, 0.18368, 0.051531, 0.76849, 0.2876, 0.32571]
Predicted label: 7
Correct prediction
Energy consumption = 202.382407 pJ
sum error= 289
Actual label: 8
Output voltages: [0.21838, 0.16252, 0.32585, 0.29225, 0.090651, 0.28608, 0.27392, 0.19643, 0.74405, 0.24729]
Predicted label: 8
Correct prediction
Energy consumption = 189.059723 pJ
sum error= 289
Actual label: 4
Output voltages: [0.18915, 0.15134, 0.30736, 0.10472, 0.76013, 0.087934, 0.25135, 0.24699, 0.25568, 0.28339]
Predicted label: 4
Correct prediction
Energy consumption = 189.502337 pJ
sum error= 289
Actual label: 6
Output voltages: [0.25854, 0.23296, 0.35924, 0.064659, 0.38846, 0.31437, 0.74878, 0.064947, 0.31161, 0.14194]
Predicted label: 6
Correct prediction
Energy consumption = 185.161343 pJ
sum error= 289
Actual label: 0
Output voltages: [0.72134, 0.21384, 0.28651, 0.13867, 0.10711, 0.23582, 0.35849, 0.14969, 0.24017, 0.29074]
Predicted label: 0
Correct prediction
Energy consumption = 193.194259 pJ
sum error= 289
Actual label: 2
Output voltages: [0.33045, 0.17911, 0.73504, 0.33835, 0.11083, 0.034254, 0.26089, 0.51677, 0.37788, 0.25632]
Predicted label: 2
Correct prediction
Energy consumption = 182.127242 pJ
sum error= 289
Actual label: 0
Output voltages: [0.6807, 0.21116, 0.26089, 0.12791, 0.15691, 0.1671, 0.48469, 0.11769, 0.30631, 0.25026]
Predicted label: 0
Correct prediction
Energy consumption = 194.963438 pJ
sum error= 289
Actual label: 7
Output voltages: [0.4425, 0.21164, 0.20321, 0.14752, 0.22558, 0.18588, 0.062447, 0.74384, 0.28547, 0.33808]
Predicted label: 7
Correct prediction
Energy consumption = 189.349904 pJ
sum error= 289
Actual label: 0
Output voltages: [0.72337, 0.24249, 0.31905, 0.13464, 0.14875, 0.18891, 0.40914, 0.16988, 0.25021, 0.30167]
Predicted label: 0
Correct prediction
Energy consumption = 186.895087 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 946 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 946 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 946 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.2929, 0.21861, 0.32602, 0.76173, 0.15164, 0.096563, 0.14304, 0.18575, 0.45504, 0.22153]
Predicted label: 3
Correct prediction
Energy consumption = 175.531903 pJ
sum error= 289
Actual label: 6
Output voltages: [0.28117, 0.20752, 0.27451, 0.1586, 0.3396, 0.41818, 0.74495, 0.061615, 0.42327, 0.19082]
Predicted label: 6
Correct prediction
Energy consumption = 190.618239 pJ
sum error= 289
Actual label: 8
Output voltages: [0.19119, 0.20726, 0.32348, 0.22493, 0.16918, 0.24086, 0.20328, 0.17116, 0.75599, 0.25799]
Predicted label: 8
Correct prediction
Energy consumption = 197.251660 pJ
sum error= 289
Actual label: 7
Output voltages: [0.37298, 0.13384, 0.18625, 0.25581, 0.23037, 0.11415, 0.045712, 0.69853, 0.40961, 0.39123]
Predicted label: 7
Correct prediction
Energy consumption = 198.275795 pJ
sum error= 289
Actual label: 1
Output voltages: [0.1436, 0.76711, 0.16946, 0.25034, 0.20617, 0.097075, 0.38668, 0.14566, 0.36086, 0.22428]
Predicted label: 1
Correct prediction
Energy consumption = 211.837518 pJ
sum error= 289
Actual label: 5
Output voltages: [0.26666, 0.10175, 0.12658, 0.46914, 0.20144, 0.70863, 0.34285, 0.11602, 0.374, 0.18975]
Predicted label: 5
Correct prediction
Energy consumption = 198.878437 pJ
sum error= 289
Actual label: 9
Output voltages: [0.32986, 0.12027, 0.17493, 0.27464, 0.34644, 0.08496, 0.064424, 0.16328, 0.39163, 0.63533]
Predicted label: 9
Correct prediction
Energy consumption = 194.953130 pJ
sum error= 289
Actual label: 9
Output voltages: [0.339, 0.13367, 0.22774, 0.25718, 0.33757, 0.17473, 0.10748, 0.20579, 0.36892, 0.67608]
Predicted label: 9
Correct prediction
Energy consumption = 184.402290 pJ
sum error= 289
Actual label: 3
Output voltages: [0.33329, 0.17889, 0.37917, 0.73954, 0.12543, 0.12622, 0.084624, 0.14852, 0.57215, 0.15884]
Predicted label: 3
Correct prediction
Energy consumption = 185.635243 pJ
sum error= 289
Actual label: 7
Output voltages: [0.27014, 0.25047, 0.17638, 0.34597, 0.08498, 0.22666, 0.033596, 0.71913, 0.34665, 0.35162]
Predicted label: 7
Correct prediction
Energy consumption = 202.538965 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 947 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 947 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 947 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36147, 0.11048, 0.74053, 0.32995, 0.14172, 0.048005, 0.23545, 0.27859, 0.4817, 0.1296]
Predicted label: 2
Correct prediction
Energy consumption = 185.516842 pJ
sum error= 289
Actual label: 4
Output voltages: [0.1943, 0.18883, 0.2991, 0.15101, 0.75335, 0.054307, 0.33519, 0.24773, 0.20243, 0.26343]
Predicted label: 4
Correct prediction
Energy consumption = 192.003988 pJ
sum error= 289
Actual label: 9
Output voltages: [0.36902, 0.093774, 0.18576, 0.19504, 0.50287, 0.19881, 0.21053, 0.29745, 0.25118, 0.64563]
Predicted label: 9
Correct prediction
Energy consumption = 193.019903 pJ
sum error= 289
Actual label: 4
Output voltages: [0.17875, 0.14719, 0.32085, 0.14707, 0.75064, 0.058004, 0.24407, 0.24489, 0.21957, 0.3044]
Predicted label: 4
Correct prediction
Energy consumption = 191.745126 pJ
sum error= 289
Actual label: 3
Output voltages: [0.32031, 0.15135, 0.27986, 0.73041, 0.1786, 0.35358, 0.15391, 0.16875, 0.42114, 0.26469]
Predicted label: 3
Correct prediction
Energy consumption = 204.646725 pJ
sum error= 289
Actual label: 6
Output voltages: [0.28482, 0.23134, 0.32205, 0.069893, 0.30306, 0.37014, 0.74202, 0.061088, 0.3473, 0.18999]
Predicted label: 6
Correct prediction
Energy consumption = 190.376080 pJ
sum error= 289
Actual label: 2
Output voltages: [0.33043, 0.20125, 0.75234, 0.29101, 0.18114, 0.04345, 0.27852, 0.24608, 0.4264, 0.19963]
Predicted label: 2
Correct prediction
Energy consumption = 180.997022 pJ
sum error= 289
Actual label: 2
Output voltages: [0.31866, 0.10609, 0.7489, 0.30355, 0.19297, 0.043949, 0.17305, 0.35702, 0.43373, 0.16168]
Predicted label: 2
Correct prediction
Energy consumption = 173.962942 pJ
sum error= 289
Actual label: 5
Output voltages: [0.27804, 0.13969, 0.053964, 0.38201, 0.23481, 0.68702, 0.32561, 0.055265, 0.5127, 0.098702]
Predicted label: 5
Correct prediction
Energy consumption = 203.091111 pJ
sum error= 289
Actual label: 3
Output voltages: [0.31518, 0.22749, 0.35353, 0.75358, 0.13527, 0.16069, 0.11587, 0.15744, 0.49488, 0.17588]
Predicted label: 3
Correct prediction
Energy consumption = 182.833996 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 948 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 948 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 948 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.34545, 0.227, 0.75736, 0.28077, 0.1759, 0.037287, 0.26751, 0.24695, 0.39227, 0.17629]
Predicted label: 2
Correct prediction
Energy consumption = 185.286845 pJ
sum error= 289
Actual label: 5
Output voltages: [0.23049, 0.077522, 0.055398, 0.3841, 0.24521, 0.74201, 0.27661, 0.1465, 0.50221, 0.14923]
Predicted label: 5
Correct prediction
Energy consumption = 190.739123 pJ
sum error= 289
Actual label: 5
Output voltages: [0.29026, 0.14554, 0.071526, 0.54437, 0.1871, 0.70872, 0.20204, 0.13847, 0.48272, 0.19556]
Predicted label: 5
Correct prediction
Energy consumption = 190.709713 pJ
sum error= 289
Actual label: 9
Output voltages: [0.2807, 0.14043, 0.159, 0.26757, 0.24763, 0.19319, 0.08327, 0.15637, 0.45687, 0.59931]
Predicted label: 9
Correct prediction
Energy consumption = 194.219902 pJ
sum error= 289
Actual label: 4
Output voltages: [0.17574, 0.12233, 0.27246, 0.087758, 0.74465, 0.089438, 0.26692, 0.27087, 0.30323, 0.2367]
Predicted label: 4
Correct prediction
Energy consumption = 192.686325 pJ
sum error= 289
Actual label: 1
Output voltages: [0.17805, 0.7204, 0.17903, 0.17771, 0.35223, 0.093929, 0.32822, 0.085075, 0.33619, 0.33529]
Predicted label: 1
Correct prediction
Energy consumption = 209.628739 pJ
sum error= 289
Actual label: 7
Output voltages: [0.32544, 0.1981, 0.1726, 0.31361, 0.16022, 0.19713, 0.046759, 0.75919, 0.30452, 0.35588]
Predicted label: 7
Correct prediction
Energy consumption = 196.261641 pJ
sum error= 289
Actual label: 2
Output voltages: [0.41141, 0.13707, 0.74749, 0.35069, 0.13086, 0.056427, 0.26773, 0.31278, 0.39747, 0.13871]
Predicted label: 2
Correct prediction
Energy consumption = 184.444717 pJ
sum error= 289
Actual label: 0
Output voltages: [0.72871, 0.19495, 0.23134, 0.19403, 0.10816, 0.24098, 0.40303, 0.20142, 0.25957, 0.28575]
Predicted label: 0
Correct prediction
Energy consumption = 185.235618 pJ
sum error= 289
Actual label: 1
Output voltages: [0.18215, 0.75124, 0.34035, 0.20239, 0.23124, 0.061265, 0.40875, 0.13603, 0.3314, 0.20714]
Predicted label: 1
Correct prediction
Energy consumption = 211.401807 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 949 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 949 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 949 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.30762, 0.38585, 0.67799, 0.38329, 0.10695, 0.037213, 0.24671, 0.23781, 0.4092, 0.15225]
Predicted label: 2
Correct prediction
Energy consumption = 191.607404 pJ
sum error= 289
Actual label: 3
Output voltages: [0.28753, 0.17445, 0.22272, 0.73882, 0.19447, 0.18595, 0.094056, 0.4477, 0.4006, 0.30809]
Predicted label: 3
Correct prediction
Energy consumption = 193.988117 pJ
sum error= 289
Actual label: 4
Output voltages: [0.20413, 0.14656, 0.40676, 0.1893, 0.68421, 0.11296, 0.27098, 0.11432, 0.34492, 0.41238]
Predicted label: 4
Correct prediction
Energy consumption = 194.493947 pJ
sum error= 289
Actual label: 5
Output voltages: [0.20874, 0.049769, 0.11343, 0.25204, 0.27551, 0.67712, 0.26849, 0.15918, 0.5737, 0.27389]
Predicted label: 5
Correct prediction
Energy consumption = 184.255042 pJ
sum error= 289
Actual label: 6
Output voltages: [0.32137, 0.21908, 0.42034, 0.040103, 0.37157, 0.2345, 0.73523, 0.082126, 0.29272, 0.17804]
Predicted label: 6
Correct prediction
Energy consumption = 191.115110 pJ
sum error= 289
Actual label: 7
Output voltages: [0.28868, 0.30023, 0.27011, 0.28343, 0.096397, 0.057498, 0.04751, 0.72437, 0.31755, 0.44466]
Predicted label: 7
Correct prediction
Energy consumption = 204.965592 pJ
sum error= 289
Actual label: 8
Output voltages: [0.17269, 0.29137, 0.3136, 0.22093, 0.18083, 0.16692, 0.20289, 0.26298, 0.74885, 0.22872]
Predicted label: 8
Correct prediction
Energy consumption = 190.719779 pJ
sum error= 289
Actual label: 9
Output voltages: [0.2158, 0.15228, 0.21599, 0.21142, 0.19476, 0.16744, 0.087262, 0.19471, 0.55793, 0.59337]
Predicted label: 9
Correct prediction
Energy consumption = 187.184250 pJ
sum error= 289
Actual label: 0
Output voltages: [0.73425, 0.26364, 0.24562, 0.18429, 0.13054, 0.18995, 0.4016, 0.17632, 0.27756, 0.27178]
Predicted label: 0
Correct prediction
Energy consumption = 190.508479 pJ
sum error= 289
Actual label: 1
Output voltages: [0.23958, 0.76101, 0.28196, 0.31457, 0.20485, 0.059831, 0.42955, 0.13551, 0.25514, 0.19149]
Predicted label: 1
Correct prediction
Energy consumption = 210.306453 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 950 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 950 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 950 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.26935, 0.20667, 0.73283, 0.31041, 0.15453, 0.038095, 0.17569, 0.40372, 0.43582, 0.14742]
Predicted label: 2
Correct prediction
Energy consumption = 185.277988 pJ
sum error= 289
Actual label: 3
Output voltages: [0.27072, 0.19322, 0.2783, 0.75437, 0.11974, 0.14596, 0.09134, 0.30365, 0.46259, 0.26493]
Predicted label: 3
Correct prediction
Energy consumption = 181.152803 pJ
sum error= 289
Actual label: 4
Output voltages: [0.14421, 0.14529, 0.23307, 0.061545, 0.72593, 0.13218, 0.32245, 0.27454, 0.4231, 0.19058]
Predicted label: 4
Correct prediction
Energy consumption = 197.072180 pJ
sum error= 289
Actual label: 5
Output voltages: [0.20423, 0.051343, 0.088166, 0.23358, 0.27163, 0.62263, 0.3164, 0.12472, 0.52788, 0.28929]
Predicted label: 5
Correct prediction
Energy consumption = 185.910325 pJ
sum error= 289
Actual label: 6
Output voltages: [0.27995, 0.22491, 0.32234, 0.12271, 0.29129, 0.42276, 0.7473, 0.075431, 0.37213, 0.17659]
Predicted label: 6
Correct prediction
Energy consumption = 182.299256 pJ
sum error= 289
Actual label: 7
Output voltages: [0.36068, 0.24588, 0.52269, 0.34189, 0.069349, 0.03856, 0.083348, 0.5224, 0.47971, 0.33313]
Predicted label: 2
Wrong prediction!
Energy consumption = 200.607038 pJ
sum error= 290
Actual label: 8
Output voltages: [0.19596, 0.18545, 0.33501, 0.20337, 0.19637, 0.10458, 0.16397, 0.27364, 0.74056, 0.27163]
Predicted label: 8
Correct prediction
Energy consumption = 189.819954 pJ
sum error= 290
Actual label: 9
Output voltages: [0.27514, 0.15934, 0.20866, 0.19617, 0.26877, 0.17664, 0.087511, 0.14116, 0.46952, 0.64974]
Predicted label: 9
Correct prediction
Energy consumption = 186.611496 pJ
sum error= 290
Actual label: 0
Output voltages: [0.67825, 0.17109, 0.23337, 0.23843, 0.19012, 0.13813, 0.30258, 0.22012, 0.41102, 0.1638]
Predicted label: 0
Correct prediction
Energy consumption = 195.842485 pJ
sum error= 290
Actual label: 1
Output voltages: [0.27695, 0.70655, 0.26199, 0.23719, 0.30814, 0.049701, 0.36357, 0.057005, 0.29917, 0.2763]
Predicted label: 1
Correct prediction
Energy consumption = 201.813881 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 951 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 951 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 951 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.34872, 0.16617, 0.74136, 0.30316, 0.1846, 0.039977, 0.23844, 0.32966, 0.46559, 0.16357]
Predicted label: 2
Correct prediction
Energy consumption = 188.470179 pJ
sum error= 290
Actual label: 3
Output voltages: [0.37343, 0.16838, 0.24147, 0.75664, 0.11655, 0.27569, 0.095528, 0.27371, 0.40407, 0.19893]
Predicted label: 3
Correct prediction
Energy consumption = 192.667189 pJ
sum error= 290
Actual label: 4
Output voltages: [0.14994, 0.18383, 0.24083, 0.15159, 0.72216, 0.071332, 0.17863, 0.24684, 0.29823, 0.29023]
Predicted label: 4
Correct prediction
Energy consumption = 193.073204 pJ
sum error= 290
Actual label: 5
Output voltages: [0.22907, 0.087889, 0.045395, 0.34149, 0.34848, 0.52475, 0.34274, 0.25428, 0.46826, 0.18806]
Predicted label: 5
Correct prediction
Energy consumption = 191.404317 pJ
sum error= 290
Actual label: 6
Output voltages: [0.30126, 0.23801, 0.31625, 0.093463, 0.3642, 0.33661, 0.74634, 0.071838, 0.32365, 0.14237]
Predicted label: 6
Correct prediction
Energy consumption = 188.028710 pJ
sum error= 290
Actual label: 7
Output voltages: [0.27292, 0.31129, 0.34747, 0.26235, 0.12849, 0.062672, 0.042762, 0.75141, 0.40744, 0.26396]
Predicted label: 7
Correct prediction
Energy consumption = 202.151347 pJ
sum error= 290
Actual label: 8
Output voltages: [0.20689, 0.2206, 0.29572, 0.25995, 0.16339, 0.25054, 0.23576, 0.17187, 0.75495, 0.23046]
Predicted label: 8
Correct prediction
Energy consumption = 186.114552 pJ
sum error= 290
Actual label: 9
Output voltages: [0.29091, 0.13477, 0.22194, 0.1912, 0.43048, 0.051274, 0.093181, 0.2345, 0.41068, 0.51704]
Predicted label: 9
Correct prediction
Energy consumption = 195.146992 pJ
sum error= 290
Actual label: 1
Output voltages: [0.24161, 0.74623, 0.30904, 0.24675, 0.32368, 0.11529, 0.42691, 0.059097, 0.29598, 0.2617]
Predicted label: 1
Correct prediction
Energy consumption = 205.657226 pJ
sum error= 290
Actual label: 0
Output voltages: [0.71288, 0.248, 0.26831, 0.15734, 0.14124, 0.12905, 0.40778, 0.1786, 0.32641, 0.26539]
Predicted label: 0
Correct prediction
Energy consumption = 187.920514 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 952 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 952 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 952 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.19953, 0.75272, 0.13584, 0.21817, 0.34747, 0.07579, 0.34232, 0.094038, 0.29911, 0.31998]
Predicted label: 1
Correct prediction
Energy consumption = 210.503286 pJ
sum error= 290
Actual label: 2
Output voltages: [0.32249, 0.19703, 0.67796, 0.38444, 0.17409, 0.032279, 0.21054, 0.25816, 0.47185, 0.21397]
Predicted label: 2
Correct prediction
Energy consumption = 186.266088 pJ
sum error= 290
Actual label: 7
Output voltages: [0.3244, 0.21195, 0.13895, 0.20531, 0.24999, 0.18755, 0.058122, 0.75303, 0.33531, 0.35694]
Predicted label: 7
Correct prediction
Energy consumption = 196.803426 pJ
sum error= 290
Actual label: 5
Output voltages: [0.24462, 0.049161, 0.14421, 0.31026, 0.23856, 0.65056, 0.30992, 0.13379, 0.47694, 0.27853]
Predicted label: 5
Correct prediction
Energy consumption = 187.719896 pJ
sum error= 290
Actual label: 3
Output voltages: [0.39369, 0.19639, 0.35327, 0.75242, 0.19298, 0.16933, 0.13887, 0.23143, 0.36138, 0.20251]
Predicted label: 3
Correct prediction
Energy consumption = 194.104586 pJ
sum error= 290
Actual label: 4
Output voltages: [0.098316, 0.17346, 0.21926, 0.1033, 0.74988, 0.12095, 0.29232, 0.40233, 0.25972, 0.19409]
Predicted label: 4
Correct prediction
Energy consumption = 189.911308 pJ
sum error= 290
Actual label: 4
Output voltages: [0.14158, 0.15407, 0.24191, 0.076091, 0.74983, 0.19318, 0.37501, 0.27929, 0.33025, 0.16532]
Predicted label: 4
Correct prediction
Energy consumption = 188.593550 pJ
sum error= 290
Actual label: 0
Output voltages: [0.63003, 0.20669, 0.27027, 0.13906, 0.19509, 0.15204, 0.54566, 0.12602, 0.29585, 0.28357]
Predicted label: 0
Correct prediction
Energy consumption = 192.934300 pJ
sum error= 290
Actual label: 0
Output voltages: [0.7314, 0.25223, 0.31703, 0.18626, 0.13956, 0.14502, 0.39883, 0.18549, 0.30677, 0.22427]
Predicted label: 0
Correct prediction
Energy consumption = 184.653766 pJ
sum error= 290
Actual label: 6
Output voltages: [0.27505, 0.22531, 0.30373, 0.10236, 0.36731, 0.35092, 0.74715, 0.075894, 0.37048, 0.11388]
Predicted label: 6
Correct prediction
Energy consumption = 187.474616 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 953 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 953 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 953 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24332, 0.28037, 0.14806, 0.18563, 0.25645, 0.14226, 0.17588, 0.15947, 0.5268, 0.49848]
Predicted label: 8
Wrong prediction!
Energy consumption = 208.418984 pJ
sum error= 291
Actual label: 6
Output voltages: [0.28139, 0.21277, 0.31663, 0.08147, 0.38145, 0.32637, 0.74208, 0.089247, 0.33065, 0.10105]
Predicted label: 6
Correct prediction
Energy consumption = 196.707295 pJ
sum error= 291
Actual label: 6
Output voltages: [0.35484, 0.25858, 0.29749, 0.10407, 0.28036, 0.29931, 0.74013, 0.091756, 0.34345, 0.18647]
Predicted label: 6
Correct prediction
Energy consumption = 184.631173 pJ
sum error= 291
Actual label: 5
Output voltages: [0.28439, 0.042299, 0.042747, 0.33597, 0.34062, 0.71889, 0.32983, 0.098732, 0.50441, 0.16135]
Predicted label: 5
Correct prediction
Energy consumption = 187.323073 pJ
sum error= 291
Actual label: 7
Output voltages: [0.43945, 0.16006, 0.2337, 0.37392, 0.17676, 0.14386, 0.040938, 0.64431, 0.30318, 0.3985]
Predicted label: 7
Correct prediction
Energy consumption = 202.916748 pJ
sum error= 291
Actual label: 2
Output voltages: [0.36965, 0.21191, 0.6277, 0.19165, 0.24718, 0.053913, 0.24927, 0.10074, 0.5558, 0.24378]
Predicted label: 2
Correct prediction
Energy consumption = 194.442319 pJ
sum error= 291
Actual label: 3
Output voltages: [0.24376, 0.25259, 0.24244, 0.74747, 0.10023, 0.13955, 0.073088, 0.25822, 0.44659, 0.33274]
Predicted label: 3
Correct prediction
Energy consumption = 182.887918 pJ
sum error= 291
Actual label: 4
Output voltages: [0.15402, 0.19876, 0.24434, 0.17554, 0.73973, 0.049473, 0.19183, 0.23517, 0.31511, 0.21581]
Predicted label: 4
Correct prediction
Energy consumption = 193.614182 pJ
sum error= 291
Actual label: 4
Output voltages: [0.093043, 0.2894, 0.15713, 0.13711, 0.61012, 0.16089, 0.22629, 0.26997, 0.44939, 0.27592]
Predicted label: 4
Correct prediction
Energy consumption = 194.752211 pJ
sum error= 291
Actual label: 9
Output voltages: [0.29472, 0.12227, 0.21228, 0.18792, 0.25873, 0.10164, 0.050119, 0.24762, 0.52076, 0.59321]
Predicted label: 9
Correct prediction
Energy consumption = 193.361921 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 954 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 954 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 954 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.13178, 0.59028, 0.18848, 0.34743, 0.19789, 0.075516, 0.19832, 0.14294, 0.5026, 0.32654]
Predicted label: 1
Correct prediction
Energy consumption = 208.357683 pJ
sum error= 291
Actual label: 4
Output voltages: [0.12036, 0.29955, 0.19304, 0.10047, 0.63756, 0.18973, 0.28349, 0.15349, 0.37727, 0.29083]
Predicted label: 4
Correct prediction
Energy consumption = 198.157107 pJ
sum error= 291
Actual label: 0
Output voltages: [0.63655, 0.16824, 0.34213, 0.30348, 0.075176, 0.083933, 0.22392, 0.24456, 0.51488, 0.19554]
Predicted label: 0
Correct prediction
Energy consumption = 200.343573 pJ
sum error= 291
Actual label: 7
Output voltages: [0.31824, 0.21974, 0.21726, 0.30517, 0.13201, 0.13234, 0.036461, 0.74758, 0.36329, 0.40548]
Predicted label: 7
Correct prediction
Energy consumption = 192.398231 pJ
sum error= 291
Actual label: 9
Output voltages: [0.35796, 0.076281, 0.1938, 0.28359, 0.37689, 0.22038, 0.083875, 0.37799, 0.36561, 0.55771]
Predicted label: 9
Correct prediction
Energy consumption = 192.376834 pJ
sum error= 291
Actual label: 5
Output voltages: [0.23822, 0.054177, 0.086332, 0.42553, 0.22894, 0.70559, 0.25448, 0.13172, 0.50649, 0.20962]
Predicted label: 5
Correct prediction
Energy consumption = 187.590897 pJ
sum error= 291
Actual label: 7
Output voltages: [0.41046, 0.1202, 0.14963, 0.27724, 0.22304, 0.22549, 0.052792, 0.73241, 0.40787, 0.28261]
Predicted label: 7
Correct prediction
Energy consumption = 192.031019 pJ
sum error= 291
Actual label: 2
Output voltages: [0.40783, 0.11244, 0.73794, 0.33879, 0.14828, 0.047696, 0.20805, 0.32963, 0.45412, 0.15352]
Predicted label: 2
Correct prediction
Energy consumption = 186.413914 pJ
sum error= 291
Actual label: 3
Output voltages: [0.36419, 0.12617, 0.37528, 0.74653, 0.20747, 0.14567, 0.12421, 0.19324, 0.46673, 0.2518]
Predicted label: 3
Correct prediction
Energy consumption = 184.001543 pJ
sum error= 291
Actual label: 1
Output voltages: [0.21095, 0.7561, 0.29419, 0.25212, 0.29581, 0.044235, 0.3309, 0.16334, 0.27497, 0.25931]
Predicted label: 1
Correct prediction
Energy consumption = 204.653802 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 955 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 955 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 955 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.18241, 0.17065, 0.30805, 0.084325, 0.74678, 0.058386, 0.32168, 0.26696, 0.22907, 0.23926]
Predicted label: 4
Correct prediction
Energy consumption = 198.757842 pJ
sum error= 291
Actual label: 4
Output voltages: [0.11403, 0.19569, 0.27552, 0.20254, 0.75107, 0.050783, 0.24335, 0.3093, 0.23258, 0.2242]
Predicted label: 4
Correct prediction
Energy consumption = 198.367756 pJ
sum error= 291
Actual label: 0
Output voltages: [0.67577, 0.2507, 0.24525, 0.22424, 0.15578, 0.11299, 0.43626, 0.20927, 0.38149, 0.3148]
Predicted label: 0
Correct prediction
Energy consumption = 205.495043 pJ
sum error= 291
Actual label: 9
Output voltages: [0.38171, 0.21128, 0.19374, 0.27612, 0.35812, 0.070893, 0.10238, 0.11676, 0.39131, 0.63781]
Predicted label: 9
Correct prediction
Energy consumption = 194.446814 pJ
sum error= 291
Actual label: 9
Output voltages: [0.3083, 0.14516, 0.23159, 0.19475, 0.30798, 0.077883, 0.042085, 0.29627, 0.47491, 0.58369]
Predicted label: 9
Correct prediction
Energy consumption = 193.404184 pJ
sum error= 291
Actual label: 6
Output voltages: [0.27858, 0.20827, 0.30307, 0.13273, 0.31742, 0.41016, 0.74187, 0.1388, 0.38631, 0.16363]
Predicted label: 6
Correct prediction
Energy consumption = 195.143033 pJ
sum error= 291
Actual label: 1
Output voltages: [0.33344, 0.58944, 0.30776, 0.21977, 0.2904, 0.051473, 0.41615, 0.044073, 0.37064, 0.25139]
Predicted label: 1
Correct prediction
Energy consumption = 202.044256 pJ
sum error= 291
Actual label: 8
Output voltages: [0.2393, 0.22352, 0.31459, 0.25861, 0.18425, 0.17945, 0.158, 0.19728, 0.75009, 0.23064]
Predicted label: 8
Correct prediction
Energy consumption = 189.978250 pJ
sum error= 291
Actual label: 3
Output voltages: [0.26973, 0.16498, 0.3275, 0.73848, 0.15649, 0.24654, 0.098557, 0.23263, 0.49787, 0.26488]
Predicted label: 3
Correct prediction
Energy consumption = 186.486813 pJ
sum error= 291
Actual label: 3
Output voltages: [0.34519, 0.1873, 0.47305, 0.674, 0.12174, 0.045816, 0.077885, 0.23268, 0.48761, 0.25711]
Predicted label: 3
Correct prediction
Energy consumption = 181.862693 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 956 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 956 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 956 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28044, 0.31055, 0.37781, 0.33973, 0.062009, 0.068167, 0.044963, 0.57463, 0.52899, 0.39226]
Predicted label: 7
Correct prediction
Energy consumption = 199.296357 pJ
sum error= 291
Actual label: 3
Output voltages: [0.2752, 0.15599, 0.33943, 0.74269, 0.16263, 0.19009, 0.085959, 0.21637, 0.46621, 0.27643]
Predicted label: 3
Correct prediction
Energy consumption = 183.101871 pJ
sum error= 291
Actual label: 9
Output voltages: [0.30115, 0.10774, 0.19572, 0.17035, 0.38604, 0.12361, 0.070333, 0.1701, 0.41874, 0.62297]
Predicted label: 9
Correct prediction
Energy consumption = 193.626208 pJ
sum error= 291
Actual label: 8
Output voltages: [0.30323, 0.19108, 0.31469, 0.25695, 0.20367, 0.26881, 0.28161, 0.14814, 0.73984, 0.24481]
Predicted label: 8
Correct prediction
Energy consumption = 187.928682 pJ
sum error= 291
Actual label: 8
Output voltages: [0.29236, 0.22327, 0.36236, 0.32953, 0.11454, 0.24162, 0.27962, 0.20335, 0.73336, 0.17425]
Predicted label: 8
Correct prediction
Energy consumption = 193.149375 pJ
sum error= 291
Actual label: 4
Output voltages: [0.16616, 0.18196, 0.25564, 0.080236, 0.74352, 0.14252, 0.44061, 0.27012, 0.26213, 0.23895]
Predicted label: 4
Correct prediction
Energy consumption = 197.869394 pJ
sum error= 291
Actual label: 7
Output voltages: [0.31423, 0.23425, 0.34686, 0.31263, 0.11814, 0.083686, 0.035984, 0.73582, 0.4009, 0.38908]
Predicted label: 7
Correct prediction
Energy consumption = 192.582142 pJ
sum error= 291
Actual label: 7
Output voltages: [0.26993, 0.28375, 0.29037, 0.31949, 0.094917, 0.066394, 0.039328, 0.75637, 0.30066, 0.32881]
Predicted label: 7
Correct prediction
Energy consumption = 186.535292 pJ
sum error= 291
Actual label: 6
Output voltages: [0.31766, 0.22057, 0.31687, 0.13422, 0.29469, 0.35347, 0.74441, 0.079806, 0.37875, 0.1752]
Predicted label: 6
Correct prediction
Energy consumption = 195.494202 pJ
sum error= 291
Actual label: 2
Output voltages: [0.33288, 0.32151, 0.73703, 0.32786, 0.16138, 0.029972, 0.22223, 0.31431, 0.36175, 0.24278]
Predicted label: 2
Correct prediction
Energy consumption = 187.405047 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 957 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 957 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 957 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23457, 0.76099, 0.2854, 0.1971, 0.29301, 0.077364, 0.4185, 0.12869, 0.27421, 0.20447]
Predicted label: 1
Correct prediction
Energy consumption = 205.106927 pJ
sum error= 291
Actual label: 9
Output voltages: [0.30951, 0.14578, 0.21984, 0.18015, 0.27914, 0.14354, 0.088383, 0.17777, 0.48511, 0.63444]
Predicted label: 9
Correct prediction
Energy consumption = 189.741336 pJ
sum error= 291
Actual label: 8
Output voltages: [0.20818, 0.13291, 0.25819, 0.27798, 0.19723, 0.27844, 0.25565, 0.10969, 0.7406, 0.26869]
Predicted label: 8
Correct prediction
Energy consumption = 192.531555 pJ
sum error= 291
Actual label: 7
Output voltages: [0.29637, 0.30432, 0.41334, 0.26699, 0.074179, 0.046757, 0.043364, 0.73493, 0.47637, 0.28366]
Predicted label: 7
Correct prediction
Energy consumption = 191.800868 pJ
sum error= 291
Actual label: 8
Output voltages: [0.28013, 0.18578, 0.31105, 0.30871, 0.13538, 0.2329, 0.1856, 0.14635, 0.75382, 0.2317]
Predicted label: 8
Correct prediction
Energy consumption = 188.671727 pJ
sum error= 291
Actual label: 8
Output voltages: [0.28147, 0.16432, 0.31449, 0.3848, 0.10604, 0.25497, 0.20985, 0.12233, 0.74371, 0.31307]
Predicted label: 8
Correct prediction
Energy consumption = 184.236543 pJ
sum error= 291
Actual label: 7
Output voltages: [0.29401, 0.24126, 0.173, 0.2847, 0.2171, 0.072933, 0.030896, 0.67782, 0.31513, 0.38599]
Predicted label: 7
Correct prediction
Energy consumption = 206.167923 pJ
sum error= 291
Actual label: 2
Output voltages: [0.20819, 0.33998, 0.72139, 0.33008, 0.15444, 0.027623, 0.23986, 0.29875, 0.3941, 0.17863]
Predicted label: 2
Correct prediction
Energy consumption = 189.928013 pJ
sum error= 291
Actual label: 2
Output voltages: [0.34685, 0.19264, 0.75139, 0.27549, 0.16104, 0.036516, 0.26391, 0.33199, 0.45518, 0.18162]
Predicted label: 2
Correct prediction
Energy consumption = 172.211129 pJ
sum error= 291
Actual label: 3
Output voltages: [0.32115, 0.1668, 0.31166, 0.75341, 0.17669, 0.2334, 0.14934, 0.16579, 0.41589, 0.24977]
Predicted label: 3
Correct prediction
Energy consumption = 180.482220 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 958 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 958 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 958 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32215, 0.13759, 0.1933, 0.23143, 0.31686, 0.12575, 0.055399, 0.17599, 0.44164, 0.65416]
Predicted label: 9
Correct prediction
Energy consumption = 197.844906 pJ
sum error= 291
Actual label: 3
Output voltages: [0.33491, 0.1643, 0.33447, 0.75424, 0.16088, 0.18996, 0.1263, 0.19758, 0.44281, 0.24697]
Predicted label: 3
Correct prediction
Energy consumption = 184.677307 pJ
sum error= 291
Actual label: 3
Output voltages: [0.40974, 0.20702, 0.25528, 0.76157, 0.13275, 0.2602, 0.11196, 0.20918, 0.42534, 0.22629]
Predicted label: 3
Correct prediction
Energy consumption = 182.773301 pJ
sum error= 291
Actual label: 5
Output voltages: [0.20866, 0.058419, 0.053012, 0.43586, 0.28533, 0.66753, 0.25781, 0.13283, 0.49894, 0.24849]
Predicted label: 5
Correct prediction
Energy consumption = 182.934532 pJ
sum error= 291
Actual label: 5
Output voltages: [0.24093, 0.051364, 0.083152, 0.24015, 0.1897, 0.74433, 0.26209, 0.21149, 0.60013, 0.16295]
Predicted label: 5
Correct prediction
Energy consumption = 184.740027 pJ
sum error= 291
Actual label: 0
Output voltages: [0.71348, 0.28448, 0.25662, 0.17339, 0.12117, 0.13285, 0.41884, 0.23457, 0.31535, 0.24558]
Predicted label: 0
Correct prediction
Energy consumption = 195.652910 pJ
sum error= 291
Actual label: 7
Output voltages: [0.40075, 0.17567, 0.38694, 0.36875, 0.12798, 0.03677, 0.054183, 0.71931, 0.35485, 0.23621]
Predicted label: 7
Correct prediction
Energy consumption = 198.578274 pJ
sum error= 291
Actual label: 9
Output voltages: [0.35297, 0.15718, 0.30566, 0.34746, 0.53953, 0.058287, 0.10717, 0.2643, 0.29489, 0.50307]
Predicted label: 4
Wrong prediction!
Energy consumption = 197.143648 pJ
sum error= 292
Actual label: 5
Output voltages: [0.20878, 0.064326, 0.12448, 0.29262, 0.20388, 0.63809, 0.28099, 0.099893, 0.49184, 0.3021]
Predicted label: 5
Correct prediction
Energy consumption = 189.716866 pJ
sum error= 292
Actual label: 6
Output voltages: [0.23963, 0.19739, 0.31415, 0.0725, 0.35628, 0.34588, 0.74135, 0.071128, 0.37193, 0.093053]
Predicted label: 6
Correct prediction
Energy consumption = 186.393294 pJ
sum error= 292
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 959 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 959 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 959 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24399, 0.070179, 0.085278, 0.32626, 0.22242, 0.67112, 0.32673, 0.079041, 0.53116, 0.22249]
Predicted label: 5
Correct prediction
Energy consumption = 187.003945 pJ
sum error= 292
Actual label: 1
Output voltages: [0.34717, 0.61547, 0.24861, 0.22724, 0.35871, 0.071125, 0.40903, 0.032575, 0.38151, 0.25816]
Predicted label: 1
Correct prediction
Energy consumption = 198.379453 pJ
sum error= 292
Actual label: 4
Output voltages: [0.16325, 0.11266, 0.25318, 0.074164, 0.71208, 0.096684, 0.35135, 0.29457, 0.41556, 0.1333]
Predicted label: 4
Correct prediction
Energy consumption = 192.487853 pJ
sum error= 292
Actual label: 1
Output voltages: [0.21122, 0.73544, 0.26497, 0.14803, 0.34806, 0.066374, 0.42105, 0.064827, 0.28884, 0.26521]
Predicted label: 1
Correct prediction
Energy consumption = 206.496152 pJ
sum error= 292
Actual label: 1
Output voltages: [0.27401, 0.57069, 0.19425, 0.23777, 0.34977, 0.11869, 0.44205, 0.035926, 0.49748, 0.25708]
Predicted label: 1
Correct prediction
Energy consumption = 199.294208 pJ
sum error= 292
Actual label: 2
Output voltages: [0.27084, 0.19819, 0.65608, 0.27337, 0.1954, 0.036034, 0.258, 0.46603, 0.47925, 0.093771]
Predicted label: 2
Correct prediction
Energy consumption = 185.972013 pJ
sum error= 292
Actual label: 8
Output voltages: [0.26459, 0.14668, 0.23423, 0.36462, 0.07531, 0.26684, 0.10688, 0.21905, 0.72872, 0.30071]
Predicted label: 8
Correct prediction
Energy consumption = 186.466337 pJ
sum error= 292
Actual label: 2
Output voltages: [0.40375, 0.19479, 0.75349, 0.25521, 0.18501, 0.04181, 0.24673, 0.2535, 0.39046, 0.19236]
Predicted label: 2
Correct prediction
Energy consumption = 181.437608 pJ
sum error= 292
Actual label: 6
Output voltages: [0.26513, 0.19536, 0.35079, 0.053529, 0.37243, 0.31764, 0.73664, 0.055804, 0.37047, 0.11783]
Predicted label: 6
Correct prediction
Energy consumption = 185.626255 pJ
sum error= 292
Actual label: 1
Output voltages: [0.17119, 0.70363, 0.17152, 0.32784, 0.26278, 0.17377, 0.48711, 0.17393, 0.35094, 0.12066]
Predicted label: 1
Correct prediction
Energy consumption = 208.430158 pJ
sum error= 292
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 960 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 960 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 960 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.33314, 0.038906, 0.077446, 0.30983, 0.27392, 0.63388, 0.3128, 0.1512, 0.5127, 0.1844]
Predicted label: 5
Correct prediction
Energy consumption = 196.207420 pJ
sum error= 292
Actual label: 0
Output voltages: [0.72024, 0.25299, 0.34961, 0.14749, 0.15614, 0.10989, 0.40699, 0.21536, 0.31766, 0.17179]
Predicted label: 0
Correct prediction
Energy consumption = 193.567363 pJ
sum error= 292
Actual label: 1
Output voltages: [0.25086, 0.73103, 0.30409, 0.25862, 0.45059, 0.048831, 0.3597, 0.14126, 0.1653, 0.27471]
Predicted label: 1
Correct prediction
Energy consumption = 209.108464 pJ
sum error= 292
Actual label: 2
Output voltages: [0.35318, 0.32023, 0.74886, 0.35254, 0.20765, 0.034646, 0.29958, 0.25067, 0.36105, 0.2573]
Predicted label: 2
Correct prediction
Energy consumption = 181.033712 pJ
sum error= 292
Actual label: 3
Output voltages: [0.3027, 0.144, 0.32215, 0.74636, 0.26807, 0.28234, 0.23832, 0.19478, 0.3744, 0.15635]
Predicted label: 3
Correct prediction
Energy consumption = 183.570776 pJ
sum error= 292
Actual label: 4
Output voltages: [0.22537, 0.14792, 0.42027, 0.19345, 0.71959, 0.034927, 0.17498, 0.33353, 0.24951, 0.23565]
Predicted label: 4
Correct prediction
Energy consumption = 189.705326 pJ
sum error= 292
Actual label: 5
Output voltages: [0.35421, 0.15955, 0.044556, 0.40027, 0.23445, 0.7474, 0.27588, 0.17337, 0.30727, 0.19009]
Predicted label: 5
Correct prediction
Energy consumption = 187.423869 pJ
sum error= 292
Actual label: 6
Output voltages: [0.3751, 0.28706, 0.28206, 0.22764, 0.30405, 0.28625, 0.64746, 0.16617, 0.38505, 0.061025]
Predicted label: 6
Correct prediction
Energy consumption = 195.483964 pJ
sum error= 292
Actual label: 7
Output voltages: [0.34452, 0.17437, 0.34449, 0.3334, 0.11095, 0.095986, 0.045439, 0.74646, 0.3749, 0.3594]
Predicted label: 7
Correct prediction
Energy consumption = 200.540062 pJ
sum error= 292
Actual label: 8
Output voltages: [0.17831, 0.2321, 0.34489, 0.2614, 0.15525, 0.15134, 0.18043, 0.14829, 0.74611, 0.32274]
Predicted label: 8
Correct prediction
Energy consumption = 175.656886 pJ
sum error= 292
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 961 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 961 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 961 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29414, 0.061876, 0.21006, 0.35795, 0.192, 0.23234, 0.0461, 0.36926, 0.4845, 0.5597]
Predicted label: 9
Correct prediction
Energy consumption = 195.168830 pJ
sum error= 292
Actual label: 0
Output voltages: [0.73707, 0.23593, 0.29049, 0.19492, 0.13778, 0.21645, 0.39654, 0.22497, 0.24108, 0.23758]
Predicted label: 0
Correct prediction
Energy consumption = 192.085703 pJ
sum error= 292
Actual label: 1
Output voltages: [0.20802, 0.54835, 0.43666, 0.4353, 0.36488, 0.032353, 0.13517, 0.19175, 0.29738, 0.33958]
Predicted label: 1
Correct prediction
Energy consumption = 199.390827 pJ
sum error= 292
Actual label: 2
Output voltages: [0.32171, 0.27489, 0.63686, 0.39579, 0.17754, 0.031258, 0.26641, 0.15881, 0.49259, 0.22548]
Predicted label: 2
Correct prediction
Energy consumption = 182.369977 pJ
sum error= 292
Actual label: 3
Output voltages: [0.42309, 0.072493, 0.27824, 0.72952, 0.20567, 0.39712, 0.11647, 0.19966, 0.45301, 0.09834]
Predicted label: 3
Correct prediction
Energy consumption = 181.209477 pJ
sum error= 292
Actual label: 4
Output voltages: [0.19484, 0.12889, 0.26737, 0.17198, 0.74386, 0.093826, 0.2812, 0.31495, 0.28551, 0.2339]
Predicted label: 4
Correct prediction
Energy consumption = 196.254401 pJ
sum error= 292
Actual label: 5
Output voltages: [0.26053, 0.089817, 0.11267, 0.41043, 0.1551, 0.73047, 0.31694, 0.16872, 0.50706, 0.1794]
Predicted label: 5
Correct prediction
Energy consumption = 185.450290 pJ
sum error= 292
Actual label: 6
Output voltages: [0.30715, 0.23256, 0.37734, 0.084032, 0.38328, 0.23575, 0.71595, 0.093732, 0.36528, 0.087474]
Predicted label: 6
Correct prediction
Energy consumption = 187.603682 pJ
sum error= 292
Actual label: 7
Output voltages: [0.40192, 0.25915, 0.57387, 0.26253, 0.073302, 0.035333, 0.081175, 0.66168, 0.34107, 0.23075]
Predicted label: 7
Correct prediction
Energy consumption = 193.529975 pJ
sum error= 292
Actual label: 8
Output voltages: [0.25128, 0.17638, 0.32213, 0.23124, 0.13621, 0.23399, 0.18594, 0.16555, 0.74439, 0.30294]
Predicted label: 8
Correct prediction
Energy consumption = 182.888544 pJ
sum error= 292
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 962 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 962 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 962 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.27076, 0.16618, 0.13, 0.2486, 0.36515, 0.18186, 0.075271, 0.40872, 0.31343, 0.48506]
Predicted label: 9
Correct prediction
Energy consumption = 205.890118 pJ
sum error= 292
Actual label: 0
Output voltages: [0.725, 0.23462, 0.1796, 0.1694, 0.1555, 0.23068, 0.43083, 0.20666, 0.33218, 0.17522]
Predicted label: 0
Correct prediction
Energy consumption = 197.535093 pJ
sum error= 292
Actual label: 1
Output voltages: [0.074745, 0.68035, 0.32826, 0.26704, 0.38701, 0.06442, 0.34652, 0.19753, 0.34364, 0.29228]
Predicted label: 1
Correct prediction
Energy consumption = 205.270226 pJ
sum error= 292
Actual label: 2
Output voltages: [0.31523, 0.25064, 0.72788, 0.40022, 0.1756, 0.038399, 0.20767, 0.30671, 0.40408, 0.16703]
Predicted label: 2
Correct prediction
Energy consumption = 184.237056 pJ
sum error= 292
Actual label: 3
Output voltages: [0.19778, 0.14983, 0.36339, 0.69973, 0.093801, 0.18349, 0.12072, 0.1178, 0.60546, 0.2053]
Predicted label: 3
Correct prediction
Energy consumption = 181.523966 pJ
sum error= 292
Actual label: 4
Output voltages: [0.20128, 0.082407, 0.29715, 0.17929, 0.64204, 0.051725, 0.12121, 0.16921, 0.33895, 0.39653]
Predicted label: 4
Correct prediction
Energy consumption = 193.127745 pJ
sum error= 292
Actual label: 5
Output voltages: [0.2718, 0.11293, 0.048703, 0.44147, 0.23595, 0.74917, 0.29715, 0.14145, 0.41416, 0.11223]
Predicted label: 5
Correct prediction
Energy consumption = 189.129631 pJ
sum error= 292
Actual label: 6
Output voltages: [0.2911, 0.21341, 0.32554, 0.11937, 0.44321, 0.22646, 0.64585, 0.14724, 0.36583, 0.06801]
Predicted label: 6
Correct prediction
Energy consumption = 189.024418 pJ
sum error= 292
Actual label: 7
Output voltages: [0.4434, 0.16436, 0.44309, 0.2832, 0.07731, 0.069876, 0.064939, 0.70868, 0.40316, 0.28454]
Predicted label: 7
Correct prediction
Energy consumption = 196.724966 pJ
sum error= 292
Actual label: 8
Output voltages: [0.22557, 0.097657, 0.35516, 0.26484, 0.19627, 0.26763, 0.19436, 0.15942, 0.74619, 0.18096]
Predicted label: 8
Correct prediction
Energy consumption = 187.561147 pJ
sum error= 292
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 963 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 963 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 963 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.21738, 0.20216, 0.34031, 0.29467, 0.13046, 0.1789, 0.18815, 0.1548, 0.7475, 0.29485]
Predicted label: 8
Correct prediction
Energy consumption = 191.892850 pJ
sum error= 292
Actual label: 0
Output voltages: [0.68935, 0.25819, 0.29572, 0.17929, 0.21423, 0.098902, 0.39556, 0.14183, 0.3425, 0.20671]
Predicted label: 0
Correct prediction
Energy consumption = 195.669077 pJ
sum error= 292
Actual label: 6
Output voltages: [0.29242, 0.35064, 0.2945, 0.22573, 0.27783, 0.2823, 0.70087, 0.081191, 0.3605, 0.069989]
Predicted label: 6
Correct prediction
Energy consumption = 193.069043 pJ
sum error= 292
Actual label: 0
Output voltages: [0.71552, 0.22986, 0.23233, 0.21177, 0.20884, 0.071573, 0.22796, 0.31495, 0.36975, 0.17907]
Predicted label: 0
Correct prediction
Energy consumption = 192.549579 pJ
sum error= 292
Actual label: 0
Output voltages: [0.43011, 0.40807, 0.28207, 0.34001, 0.085789, 0.084549, 0.43971, 0.055658, 0.55045, 0.17089]
Predicted label: 8
Wrong prediction!
Energy consumption = 200.605866 pJ
sum error= 293
Actual label: 2
Output voltages: [0.36804, 0.29347, 0.73825, 0.36997, 0.22176, 0.034303, 0.28576, 0.24819, 0.37301, 0.22049]
Predicted label: 2
Correct prediction
Energy consumption = 183.927831 pJ
sum error= 293
Actual label: 3
Output voltages: [0.38391, 0.17036, 0.23027, 0.73379, 0.16465, 0.38772, 0.25922, 0.25101, 0.34869, 0.099861]
Predicted label: 3
Correct prediction
Energy consumption = 181.785065 pJ
sum error= 293
Actual label: 7
Output voltages: [0.36569, 0.19144, 0.26866, 0.36917, 0.070067, 0.066293, 0.050016, 0.73625, 0.4236, 0.26637]
Predicted label: 7
Correct prediction
Energy consumption = 189.071175 pJ
sum error= 293
Actual label: 9
Output voltages: [0.38898, 0.17701, 0.23546, 0.30717, 0.26089, 0.14269, 0.072424, 0.34514, 0.32306, 0.65817]
Predicted label: 9
Correct prediction
Energy consumption = 187.321505 pJ
sum error= 293
Actual label: 4
Output voltages: [0.12708, 0.19222, 0.21518, 0.14955, 0.75512, 0.077396, 0.26412, 0.35309, 0.23874, 0.19925]
Predicted label: 4
Correct prediction
Energy consumption = 195.755357 pJ
sum error= 293
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 964 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 964 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 964 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28574, 0.27907, 0.43462, 0.37289, 0.097541, 0.04372, 0.041024, 0.71441, 0.36212, 0.34817]
Predicted label: 7
Correct prediction
Energy consumption = 193.246715 pJ
sum error= 293
Actual label: 1
Output voltages: [0.22382, 0.73626, 0.2257, 0.25312, 0.43813, 0.048947, 0.33956, 0.082013, 0.19349, 0.28882]
Predicted label: 1
Correct prediction
Energy consumption = 207.099530 pJ
sum error= 293
Actual label: 9
Output voltages: [0.46643, 0.12065, 0.19593, 0.24923, 0.32102, 0.22135, 0.095813, 0.42292, 0.26931, 0.59732]
Predicted label: 9
Correct prediction
Energy consumption = 197.191521 pJ
sum error= 293
Actual label: 1
Output voltages: [0.28845, 0.55618, 0.25359, 0.30389, 0.40469, 0.038133, 0.096679, 0.24067, 0.24992, 0.34737]
Predicted label: 1
Correct prediction
Energy consumption = 201.132804 pJ
sum error= 293
Actual label: 7
Output voltages: [0.34262, 0.28133, 0.42896, 0.3795, 0.099386, 0.04643, 0.052039, 0.74297, 0.26374, 0.335]
Predicted label: 7
Correct prediction
Energy consumption = 192.619056 pJ
sum error= 293
Actual label: 1
Output voltages: [0.18331, 0.69488, 0.29458, 0.17877, 0.48667, 0.045914, 0.23389, 0.23824, 0.18494, 0.30389]
Predicted label: 1
Correct prediction
Energy consumption = 205.129119 pJ
sum error= 293
Actual label: 4
Output voltages: [0.20413, 0.13194, 0.25604, 0.21154, 0.72998, 0.058135, 0.20059, 0.34779, 0.33443, 0.18947]
Predicted label: 4
Correct prediction
Energy consumption = 194.476705 pJ
sum error= 293
Actual label: 0
Output voltages: [0.7327, 0.26081, 0.2418, 0.13648, 0.15621, 0.15822, 0.39071, 0.2489, 0.29353, 0.23132]
Predicted label: 0
Correct prediction
Energy consumption = 192.231689 pJ
sum error= 293
Actual label: 0
Output voltages: [0.70506, 0.23926, 0.28295, 0.14002, 0.17053, 0.112, 0.42221, 0.17685, 0.36361, 0.18527]
Predicted label: 0
Correct prediction
Energy consumption = 182.629740 pJ
sum error= 293
Actual label: 1
Output voltages: [0.1189, 0.72861, 0.25722, 0.26327, 0.26662, 0.062965, 0.25535, 0.13849, 0.38787, 0.24097]
Predicted label: 1
Correct prediction
Energy consumption = 189.448726 pJ
sum error= 293
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 965 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 965 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 965 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.38608, 0.25533, 0.17757, 0.21206, 0.25029, 0.22823, 0.055774, 0.75678, 0.19933, 0.26444]
Predicted label: 7
Correct prediction
Energy consumption = 196.325306 pJ
sum error= 293
Actual label: 5
Output voltages: [0.2485, 0.1359, 0.054698, 0.43015, 0.2311, 0.75256, 0.28791, 0.15098, 0.42676, 0.14088]
Predicted label: 5
Correct prediction
Energy consumption = 192.407665 pJ
sum error= 293
Actual label: 7
Output voltages: [0.37363, 0.14876, 0.31093, 0.29997, 0.2151, 0.17671, 0.064927, 0.59789, 0.25003, 0.45328]
Predicted label: 7
Correct prediction
Energy consumption = 202.283609 pJ
sum error= 293
Actual label: 1
Output voltages: [0.24353, 0.65378, 0.27389, 0.19901, 0.34203, 0.0401, 0.19957, 0.13397, 0.35899, 0.31874]
Predicted label: 1
Correct prediction
Energy consumption = 200.384970 pJ
sum error= 293
Actual label: 3
Output voltages: [0.35632, 0.12545, 0.31663, 0.74443, 0.13728, 0.2332, 0.11907, 0.19707, 0.505, 0.14226]
Predicted label: 3
Correct prediction
Energy consumption = 179.709866 pJ
sum error= 293
Actual label: 3
Output voltages: [0.20349, 0.089238, 0.26603, 0.64119, 0.15409, 0.48883, 0.16283, 0.1889, 0.52394, 0.19246]
Predicted label: 3
Correct prediction
Energy consumption = 183.068268 pJ
sum error= 293
Actual label: 3
Output voltages: [0.385, 0.072368, 0.39484, 0.69614, 0.12472, 0.29542, 0.082613, 0.17887, 0.47953, 0.12178]
Predicted label: 3
Correct prediction
Energy consumption = 173.351091 pJ
sum error= 293
Actual label: 1
Output voltages: [0.24836, 0.69424, 0.36666, 0.17939, 0.38626, 0.045057, 0.31197, 0.087782, 0.31799, 0.28897]
Predicted label: 1
Correct prediction
Energy consumption = 201.580566 pJ
sum error= 293
Actual label: 6
Output voltages: [0.32766, 0.18192, 0.35895, 0.074329, 0.35821, 0.32078, 0.6958, 0.13814, 0.40347, 0.09203]
Predicted label: 6
Correct prediction
Energy consumption = 193.888951 pJ
sum error= 293
Actual label: 9
Output voltages: [0.32147, 0.14834, 0.19448, 0.28672, 0.36073, 0.15372, 0.085955, 0.16912, 0.36104, 0.6751]
Predicted label: 9
Correct prediction
Energy consumption = 194.041030 pJ
sum error= 293
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 966 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 966 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 966 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.38755, 0.22676, 0.25371, 0.26572, 0.14846, 0.12309, 0.062069, 0.74989, 0.27976, 0.30491]
Predicted label: 7
Correct prediction
Energy consumption = 200.845407 pJ
sum error= 293
Actual label: 1
Output voltages: [0.18461, 0.71801, 0.23502, 0.26756, 0.37737, 0.039901, 0.30056, 0.10496, 0.30087, 0.31745]
Predicted label: 1
Correct prediction
Energy consumption = 205.685290 pJ
sum error= 293
Actual label: 3
Output voltages: [0.2574, 0.10884, 0.46315, 0.62348, 0.14641, 0.11824, 0.13286, 0.16707, 0.60858, 0.18242]
Predicted label: 3
Correct prediction
Energy consumption = 190.845223 pJ
sum error= 293
Actual label: 0
Output voltages: [0.63639, 0.2066, 0.35682, 0.14446, 0.2832, 0.064988, 0.42291, 0.19705, 0.33102, 0.1725]
Predicted label: 0
Correct prediction
Energy consumption = 189.994738 pJ
sum error= 293
Actual label: 2
Output voltages: [0.34746, 0.15087, 0.70718, 0.27457, 0.11145, 0.035934, 0.13177, 0.55261, 0.42432, 0.22506]
Predicted label: 2
Correct prediction
Energy consumption = 180.982214 pJ
sum error= 293
Actual label: 6
Output voltages: [0.33581, 0.15018, 0.26182, 0.09231, 0.39195, 0.30848, 0.71398, 0.10669, 0.37694, 0.10391]
Predicted label: 6
Correct prediction
Energy consumption = 190.516550 pJ
sum error= 293
Actual label: 0
Output voltages: [0.61884, 0.27707, 0.36605, 0.15954, 0.25811, 0.044096, 0.34447, 0.16823, 0.38912, 0.23598]
Predicted label: 0
Correct prediction
Energy consumption = 199.973283 pJ
sum error= 293
Actual label: 8
Output voltages: [0.14555, 0.23221, 0.34506, 0.23888, 0.15967, 0.1651, 0.17465, 0.17745, 0.74836, 0.26463]
Predicted label: 8
Correct prediction
Energy consumption = 189.784314 pJ
sum error= 293
Actual label: 9
Output voltages: [0.35955, 0.16276, 0.20386, 0.32414, 0.30616, 0.15422, 0.086448, 0.21748, 0.35581, 0.70583]
Predicted label: 9
Correct prediction
Energy consumption = 188.975843 pJ
sum error= 293
Actual label: 4
Output voltages: [0.16798, 0.30708, 0.19795, 0.32311, 0.71001, 0.089373, 0.084656, 0.28354, 0.11906, 0.38754]
Predicted label: 4
Correct prediction
Energy consumption = 193.852931 pJ
sum error= 293
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 967 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 967 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 967 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.25993, 0.17603, 0.30621, 0.73324, 0.11227, 0.23172, 0.122, 0.11641, 0.53202, 0.24192]
Predicted label: 3
Correct prediction
Energy consumption = 182.582883 pJ
sum error= 293
Actual label: 5
Output voltages: [0.31612, 0.13635, 0.066891, 0.34857, 0.21937, 0.73964, 0.29182, 0.060287, 0.44195, 0.23057]
Predicted label: 5
Correct prediction
Energy consumption = 188.157733 pJ
sum error= 293
Actual label: 4
Output voltages: [0.16105, 0.087511, 0.22067, 0.20887, 0.73577, 0.10361, 0.30145, 0.27974, 0.34412, 0.15139]
Predicted label: 4
Correct prediction
Energy consumption = 197.769435 pJ
sum error= 293
Actual label: 8
Output voltages: [0.21558, 0.17015, 0.25836, 0.29954, 0.15222, 0.26565, 0.16323, 0.13503, 0.74648, 0.30336]
Predicted label: 8
Correct prediction
Energy consumption = 186.067054 pJ
sum error= 293
Actual label: 1
Output voltages: [0.20036, 0.7155, 0.26411, 0.13836, 0.4079, 0.066965, 0.33466, 0.12327, 0.32871, 0.28297]
Predicted label: 1
Correct prediction
Energy consumption = 204.321814 pJ
sum error= 293
Actual label: 5
Output voltages: [0.38853, 0.080971, 0.051186, 0.35363, 0.25066, 0.75, 0.30822, 0.16091, 0.35901, 0.22441]
Predicted label: 5
Correct prediction
Energy consumption = 189.070717 pJ
sum error= 293
Actual label: 9
Output voltages: [0.31684, 0.15159, 0.18155, 0.3569, 0.32219, 0.14463, 0.055247, 0.22526, 0.36811, 0.65164]
Predicted label: 9
Correct prediction
Energy consumption = 184.859224 pJ
sum error= 293
Actual label: 0
Output voltages: [0.66005, 0.16528, 0.42187, 0.20651, 0.28809, 0.038695, 0.32555, 0.22889, 0.35433, 0.23956]
Predicted label: 0
Correct prediction
Energy consumption = 193.499002 pJ
sum error= 293
Actual label: 6
Output voltages: [0.28913, 0.21494, 0.38603, 0.058009, 0.42493, 0.25312, 0.70376, 0.095513, 0.30861, 0.075398]
Predicted label: 6
Correct prediction
Energy consumption = 188.783638 pJ
sum error= 293
Actual label: 6
Output voltages: [0.17139, 0.43414, 0.24392, 0.47374, 0.32835, 0.36922, 0.424, 0.29755, 0.092983, 0.03607]
Predicted label: 3
Wrong prediction!
Energy consumption = 192.158417 pJ
sum error= 294
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 968 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 968 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 968 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23623, 0.1954, 0.326, 0.74459, 0.11891, 0.14244, 0.11718, 0.14916, 0.52584, 0.23604]
Predicted label: 3
Correct prediction
Energy consumption = 189.519988 pJ
sum error= 294
Actual label: 8
Output voltages: [0.25174, 0.16749, 0.28773, 0.37935, 0.088001, 0.29097, 0.16602, 0.17109, 0.75138, 0.24269]
Predicted label: 8
Correct prediction
Energy consumption = 191.608430 pJ
sum error= 294
Actual label: 1
Output voltages: [0.20587, 0.73931, 0.3242, 0.26024, 0.28288, 0.044472, 0.28907, 0.13242, 0.30978, 0.29057]
Predicted label: 1
Correct prediction
Energy consumption = 210.274111 pJ
sum error= 294
Actual label: 4
Output voltages: [0.17162, 0.10259, 0.2619, 0.30852, 0.6795, 0.050274, 0.14791, 0.22004, 0.3078, 0.25205]
Predicted label: 4
Correct prediction
Energy consumption = 198.050726 pJ
sum error= 294
Actual label: 7
Output voltages: [0.42308, 0.18417, 0.1789, 0.20195, 0.22791, 0.18972, 0.08511, 0.75172, 0.25895, 0.28175]
Predicted label: 7
Correct prediction
Energy consumption = 191.399230 pJ
sum error= 294
Actual label: 5
Output voltages: [0.28417, 0.068364, 0.053017, 0.38382, 0.35734, 0.7451, 0.29754, 0.15215, 0.3387, 0.22007]
Predicted label: 5
Correct prediction
Energy consumption = 190.539047 pJ
sum error= 294
Actual label: 2
Output voltages: [0.24597, 0.32901, 0.72215, 0.36991, 0.25165, 0.030546, 0.18153, 0.28062, 0.35287, 0.19694]
Predicted label: 2
Correct prediction
Energy consumption = 184.261498 pJ
sum error= 294
Actual label: 0
Output voltages: [0.70389, 0.28178, 0.21872, 0.32768, 0.089828, 0.1658, 0.33532, 0.12638, 0.4094, 0.2485]
Predicted label: 0
Correct prediction
Energy consumption = 201.387858 pJ
sum error= 294
Actual label: 0
Output voltages: [0.7321, 0.19292, 0.24079, 0.13747, 0.19866, 0.18234, 0.37089, 0.22701, 0.37981, 0.17077]
Predicted label: 0
Correct prediction
Energy consumption = 187.035721 pJ
sum error= 294
Actual label: 1
Output voltages: [0.19664, 0.73311, 0.19661, 0.18375, 0.43616, 0.0705, 0.28886, 0.15805, 0.25511, 0.32152]
Predicted label: 1
Correct prediction
Energy consumption = 198.686201 pJ
sum error= 294
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 969 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 969 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 969 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.45085, 0.20463, 0.24904, 0.25911, 0.21553, 0.096631, 0.048299, 0.7538, 0.26604, 0.24807]
Predicted label: 7
Correct prediction
Energy consumption = 192.899872 pJ
sum error= 294
Actual label: 8
Output voltages: [0.209, 0.2063, 0.23066, 0.34081, 0.10674, 0.31499, 0.15, 0.21455, 0.7565, 0.24791]
Predicted label: 8
Correct prediction
Energy consumption = 187.306047 pJ
sum error= 294
Actual label: 9
Output voltages: [0.36027, 0.25318, 0.18111, 0.39152, 0.22054, 0.05632, 0.045242, 0.57926, 0.38357, 0.43156]
Predicted label: 7
Wrong prediction!
Energy consumption = 209.785864 pJ
sum error= 295
Actual label: 6
Output voltages: [0.33275, 0.17129, 0.23006, 0.19086, 0.22382, 0.45409, 0.65713, 0.13618, 0.43917, 0.14516]
Predicted label: 6
Correct prediction
Energy consumption = 198.722518 pJ
sum error= 295
Actual label: 8
Output voltages: [0.15762, 0.15929, 0.41771, 0.36539, 0.077508, 0.17354, 0.078002, 0.1864, 0.7257, 0.20314]
Predicted label: 8
Correct prediction
Energy consumption = 192.476652 pJ
sum error= 295
Actual label: 8
Output voltages: [0.17108, 0.1828, 0.27639, 0.43462, 0.10145, 0.19669, 0.14673, 0.16784, 0.71821, 0.25203]
Predicted label: 8
Correct prediction
Energy consumption = 184.025496 pJ
sum error= 295
Actual label: 2
Output voltages: [0.24762, 0.42413, 0.66353, 0.38799, 0.12262, 0.036509, 0.22984, 0.20591, 0.35182, 0.14363]
Predicted label: 2
Correct prediction
Energy consumption = 190.128735 pJ
sum error= 295
Actual label: 3
Output voltages: [0.2768, 0.13474, 0.30625, 0.7502, 0.22346, 0.27892, 0.18021, 0.21172, 0.49356, 0.1518]
Predicted label: 3
Correct prediction
Energy consumption = 177.281105 pJ
sum error= 295
Actual label: 6
Output voltages: [0.2913, 0.33274, 0.26901, 0.21924, 0.35937, 0.33948, 0.57262, 0.34641, 0.24916, 0.031312]
Predicted label: 6
Correct prediction
Energy consumption = 193.108768 pJ
sum error= 295
Actual label: 1
Output voltages: [0.26355, 0.60235, 0.32698, 0.17184, 0.38387, 0.045222, 0.20229, 0.13647, 0.39118, 0.32755]
Predicted label: 1
Correct prediction
Energy consumption = 207.961433 pJ
sum error= 295
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 970 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 970 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 970 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.17644, 0.18504, 0.60911, 0.2988, 0.15835, 0.037549, 0.30599, 0.34379, 0.50257, 0.1967]
Predicted label: 2
Correct prediction
Energy consumption = 187.881021 pJ
sum error= 295
Actual label: 9
Output voltages: [0.42461, 0.16299, 0.19068, 0.2839, 0.28713, 0.2427, 0.17288, 0.31976, 0.27505, 0.66285]
Predicted label: 9
Correct prediction
Energy consumption = 199.006938 pJ
sum error= 295
Actual label: 5
Output voltages: [0.33556, 0.071244, 0.054954, 0.42582, 0.13494, 0.75782, 0.29399, 0.26467, 0.44487, 0.12275]
Predicted label: 5
Correct prediction
Energy consumption = 185.712206 pJ
sum error= 295
Actual label: 2
Output voltages: [0.35021, 0.33935, 0.74686, 0.31568, 0.19983, 0.040441, 0.31502, 0.16901, 0.3881, 0.21703]
Predicted label: 2
Correct prediction
Energy consumption = 184.721520 pJ
sum error= 295
Actual label: 0
Output voltages: [0.7189, 0.24558, 0.2096, 0.18791, 0.17023, 0.13839, 0.33799, 0.15572, 0.39512, 0.3143]
Predicted label: 0
Correct prediction
Energy consumption = 193.755866 pJ
sum error= 295
Actual label: 1
Output voltages: [0.17582, 0.76171, 0.2618, 0.25533, 0.28097, 0.094115, 0.43843, 0.13461, 0.23964, 0.23249]
Predicted label: 1
Correct prediction
Energy consumption = 202.427624 pJ
sum error= 295
Actual label: 2
Output voltages: [0.34974, 0.21966, 0.72527, 0.36812, 0.14989, 0.042215, 0.2971, 0.31233, 0.31218, 0.14826]
Predicted label: 2
Correct prediction
Energy consumption = 195.208099 pJ
sum error= 295
Actual label: 3
Output voltages: [0.34296, 0.1649, 0.33208, 0.76178, 0.19236, 0.16105, 0.14739, 0.20941, 0.45421, 0.194]
Predicted label: 3
Correct prediction
Energy consumption = 180.983270 pJ
sum error= 295
Actual label: 4
Output voltages: [0.1536, 0.20138, 0.24025, 0.15308, 0.74597, 0.081459, 0.33643, 0.20467, 0.27719, 0.20637]
Predicted label: 4
Correct prediction
Energy consumption = 194.024310 pJ
sum error= 295
Actual label: 5
Output voltages: [0.32839, 0.13452, 0.09018, 0.3646, 0.21607, 0.67581, 0.48157, 0.10397, 0.45948, 0.077327]
Predicted label: 5
Correct prediction
Energy consumption = 185.557865 pJ
sum error= 295
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 971 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 971 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 971 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.36668, 0.18813, 0.28707, 0.093597, 0.29271, 0.30896, 0.70713, 0.051696, 0.40988, 0.20492]
Predicted label: 6
Correct prediction
Energy consumption = 186.457581 pJ
sum error= 295
Actual label: 7
Output voltages: [0.33159, 0.21194, 0.19805, 0.19376, 0.39906, 0.090249, 0.038396, 0.70362, 0.37208, 0.34648]
Predicted label: 7
Correct prediction
Energy consumption = 207.790607 pJ
sum error= 295
Actual label: 8
Output voltages: [0.29574, 0.28909, 0.23967, 0.32829, 0.088358, 0.40624, 0.26714, 0.12702, 0.69733, 0.18708]
Predicted label: 8
Correct prediction
Energy consumption = 199.386767 pJ
sum error= 295
Actual label: 9
Output voltages: [0.33711, 0.13902, 0.22465, 0.25326, 0.31395, 0.13147, 0.11067, 0.17646, 0.42106, 0.67346]
Predicted label: 9
Correct prediction
Energy consumption = 185.040055 pJ
sum error= 295
Actual label: 0
Output voltages: [0.65543, 0.21241, 0.13131, 0.20046, 0.14591, 0.28077, 0.49129, 0.21887, 0.30596, 0.2433]
Predicted label: 0
Correct prediction
Energy consumption = 195.174908 pJ
sum error= 295
Actual label: 1
Output voltages: [0.17839, 0.73951, 0.29862, 0.27941, 0.38911, 0.046653, 0.32498, 0.25328, 0.1694, 0.23191]
Predicted label: 1
Correct prediction
Energy consumption = 204.911009 pJ
sum error= 295
Actual label: 2
Output voltages: [0.59214, 0.27813, 0.53461, 0.38579, 0.13681, 0.082362, 0.24105, 0.21952, 0.18266, 0.25946]
Predicted label: 0
Wrong prediction!
Energy consumption = 202.661882 pJ
sum error= 296
Actual label: 3
Output voltages: [0.29291, 0.20534, 0.28484, 0.7624, 0.14567, 0.19792, 0.1435, 0.17753, 0.47771, 0.22566]
Predicted label: 3
Correct prediction
Energy consumption = 181.985336 pJ
sum error= 296
Actual label: 4
Output voltages: [0.14962, 0.12617, 0.24167, 0.1165, 0.75112, 0.13028, 0.36844, 0.26245, 0.33605, 0.16441]
Predicted label: 4
Correct prediction
Energy consumption = 194.831697 pJ
sum error= 296
Actual label: 5
Output voltages: [0.47344, 0.10963, 0.069464, 0.47956, 0.1418, 0.60312, 0.25309, 0.12863, 0.37441, 0.23589]
Predicted label: 5
Correct prediction
Energy consumption = 194.784717 pJ
sum error= 296
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 972 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 972 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 972 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32277, 0.10107, 0.17001, 0.21429, 0.26254, 0.46357, 0.61232, 0.046259, 0.47829, 0.16889]
Predicted label: 6
Correct prediction
Energy consumption = 188.326765 pJ
sum error= 296
Actual label: 7
Output voltages: [0.27358, 0.30385, 0.22713, 0.29484, 0.19257, 0.15151, 0.029505, 0.6544, 0.40803, 0.40358]
Predicted label: 7
Correct prediction
Energy consumption = 202.185050 pJ
sum error= 296
Actual label: 8
Output voltages: [0.24757, 0.28182, 0.17216, 0.37157, 0.17003, 0.28103, 0.2731, 0.10375, 0.71021, 0.22611]
Predicted label: 8
Correct prediction
Energy consumption = 198.936975 pJ
sum error= 296
Actual label: 9
Output voltages: [0.36895, 0.11197, 0.20882, 0.12893, 0.38353, 0.13376, 0.1017, 0.19816, 0.40507, 0.65563]
Predicted label: 9
Correct prediction
Energy consumption = 185.769190 pJ
sum error= 296
Actual label: 0
Output voltages: [0.73357, 0.23464, 0.20952, 0.15192, 0.20467, 0.24703, 0.41237, 0.27645, 0.24744, 0.17492]
Predicted label: 0
Correct prediction
Energy consumption = 189.098598 pJ
sum error= 296
Actual label: 1
Output voltages: [0.22709, 0.74247, 0.24158, 0.16456, 0.40077, 0.12992, 0.37109, 0.1745, 0.2841, 0.17334]
Predicted label: 1
Correct prediction
Energy consumption = 199.440484 pJ
sum error= 296
Actual label: 2
Output voltages: [0.37533, 0.281, 0.72134, 0.35631, 0.11319, 0.040484, 0.32405, 0.26833, 0.33076, 0.18786]
Predicted label: 2
Correct prediction
Energy consumption = 193.232616 pJ
sum error= 296
Actual label: 3
Output voltages: [0.35625, 0.15137, 0.26316, 0.75815, 0.17227, 0.26952, 0.10692, 0.2031, 0.42512, 0.23667]
Predicted label: 3
Correct prediction
Energy consumption = 182.608936 pJ
sum error= 296
Actual label: 4
Output voltages: [0.175, 0.24897, 0.24316, 0.15913, 0.74958, 0.057835, 0.2637, 0.21872, 0.23975, 0.27782]
Predicted label: 4
Correct prediction
Energy consumption = 196.487565 pJ
sum error= 296
Actual label: 5
Output voltages: [0.45281, 0.18649, 0.11154, 0.11618, 0.41841, 0.47262, 0.61017, 0.13927, 0.25931, 0.12571]
Predicted label: 6
Wrong prediction!
Energy consumption = 193.298224 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 973 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 973 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 973 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31967, 0.11131, 0.24814, 0.166, 0.29493, 0.40275, 0.69317, 0.047096, 0.4763, 0.18564]
Predicted label: 6
Correct prediction
Energy consumption = 186.539398 pJ
sum error= 297
Actual label: 7
Output voltages: [0.33233, 0.26907, 0.28915, 0.16946, 0.32171, 0.080767, 0.048686, 0.65601, 0.38971, 0.34929]
Predicted label: 7
Correct prediction
Energy consumption = 192.954464 pJ
sum error= 297
Actual label: 8
Output voltages: [0.31237, 0.11556, 0.19975, 0.38719, 0.098543, 0.42546, 0.24478, 0.10198, 0.70074, 0.18524]
Predicted label: 8
Correct prediction
Energy consumption = 194.876898 pJ
sum error= 297
Actual label: 9
Output voltages: [0.3046, 0.10997, 0.17785, 0.12865, 0.22401, 0.16278, 0.057149, 0.2707, 0.59183, 0.5594]
Predicted label: 8
Wrong prediction!
Energy consumption = 191.863873 pJ
sum error= 298
Actual label: 7
Output voltages: [0.43418, 0.20433, 0.15004, 0.26036, 0.31901, 0.17653, 0.068977, 0.68763, 0.2406, 0.30755]
Predicted label: 7
Correct prediction
Energy consumption = 201.746839 pJ
sum error= 298
Actual label: 4
Output voltages: [0.18952, 0.24157, 0.21721, 0.2603, 0.71237, 0.052082, 0.23491, 0.22415, 0.24369, 0.32434]
Predicted label: 4
Correct prediction
Energy consumption = 195.265699 pJ
sum error= 298
Actual label: 6
Output voltages: [0.33955, 0.10493, 0.17376, 0.22417, 0.25351, 0.49857, 0.62631, 0.048691, 0.45137, 0.25328]
Predicted label: 6
Correct prediction
Energy consumption = 186.507232 pJ
sum error= 298
Actual label: 1
Output voltages: [0.19038, 0.75742, 0.25207, 0.25412, 0.28004, 0.13724, 0.40255, 0.23815, 0.27666, 0.21322]
Predicted label: 1
Correct prediction
Energy consumption = 206.111816 pJ
sum error= 298
Actual label: 4
Output voltages: [0.25132, 0.25566, 0.31958, 0.3311, 0.59289, 0.048945, 0.21988, 0.14257, 0.38285, 0.14107]
Predicted label: 4
Correct prediction
Energy consumption = 199.078662 pJ
sum error= 298
Actual label: 0
Output voltages: [0.64861, 0.21791, 0.28864, 0.15106, 0.20853, 0.074686, 0.32362, 0.30944, 0.37634, 0.21459]
Predicted label: 0
Correct prediction
Energy consumption = 198.813546 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 974 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 974 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 974 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36877, 0.1452, 0.21251, 0.21255, 0.34595, 0.12906, 0.073781, 0.22207, 0.41552, 0.57679]
Predicted label: 9
Correct prediction
Energy consumption = 199.205948 pJ
sum error= 298
Actual label: 9
Output voltages: [0.39242, 0.18477, 0.19782, 0.24389, 0.45961, 0.063613, 0.14335, 0.27517, 0.26999, 0.53992]
Predicted label: 9
Correct prediction
Energy consumption = 199.694297 pJ
sum error= 298
Actual label: 3
Output voltages: [0.37984, 0.11458, 0.33505, 0.73905, 0.078002, 0.22628, 0.099407, 0.16818, 0.46549, 0.23762]
Predicted label: 3
Correct prediction
Energy consumption = 190.573832 pJ
sum error= 298
Actual label: 7
Output voltages: [0.25995, 0.28084, 0.27028, 0.20541, 0.3224, 0.095011, 0.038993, 0.74678, 0.33152, 0.3154]
Predicted label: 7
Correct prediction
Energy consumption = 193.684434 pJ
sum error= 298
Actual label: 8
Output voltages: [0.18717, 0.33683, 0.32559, 0.18409, 0.22455, 0.23913, 0.3629, 0.1213, 0.67992, 0.2555]
Predicted label: 8
Correct prediction
Energy consumption = 197.175951 pJ
sum error= 298
Actual label: 4
Output voltages: [0.38056, 0.18933, 0.43869, 0.16163, 0.53671, 0.018924, 0.28894, 0.20716, 0.33451, 0.26165]
Predicted label: 4
Correct prediction
Energy consumption = 195.005285 pJ
sum error= 298
Actual label: 7
Output voltages: [0.37424, 0.24132, 0.20618, 0.20488, 0.32351, 0.16319, 0.04296, 0.73335, 0.24188, 0.36572]
Predicted label: 7
Correct prediction
Energy consumption = 198.743022 pJ
sum error= 298
Actual label: 5
Output voltages: [0.43982, 0.16277, 0.076933, 0.33173, 0.25047, 0.59506, 0.45638, 0.14195, 0.21869, 0.29514]
Predicted label: 5
Correct prediction
Energy consumption = 192.801490 pJ
sum error= 298
Actual label: 8
Output voltages: [0.3322, 0.097845, 0.29726, 0.29417, 0.21601, 0.29633, 0.29786, 0.11226, 0.73251, 0.11864]
Predicted label: 8
Correct prediction
Energy consumption = 192.229753 pJ
sum error= 298
Actual label: 5
Output voltages: [0.39885, 0.12389, 0.052555, 0.33545, 0.25311, 0.62281, 0.52705, 0.082947, 0.35911, 0.17332]
Predicted label: 5
Correct prediction
Energy consumption = 189.987221 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 975 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 975 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 975 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.28255, 0.1257, 0.31233, 0.73514, 0.20939, 0.24475, 0.095067, 0.21643, 0.42389, 0.27685]
Predicted label: 3
Correct prediction
Energy consumption = 193.807998 pJ
sum error= 298
Actual label: 2
Output voltages: [0.44489, 0.20009, 0.67203, 0.36707, 0.15449, 0.052768, 0.27112, 0.25517, 0.33208, 0.25861]
Predicted label: 2
Correct prediction
Energy consumption = 199.661655 pJ
sum error= 298
Actual label: 2
Output voltages: [0.37265, 0.22014, 0.68883, 0.36953, 0.18596, 0.043222, 0.29383, 0.19687, 0.31572, 0.25277]
Predicted label: 2
Correct prediction
Energy consumption = 193.345726 pJ
sum error= 298
Actual label: 0
Output voltages: [0.7347, 0.2132, 0.2584, 0.14208, 0.17393, 0.14052, 0.41939, 0.24496, 0.32478, 0.20537]
Predicted label: 0
Correct prediction
Energy consumption = 187.315971 pJ
sum error= 298
Actual label: 5
Output voltages: [0.41211, 0.29259, 0.10514, 0.30026, 0.24402, 0.57682, 0.51629, 0.059632, 0.19097, 0.15249]
Predicted label: 5
Correct prediction
Energy consumption = 196.634844 pJ
sum error= 298
Actual label: 8
Output voltages: [0.32253, 0.16501, 0.17643, 0.22639, 0.16091, 0.50358, 0.35547, 0.1009, 0.69741, 0.070318]
Predicted label: 8
Correct prediction
Energy consumption = 192.177690 pJ
sum error= 298
Actual label: 6
Output voltages: [0.3077, 0.095833, 0.30107, 0.068183, 0.33338, 0.34746, 0.65926, 0.043517, 0.44443, 0.16677]
Predicted label: 6
Correct prediction
Energy consumption = 176.423280 pJ
sum error= 298
Actual label: 0
Output voltages: [0.68657, 0.25381, 0.32151, 0.13439, 0.19798, 0.059967, 0.31296, 0.19997, 0.36899, 0.25628]
Predicted label: 0
Correct prediction
Energy consumption = 193.359504 pJ
sum error= 298
Actual label: 3
Output voltages: [0.45883, 0.10997, 0.27985, 0.75013, 0.18974, 0.35213, 0.10695, 0.16635, 0.3954, 0.23419]
Predicted label: 3
Correct prediction
Energy consumption = 191.480029 pJ
sum error= 298
Actual label: 8
Output voltages: [0.23741, 0.19561, 0.27346, 0.37852, 0.10538, 0.28858, 0.16659, 0.12927, 0.74224, 0.25739]
Predicted label: 8
Correct prediction
Energy consumption = 191.403172 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 976 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 976 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 976 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.16128, 0.75394, 0.12626, 0.15121, 0.40839, 0.20391, 0.38846, 0.1801, 0.27521, 0.30189]
Predicted label: 1
Correct prediction
Energy consumption = 204.944982 pJ
sum error= 298
Actual label: 0
Output voltages: [0.70946, 0.21163, 0.25098, 0.13304, 0.18824, 0.14655, 0.40232, 0.31797, 0.35753, 0.19422]
Predicted label: 0
Correct prediction
Energy consumption = 197.683638 pJ
sum error= 298
Actual label: 3
Output voltages: [0.37633, 0.12961, 0.41579, 0.69418, 0.1153, 0.14841, 0.13825, 0.21125, 0.51707, 0.21914]
Predicted label: 3
Correct prediction
Energy consumption = 209.679199 pJ
sum error= 298
Actual label: 0
Output voltages: [0.69402, 0.21806, 0.23799, 0.14478, 0.21702, 0.16291, 0.47167, 0.30241, 0.31738, 0.19388]
Predicted label: 0
Correct prediction
Energy consumption = 195.788824 pJ
sum error= 298
Actual label: 4
Output voltages: [0.2104, 0.2281, 0.24629, 0.23773, 0.68129, 0.03263, 0.21499, 0.22346, 0.23746, 0.30536]
Predicted label: 4
Correct prediction
Energy consumption = 201.016801 pJ
sum error= 298
Actual label: 7
Output voltages: [0.38768, 0.22833, 0.20031, 0.37319, 0.24382, 0.15813, 0.058993, 0.73431, 0.2652, 0.40241]
Predicted label: 7
Correct prediction
Energy consumption = 201.153616 pJ
sum error= 298
Actual label: 4
Output voltages: [0.17321, 0.22001, 0.22482, 0.25255, 0.73959, 0.061201, 0.25131, 0.2685, 0.21537, 0.22737]
Predicted label: 4
Correct prediction
Energy consumption = 193.764182 pJ
sum error= 298
Actual label: 9
Output voltages: [0.30407, 0.13328, 0.18923, 0.26388, 0.37848, 0.15898, 0.11449, 0.17043, 0.36411, 0.62937]
Predicted label: 9
Correct prediction
Energy consumption = 190.407754 pJ
sum error= 298
Actual label: 2
Output voltages: [0.54325, 0.073644, 0.44948, 0.25412, 0.20919, 0.058903, 0.2195, 0.20335, 0.48775, 0.23544]
Predicted label: 0
Wrong prediction!
Energy consumption = 197.083164 pJ
sum error= 299
Actual label: 9
Output voltages: [0.38911, 0.1368, 0.22176, 0.20683, 0.26289, 0.09788, 0.073966, 0.19846, 0.43457, 0.63043]
Predicted label: 9
Correct prediction
Energy consumption = 191.395121 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 977 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 977 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 977 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.64159, 0.15331, 0.18574, 0.15146, 0.19956, 0.37011, 0.47201, 0.33354, 0.25432, 0.11537]
Predicted label: 0
Wrong prediction!
Energy consumption = 199.975626 pJ
sum error= 300
Actual label: 7
Output voltages: [0.42639, 0.2286, 0.18291, 0.27031, 0.32857, 0.14367, 0.054069, 0.71469, 0.2712, 0.3374]
Predicted label: 7
Correct prediction
Energy consumption = 196.908502 pJ
sum error= 300
Actual label: 1
Output voltages: [0.16993, 0.70048, 0.30386, 0.13837, 0.33338, 0.13604, 0.42039, 0.063985, 0.38678, 0.18295]
Predicted label: 1
Correct prediction
Energy consumption = 202.414534 pJ
sum error= 300
Actual label: 7
Output voltages: [0.35487, 0.25051, 0.22509, 0.26365, 0.39109, 0.10527, 0.04368, 0.71425, 0.251, 0.29962]
Predicted label: 7
Correct prediction
Energy consumption = 199.317621 pJ
sum error= 300
Actual label: 1
Output voltages: [0.17263, 0.74781, 0.2801, 0.20177, 0.35612, 0.12929, 0.39509, 0.1565, 0.30727, 0.19662]
Predicted label: 1
Correct prediction
Energy consumption = 201.527802 pJ
sum error= 300
Actual label: 6
Output voltages: [0.31775, 0.17026, 0.30157, 0.079599, 0.30935, 0.3079, 0.69159, 0.053203, 0.46255, 0.12576]
Predicted label: 6
Correct prediction
Energy consumption = 188.130325 pJ
sum error= 300
Actual label: 6
Output voltages: [0.27447, 0.089532, 0.29744, 0.18465, 0.2775, 0.37986, 0.68407, 0.041199, 0.39833, 0.19927]
Predicted label: 6
Correct prediction
Energy consumption = 176.130915 pJ
sum error= 300
Actual label: 5
Output voltages: [0.46359, 0.15469, 0.062304, 0.33176, 0.32875, 0.56365, 0.48343, 0.11041, 0.23628, 0.13134]
Predicted label: 5
Correct prediction
Energy consumption = 186.814013 pJ
sum error= 300
Actual label: 6
Output voltages: [0.37748, 0.13184, 0.3077, 0.16415, 0.23864, 0.44113, 0.67453, 0.056517, 0.42128, 0.21345]
Predicted label: 6
Correct prediction
Energy consumption = 189.245149 pJ
sum error= 300
Actual label: 2
Output voltages: [0.46895, 0.058424, 0.54485, 0.33209, 0.11533, 0.11589, 0.23299, 0.23993, 0.44118, 0.19432]
Predicted label: 2
Correct prediction
Energy consumption = 196.238105 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 978 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 978 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 978 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.35905, 0.16731, 0.31231, 0.30689, 0.1305, 0.30573, 0.10347, 0.20418, 0.70796, 0.20166]
Predicted label: 8
Correct prediction
Energy consumption = 199.648016 pJ
sum error= 300
Actual label: 7
Output voltages: [0.34036, 0.20159, 0.26328, 0.095587, 0.31016, 0.091235, 0.047687, 0.64891, 0.39966, 0.33005]
Predicted label: 7
Correct prediction
Energy consumption = 191.636975 pJ
sum error= 300
Actual label: 6
Output voltages: [0.30092, 0.10469, 0.2621, 0.16971, 0.28237, 0.4607, 0.67976, 0.053748, 0.42849, 0.16029]
Predicted label: 6
Correct prediction
Energy consumption = 188.016439 pJ
sum error= 300
Actual label: 4
Output voltages: [0.15551, 0.23657, 0.30065, 0.2885, 0.73071, 0.042297, 0.19703, 0.25308, 0.17484, 0.26019]
Predicted label: 4
Correct prediction
Energy consumption = 192.450895 pJ
sum error= 300
Actual label: 9
Output voltages: [0.34383, 0.13032, 0.20852, 0.25894, 0.4058, 0.09797, 0.075902, 0.15952, 0.31817, 0.67135]
Predicted label: 9
Correct prediction
Energy consumption = 188.050513 pJ
sum error= 300
Actual label: 9
Output voltages: [0.30885, 0.15431, 0.16484, 0.28979, 0.32228, 0.15121, 0.062469, 0.14051, 0.38203, 0.68033]
Predicted label: 9
Correct prediction
Energy consumption = 180.625249 pJ
sum error= 300
Actual label: 5
Output voltages: [0.40721, 0.16917, 0.047825, 0.37903, 0.24723, 0.7285, 0.35915, 0.13313, 0.34521, 0.15592]
Predicted label: 5
Correct prediction
Energy consumption = 194.102862 pJ
sum error= 300
Actual label: 3
Output voltages: [0.38437, 0.17741, 0.29153, 0.75919, 0.15934, 0.27338, 0.10551, 0.14945, 0.45141, 0.2383]
Predicted label: 3
Correct prediction
Energy consumption = 184.739536 pJ
sum error= 300
Actual label: 7
Output voltages: [0.32175, 0.2495, 0.35128, 0.1684, 0.26767, 0.08266, 0.036387, 0.7159, 0.28194, 0.38487]
Predicted label: 7
Correct prediction
Energy consumption = 188.714497 pJ
sum error= 300
Actual label: 4
Output voltages: [0.22166, 0.19704, 0.31834, 0.18444, 0.753, 0.055295, 0.2755, 0.22591, 0.25355, 0.23953]
Predicted label: 4
Correct prediction
Energy consumption = 191.022232 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 979 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 979 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 979 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.49576, 0.21126, 0.2796, 0.73348, 0.068117, 0.21388, 0.081107, 0.40962, 0.30482, 0.17142]
Predicted label: 3
Correct prediction
Energy consumption = 196.079455 pJ
sum error= 300
Actual label: 0
Output voltages: [0.69342, 0.2634, 0.25844, 0.1605, 0.19352, 0.097531, 0.2775, 0.30277, 0.35437, 0.20307]
Predicted label: 0
Correct prediction
Energy consumption = 200.701187 pJ
sum error= 300
Actual label: 4
Output voltages: [0.2809, 0.34611, 0.20286, 0.25589, 0.57349, 0.040927, 0.16788, 0.25986, 0.16181, 0.45743]
Predicted label: 4
Correct prediction
Energy consumption = 204.780934 pJ
sum error= 300
Actual label: 6
Output voltages: [0.32348, 0.11845, 0.15774, 0.21473, 0.30528, 0.48337, 0.68239, 0.088441, 0.48912, 0.1349]
Predicted label: 6
Correct prediction
Energy consumption = 188.012800 pJ
sum error= 300
Actual label: 6
Output voltages: [0.31462, 0.18242, 0.31748, 0.10235, 0.28902, 0.32923, 0.71398, 0.043169, 0.39272, 0.19376]
Predicted label: 6
Correct prediction
Energy consumption = 179.552528 pJ
sum error= 300
Actual label: 1
Output voltages: [0.19122, 0.7138, 0.29421, 0.13653, 0.28907, 0.10777, 0.3803, 0.13712, 0.38605, 0.17602]
Predicted label: 1
Correct prediction
Energy consumption = 201.116561 pJ
sum error= 300
Actual label: 1
Output voltages: [0.2276, 0.70984, 0.31541, 0.13947, 0.46627, 0.084557, 0.35694, 0.079054, 0.26705, 0.22991]
Predicted label: 1
Correct prediction
Energy consumption = 193.961007 pJ
sum error= 300
Actual label: 3
Output voltages: [0.35919, 0.23852, 0.29652, 0.7508, 0.098516, 0.1848, 0.15434, 0.10963, 0.49398, 0.24843]
Predicted label: 3
Correct prediction
Energy consumption = 192.655496 pJ
sum error= 300
Actual label: 2
Output voltages: [0.3354, 0.19535, 0.74507, 0.26504, 0.20766, 0.037351, 0.27096, 0.29354, 0.41314, 0.15038]
Predicted label: 2
Correct prediction
Energy consumption = 191.412398 pJ
sum error= 300
Actual label: 1
Output voltages: [0.17669, 0.71612, 0.26691, 0.14131, 0.33956, 0.1106, 0.34371, 0.082401, 0.35068, 0.25243]
Predicted label: 1
Correct prediction
Energy consumption = 195.398295 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 980 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 980 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 980 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.63722, 0.14182, 0.25631, 0.07951, 0.22268, 0.13612, 0.42179, 0.27475, 0.2584, 0.3929]
Predicted label: 0
Correct prediction
Energy consumption = 199.335325 pJ
sum error= 300
Actual label: 0
Output voltages: [0.68742, 0.23651, 0.22693, 0.14561, 0.21818, 0.15303, 0.45515, 0.14337, 0.34365, 0.24993]
Predicted label: 0
Correct prediction
Energy consumption = 186.771266 pJ
sum error= 300
Actual label: 1
Output voltages: [0.16765, 0.75443, 0.25645, 0.1699, 0.29277, 0.14999, 0.39763, 0.098091, 0.3634, 0.21075]
Predicted label: 1
Correct prediction
Energy consumption = 206.280470 pJ
sum error= 300
Actual label: 2
Output voltages: [0.32819, 0.15783, 0.69701, 0.3872, 0.14634, 0.033854, 0.2282, 0.2576, 0.51868, 0.16458]
Predicted label: 2
Correct prediction
Energy consumption = 185.222827 pJ
sum error= 300
Actual label: 3
Output voltages: [0.29422, 0.12179, 0.29401, 0.74586, 0.16131, 0.23439, 0.16914, 0.15304, 0.4458, 0.22484]
Predicted label: 3
Correct prediction
Energy consumption = 185.385135 pJ
sum error= 300
Actual label: 4
Output voltages: [0.13388, 0.20761, 0.24711, 0.17946, 0.75371, 0.073255, 0.30148, 0.34186, 0.19145, 0.17322]
Predicted label: 4
Correct prediction
Energy consumption = 191.583743 pJ
sum error= 300
Actual label: 7
Output voltages: [0.28152, 0.23123, 0.19182, 0.2344, 0.13735, 0.072056, 0.043437, 0.73476, 0.40217, 0.4147]
Predicted label: 7
Correct prediction
Energy consumption = 201.059230 pJ
sum error= 300
Actual label: 8
Output voltages: [0.25994, 0.27081, 0.29748, 0.32302, 0.12912, 0.13636, 0.22861, 0.1027, 0.74134, 0.30891]
Predicted label: 8
Correct prediction
Energy consumption = 185.341317 pJ
sum error= 300
Actual label: 9
Output voltages: [0.33985, 0.12406, 0.089767, 0.32193, 0.44146, 0.28722, 0.12119, 0.39294, 0.2623, 0.50506]
Predicted label: 9
Correct prediction
Energy consumption = 197.869428 pJ
sum error= 300
Actual label: 0
Output voltages: [0.72738, 0.27571, 0.24135, 0.1891, 0.21475, 0.11331, 0.31576, 0.2423, 0.36342, 0.2387]
Predicted label: 0
Correct prediction
Energy consumption = 196.048387 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 981 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 981 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 981 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.27992, 0.7295, 0.23045, 0.13433, 0.33534, 0.082934, 0.29063, 0.20018, 0.30798, 0.27059]
Predicted label: 1
Correct prediction
Energy consumption = 208.681149 pJ
sum error= 300
Actual label: 2
Output voltages: [0.31149, 0.19087, 0.59495, 0.41365, 0.052618, 0.046947, 0.13942, 0.32058, 0.55394, 0.16279]
Predicted label: 2
Correct prediction
Energy consumption = 187.812521 pJ
sum error= 300
Actual label: 3
Output voltages: [0.33944, 0.18226, 0.2839, 0.74682, 0.18167, 0.37013, 0.1897, 0.1725, 0.36173, 0.2014]
Predicted label: 3
Correct prediction
Energy consumption = 192.533899 pJ
sum error= 300
Actual label: 4
Output voltages: [0.18077, 0.21862, 0.28532, 0.16407, 0.73538, 0.058507, 0.34502, 0.28261, 0.15999, 0.23276]
Predicted label: 4
Correct prediction
Energy consumption = 192.400728 pJ
sum error= 300
Actual label: 5
Output voltages: [0.28263, 0.27643, 0.15391, 0.32993, 0.10794, 0.73745, 0.25669, 0.094201, 0.59427, 0.15461]
Predicted label: 5
Correct prediction
Energy consumption = 204.730772 pJ
sum error= 300
Actual label: 6
Output voltages: [0.34635, 0.16008, 0.16697, 0.2568, 0.24148, 0.55725, 0.69398, 0.085892, 0.44561, 0.19608]
Predicted label: 6
Correct prediction
Energy consumption = 188.628240 pJ
sum error= 300
Actual label: 7
Output voltages: [0.37386, 0.25045, 0.3533, 0.29969, 0.1338, 0.041432, 0.048183, 0.70925, 0.27379, 0.35558]
Predicted label: 7
Correct prediction
Energy consumption = 198.757330 pJ
sum error= 300
Actual label: 8
Output voltages: [0.28211, 0.29855, 0.2602, 0.32857, 0.20168, 0.20643, 0.32895, 0.055238, 0.69889, 0.25007]
Predicted label: 8
Correct prediction
Energy consumption = 198.171839 pJ
sum error= 300
Actual label: 0
Output voltages: [0.71319, 0.21165, 0.25846, 0.14169, 0.16251, 0.11017, 0.30621, 0.21314, 0.41775, 0.23564]
Predicted label: 0
Correct prediction
Energy consumption = 191.973700 pJ
sum error= 300
Actual label: 1
Output voltages: [0.20531, 0.73378, 0.18557, 0.19077, 0.31545, 0.087172, 0.30656, 0.12787, 0.369, 0.28702]
Predicted label: 1
Correct prediction
Energy consumption = 199.903336 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 982 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 982 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 982 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.34842, 0.20925, 0.68308, 0.40814, 0.15881, 0.032142, 0.27968, 0.21144, 0.54648, 0.21735]
Predicted label: 2
Correct prediction
Energy consumption = 188.521298 pJ
sum error= 300
Actual label: 3
Output voltages: [0.44271, 0.15569, 0.31716, 0.75704, 0.16925, 0.20805, 0.14866, 0.17524, 0.42078, 0.17648]
Predicted label: 3
Correct prediction
Energy consumption = 182.718464 pJ
sum error= 300
Actual label: 4
Output voltages: [0.13248, 0.18572, 0.22913, 0.20898, 0.75466, 0.10035, 0.27541, 0.32854, 0.22994, 0.16488]
Predicted label: 4
Correct prediction
Energy consumption = 192.971317 pJ
sum error= 300
Actual label: 7
Output voltages: [0.33303, 0.27798, 0.3768, 0.36544, 0.073491, 0.046011, 0.04163, 0.73106, 0.34209, 0.32478]
Predicted label: 7
Correct prediction
Energy consumption = 196.278403 pJ
sum error= 300
Actual label: 8
Output voltages: [0.23873, 0.2406, 0.27454, 0.34747, 0.086694, 0.21753, 0.30999, 0.11073, 0.74171, 0.27912]
Predicted label: 8
Correct prediction
Energy consumption = 196.727586 pJ
sum error= 300
Actual label: 9
Output voltages: [0.31144, 0.14752, 0.18905, 0.31675, 0.26922, 0.13681, 0.067603, 0.26873, 0.40285, 0.66328]
Predicted label: 9
Correct prediction
Energy consumption = 186.729139 pJ
sum error= 300
Actual label: 0
Output voltages: [0.63652, 0.19892, 0.26887, 0.21488, 0.19906, 0.079543, 0.39031, 0.15952, 0.3921, 0.26881]
Predicted label: 0
Correct prediction
Energy consumption = 203.650607 pJ
sum error= 300
Actual label: 8
Output voltages: [0.20443, 0.28602, 0.22112, 0.2734, 0.15236, 0.12891, 0.33315, 0.13072, 0.72308, 0.31677]
Predicted label: 8
Correct prediction
Energy consumption = 202.783742 pJ
sum error= 300
Actual label: 3
Output voltages: [0.33113, 0.096149, 0.26789, 0.69776, 0.21032, 0.34578, 0.11464, 0.12423, 0.43064, 0.25138]
Predicted label: 3
Correct prediction
Energy consumption = 204.916085 pJ
sum error= 300
Actual label: 9
Output voltages: [0.37283, 0.15811, 0.20742, 0.21712, 0.42211, 0.080754, 0.17151, 0.20546, 0.32458, 0.64225]
Predicted label: 9
Correct prediction
Energy consumption = 193.803120 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 983 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 983 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 983 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.30822, 0.19555, 0.061839, 0.33806, 0.12671, 0.74547, 0.32364, 0.16619, 0.48785, 0.12818]
Predicted label: 5
Correct prediction
Energy consumption = 204.122514 pJ
sum error= 300
Actual label: 5
Output voltages: [0.23008, 0.36919, 0.062163, 0.39266, 0.12189, 0.73899, 0.37015, 0.11848, 0.42864, 0.14025]
Predicted label: 5
Correct prediction
Energy consumption = 195.143214 pJ
sum error= 300
Actual label: 2
Output voltages: [0.29767, 0.32497, 0.63956, 0.36484, 0.12323, 0.02904, 0.29566, 0.24096, 0.45489, 0.18555]
Predicted label: 2
Correct prediction
Energy consumption = 196.830729 pJ
sum error= 300
Actual label: 6
Output voltages: [0.31705, 0.21675, 0.22789, 0.12273, 0.36176, 0.2455, 0.67495, 0.12046, 0.45145, 0.15646]
Predicted label: 6
Correct prediction
Energy consumption = 197.559263 pJ
sum error= 300
Actual label: 8
Output voltages: [0.30168, 0.24397, 0.22859, 0.34105, 0.054852, 0.33906, 0.4526, 0.076532, 0.59538, 0.25275]
Predicted label: 8
Correct prediction
Energy consumption = 198.397321 pJ
sum error= 300
Actual label: 4
Output voltages: [0.2437, 0.22089, 0.28384, 0.076977, 0.69483, 0.059052, 0.36582, 0.2016, 0.31899, 0.20185]
Predicted label: 4
Correct prediction
Energy consumption = 195.775836 pJ
sum error= 300
Actual label: 1
Output voltages: [0.22728, 0.748, 0.1846, 0.20247, 0.39639, 0.086268, 0.3115, 0.097126, 0.30121, 0.33223]
Predicted label: 1
Correct prediction
Energy consumption = 204.084207 pJ
sum error= 300
Actual label: 7
Output voltages: [0.35258, 0.24464, 0.31664, 0.28435, 0.1205, 0.048063, 0.0388, 0.7331, 0.33463, 0.3449]
Predicted label: 7
Correct prediction
Energy consumption = 197.034703 pJ
sum error= 300
Actual label: 1
Output voltages: [0.26037, 0.74709, 0.13156, 0.19167, 0.42072, 0.1173, 0.30971, 0.1512, 0.28418, 0.2678]
Predicted label: 1
Correct prediction
Energy consumption = 207.863553 pJ
sum error= 300
Actual label: 2
Output voltages: [0.32892, 0.30258, 0.55222, 0.4084, 0.05836, 0.036734, 0.13288, 0.44887, 0.43575, 0.21754]
Predicted label: 2
Correct prediction
Energy consumption = 192.793123 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 984 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 984 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 984 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36922, 0.13397, 0.31865, 0.7237, 0.11685, 0.28424, 0.14961, 0.13083, 0.41537, 0.17418]
Predicted label: 3
Correct prediction
Energy consumption = 197.826583 pJ
sum error= 300
Actual label: 5
Output voltages: [0.33104, 0.26193, 0.047613, 0.33283, 0.16158, 0.75316, 0.3983, 0.10214, 0.424, 0.11422]
Predicted label: 5
Correct prediction
Energy consumption = 196.837535 pJ
sum error= 300
Actual label: 6
Output voltages: [0.31541, 0.17747, 0.22332, 0.11654, 0.34475, 0.36342, 0.70019, 0.094596, 0.44013, 0.12397]
Predicted label: 6
Correct prediction
Energy consumption = 189.571218 pJ
sum error= 300
Actual label: 9
Output voltages: [0.32292, 0.16018, 0.2119, 0.30688, 0.4038, 0.11104, 0.093217, 0.17099, 0.31223, 0.66767]
Predicted label: 9
Correct prediction
Energy consumption = 186.377189 pJ
sum error= 300
Actual label: 1
Output voltages: [0.2165, 0.7591, 0.17296, 0.20745, 0.33636, 0.0682, 0.34457, 0.16301, 0.24595, 0.28487]
Predicted label: 1
Correct prediction
Energy consumption = 207.043185 pJ
sum error= 300
Actual label: 1
Output voltages: [0.28696, 0.72539, 0.19481, 0.1614, 0.40987, 0.060725, 0.26961, 0.21816, 0.24278, 0.31561]
Predicted label: 1
Correct prediction
Energy consumption = 202.629101 pJ
sum error= 300
Actual label: 1
Output voltages: [0.25934, 0.72592, 0.20339, 0.17472, 0.4355, 0.062187, 0.27072, 0.23512, 0.22013, 0.32231]
Predicted label: 1
Correct prediction
Energy consumption = 199.727907 pJ
sum error= 300
Actual label: 2
Output voltages: [0.24854, 0.35105, 0.69057, 0.35133, 0.079634, 0.026521, 0.19982, 0.38802, 0.38658, 0.18485]
Predicted label: 2
Correct prediction
Energy consumption = 188.091544 pJ
sum error= 300
Actual label: 1
Output voltages: [0.17604, 0.73911, 0.17219, 0.19674, 0.35317, 0.102, 0.29141, 0.14551, 0.35884, 0.27916]
Predicted label: 1
Correct prediction
Energy consumption = 200.828581 pJ
sum error= 300
Actual label: 2
Output voltages: [0.29233, 0.32519, 0.67838, 0.41015, 0.12014, 0.036414, 0.27952, 0.18505, 0.50196, 0.19121]
Predicted label: 2
Correct prediction
Energy consumption = 188.711229 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 985 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 985 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 985 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.60303, 0.17229, 0.26082, 0.18866, 0.16387, 0.14637, 0.41771, 0.095413, 0.43679, 0.30673]
Predicted label: 0
Correct prediction
Energy consumption = 191.484431 pJ
sum error= 300
Actual label: 7
Output voltages: [0.2768, 0.21391, 0.21683, 0.28526, 0.11135, 0.072218, 0.042047, 0.74935, 0.36601, 0.41258]
Predicted label: 7
Correct prediction
Energy consumption = 194.574047 pJ
sum error= 300
Actual label: 7
Output voltages: [0.2695, 0.32459, 0.29427, 0.35471, 0.086382, 0.066579, 0.041407, 0.74504, 0.26965, 0.40171]
Predicted label: 7
Correct prediction
Energy consumption = 186.179005 pJ
sum error= 300
Actual label: 5
Output voltages: [0.23491, 0.22285, 0.13094, 0.27315, 0.10264, 0.71801, 0.19663, 0.095586, 0.63575, 0.17955]
Predicted label: 5
Correct prediction
Energy consumption = 199.518078 pJ
sum error= 300
Actual label: 8
Output voltages: [0.21014, 0.16782, 0.20383, 0.31117, 0.11578, 0.416, 0.33476, 0.09802, 0.70056, 0.2358]
Predicted label: 8
Correct prediction
Energy consumption = 192.807524 pJ
sum error= 300
Actual label: 2
Output voltages: [0.23746, 0.33357, 0.63409, 0.45019, 0.064091, 0.041234, 0.23317, 0.18925, 0.46137, 0.18396]
Predicted label: 2
Correct prediction
Energy consumption = 194.315372 pJ
sum error= 300
Actual label: 9
Output voltages: [0.25706, 0.054153, 0.04735, 0.24409, 0.364, 0.63783, 0.17907, 0.25668, 0.3255, 0.42871]
Predicted label: 5
Wrong prediction!
Energy consumption = 192.773348 pJ
sum error= 301
Actual label: 8
Output voltages: [0.18846, 0.28343, 0.23162, 0.3039, 0.064487, 0.32015, 0.28824, 0.12643, 0.6922, 0.26119]
Predicted label: 8
Correct prediction
Energy consumption = 195.361387 pJ
sum error= 301
Actual label: 6
Output voltages: [0.45323, 0.35954, 0.1061, 0.3781, 0.18013, 0.30529, 0.59497, 0.089392, 0.44332, 0.09457]
Predicted label: 6
Correct prediction
Energy consumption = 203.830262 pJ
sum error= 301
Actual label: 7
Output voltages: [0.3047, 0.27823, 0.24395, 0.28825, 0.19968, 0.065646, 0.041882, 0.7529, 0.26355, 0.36402]
Predicted label: 7
Correct prediction
Energy consumption = 196.678460 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 986 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 986 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 986 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.40293, 0.16217, 0.29103, 0.74943, 0.12064, 0.30357, 0.10807, 0.17271, 0.4387, 0.16232]
Predicted label: 3
Correct prediction
Energy consumption = 186.875056 pJ
sum error= 301
Actual label: 4
Output voltages: [0.21589, 0.17567, 0.31572, 0.14509, 0.73876, 0.054017, 0.3757, 0.24813, 0.18648, 0.2382]
Predicted label: 4
Correct prediction
Energy consumption = 189.989565 pJ
sum error= 301
Actual label: 6
Output voltages: [0.33767, 0.24468, 0.16843, 0.26443, 0.21963, 0.37555, 0.62887, 0.1805, 0.55613, 0.062277]
Predicted label: 6
Correct prediction
Energy consumption = 207.315679 pJ
sum error= 301
Actual label: 8
Output voltages: [0.25551, 0.25586, 0.19495, 0.3762, 0.054358, 0.31441, 0.33227, 0.12564, 0.68309, 0.23733]
Predicted label: 8
Correct prediction
Energy consumption = 201.881418 pJ
sum error= 301
Actual label: 7
Output voltages: [0.32594, 0.30644, 0.30941, 0.19571, 0.18065, 0.043682, 0.037563, 0.71201, 0.27824, 0.3539]
Predicted label: 7
Correct prediction
Energy consumption = 196.095512 pJ
sum error= 301
Actual label: 0
Output voltages: [0.72735, 0.20355, 0.34187, 0.18159, 0.2073, 0.084549, 0.29782, 0.28282, 0.34015, 0.25912]
Predicted label: 0
Correct prediction
Energy consumption = 196.677500 pJ
sum error= 301
Actual label: 4
Output voltages: [0.19423, 0.11601, 0.42304, 0.14283, 0.74925, 0.094708, 0.41518, 0.31033, 0.15978, 0.159]
Predicted label: 4
Correct prediction
Energy consumption = 189.463610 pJ
sum error= 301
Actual label: 2
Output voltages: [0.28799, 0.26648, 0.69213, 0.28573, 0.052885, 0.040716, 0.18785, 0.45062, 0.49342, 0.13102]
Predicted label: 2
Correct prediction
Energy consumption = 188.547466 pJ
sum error= 301
Actual label: 7
Output voltages: [0.28493, 0.30768, 0.4193, 0.21674, 0.1567, 0.044181, 0.04256, 0.74105, 0.30541, 0.32418]
Predicted label: 7
Correct prediction
Energy consumption = 190.071153 pJ
sum error= 301
Actual label: 7
Output voltages: [0.28355, 0.30558, 0.3006, 0.19086, 0.13654, 0.054334, 0.039354, 0.73664, 0.39619, 0.33022]
Predicted label: 7
Correct prediction
Energy consumption = 181.459154 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 987 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 987 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 987 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2375, 0.17383, 0.067345, 0.31988, 0.25283, 0.74395, 0.39266, 0.059066, 0.45758, 0.19506]
Predicted label: 5
Correct prediction
Energy consumption = 197.771189 pJ
sum error= 301
Actual label: 4
Output voltages: [0.15634, 0.20624, 0.26988, 0.15327, 0.74825, 0.081307, 0.38227, 0.23989, 0.19014, 0.18859]
Predicted label: 4
Correct prediction
Energy consumption = 195.122845 pJ
sum error= 301
Actual label: 3
Output voltages: [0.39571, 0.21163, 0.25045, 0.75196, 0.16565, 0.2578, 0.24877, 0.20305, 0.34797, 0.1298]
Predicted label: 3
Correct prediction
Energy consumption = 191.528511 pJ
sum error= 301
Actual label: 4
Output voltages: [0.27451, 0.20326, 0.3718, 0.082366, 0.71843, 0.16258, 0.52061, 0.1934, 0.22922, 0.10652]
Predicted label: 4
Correct prediction
Energy consumption = 189.596479 pJ
sum error= 301
Actual label: 2
Output voltages: [0.31714, 0.29384, 0.64682, 0.41391, 0.066634, 0.027907, 0.22104, 0.28714, 0.46228, 0.22096]
Predicted label: 2
Correct prediction
Energy consumption = 195.550066 pJ
sum error= 301
Actual label: 8
Output voltages: [0.1997, 0.16883, 0.26046, 0.31466, 0.18287, 0.20947, 0.25414, 0.084488, 0.71335, 0.31635]
Predicted label: 8
Correct prediction
Energy consumption = 194.757644 pJ
sum error= 301
Actual label: 1
Output voltages: [0.16166, 0.74635, 0.21331, 0.24184, 0.33576, 0.063443, 0.34891, 0.13225, 0.27566, 0.29047]
Predicted label: 1
Correct prediction
Energy consumption = 198.426470 pJ
sum error= 301
Actual label: 5
Output voltages: [0.3222, 0.22617, 0.049601, 0.3658, 0.094864, 0.75415, 0.34469, 0.16121, 0.48379, 0.12119]
Predicted label: 5
Correct prediction
Energy consumption = 192.165870 pJ
sum error= 301
Actual label: 1
Output voltages: [0.22262, 0.73909, 0.21027, 0.20511, 0.36597, 0.10148, 0.30306, 0.1565, 0.24613, 0.24562]
Predicted label: 1
Correct prediction
Energy consumption = 204.154234 pJ
sum error= 301
Actual label: 0
Output voltages: [0.48573, 0.3405, 0.35936, 0.14324, 0.31415, 0.061701, 0.37891, 0.064423, 0.45906, 0.29179]
Predicted label: 0
Correct prediction
Energy consumption = 201.693071 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 988 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 988 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 988 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.2494, 0.32177, 0.58961, 0.39756, 0.067854, 0.046932, 0.24671, 0.13773, 0.5558, 0.23124]
Predicted label: 2
Correct prediction
Energy consumption = 196.749777 pJ
sum error= 301
Actual label: 3
Output voltages: [0.29321, 0.14283, 0.22484, 0.7481, 0.2246, 0.37449, 0.25008, 0.10574, 0.35362, 0.23651]
Predicted label: 3
Correct prediction
Energy consumption = 193.041179 pJ
sum error= 301
Actual label: 3
Output voltages: [0.28127, 0.19382, 0.25769, 0.75627, 0.17803, 0.22861, 0.20088, 0.15593, 0.39533, 0.27261]
Predicted label: 3
Correct prediction
Energy consumption = 186.410005 pJ
sum error= 301
Actual label: 5
Output voltages: [0.21976, 0.34664, 0.19755, 0.39819, 0.092558, 0.52922, 0.48541, 0.05134, 0.43789, 0.11848]
Predicted label: 5
Correct prediction
Energy consumption = 196.641811 pJ
sum error= 301
Actual label: 7
Output voltages: [0.25829, 0.25955, 0.21023, 0.16233, 0.3073, 0.10748, 0.039303, 0.73464, 0.27611, 0.33739]
Predicted label: 7
Correct prediction
Energy consumption = 200.199070 pJ
sum error= 301
Actual label: 0
Output voltages: [0.71618, 0.22834, 0.25804, 0.18837, 0.13756, 0.1211, 0.36354, 0.22513, 0.36574, 0.2414]
Predicted label: 0
Correct prediction
Energy consumption = 198.599226 pJ
sum error= 301
Actual label: 6
Output voltages: [0.35054, 0.20789, 0.26752, 0.11393, 0.44353, 0.30313, 0.69468, 0.10148, 0.35484, 0.080525]
Predicted label: 6
Correct prediction
Energy consumption = 191.570030 pJ
sum error= 301
Actual label: 8
Output voltages: [0.2538, 0.40038, 0.1221, 0.34401, 0.14291, 0.30891, 0.46088, 0.072789, 0.643, 0.18492]
Predicted label: 8
Correct prediction
Energy consumption = 197.615685 pJ
sum error= 301
Actual label: 6
Output voltages: [0.49495, 0.21402, 0.18663, 0.2731, 0.29194, 0.18312, 0.53996, 0.10595, 0.43003, 0.2053]
Predicted label: 6
Correct prediction
Energy consumption = 203.620817 pJ
sum error= 301
Actual label: 3
Output voltages: [0.3186, 0.24529, 0.37282, 0.75808, 0.12361, 0.16024, 0.10054, 0.27866, 0.46098, 0.22741]
Predicted label: 3
Correct prediction
Energy consumption = 192.184851 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 989 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 989 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 989 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33009, 0.10067, 0.069495, 0.19218, 0.34922, 0.30633, 0.3236, 0.2849, 0.33346, 0.47504]
Predicted label: 9
Correct prediction
Energy consumption = 196.367872 pJ
sum error= 301
Actual label: 9
Output voltages: [0.27582, 0.11672, 0.1045, 0.42916, 0.30062, 0.37961, 0.15308, 0.44765, 0.26816, 0.45004]
Predicted label: 9
Correct prediction
Energy consumption = 197.108700 pJ
sum error= 301
Actual label: 8
Output voltages: [0.18164, 0.092819, 0.2341, 0.23041, 0.21008, 0.42927, 0.27661, 0.078997, 0.6342, 0.33895]
Predicted label: 8
Correct prediction
Energy consumption = 192.293439 pJ
sum error= 301
Actual label: 2
Output voltages: [0.26053, 0.25196, 0.66898, 0.34107, 0.10764, 0.030974, 0.23144, 0.42107, 0.48961, 0.11363]
Predicted label: 2
Correct prediction
Energy consumption = 190.484242 pJ
sum error= 301
Actual label: 7
Output voltages: [0.2653, 0.35574, 0.48197, 0.20304, 0.14958, 0.037765, 0.043429, 0.72064, 0.29147, 0.2972]
Predicted label: 7
Correct prediction
Energy consumption = 191.407060 pJ
sum error= 301
Actual label: 7
Output voltages: [0.26176, 0.29796, 0.42515, 0.19005, 0.18353, 0.041807, 0.046053, 0.75197, 0.29878, 0.2994]
Predicted label: 7
Correct prediction
Energy consumption = 184.692149 pJ
sum error= 301
Actual label: 1
Output voltages: [0.25869, 0.73114, 0.15503, 0.19797, 0.43427, 0.08884, 0.28915, 0.20307, 0.21369, 0.29675]
Predicted label: 1
Correct prediction
Energy consumption = 198.491034 pJ
sum error= 301
Actual label: 0
Output voltages: [0.68773, 0.27956, 0.29792, 0.16757, 0.24182, 0.097825, 0.38949, 0.15191, 0.34194, 0.21543]
Predicted label: 0
Correct prediction
Energy consumption = 194.240621 pJ
sum error= 301
Actual label: 1
Output voltages: [0.1839, 0.758, 0.24411, 0.18856, 0.28984, 0.16751, 0.46877, 0.16797, 0.29731, 0.2388]
Predicted label: 1
Correct prediction
Energy consumption = 202.866171 pJ
sum error= 301
Actual label: 7
Output voltages: [0.28073, 0.21078, 0.269, 0.27883, 0.14809, 0.10895, 0.039569, 0.75574, 0.40182, 0.39426]
Predicted label: 7
Correct prediction
Energy consumption = 193.084447 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 990 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 990 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 990 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18707, 0.18232, 0.24202, 0.37238, 0.11394, 0.26396, 0.20335, 0.14184, 0.74461, 0.21854]
Predicted label: 8
Correct prediction
Energy consumption = 191.623942 pJ
sum error= 301
Actual label: 9
Output voltages: [0.31804, 0.094293, 0.19184, 0.21303, 0.29939, 0.19384, 0.083381, 0.15794, 0.48239, 0.60467]
Predicted label: 9
Correct prediction
Energy consumption = 187.869991 pJ
sum error= 301
Actual label: 0
Output voltages: [0.7109, 0.18868, 0.36449, 0.14633, 0.22691, 0.081357, 0.35824, 0.34659, 0.29585, 0.16279]
Predicted label: 0
Correct prediction
Energy consumption = 200.709590 pJ
sum error= 301
Actual label: 1
Output voltages: [0.19421, 0.73598, 0.27676, 0.18417, 0.33595, 0.07171, 0.3105, 0.2104, 0.33918, 0.18965]
Predicted label: 1
Correct prediction
Energy consumption = 194.021247 pJ
sum error= 301
Actual label: 2
Output voltages: [0.45711, 0.067843, 0.41104, 0.23183, 0.18049, 0.20541, 0.40279, 0.12244, 0.49079, 0.19822]
Predicted label: 8
Wrong prediction!
Energy consumption = 197.455707 pJ
sum error= 302
Actual label: 3
Output voltages: [0.23952, 0.21157, 0.42653, 0.56398, 0.079951, 0.072063, 0.062787, 0.38506, 0.51312, 0.34381]
Predicted label: 3
Correct prediction
Energy consumption = 189.670331 pJ
sum error= 302
Actual label: 4
Output voltages: [0.15981, 0.24093, 0.39807, 0.27689, 0.66545, 0.057058, 0.36199, 0.2463, 0.24185, 0.11832]
Predicted label: 4
Correct prediction
Energy consumption = 188.434059 pJ
sum error= 302
Actual label: 5
Output voltages: [0.31138, 0.090714, 0.040198, 0.32441, 0.30249, 0.75067, 0.41144, 0.12966, 0.40513, 0.13857]
Predicted label: 5
Correct prediction
Energy consumption = 189.782954 pJ
sum error= 302
Actual label: 6
Output voltages: [0.28594, 0.21088, 0.30559, 0.086055, 0.33162, 0.36102, 0.74884, 0.093807, 0.39829, 0.10342]
Predicted label: 6
Correct prediction
Energy consumption = 180.649908 pJ
sum error= 302
Actual label: 7
Output voltages: [0.34795, 0.21636, 0.33231, 0.2385, 0.24649, 0.068082, 0.043147, 0.73858, 0.29025, 0.34779]
Predicted label: 7
Correct prediction
Energy consumption = 194.478553 pJ
sum error= 302
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 991 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 991 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 991 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26383, 0.35361, 0.16084, 0.3016, 0.1708, 0.31323, 0.30104, 0.073137, 0.68401, 0.17823]
Predicted label: 8
Correct prediction
Energy consumption = 205.212412 pJ
sum error= 302
Actual label: 0
Output voltages: [0.69386, 0.18091, 0.37233, 0.20289, 0.17081, 0.064889, 0.37522, 0.24056, 0.31241, 0.22081]
Predicted label: 0
Correct prediction
Energy consumption = 193.729719 pJ
sum error= 302
Actual label: 1
Output voltages: [0.18641, 0.71089, 0.27598, 0.22384, 0.37617, 0.07674, 0.28411, 0.12169, 0.35643, 0.23276]
Predicted label: 1
Correct prediction
Energy consumption = 196.195413 pJ
sum error= 302
Actual label: 2
Output voltages: [0.27886, 0.11634, 0.68319, 0.39033, 0.13558, 0.061711, 0.15025, 0.28409, 0.55297, 0.15719]
Predicted label: 2
Correct prediction
Energy consumption = 184.943689 pJ
sum error= 302
Actual label: 3
Output voltages: [0.21718, 0.23248, 0.34512, 0.71381, 0.10696, 0.20052, 0.086374, 0.19634, 0.53623, 0.28903]
Predicted label: 3
Correct prediction
Energy consumption = 183.241456 pJ
sum error= 302
Actual label: 4
Output voltages: [0.095469, 0.24067, 0.16759, 0.1329, 0.74827, 0.23267, 0.27668, 0.31346, 0.28113, 0.16598]
Predicted label: 4
Correct prediction
Energy consumption = 199.462634 pJ
sum error= 302
Actual label: 7
Output voltages: [0.35676, 0.19776, 0.2979, 0.26861, 0.1945, 0.096095, 0.043825, 0.74778, 0.28705, 0.2651]
Predicted label: 7
Correct prediction
Energy consumption = 194.350117 pJ
sum error= 302
Actual label: 8
Output voltages: [0.22492, 0.22948, 0.30949, 0.25649, 0.1791, 0.22809, 0.16899, 0.17569, 0.7523, 0.26289]
Predicted label: 8
Correct prediction
Energy consumption = 182.758507 pJ
sum error= 302
Actual label: 9
Output voltages: [0.37665, 0.12366, 0.18369, 0.27561, 0.31886, 0.23507, 0.16443, 0.23928, 0.29981, 0.63295]
Predicted label: 9
Correct prediction
Energy consumption = 192.448412 pJ
sum error= 302
Actual label: 7
Output voltages: [0.32096, 0.28362, 0.33374, 0.13043, 0.30986, 0.056708, 0.046878, 0.73378, 0.20197, 0.31647]
Predicted label: 7
Correct prediction
Energy consumption = 191.672116 pJ
sum error= 302
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 992 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 992 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 992 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.19816, 0.25113, 0.28912, 0.3376, 0.11173, 0.22082, 0.19711, 0.15703, 0.75055, 0.23991]
Predicted label: 8
Correct prediction
Energy consumption = 196.920939 pJ
sum error= 302
Actual label: 6
Output voltages: [0.27694, 0.17879, 0.31226, 0.063502, 0.34877, 0.37236, 0.72931, 0.067774, 0.36425, 0.12113]
Predicted label: 6
Correct prediction
Energy consumption = 197.868762 pJ
sum error= 302
Actual label: 4
Output voltages: [0.15378, 0.26108, 0.22159, 0.1391, 0.70806, 0.055404, 0.13266, 0.20239, 0.27279, 0.37116]
Predicted label: 4
Correct prediction
Energy consumption = 198.898360 pJ
sum error= 302
Actual label: 1
Output voltages: [0.25271, 0.71916, 0.32721, 0.14267, 0.40047, 0.083722, 0.36007, 0.10494, 0.28901, 0.23431]
Predicted label: 1
Correct prediction
Energy consumption = 196.660153 pJ
sum error= 302
Actual label: 9
Output voltages: [0.35145, 0.079701, 0.14061, 0.28686, 0.32287, 0.23642, 0.10089, 0.26192, 0.40824, 0.58451]
Predicted label: 9
Correct prediction
Energy consumption = 196.630860 pJ
sum error= 302
Actual label: 3
Output voltages: [0.28185, 0.082464, 0.35451, 0.64434, 0.084466, 0.25321, 0.11218, 0.1959, 0.57047, 0.18688]
Predicted label: 3
Correct prediction
Energy consumption = 186.777436 pJ
sum error= 302
Actual label: 8
Output voltages: [0.24272, 0.1793, 0.27823, 0.37906, 0.17037, 0.27963, 0.24032, 0.17225, 0.70502, 0.16135]
Predicted label: 8
Correct prediction
Energy consumption = 195.191255 pJ
sum error= 302
Actual label: 4
Output voltages: [0.14924, 0.1875, 0.34071, 0.21602, 0.73928, 0.06206, 0.27497, 0.25857, 0.16105, 0.23012]
Predicted label: 4
Correct prediction
Energy consumption = 188.615366 pJ
sum error= 302
Actual label: 4
Output voltages: [0.1701, 0.19557, 0.31515, 0.30962, 0.744, 0.084846, 0.20906, 0.23365, 0.17179, 0.24248]
Predicted label: 4
Correct prediction
Energy consumption = 188.420406 pJ
sum error= 302
Actual label: 7
Output voltages: [0.25772, 0.29178, 0.29026, 0.26068, 0.15984, 0.083414, 0.041915, 0.75418, 0.2651, 0.32091]
Predicted label: 7
Correct prediction
Energy consumption = 185.575337 pJ
sum error= 302
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 993 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 993 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 993 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.70839, 0.28967, 0.24997, 0.22397, 0.14845, 0.17757, 0.40831, 0.16726, 0.36479, 0.16289]
Predicted label: 0
Correct prediction
Energy consumption = 202.803171 pJ
sum error= 302
Actual label: 1
Output voltages: [0.16241, 0.74881, 0.2377, 0.24777, 0.35352, 0.056484, 0.33904, 0.18161, 0.25222, 0.2619]
Predicted label: 1
Correct prediction
Energy consumption = 209.769948 pJ
sum error= 302
Actual label: 9
Output voltages: [0.4052, 0.15255, 0.20997, 0.2813, 0.31165, 0.18876, 0.24437, 0.2411, 0.26416, 0.66928]
Predicted label: 9
Correct prediction
Energy consumption = 198.428421 pJ
sum error= 302
Actual label: 2
Output voltages: [0.29853, 0.1848, 0.75515, 0.30809, 0.17272, 0.051286, 0.2551, 0.21367, 0.42669, 0.16154]
Predicted label: 2
Correct prediction
Energy consumption = 185.373543 pJ
sum error= 302
Actual label: 8
Output voltages: [0.18857, 0.26496, 0.20372, 0.38656, 0.080383, 0.24145, 0.16135, 0.17258, 0.73557, 0.29067]
Predicted label: 8
Correct prediction
Energy consumption = 197.842696 pJ
sum error= 302
Actual label: 7
Output voltages: [0.32723, 0.24709, 0.23343, 0.28804, 0.13974, 0.077353, 0.042726, 0.70403, 0.31493, 0.43448]
Predicted label: 7
Correct prediction
Energy consumption = 198.241365 pJ
sum error= 302
Actual label: 8
Output voltages: [0.20415, 0.1736, 0.20326, 0.29634, 0.080051, 0.36244, 0.2115, 0.14479, 0.74004, 0.23917]
Predicted label: 8
Correct prediction
Energy consumption = 195.397323 pJ
sum error= 302
Actual label: 2
Output voltages: [0.35307, 0.12952, 0.73947, 0.35778, 0.16186, 0.052386, 0.20394, 0.21888, 0.45449, 0.1553]
Predicted label: 2
Correct prediction
Energy consumption = 187.571873 pJ
sum error= 302
Actual label: 6
Output voltages: [0.33824, 0.24957, 0.31309, 0.088763, 0.33332, 0.324, 0.74837, 0.11832, 0.39343, 0.10628]
Predicted label: 6
Correct prediction
Energy consumption = 185.993713 pJ
sum error= 302
Actual label: 0
Output voltages: [0.70372, 0.16987, 0.23494, 0.15941, 0.18091, 0.15339, 0.45746, 0.17298, 0.29473, 0.29186]
Predicted label: 0
Correct prediction
Energy consumption = 180.663361 pJ
sum error= 302
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 994 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 994 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 994 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31461, 0.28953, 0.34171, 0.052079, 0.36431, 0.24356, 0.6854, 0.10658, 0.3901, 0.070659]
Predicted label: 6
Correct prediction
Energy consumption = 195.443981 pJ
sum error= 302
Actual label: 5
Output voltages: [0.37986, 0.044016, 0.23433, 0.42794, 0.085783, 0.52202, 0.37124, 0.15814, 0.50628, 0.20925]
Predicted label: 5
Correct prediction
Energy consumption = 195.975901 pJ
sum error= 302
Actual label: 3
Output voltages: [0.23985, 0.1884, 0.27573, 0.74903, 0.16028, 0.25433, 0.12716, 0.21097, 0.50362, 0.19854]
Predicted label: 3
Correct prediction
Energy consumption = 175.286447 pJ
sum error= 302
Actual label: 3
Output voltages: [0.22828, 0.1691, 0.34523, 0.68732, 0.076946, 0.15907, 0.12339, 0.16611, 0.55768, 0.17499]
Predicted label: 3
Correct prediction
Energy consumption = 178.439210 pJ
sum error= 302
Actual label: 3
Output voltages: [0.18609, 0.21092, 0.29346, 0.53811, 0.20831, 0.13803, 0.13422, 0.16198, 0.57878, 0.25079]
Predicted label: 8
Wrong prediction!
Energy consumption = 190.354507 pJ
sum error= 303
Actual label: 9
Output voltages: [0.24647, 0.1956, 0.15735, 0.22865, 0.5296, 0.1509, 0.06785, 0.21053, 0.28437, 0.56445]
Predicted label: 9
Correct prediction
Energy consumption = 189.936577 pJ
sum error= 303
Actual label: 1
Output voltages: [0.13958, 0.75642, 0.20348, 0.24833, 0.27448, 0.062562, 0.3215, 0.20347, 0.30001, 0.23886]
Predicted label: 1
Correct prediction
Energy consumption = 202.625263 pJ
sum error= 303
Actual label: 4
Output voltages: [0.30259, 0.22212, 0.30457, 0.17393, 0.67819, 0.074549, 0.50046, 0.22996, 0.18556, 0.11623]
Predicted label: 4
Correct prediction
Energy consumption = 193.324776 pJ
sum error= 303
Actual label: 0
Output voltages: [0.69958, 0.22456, 0.20504, 0.23795, 0.13168, 0.22629, 0.40754, 0.18086, 0.37317, 0.23119]
Predicted label: 0
Correct prediction
Energy consumption = 203.076760 pJ
sum error= 303
Actual label: 6
Output voltages: [0.31219, 0.25164, 0.29069, 0.1185, 0.32714, 0.32114, 0.74087, 0.083755, 0.3688, 0.13175]
Predicted label: 6
Correct prediction
Energy consumption = 192.972965 pJ
sum error= 303
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 995 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 995 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 995 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.25069, 0.74554, 0.2056, 0.1588, 0.29969, 0.10992, 0.31551, 0.14657, 0.26216, 0.27881]
Predicted label: 1
Correct prediction
Energy consumption = 208.232545 pJ
sum error= 303
Actual label: 0
Output voltages: [0.71205, 0.17482, 0.27856, 0.24487, 0.18305, 0.10968, 0.21708, 0.27504, 0.40492, 0.31745]
Predicted label: 0
Correct prediction
Energy consumption = 200.764635 pJ
sum error= 303
Actual label: 0
Output voltages: [0.71247, 0.2227, 0.33113, 0.15539, 0.16258, 0.10663, 0.37641, 0.14758, 0.32762, 0.27153]
Predicted label: 0
Correct prediction
Energy consumption = 187.632366 pJ
sum error= 303
Actual label: 6
Output voltages: [0.32472, 0.28536, 0.33524, 0.077869, 0.26515, 0.29644, 0.73209, 0.090643, 0.41998, 0.10173]
Predicted label: 6
Correct prediction
Energy consumption = 188.084014 pJ
sum error= 303
Actual label: 2
Output voltages: [0.32983, 0.11022, 0.65868, 0.44131, 0.080448, 0.042322, 0.22896, 0.27112, 0.51352, 0.16637]
Predicted label: 2
Correct prediction
Energy consumption = 190.235872 pJ
sum error= 303
Actual label: 1
Output voltages: [0.21806, 0.68484, 0.31152, 0.15032, 0.3036, 0.064371, 0.3127, 0.10914, 0.36402, 0.19008]
Predicted label: 1
Correct prediction
Energy consumption = 197.356594 pJ
sum error= 303
Actual label: 1
Output voltages: [0.2752, 0.67327, 0.33846, 0.13757, 0.47462, 0.06274, 0.32104, 0.097333, 0.26841, 0.29329]
Predicted label: 1
Correct prediction
Energy consumption = 195.755130 pJ
sum error= 303
Actual label: 7
Output voltages: [0.32261, 0.22977, 0.28261, 0.33944, 0.19233, 0.13256, 0.039506, 0.73631, 0.2399, 0.38123]
Predicted label: 7
Correct prediction
Energy consumption = 192.112391 pJ
sum error= 303
Actual label: 7
Output voltages: [0.2842, 0.33298, 0.37672, 0.2759, 0.11666, 0.047014, 0.04376, 0.74388, 0.32549, 0.33199]
Predicted label: 7
Correct prediction
Energy consumption = 188.745792 pJ
sum error= 303
Actual label: 8
Output voltages: [0.27558, 0.30135, 0.27553, 0.30703, 0.073178, 0.1561, 0.19151, 0.2487, 0.72782, 0.22855]
Predicted label: 8
Correct prediction
Energy consumption = 201.418652 pJ
sum error= 303
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 996 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 996 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 996 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.18484, 0.15352, 0.28704, 0.17143, 0.75361, 0.089125, 0.24894, 0.26997, 0.19959, 0.23562]
Predicted label: 4
Correct prediction
Energy consumption = 192.776620 pJ
sum error= 303
Actual label: 6
Output voltages: [0.26803, 0.21779, 0.25996, 0.12709, 0.36001, 0.34817, 0.74535, 0.094523, 0.38442, 0.097114]
Predicted label: 6
Correct prediction
Energy consumption = 193.283177 pJ
sum error= 303
Actual label: 0
Output voltages: [0.65099, 0.25622, 0.25192, 0.21902, 0.32075, 0.079799, 0.33934, 0.13249, 0.3941, 0.21929]
Predicted label: 0
Correct prediction
Energy consumption = 200.421141 pJ
sum error= 303
Actual label: 7
Output voltages: [0.40146, 0.15414, 0.1954, 0.41796, 0.11067, 0.21214, 0.050073, 0.69176, 0.28963, 0.39594]
Predicted label: 7
Correct prediction
Energy consumption = 193.023639 pJ
sum error= 303
Actual label: 0
Output voltages: [0.66981, 0.22982, 0.35327, 0.20913, 0.16408, 0.061967, 0.39932, 0.17982, 0.39303, 0.18536]
Predicted label: 0
Correct prediction
Energy consumption = 192.666303 pJ
sum error= 303
Actual label: 3
Output voltages: [0.33223, 0.15194, 0.2631, 0.74696, 0.18554, 0.30737, 0.11502, 0.15736, 0.48408, 0.26468]
Predicted label: 3
Correct prediction
Energy consumption = 193.757306 pJ
sum error= 303
Actual label: 6
Output voltages: [0.32646, 0.20442, 0.30983, 0.053797, 0.36128, 0.28004, 0.72287, 0.090028, 0.33295, 0.098192]
Predicted label: 6
Correct prediction
Energy consumption = 189.495597 pJ
sum error= 303
Actual label: 8
Output voltages: [0.27985, 0.19771, 0.22963, 0.38402, 0.064761, 0.298, 0.18237, 0.096242, 0.7392, 0.22309]
Predicted label: 8
Correct prediction
Energy consumption = 193.703148 pJ
sum error= 303
Actual label: 7
Output voltages: [0.31964, 0.34425, 0.36711, 0.31612, 0.16692, 0.046854, 0.048172, 0.74931, 0.23258, 0.30806]
Predicted label: 7
Correct prediction
Energy consumption = 195.281916 pJ
sum error= 303
Actual label: 1
Output voltages: [0.26703, 0.74555, 0.18241, 0.22513, 0.42339, 0.11433, 0.33081, 0.22886, 0.18812, 0.2844]
Predicted label: 1
Correct prediction
Energy consumption = 200.051064 pJ
sum error= 303
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 997 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 997 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 997 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.30738, 0.16516, 0.091862, 0.37973, 0.14314, 0.62599, 0.46181, 0.055591, 0.35381, 0.17076]
Predicted label: 5
Correct prediction
Energy consumption = 200.939934 pJ
sum error= 303
Actual label: 2
Output voltages: [0.33014, 0.17584, 0.74994, 0.30122, 0.18899, 0.038006, 0.23565, 0.30133, 0.41413, 0.19637]
Predicted label: 2
Correct prediction
Energy consumption = 190.174657 pJ
sum error= 303
Actual label: 4
Output voltages: [0.16384, 0.17384, 0.26613, 0.16183, 0.74164, 0.087098, 0.24338, 0.19428, 0.24258, 0.24388]
Predicted label: 4
Correct prediction
Energy consumption = 196.116110 pJ
sum error= 303
Actual label: 9
Output voltages: [0.33692, 0.13358, 0.23447, 0.25839, 0.39254, 0.12912, 0.063405, 0.20293, 0.34666, 0.60876]
Predicted label: 9
Correct prediction
Energy consumption = 181.296555 pJ
sum error= 303
Actual label: 4
Output voltages: [0.17506, 0.19012, 0.31815, 0.26075, 0.72913, 0.050423, 0.23709, 0.25694, 0.18442, 0.21011]
Predicted label: 4
Correct prediction
Energy consumption = 189.859259 pJ
sum error= 303
Actual label: 3
Output voltages: [0.29344, 0.13784, 0.5266, 0.58626, 0.075187, 0.15746, 0.11546, 0.15287, 0.57764, 0.16395]
Predicted label: 3
Correct prediction
Energy consumption = 191.803220 pJ
sum error= 303
Actual label: 6
Output voltages: [0.29902, 0.18519, 0.25938, 0.10305, 0.40569, 0.29255, 0.70876, 0.09669, 0.39643, 0.12676]
Predicted label: 6
Correct prediction
Energy consumption = 193.223760 pJ
sum error= 303
Actual label: 4
Output voltages: [0.25588, 0.12658, 0.3226, 0.16576, 0.74227, 0.055376, 0.30374, 0.23203, 0.25519, 0.16093]
Predicted label: 4
Correct prediction
Energy consumption = 187.390576 pJ
sum error= 303
Actual label: 1
Output voltages: [0.23092, 0.67562, 0.32532, 0.10686, 0.42864, 0.044578, 0.23805, 0.21968, 0.26244, 0.30509]
Predicted label: 1
Correct prediction
Energy consumption = 200.363952 pJ
sum error= 303
Actual label: 7
Output voltages: [0.4276, 0.20277, 0.19816, 0.32377, 0.21435, 0.20592, 0.050211, 0.73665, 0.27845, 0.35845]
Predicted label: 7
Correct prediction
Energy consumption = 189.935627 pJ
sum error= 303
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 998 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 998 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 998 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.30214, 0.11757, 0.67092, 0.39274, 0.073261, 0.046618, 0.18382, 0.30067, 0.52388, 0.10299]
Predicted label: 2
Correct prediction
Energy consumption = 192.229808 pJ
sum error= 303
Actual label: 6
Output voltages: [0.32288, 0.23408, 0.35387, 0.1145, 0.33452, 0.27269, 0.69745, 0.12192, 0.39532, 0.067282]
Predicted label: 6
Correct prediction
Energy consumption = 191.530507 pJ
sum error= 303
Actual label: 5
Output voltages: [0.25176, 0.16322, 0.23237, 0.28337, 0.21627, 0.47226, 0.56184, 0.065093, 0.31344, 0.15933]
Predicted label: 6
Wrong prediction!
Energy consumption = 203.381672 pJ
sum error= 304
Actual label: 0
Output voltages: [0.7406, 0.24381, 0.25642, 0.19254, 0.1416, 0.22071, 0.37612, 0.14473, 0.31699, 0.25109]
Predicted label: 0
Correct prediction
Energy consumption = 189.639639 pJ
sum error= 304
Actual label: 1
Output voltages: [0.22886, 0.75343, 0.27506, 0.30066, 0.32425, 0.061634, 0.361, 0.12917, 0.25772, 0.23773]
Predicted label: 1
Correct prediction
Energy consumption = 215.028336 pJ
sum error= 304
Actual label: 2
Output voltages: [0.37051, 0.3766, 0.69516, 0.31564, 0.11537, 0.025697, 0.20572, 0.30496, 0.35384, 0.21604]
Predicted label: 2
Correct prediction
Energy consumption = 193.803856 pJ
sum error= 304
Actual label: 3
Output voltages: [0.26316, 0.22305, 0.28307, 0.73591, 0.15322, 0.15229, 0.13188, 0.14231, 0.50584, 0.25285]
Predicted label: 3
Correct prediction
Energy consumption = 190.489175 pJ
sum error= 304
Actual label: 4
Output voltages: [0.11104, 0.15238, 0.26178, 0.26069, 0.73894, 0.047482, 0.22311, 0.2415, 0.26544, 0.19602]
Predicted label: 4
Correct prediction
Energy consumption = 194.216198 pJ
sum error= 304
Actual label: 5
Output voltages: [0.30657, 0.072569, 0.06214, 0.43244, 0.13539, 0.71298, 0.28075, 0.17021, 0.58576, 0.12652]
Predicted label: 5
Correct prediction
Energy consumption = 192.852458 pJ
sum error= 304
Actual label: 6
Output voltages: [0.30408, 0.20401, 0.2411, 0.15332, 0.30365, 0.4094, 0.72576, 0.083963, 0.46568, 0.14856]
Predicted label: 6
Correct prediction
Energy consumption = 182.966163 pJ
sum error= 304
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 999 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 999 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 999 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26715, 0.34589, 0.38654, 0.25511, 0.12864, 0.035049, 0.046155, 0.74119, 0.35968, 0.28856]
Predicted label: 7
Correct prediction
Energy consumption = 202.200581 pJ
sum error= 304
Actual label: 8
Output voltages: [0.26692, 0.15653, 0.2897, 0.3633, 0.098529, 0.33687, 0.22405, 0.13778, 0.74751, 0.22084]
Predicted label: 8
Correct prediction
Energy consumption = 192.235545 pJ
sum error= 304
Actual label: 9
Output voltages: [0.27845, 0.1414, 0.13491, 0.26595, 0.46543, 0.20367, 0.15877, 0.2525, 0.31592, 0.57988]
Predicted label: 9
Correct prediction
Energy consumption = 197.596354 pJ
sum error= 304
Actual label: 0
Output voltages: [0.64941, 0.20346, 0.29762, 0.16364, 0.18051, 0.10108, 0.3779, 0.12558, 0.43154, 0.26805]
Predicted label: 0
Correct prediction
Energy consumption = 185.912068 pJ
sum error= 304
Actual label: 1
Output voltages: [0.19445, 0.75192, 0.33751, 0.26934, 0.31695, 0.056393, 0.36594, 0.14005, 0.23431, 0.24914]
Predicted label: 1
Correct prediction
Energy consumption = 210.804850 pJ
sum error= 304
Actual label: 2
Output voltages: [0.28565, 0.32735, 0.72748, 0.32263, 0.11655, 0.029947, 0.2343, 0.27841, 0.38209, 0.17877]
Predicted label: 2
Correct prediction
Energy consumption = 186.790490 pJ
sum error= 304
Actual label: 3
Output voltages: [0.41812, 0.17805, 0.32195, 0.75013, 0.1342, 0.19001, 0.18532, 0.17186, 0.35777, 0.23258]
Predicted label: 3
Correct prediction
Energy consumption = 193.816699 pJ
sum error= 304
Actual label: 4
Output voltages: [0.12321, 0.152, 0.19055, 0.15464, 0.74829, 0.092811, 0.2743, 0.28917, 0.30684, 0.14705]
Predicted label: 4
Correct prediction
Energy consumption = 190.204089 pJ
sum error= 304
Actual label: 5
Output voltages: [0.33355, 0.058506, 0.058541, 0.34158, 0.2192, 0.69956, 0.36136, 0.13362, 0.57172, 0.13559]
Predicted label: 5
Correct prediction
Energy consumption = 194.080021 pJ
sum error= 304
Actual label: 6
Output voltages: [0.27357, 0.16316, 0.35831, 0.064751, 0.32853, 0.27853, 0.73329, 0.060022, 0.37105, 0.12301]
Predicted label: 6
Correct prediction
Energy consumption = 177.250546 pJ
sum error= 304
End-to-End CSV Created: 4_30_2025_full_run.csv
Total area = 3401.58464 m^2
Task completed!
Total error= 304
error rate = 0.030400
accuracy = 96.960000%
Program Execution Time = 5 hours 14 minutes 42 seconds
real	314m43.401s
user	329m44.341s
sys	16m48.683s
